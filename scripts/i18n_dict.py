i18n_dict={
'## TensorFlow':'',
' pip install tensorflow':'',
'## Modules':'',
'## Classes':'',
'## Functions':'',
'## Other Members':'',
'## AggregationMethod 类':'',
'列出用于组合渐变的聚合方法的类。':'',
'### Aliases:':'',
'Computing partial derivatives can require aggregating gradient contributions. This class lists the various methods that can be used to combine gradients in the graph.':'',
'The following aggregation methods are part of the stable API for aggregating gradients:':'',
'The following aggregation methods are experimental and may not be supported in future releases:':'',
'## Class Members':'',
'## Class AggregationMethod':'',
'A class listing aggregation methods used to combine gradients.':'',
'Returns the indices of a tensor that give its sorted order along an axis.':'',
'#### Usage:':'',
'#### Args:':'',
'#### Returns:':'',
'An int32 Tensor with the same shape as values. The indices that would sort each slice of the given values along the given axis.':'',
'#### Raises:':'',
'A Tensor. Has the same type as input.':'',
'Bitcasts a tensor from one type to another without copying data.':'',
'#### Example 1:':'',
'Example 2:':'',
'Example 3:':'',
'A Tensor of type type.':'',
'Apply boolean mask to tensor.':'',
'#### Examples:':'',
'Computes the shape of a broadcast given symbolic shapes.':'',
'This is useful when validating the result of a broadcasting operation when the tensors do not have statically known shapes.':'',
'A rank 1 integer Tensor representing the broadcasted shape.':'',
'Computes the shape of a broadcast given known shapes.':'',
'This is useful when validating the result of a broadcasting operation when the tensors have statically known shapes.':'',
'A TensorShape representing the broadcasted shape.':'',
'Broadcast an array for a compatible shape.':'',
'Create a case operation.':'',
'Example 1:':'',
'#### Pseudocode:':'',
'#### Expressions:':'',
'#### V2 Compatibility':'',
'Clips values of multiple tensors by the ratio of the sum of their norms.':'',
'### Used in the guide:':'',
'This operation is typically used to clip gradients before applying them with an optimizer.':'',
'A clipped Tensor or IndexedSlices.':'',
'Clips tensor values to a specified min and max.':'',
'### Used in the tutorials:':'',
'#### For example:':'',
'Concatenates tensors along one dimension.':'',
'would produce:':'',
'can be rewritten as':'',
'A Tensor resulting from concatenation of the input tensors.':'',
'#### Example:':'',
'Creates a constant tensor.':'',
'A Constant Tensor.':'',
'Initializer that generates tensors with constant values.':'',
'    &gt;&gt;&gt; import tensorflow as tf':'',
'  ':'',
'Initialize self. See help(type(self)) for accurate signature.':'',
'## Methods':'',
'Returns a tensor object initialized as specified by the initializer.':'',
'    config':'',
'Instantiates an initializer from a configuration dictionary.':'',
'An Initializer instance.':'',
'A context manager that specifies control dependencies for all operations constructed within the context.':'',
'Converts the given value to a Tensor.':'',
'A Tensor based on value.':'',
'## Class CriticalSection':'',
'Critical section.':'',
'A CriticalSection object is a resource in the graph which executes subgraphs in serial order. A common example of a subgraph one may wish to run exclusively is the one given by the following function:':'',
'The solution is to ensure any access to the underlying resource v is only processed through a critical section:':'',
'NOTES':'',
'Creates a critical section.':'',
'## Properties':'',
'### name':'',
'### execute':'',
'Execute function fn() inside the critical section.':'',
'The tensors returned from fn().':'',
'Decorator to define a function with a custom gradient.':'',
'The gradient expression can be analytically simplified to provide numerical stability:':'',
'Specifies the device for ops created/executed in this context.':'',
'A context manager that specifies the default device to use for newly created ops.':'',
'## Class DeviceSpec':'',
'Represents a (possibly partial) specification for a TensorFlow device.':'',
'Create a new DeviceSpec object.':'',
'### job':'',
'### replica':'',
'### task':'',
'same value for all the internal fields.':'',
'Return True if other is also a DeviceSpec instance and has same value as the current instance. Return False otherwise.':'',
'    spec':'',
'Construct a DeviceSpec from a string.':'',
'A DeviceSpec.':'',
'Returns a new DeviceSpec which incorporates dev.':'',
'is equivalent to:':'',
'A new DeviceSpec which combines self and dev':'',
'Parse a DeviceSpec name into its components.':'',
'Recommended:':'',
'Will work in 1.x and 2.x (though deprecated in 2.x):':'',
'Will NOT work in 2.x:':'',
'The DeviceSpec.':'',
'### replace':'',
'Convenience method for making a new DeviceSpec by overriding fields.':'',
'#### For instance:':'',
'A DeviceSpec with the fields specified in kwargs overridden.':'',
'Return a string representation of this DeviceSpec.':'',
'a string of the form /job:/replica:/task:/device::.':'',
'data.shape must start with partitions.shape.':'',
'Interleave the values from the data tensors into a single tensor.':'',
'Builds a merged tensor such that':'',
'A Tensor. Has the same type as data.':'',
'Computes the Levenshtein distance between sequences.':'',
'This operation would return the following:':'',
'A generalized contraction between tensors of arbitrary dimension.':'',
'The corresponding equation is:':'',
'Many common operations can be expressed in this way. For example:':'',
'the input shapes are inconsistent along a particular axis.':'',
'Updates the shape of a tensor and checks at runtime that the shape holds.':'',
'Returns True if the current thread has eager execution enabled.':'',
'Inserts a dimension of 1 into a tensor\'s shape.':'',
'#### Other examples:':'',
'This operation requires that:':'',
'Creates a tensor filled with a scalar value.':'',
'This operation creates a tensor of shape dims and fills it with value.':'',
'A Tensor. Has the same type as value.':'',
'Generates fingerprint values.':'',
'Generates fingerprint values of data.':'',
'Creates a callable TensorFlow graph from a Python function.':'',
'Example Usage':'',
'function can be applied to methods of an object. For example:':'',
'Input Signatures':'',
'Tracing and staging':'',
'Retracing':'',
'Gather slices from params axis axis according to indices.':'',
'Where':'',
'The shape of the output tensor is:':'',
'A Tensor. Has the same type as params.':'',
'Gather slices from params into a Tensor with shape specified by indices.':'',
'The last dimension of indices can be at most the rank of params:':'',
'Some examples below.':'',
'Simple indexing into a matrix:':'',
'Slice indexing into a matrix:':'',
'Batched indexing into a matrix:':'',
'Batched slice indexing into a matrix:':'',
'Examples with batched \'params\' and \'indices\':':'',
'Return TF logger instance.':'',
'Constructs symbolic derivatives of sum of ys w.r.t. x in xs.':'',
'gradients() adds ops to the graph to output the derivatives of ys with respect to xs. It returns a list of Tensor of length len(xs) where each tensor is the sum(dy/dx) for y in ys.':'',
'A list of sum(dy/dx) for each x in xs.':'',
'## Class GradientTape':'',
'Record operations for automatic differentiation.':'',
'Operations are recorded if they are executed within this context manager and at least one of their inputs is being "watched".':'',
'del g  # Drop the reference to the tape':'',
'Note that only tensors with real or complex dtypes are differentiable.':'',
'Creates a new GradientTape.':'',
'Enters a context inside which operations are recorded on this tape.':'',
'    traceback':'',
'#### Example usage:':'',
'### gradient':'',
'Computes the gradient using operations recorded in context of this tape.':'',
'### jacobian':'',
'Computes the jacobian using operations recorded in context of this tape.':'',
'### reset':'',
'Clears all information stored in this tape.':'',
'Temporarily stops recording operations on this tape.':'',
'Operations executed while this context manager is active will not be recorded on the tape. This is useful for reducing the memory used by tracing all computations.':'',
'#### Yields:':'',
'### watch':'',
'Ensures that tensor is being traced by this tape.':'',
'Returns variables watched by this tape in order of construction.':'',
'A function h(x) which returns the same values as f(x) and whose gradients are the same as those of an identity function.':'',
'## Class Graph':'',
'Returns True iff this graph represents a function.':'',
'### collections':'',
'Returns the names of the collections known to this graph.':'',
'### finalized':'',
'True if this graph has been finalized.':'',
'The GraphDef version information of this graph.':'',
'A VersionDef.':'',
'### seed':'',
'### version':'',
'Returns a version number that increases as ops are added to the graph.':'',
'An integer version that increases as ops are added to the graph.':'',
'    value':'',
'Stores value in the collection with the given name.':'',
'Stores value in the collections given by names.':'',
'Returns a context manager that makes this Graph the default graph.':'',
'The following code examples are equivalent:':'',
'If eager execution is enabled ops created under this context manager will be added to the graph instead of executed eagerly.':'',
'A context manager for using this graph as the default graph.':'',
'Returns a serialized GraphDef representation of this graph.':'',
'This function is the canonical way to get/validate an object of one of the allowed types from an external argument reference in the Session API.':'',
'This method may be called concurrently from multiple threads.':'',
'The Tensor or Operation in the Graph corresponding to obj.':'',
'Clears all values in a collection.':'',
'Returns a context manager that specifies an op to colocate with.':'',
'NOTE Using a colocation scope resets any existing device constraints.':'',
'A context manager that specifies the op with which to colocate newly created ops.':'',
'### container':'',
'Returns a context manager that specifies the resource container to use.':'',
'Returns a context manager that specifies control dependencies.':'',
'You can pass None to clear the control dependencies:':'',
'N.B. The control dependencies context applies only to ops that are constructed within the context. Merely using an op or tensor in the context does not add a control dependency. The following example illustrates this point:':'',
'This is because evaluating the gradient graph does not require evaluating the constant(1) op created in the forward pass.':'',
'An Operation object.':'',
'### device':'',
'Returns a context manager that specifies the default device to use.':'',
'### finalize':'',
'Returns a list of collections used in this graph.':'',
'Returns a list of values in the collection with the given name.':'',
'Returns the current name scope.':'',
'would print the string scope1/scope2.':'',
'A string representing the current name scope.':'',
'Returns the Operation with the given name.':'',
'The Operation with the given name.':'',
'Return the list of operations in the graph.':'',
'A list of Operations.':'',
'Returns the Tensor with the given name.':'',
'The Tensor with the given name.':'',
'EXPERIMENTAL: A context manager for overriding gradient functions.':'',
'This context manager can be used to override the gradient function that will be used for ops within the scope of the context.':'',
'A context manager that sets the alternative op type to be used for one or more ops created in that context.':'',
'Returns True if and only if tensor is feedable.':'',
'Returns a context manager that creates hierarchical names for operations.':'',
'The name argument will be interpreted as follows:':'',
'NOTE: This constructor validates the given name. Valid scope names match one of the following regular expressions:':'',
'A context manager that installs name as a new name scope.':'',
'Marks the given tensor as unfeedable in this graph.':'',
'Marks the given op as unfetchable in this graph.':'',
'Return a unique operation name for name.':'',
'Create an op that groups multiple operations.':'',
'An Operation that executes all its inputs.':'',
'Gives a guarantee to the TF runtime that the input tensor is a constant.':'',
'The runtime is then free to make optimizations based on this.':'',
'Only accepts value typed tensors as inputs and rejects resource variable handles as input.':'',
'Returns the input tensor without modification.':'',
'Constructs the Hessian of sum of ys with respect to x in xs.':'',
'hessians() adds ops to the graph to output the Hessian matrix of ys with respect to xs. It returns a list of Tensor of length len(xs) where each tensor is the Hessian of sum(ys).':'',
'A list of Hessian matrices of sum(ys) for each x in xs.':'',
'Return histogram of values.':'',
'Bins the given values for use in a histogram.':'',
'A Tensor holding the indices of the binned values whose shape matches values.':'',
'Return a tensor with the same shape and contents as input.':'',
'Returns a list of tensors with the same shapes and contents as the input':'',
'tensors.':'',
'A list of Tensor objects. Has the same type as input.':'',
'## Class IndexedSlices':'',
'A sparse representation of a set of tensor slices at given indices.':'',
'This class is a simple wrapper for a pair of Tensor objects:':'',
'The dense tensor dense represented by an IndexedSlices slices has':'',
'Creates an IndexedSlices.':'',
'### dtype':'',
'The DType of elements in this tensor.':'',
'### graph':'',
'### indices':'',
'The name of this IndexedSlices.':'',
'### op':'',
'The Operation that produces values as an output.':'',
'### values':'',
'A Tensor containing the values of the slices.':'',
'### consumers':'',
'## Class IndexedSlicesSpec':'',
'Returns the most specific TypeSpec compatible with self and other.':'',
'(3) The gradient tape is paused while the scope is active.':'',
'Generates values in an interval.':'',
'A Tensor. Has the same type as start.':'',
'Loads a TensorFlow plugin.':'',
'A python module containing the Python wrappers for Ops defined in the plugin.':'',
'Create a numpy ndarray from a tensor.':'',
'Create a numpy ndarray with the same shape and data as the tensor.':'',
'A numpy array with the tensor contents.':'',
'Create a TensorProto.':'',
'instead.':'',
'#### Notes:':'',
'## Class Module':'',
'Base neural network module class.':'',
'You can use the Dense layer as you would expect:':'',
' d.variables':'',
'Returns the name of this module as passed or determined in the ctor.':'',
'### submodules':'',
'A sequence of all submodules.':'',
'Sequence of variables owned by this module and it\'s submodules.':'',
'A sequence of variables for the current module (sorted by attribute name) followed by variables from all submodules recursively (breadth first).':'',
'### variables':'',
'Decorator to automatically enter the module name scope.':'',
'mod.w':'',
'The original method wrapped such that it enters the module\'s name scope.':'',
'A context manager for use when defining a Python op.':'',
'Initialize the context manager.':'',
'Start the scope block.':'',
'The scope name.':'',
'Batches the computation done by the decorated function.':'',
'Assumes that all arguments of the decorated function are Tensors which will be batched along their first dimension.':'',
'SparseTensor is not supported. The return value of the decorated function must be a Tensor or a list/tuple of Tensors.':'',
'The decorated function will return the unbatched computation output Tensors.':'',
'#### Numpy Compatibility':'',
'Does nothing. Only useful as a placeholder for control edges.':'',
'The created Operation.':'',
'Wraps a python function and uses it as a TensorFlow op.':'',
'A list of Tensor or a single Tensor which func computes.':'',
'Creates a tensor with all elements set to 1.':'',
'This operation returns a tensor of type dtype with shape shape and all elements set to 1.':'',
'A Tensor with all elements set to 1.':'',
'Initializer that generates tensors initialized to 1.':'',
'Creates a tensor with all elements set to one.':'',
'A Tensor with all elements set to one.':'',
'If indices is a scalar the output shape will be a vector of length depth':'',
'## Class Operation':'',
'Represents a graph node that performs computation on tensors.':'',
'Creates an Operation.':'',
'The Operation objects on which this op has a control dependency.':'',
'A list of Operation objects.':'',
'The Graph that contains this operation.':'',
'### inputs':'',
'The list of Tensor objects representing the data inputs of this op.':'',
'The full name of this operation.':'',
'Returns the NodeDef representation of this operation.':'',
'Returns the OpDef proto that represents the type of this op.':'',
'### outputs':'',
'The list of Tensor objects representing the outputs of this op.':'',
'### traceback':'',
'Returns the call stack from when this operation was constructed.':'',
'Same as traceback but includes start line of function definition.':'',
'### type':'',
'The type of the op (e.g. "MatMul").':'',
'Returns the list of colocation groups of the op.':'',
'Returns the value of the attr of this op with the given name.':'',
'### run':'',
'Runs this operation in a Session.':'',
'Calling this method will execute all preceding operations that produce the inputs needed for this operation.':'',
'DEPRECATED: Use outputs.':'',
'## Class OptionalSpec':'',
'Represents an optional potentially containing a structured value.':'',
'The Python type for values that are compatible with this TypeSpec.':'',
'Pads a tensor.':'',
'The padded size of each dimension D of the output is:':'',
'A Tensor. Has the same type as tensor.':'',
'Requires that the shape of inputs be known at graph construction time.':'',
'This is the opposite of unstack. The numpy equivalent is':'',
'Print the specified inputs.':'',
'Changing the input separator:':'',
'Compatibility usage in TF 1.x graphs:':'',
'#### Python2 Compatibility':'',
'Wraps a python function into a TensorFlow op that executes it eagerly.':'',
'A list of Tensor or a single Tensor which func computes; an empty list if func returns None.':'',
'## Class RaggedTensor':'',
'Represents a ragged tensor.':'',
'### Potentially Ragged Tensors':'',
'### Documenting RaggedTensor Shapes':'',
'### Component Tensors':'',
'### Multiple Ragged Dimensions':'',
'RaggedTensors with multiple ragged dimensions can be defined by using a nested RaggedTensor for the values tensor. Each nested RaggedTensor adds a single ragged dimension.':'',
'### Uniform Inner Dimensions':'',
'RaggedTensors with uniform inner dimensions can be defined by using a multidimensional Tensor for values.':'',
'### RaggedTensor Shape Restrictions':'',
'The shape of a RaggedTensor is currently restricted to have the following form:':'',
'This restriction follows from the fact that each nested RaggedTensor replaces the uniform outermost dimension of its values with a uniform dimension followed by a ragged dimension.':'',
'Creates a RaggedTensor with a specified partitioning for values.':'',
'The DType of values in this tensor.':'',
'The innermost values tensor for this ragged tensor.':'',
'A Tensor.':'',
'The number of ragged dimensions in this ragged tensor.':'',
'A Python int indicating the number of ragged dimensions in this ragged tensor. The outermost dimension is not considered ragged.':'',
'### shape':'',
'The statically known shape of this ragged tensor.':'',
'A TensorShape containing the statically known shape of this ragged tensor. Ragged dimensions have a size of None.':'',
'The concatenated rows for this ragged tensor.':'',
'rt.values is a potentially ragged tensor formed by flattening the two outermost dimensions of rt into a single dimension.':'',
'A potentially ragged tensor.':'',
'Computes the absolute value of a tensor.':'',
'A Tensor. Has the same type as x.':'',
'A Tensor of type bool.':'',
'Dummy method to prevent a RaggedTensor from being used as a Python bool.':'',
'NOTE: Prefer using the Tensor division operator or tf.divide which obey Python 3 division operator semantics.':'',
'x / y returns the quotient of x and y.':'',
'x / y rounded down.':'',
'Returns the specified piece of this RaggedTensor.':'',
'Scalar `int`eger `Tensor`':'',
'A Tensor or RaggedTensor object. Values that include at least one ragged dimension are returned as RaggedTensor. Values that include no ragged dimensions are returned as Tensor. See above for examples of expressions that return Tensors vs RaggedTensors.':'',
'Computes the power of one value to another.':'',
'Divides x / y elementwise (using Python 3 division operator semantics).':'',
'NOTE: Prefer using the Tensor operator or tf.divide which obey Python division operator semantics.':'',
'x / y evaluated in floating point.':'',
'Logical XOR function.':'',
'A Tensor of type bool with the same size as that of x or y.':'',
'Returns the tight bounding box shape for this RaggedTensor.':'',
'#### Equivalent to:':'',
'The returned RaggedTensor corresponds with the python list defined by:':'',
' #### Args:':'',
'  higher.':'',
'  will be used as nested row lengths to construct a ragged tensor with':'',
'  multiple ragged dimensions.':'',
'  consisting entirely of `padding` will be excluded from the returned':'',
'  RaggedTensor.  `padding` is a `Tensor` with the same dtype as `tensor`':'',
'### nrows':'',
'Returns the number of rows in this ragged tensor.':'',
'Returns the lengths of the rows in this ragged tensor.':'',
'Returns the limit indices for rows in this ragged tensor.':'',
'Returns the start indices for rows in this ragged tensor.':'',
'Returns a nested Python list with the values for this RaggedTensor.':'',
'Requires that rt was constructed in eager execution mode.':'',
'A nested Python list.':'',
'A SparseTensor with the same values as self.':'',
'Returns the row indices for the values in this ragged tensor.':'',
'## Class RaggedTensorSpec':'',
'Initializer that generates tensors with a normal distribution.':'',
'Initializer that generates tensors with a uniform distribution.':'',
'Creates a sequence of numbers.':'',
'Creates a sequence of numbers that begins at start and extends by increments of delta up to but not including limit.':'',
'The dtype of the resulting tensor is inferred from the inputs unless it is provided explicitly.':'',
'Equivalent to np.arange':'',
'Returns the rank of a tensor.':'',
'A Tensor of type int32.':'',
'Equivalent to np.ndim':'',
'Computes the "logical and" of elements across dimensions of a tensor.':'',
'The reduced tensor.':'',
'Equivalent to np.all':'',
'## Class RegisterGradient':'',
'A decorator for registering the gradient function for an op type.':'',
'The conversion function must have the following signature:':'',
'Raises: ValueError if called with incompatible shapes.':'',
'Reshapes a tensor.':'',
'Reverses specific dimensions of a tensor.':'',
'Reverses variable length slices.':'',
'Rolls the elements of a tensor along an axis.':'',
'The elements are shifted positively (towards larger indices) by the offset of shift along the dimension of axis. Negative shift values will shift elements in the opposite direction. Elements that roll passed the last position will wrap around to the first and vice versa. Multiple shifts along multiple axes may be specified.':'',
'Scatter updates into a new tensor according to indices.':'',
'indices is an integer tensor containing indices into a new tensor of shape shape. The last dimension of indices can be at most the rank of shape:':'',
'The resulting tensor would look like this:':'',
'A Tensor. Has the same type as updates.':'',
'Searches input tensor for values on the innermost dimension.':'',
'Returns a mask tensor representing the first N positions of each cell.':'',
'Returns the shape of a tensor.':'',
'Returns shape of tensors.':'',
'Extracts a slice from a tensor.':'',
'Sorts a tensor.':'',
'Th`i`s` `operat`i`on` ``i`s` `equ`i`valent` `to` `the` `follow`i`ng` `steps:':'',
'Some` `examples:':'',
'## Class SparseTensorSpec':'',
'Splits a tensor into sub tensors.':'',
'Removes dimensions of size 1 from the shape of a tensor.':'',
'Stops gradient computation.':'',
'This is useful any time you want to compute a value with TensorFlow but need to pretend that the value was a constant. Some examples include:':'',
'Extracts a strided slice of a tensor (generalized python array indexing).':'',
'A Tensor the same type as input.':'',
'Example:':'',
'or':'',
'## Class Tensor':'',
'Represents one of the outputs of an Operation.':'',
'This class has two primary purposes:':'',
'    dtype':'',
'Creates a new Tensor.':'',
'The Graph that contains this tensor.':'',
'The string name of this tensor.':'',
'The Operation that produces this tensor as an output.':'',
'Returns the TensorShape that represents the shape of this tensor.':'',
'A TensorShape representing the shape of this tensor.':'',
'The index of this tensor in the outputs of its Operation.':'',
'    y':'',
'Dummy method to prevent a tensor from being used as a Python bool.':'',
'Divide two values using Python 2 semantics.':'',
'Used for Tensor.div.':'',
'Overload for Tensor.getitem.':'',
'#### Some useful examples:':'',
'Either matrix can be transposed or adjointed (conjugated and transposed) on the fly by setting one of the corresponding flag to True. These are False by default.':'',
'Dispatches cwise mul for "DenseDense" and "DenseSparse".':'',
'    x':'',
'Returns a list of Operations that consume this tensor.':'',
'### eval':'',
'Evaluates this tensor in a Session.':'',
'Calling this method will execute all preceding operations that produce the inputs needed for the operation that produces this tensor.':'',
'A numpy array corresponding to the value of this tensor.':'',
'Returns a hashable reference object to this Tensor.':'',
'Alias of Tensor.shape.':'',
'Updates the shape of this tensor.':'',
'## Class TensorArray':'',
'Construct a new TensorArray or wrap an existing TensorArray handle.':'',
'A note about the parameter name:':'',
'The data type of this TensorArray.':'',
'Python bool; if True the TensorArray can grow dynamically.':'',
'### flow':'',
'The flow Tensor forcing ops leading to this TensorArray state.':'',
'### handle':'',
'The reference to the TensorArray.':'',
'### close':'',
'Close the current TensorArray.':'',
'### concat':'',
'Return the values in the TensorArray as a concatenated Tensor.':'',
'All the tensors in the TensorArray concatenated into one tensor.':'',
'### gather':'',
'Return selected values in the TensorArray as a packed Tensor.':'',
'All of selected values must have been written and their shapes must all match.':'',
'### grad':'',
'### identity':'',
'Returns a TensorArray with the same content and properties.':'',
'### read':'',
'Read the value at location index in the TensorArray.':'',
'The tensor at index index.':'',
'### scatter':'',
'Scatter the values of a Tensor in specific indices of a TensorArray.':'',
'Returns: A new TensorArray object with flow that ensures the scatter occurs. Use this object all for subsequent operations.':'',
'Raises: ValueError: if the shape inference fails.':'',
'### size':'',
'Return the size of the TensorArray.':'',
'### split':'',
'Split the values of a Tensor into the TensorArray.':'',
'Returns: A new TensorArray object with flow that ensures the split occurs. Use this object all for subsequent operations.':'',
'### stack':'',
'Return the values in the TensorArray as a stacked Tensor.':'',
'All the tensors in the TensorArray stacked into one tensor.':'',
'### unstack':'',
'Unstack the values of a Tensor in the TensorArray.':'',
'Returns: A new TensorArray object with flow that ensures the unstack occurs. Use this object all for subsequent operations.':'',
'### write':'',
'Write value into index index of the TensorArray.':'',
'A new TensorArray object with flow that ensures the write occurs. Use this object all for subsequent operations.':'',
'## Class TensorArraySpec':'',
'Tensor contraction of a and b along specified axes.':'',
'Example 3: Suppose that':'',
'whose entry corresponding to the indices':'',
'is given by:':'',
'A Tensor with the same type as a.':'',
'## Class TensorShape':'',
'Represents the shape of a Tensor.':'',
'Creates a new TensorShape with the given dimensions.':'',
'### dims':'',
'### ndims':'',
'Deprecated accessor for rank.':'',
'### rank':'',
'Returns True if self is equivalent to other.':'',
'Returns True if self is known to be different from other.':'',
'Returns a list of integers or None for each dimension.':'',
'A list of integers or None for each dimension.':'',
'Returns this shape as a TensorShapeProto.':'',
'Raises an exception if self is not compatible with the given rank.':'',
'Raises exception if self and other do not represent the same shape.':'',
'This method can be used to assert that there exists a shape that both self and other represent.':'',
'Raises an exception if self is not fully defined in every dimension.':'',
'Raises an exception if self and other do not have compatible ranks.':'',
'### concatenate':'',
'Returns the concatenation of the dimension in self and other.':'',
'A TensorShape whose dimensions are the concatenation of the dimensions in self and other.':'',
'Returns True iff self is compatible with other.':'',
'True iff self is compatible with other.':'',
'Returns True iff self is fully defined in every dimension.':'',
'Returns a TensorShape combining the information in self and other.':'',
'A TensorShape containing the combined information of self and other.':'',
'Returns the most specific TensorShape compatible with self and other.':'',
'A TensorShape which is the most specific compatible shape of self and other.':'',
'Returns a shape based on self with the given rank.':'',
'This method promotes a completely unknown shape to one with a known rank.':'',
'A shape that is at least as specific as self with the given rank.':'',
'Returns a shape based on self with at least the given rank.':'',
'A shape that is at least as specific as self with at least the given rank.':'',
'Returns a shape based on self with at most the given rank.':'',
'A shape that is at least as specific as self with at most the given rank.':'',
'## Class TensorSpec':'',
'Describes a tf.Tensor.':'',
'Creates a TensorSpec.':'',
'Returns the dtype of elements in the tensor.':'',
'Returns the (optionally provided) name of the described tensor.':'',
'Returns the TensorShape that represents the shape of the tensor.':'',
'Adds sparse updates to an existing tensor according to indices.':'',
'Subtracts sparse updates from an existing tensor according to indices.':'',
'Scatter updates into an existing tensor according to indices.':'',
'Constructs a tensor by tiling a given tensor.':'',
'Provides the time since epoch in seconds.':'',
'Returns the timestamp as a float64 for seconds since the Unix epoch.':'',
'A Tensor of type float64.':'',
'Transposes a.':'',
'Permutes the dimensions according to perm.':'',
'A transposed Tensor.':'',
'Group tensors together.':'',
'Same as tensors.':'',
'## Class TypeSpec':'',
'Specifies a TensorFlow value type.':'',
'## Class UnconnectedGradients':'',
'Controls how gradient computation behaves when y does not depend on x.':'',
'This operation returns a tensor y containing all of the unique elements of x sorted in the same order that they occur in x. This operation also returns a tensor idx the same size as x that contains the index of each value of x in the unique output y. In other words:':'',
'Converts a flat index or array of flat indices into a tuple of':'',
'coordinate arrays.':'',
'A Tensor. Has the same type as indices.':'',
'This is the opposite of stack.':'',
'The list of Tensor objects unstacked from value.':'',
'## Class Variable':'',
'A variable maintains state in the graph across calls to run(). You add a variable to the graph by constructing an instance of the class Variable.':'',
'This constructor creates both a variable Op and an assign Op to set the variable to its initial value.':'',
'## Child Classes':'',
'### aggregation':'',
'### constraint':'',
'Returns the constraint function associated with this variable.':'',
'The constraint function that was passed to the variable constructor. Can be None if no constraint was passed.':'',
'The device of this variable.':'',
'The DType of this variable.':'',
'The Graph of this variable.':'',
'Returns the Tensor used as the initial value for the variable.':'',
'### initializer':'',
'The initializer operation for this variable.':'',
'The name of this variable.':'',
'The Operation of this variable.':'',
'The TensorShape of this variable.':'',
'A TensorShape.':'',
'### synchronization':'',
'### trainable':'',
'Creates a slice helper object given a variable.':'',
'Note that assignments currently do not support NumPy broadcasting semantics.':'',
'Dummy method to prevent iteration.':'',
'Do not call.':'',
'### assign':'',
'Assigns a new value to the variable.':'',
'A Tensor that will hold the new value of this variable after the assignment has completed.':'',
'Adds a value to this variable.':'',
'A Tensor that will hold the new value of this variable after the addition has completed.':'',
'Subtracts a value from this variable.':'',
'A Tensor that will hold the new value of this variable after the subtraction has completed.':'',
'And the operation performed can be expressed as:':'',
'A Tensor that will hold the new value of this variable after the scattered assignment has completed.':'',
'When that Op is run it tries to increment the variable by 1. If incrementing the variable would bring it above limit then the Op raises the exception OutOfRangeError.':'',
'A numpy ndarray with a copy of the value of this variable.':'',
'Returns a hashable reference object to this Variable.':'',
'You should use this instead of the variable itself to initialize another variable with a value that depends on the value of this variable.':'',
'A Tensor holding the value of this variable after its initializer has run.':'',
'### load':'',
'Writes new value to variable\'s memory. Doesn\'t add ops to the graph.':'',
'A Tensor containing the value of the variable.':'',
'A Tensor that will hold the new value of this variable after the scattered addition has completed.':'',
'A Tensor that will hold the new value of this variable after the scattered division has completed.':'',
'A Tensor that will hold the new value of this variable after the scattered maximization has completed.':'',
'A Tensor that will hold the new value of this variable after the scattered minimization has completed.':'',
'A Tensor that will hold the new value of this variable after the scattered multiplication has completed.':'',
'Applies sparse addition to individual values or slices in a Variable.':'',
'The Variable has rank P and indices is a Tensor of rank Q.':'',
'The resulting update to v would look like this:':'',
'Applies sparse subtraction to individual values or slices in a Variable.':'',
'Assuming the variable has rank P and indices is a Tensor of rank Q.':'',
'A Tensor that will hold the new value of this variable after the scattered subtraction has completed.':'',
'Applies sparse assignment to individual values or slices in a Variable.':'',
'Overrides the shape for this variable.':'',
'Converts a Variable to a VariableDef protocol buffer.':'',
'### value':'',
'Returns the last snapshot of this variable.':'',
'Returns a Tensor which holds the value of the variable. You can not assign a new value to this tensor as it is not a reference to the variable.':'',
'## Class SaveSliceInfo':'',
'Information on how to save this Variable as a slice.':'',
'Provides internal support for saving variables as slices of a larger variable. This API is not public and is subject to change.':'',
'#### Available properties:':'',
'Create a SaveSliceInfo.':'',
'### spec':'',
'Computes the spec string used for saving.':'',
'Returns a SaveSliceInfoDef() proto.':'',
'## Class VariableAggregation':'',
'Indicates how a distributed variable will be aggregated.':'',
'## Class VariableSynchronization':'',
'Indicates when a distributed variable will be synced.':'',
'Scope which defines a variable creation function to be used by variable().':'',
'Custom getters in the variable scope will eventually resolve down to these custom creators when they do create variables.':'',
'A scope in which the creator is active':'',
'    elems':'',
'Repeat body while the condition cond is true.':'',
'Example with nesting and a namedtuple:':'',
'Creates a tensor with all elements set to zero.':'',
'This operation returns a tensor of type dtype with shape shape and all elements set to zero.':'',
'A Tensor with all elements set to zero.':'',
'Public API for tf.audio namespace.':'',
'Encode audio data using the WAV file format.':'',
'A Tensor of type string.':'',
'Conversion of plain Python into TensorFlow graph code.':'',
'Sets the AutoGraph verbosity level.':'',
'Debug logging in AutoGraph':'',
'There are two means to control the logging verbosity:':'',
'The converted code as string.':'',
'Converts a Python entity into a TensorFlow graph.':'',
'Functions are converted into new functions with converted code.':'',
'Classes are converted by generating a new class whose methods use converted code.':'',
'Methods are converted into unbound function that have an additional first argument called self.':'',
'Traces argument information at compilation time.':'',
'Example usage':'',
'Public API for tf.autograph.experimental namespace.':'',
'Decorator that suppresses the conversion of a function.':'',
'## Class Feature':'',
'This enumeration represents optional conversion options.':'',
'These conversion options are experimental. They are subject to change without notice and offer no guarantees.':'',
'#### Attributes:':'',
'Operations for manipulating the binary representations of integers.':'',
'Elementwise computes the bitwise AND of x and y.':'',
'Elementwise computes the bitwise OR of x and y.':'',
'Elementwise computes the bitwise XOR of x and y.':'',
'Functions for Python 2 vs. 3 compatibility.':'',
'## Conversion routines':'',
'## Types':'',
'The compatibility module also provides the following types:':'',
'A bytes object.':'',
'Converts input to str type.':'',
'A str object.':'',
'A unicode (Python 2) or str (Python 3) object.':'',
'Compatibility utility required to allow for both V1 and V2 behavior in TF.':'',
'    index':'',
'#### Arguments:':'',
'A dimension object.':'',
'Context manager for testing forward compatibility of generated graphs.':'',
'    day':'',
' from tensorflow.python.compat import compat':'',
'Nothing.':'',
'Return true if the forward compatibility window has expired.':'',
'to:':'',
'Converts input which is a PathLike object to str type.':'',
'In case a simplified str version of the path is needed from an os.PathLike object':'',
'Bring in all of the public TensorFlow interface into this module.':'',
'#### Eager Compatibility':'',
'Collections are only supported in eager when variables are created inside an EagerVariableStore (e.g. as part of a layer or template).':'',
'Note that in case of ties the identity of the return value is not guaranteed.':'',
'Returns the index with the largest value across dimensions of a tensor.':'',
'Returns the index with the smallest value across dimensions of a tensor.':'',
'Example of adding a dependency to an operation:':'',
'Op that raises InvalidArgumentError if x > y is False.':'',
'Assert that x is of integer dtype.':'',
'Op that raises InvalidArgumentError if x < y is False.':'',
'Op that raises InvalidArgumentError if x and y are not close enough.':'',
'Op raising InvalidArgumentError unless x is all negative.':'',
'Op raising InvalidArgumentError unless x is all positive.':'',
'Assert x has rank equal to rank.':'',
'Assert x has rank equal to rank or higher.':'',
'Assert x has rank in ranks.':'',
'This function raises ValueError unless it can be certain that the given tensor is a scalar. ValueError is also raised if the shape of tensor is unknown.':'',
'The input tensor (potentially converted to a Tensor).':'',
'Statically asserts that the given Tensor is of the specified type.':'',
'Returns an Op to check if variables are initialized.':'',
'Update ref by assigning value to it.':'',
'This operation outputs a Tensor that holds the new value of ref after the value has been assigned. This makes it easier to chain operations that need to use the reset value.':'',
'A Tensor that will hold the new value of ref after the assignment has completed.':'',
'Update ref by adding value to it.':'',
'Same as "ref". Returned as a convenience for operations that want to use the new value after the variable has been updated.':'',
'Update ref by subtracting value from it.':'',
'## Class AttrValue':'',
'A ProtocolMessage':'',
'### b':'',
'### f':'',
'### func':'',
'NameAttrList func':'',
'### i':'',
'### list':'',
'ListValue list':'',
'### placeholder':'',
'string placeholder':'',
'### s':'',
'TensorShapeProto shape':'',
'### tensor':'',
'TensorProto tensor':'',
'DataType type':'',
'## Class ListValue':'',
'repeated bool b':'',
'repeated float f':'',
'repeated NameAttrList func':'',
'repeated int64 i':'',
'repeated bytes s':'',
'repeated TensorShapeProto shape':'',
'repeated TensorProto tensor':'',
'repeated DataType type':'',
'Ref to variable after it has been modified.':'',
'This is a legacy version of the more general BatchToSpaceND.':'',
'Counts the number of occurrences of each value in an integer array.':'',
'A vector with the same dtype as weights or the given dtype. The bin values.':'',
'A clipped Tensor.':'',
'DEPRECATED FUNCTION':'',
'A conditional accumulator for aggregating gradients.':'',
'Extraction of the average gradient is blocked until the required number of gradients has been accumulated.':'',
'Creates a new ConditionalAccumulator.':'',
'The underlying accumulator reference.':'',
'The datatype of the gradients accumulated by this accumulator.':'',
'The name of the underlying accumulator.':'',
'Attempts to apply a gradient to the accumulator.':'',
'The operation that (conditionally) applies a gradient to the accumulator.':'',
'Number of gradients that have currently been aggregated in accumulator.':'',
'Number of accumulated gradients currently in accumulator.':'',
'Sets the global time step of the accumulator.':'',
'The operation logs a warning if we attempt to set to a time step that is lower than the accumulator\'s own time step.':'',
'Operation that sets the accumulator\'s time step.':'',
'Attempts to extract the average gradient from the accumulator.':'',
'The operation blocks until sufficient number of gradients have been successfully applied to the accumulator.':'',
'A tensor holding the value of the average gradient.':'',
'## Class ConditionalAccumulatorBase':'',
'## Class ConfigProto':'',
'### experimental':'',
'Experimental experimental':'',
'### key':'',
'string key':'',
'## Class Experimental':'',
'Computes the confusion matrix from predictions and labels.':'',
'Wrapper for Graph.container() using the default graph.':'',
'A context manager that specifies the default container to use for newly created stateful ops.':'',
'Returns True if v2 control flow is enabled.':'',
'Converts the given object to a Tensor or an IndexedSlices.':'',
'Converts value to a SparseTensor or Tensor.':'',
'A SparseTensor or Tensor based on value.':'',
'NOTE Floating point comparison to zero is done by exact floating point equality check. Small values are not rounded to zero for purposes of the nonzero check.':'',
'The reduced tensor (number of nonzero values).':'',
'A list of Variables corresponding to the slicing.':'',
'Convert CSV records to tensors. Each column maps to one tensor.':'',
'A Tensor object storing the decoded bytes.':'',
'Delete the tensor for the given tensor handle.':'',
'This is EXPERIMENTAL and subject to change.':'',
'Delete the tensor of a given tensor handle. The tensor is produced in a previous run() and stored in the state of the session.':'',
'A pair of graph elements. The first is a placeholder for feeding a tensor handle and the second is a deletion operation.':'',
'DepthToSpace for tensors of type T.':'',
'the operator will return the following tensor of shape [1 4 4 1]:':'',
'Wrapper for Graph.device() using the default graph.':'',
'Merge the properties of "dev" into this DeviceSpec.':'',
'## Class Dimension':'',
'Represents the value of one dimension in a TensorShape.':'',
'Creates a new Dimension with the given value.':'',
'Returns the sum of self and other.':'',
'Dimensions are summed as follows:':'',
'A Dimension whose value is the sum of self and other.':'',
'A Dimension whose value is the integer quotient of self and other.':'',
'Returns true if other has the same known value as this Dimension.':'',
'Returns the quotient of self and other rounded down.':'',
'Dimensions are divided as follows:':'',
'Returns True if self is known to be greater than or equal to other.':'',
'Dimensions are compared as follows:':'',
'Returns True if self is known to be greater than other.':'',
'Returns True if self is known to be less than or equal to other.':'',
'Returns True if self is known to be less than other.':'',
'Returns self modulo other.':'',
'Dimension moduli are computed as follows:':'',
'A Dimension whose value is self modulo other.':'',
'Returns the product of self and other.':'',
'A Dimension whose value is the product of self and other.':'',
'Returns true if other has a different known value from self.':'',
'Returns the sum of other and self.':'',
'Returns the quotient of other and self rounded down.':'',
'Returns other modulo self.':'',
'A Dimension whose value is other modulo self.':'',
'Returns the subtraction of self from other.':'',
'A Dimension whose value is the subtraction of self from other.':'',
'Returns the subtraction of other from self.':'',
'Dimensions are subtracted as follows:':'',
'A Dimension whose value is the subtraction of other from self.':'',
'Raises an exception if other is not compatible with this Dimension.':'',
'Returns true if other is compatible with this Dimension.':'',
'Two known Dimensions are compatible if they have the same value. An unknown Dimension is compatible with all other Dimensions.':'',
'True if this Dimension and other are compatible.':'',
'Returns a Dimension that combines the information in self and other.':'',
'Dimensions are combined as follows:':'',
'A Dimension containing the combined information of self and other.':'',
'Opts out of control flow v2.':'',
'Disables eager execution.':'',
'Compare Tensors by their id and be hashable.':'',
'This is a legacy behaviour of TensorFlow and is highly discouraged.':'',
'Disables TensorFlow 2.x behaviors.':'',
'User can call this function to disable 2.x behavior during complex migrations.':'',
'Disables the V2 TensorShape behavior and reverts to V1 behavior.':'',
'Use control flow v2.':'',
'Enables eager execution for the lifetime of this program.':'',
'Eager execution cannot be enabled after TensorFlow APIs have been used to create or execute graphs. It is typically recommended to invoke this function at program startup and not in a library (as most libraries should be usable both with and without eager execution).':'',
'Creates resource variables by default.':'',
'Enables TensorFlow 2.x behaviors.':'',
'This enables the new behavior.':'',
' #######################':'',
'#######################':'',
'## Class Event':'',
'### step':'',
'### summary':'',
'Summary summary':'',
'Extract patches from images and put them in the "depth" output dimension.':'',
'A Tensor. Has the same type as images.':'',
'## Class FixedLengthRecordReader':'',
'See ReaderBase for supported methods.':'',
'Op that implements the reader.':'',
'Whether the Reader implementation can serialize its state.':'',
'Returns the number of records this reader has produced.':'',
'This is the same as the number of Read executions that have succeeded.':'',
'An int64 Tensor.':'',
'Returns the number of work units this reader has finished processing.':'',
'Will dequeue a work unit from queue if necessary (e.g. when the Reader needs to start reading from a new file since it has finished with the previous file).':'',
'Restore a reader to its initial clean state.':'',
'Restore a reader to a previously saved state.':'',
'Produce a string tensor that encodes the state of a reader.':'',
'A string Tensor.':'',
'Partitioner to specify a fixed number of shards along given axis.':'',
'Collections are not supported when eager execution is enabled.':'',
'Returns the default graph for the current thread.':'',
'The default Graph being used in the current thread.':'',
'Returns the default session for the current thread.':'',
'The default Session being used in the current thread.':'',
'Gets an existing local variable or creates a new one.':'',
'A tuple of two integers that should be used for the local seed of this operation.':'',
'Return the handle of data.':'',
'A scalar string tensor representing a unique handle for data.':'',
'Get the tensor of type dtype by feeding a tensor handle.':'',
'Get the value of the tensor from a tensor handle. The tensor is produced in a previous run() and stored in the state of the session.':'',
'A pair of tensors. The first is a placeholder for feeding a tensor handle and the second is the tensor in the session state keyed by the tensor handle.':'',
'Gets an existing variable with these parameters or create a new one.':'',
'Returns the current variable scope.':'',
'Returns global variables.':'',
'A list of Variable objects.':'',
'Returns an Op that initializes global variables.':'',
'An Op that initializes global variables in the graph.':'',
'## Class GPUOptions':'',
'## Class VirtualDevices':'',
'## Class GraphDef':'',
'### library':'',
'FunctionDefLibrary library':'',
'### node':'',
'repeated NodeDef node':'',
'### versions':'',
'VersionDef versions':'',
'## Class GraphKeys':'',
'Standard names to use for graph collections.':'',
'The following standard keys are defined:':'',
'## Class GraphOptions':'',
'## Class HistogramProto':'',
'### bucket':'',
'repeated double bucket':'',
'### max':'',
'### min':'',
'### num':'',
'### sum':'',
'## Class IdentityReader':'',
'A Reader that outputs the queued work as both the key and value.':'',
'An Op that initializes all tables. Note that if there are not tables the returned Op is a NoOp.':'',
'## Class InteractiveSession':'',
'Creates a new interactive TensorFlow session.':'',
'The graph that was launched in this session.':'',
'A serializable version of the underlying TensorFlow graph.':'',
'The TensorFlow process to which this session will connect.':'',
'Returns a context manager that makes this object the default session.':'',
'A context manager using this session as the default session.':'',
'Closes an InteractiveSession.':'',
'Lists available devices in this session.':'',
'#### Where:':'',
'Each element in the list has the following properties':'',
'A list of devices in the session.':'',
'Returns a Python callable that runs a particular step.':'',
'Continues the execution with more feeds and fetches.':'',
'Below is a simple example:':'',
'Sets up a graph with feeds and fetches for partial run.':'',
'A handle for partial run.':'',
'Runs operations and evaluates tensors in fetches.':'',
'The optional options argument expects a [RunOptions] proto. The options allow controlling the behavior of this particular step (e.g. turning tracing on).':'',
'Tests if a variable has been initialized.':'',
'## Class LMDBReader':'',
'A Reader that outputs the records from a LMDB file.':'',
'Returns local variables.':'',
'A list of local Variable objects.':'',
'Returns an Op that initializes all local variables.':'',
'An Op that initializes all local variables in the graph.':'',
'## Class LogMessage':'',
'### level':'',
'Level level':'',
'### message':'',
'string message':'',
'## Class MetaGraphDef':'',
'## Class CollectionDefEntry':'',
'CollectionDef value':'',
'## Class MetaInfoDef':'',
'### tags':'',
'repeated string tags':'',
'## Class SignatureDefEntry':'',
'SignatureDef value':'',
'Partitioner to allocate minimum size per slice.':'',
'Returns all variables that maintain their moving averages.':'',
'## Class NameAttrList':'',
'### attr':'',
'repeated AttrEntry attr':'',
'string name':'',
'## Class AttrEntry':'',
'AttrValue value':'',
'## Class NodeDef':'',
'string device':'',
'### input':'',
'repeated string input':'',
'string op':'',
'## Class ExperimentalDebugInfo':'',
'Use this function to prevent regularization of variables.':'',
'## Class OptimizerOptions':'',
'Parses Example protos into a dict of tensors.':'',
'  features':'',
']':'',
'then the output will look like:':'',
'Given two Example input protos in serialized:':'',
'  features {':'',
'    feature { key: "gps" value { } }':'',
'And arguments':'',
'features: {':'',
'Then the output is a dictionary:':'',
'For dense results in two serialized Examples:':'',
'   features {':'',
'#### We can use arguments:':'',
'And the expected output is:':'',
'A dict mapping feature keys to Tensor and SparseTensor values.':'',
'Parses a single Example proto.':'',
'Inserts a placeholder for a tensor that will be always fed.':'',
'Placeholders are not compatible with eager execution.':'',
'A placeholder op that passes through input when its output is not fed.':'',
'DEPRECATED FUNCTION ARGUMENTS':'',
'Draws shape samples from each of the given Poisson distribution(s).':'',
'lam is the rate parameter describing the distribution(s).':'',
'## Class ReaderBase':'',
'Therefore we introduce some decoupling using a queue. The queue contains the work units and the Reader dequeues from the queue when it is asked to produce a record (via Read()) but it has finished the last work unit.':'',
'Creates a new ReaderBase.':'',
'Equivalent to np.any':'',
'Joins a string Tensor across the given dimensions.':'',
'This function is more numerically stable than log(sum(exp(input))). It avoids overflows caused by taking the exp of large inputs and underflows caused by taking the log of small inputs.':'',
'Equivalent to np.max':'',
'Computes the mean of elements across dimensions of a tensor.':'',
'Equivalent to np.mean':'',
'Equivalent to np.min':'',
'Equivalent to np.prod':'',
'Equivalent to np.sum apart the fact that numpy upcast uint8 and int32 to int64 while tensorflow returns the same dtype as the input.':'',
'Adds ops to list the names of uninitialized variables.':'',
'Clears the default graph stack and resets the global default graph.':'',
'Returns True if resource variables are enabled.':'',
'## Class RunMetadata':'',
'## Class FunctionGraphs':'',
'## Class RunOptions':'',
'Multiplies a scalar times a Tensor or IndexedSlices object.':'',
'Adds sparse updates to the variable referenced by resource.':'',
'This operation computes':'',
'Same as ref. Returned as a convenience for operations that want to use the updated values after the update is done.':'',
'Divides a variable reference by sparse updates.':'',
'This operation outputs ref after the update is done. This makes it easier to chain operations that need to use the reset value.':'',
'A mutable Tensor. Has the same type as ref.':'',
'Reduces sparse updates into a variable reference using the max operation.':'',
'Reduces sparse updates into a variable reference using the min operation.':'',
'Multiplies sparse updates into a variable reference.':'',
'ref is a Tensor with rank P and indices is a Tensor of rank Q.':'',
'The resulting update to ref would look like this:':'',
'Applies sparse updates to individual values or slices in a Variable.':'',
'The value of the variable after the update.':'',
'Subtracts sparse updates to a variable reference.':'',
'Applies sparse updates to a variable reference.':'',
'## Class Session':'',
'A class for running TensorFlow operations.':'',
'Creates a new TensorFlow session.':'',
'Closes this session.':'',
'Calling this method frees all resources associated with the session.':'',
'#### NOTE:':'',
'(i) reset() is currently only implemented for distributed sessions. (ii) Any sessions on the master named by target will be closed.':'',
'## Class SessionLog':'',
'### msg':'',
'string msg':'',
'### status':'',
'SessionStatus status':'',
'Computes the difference between two lists of numbers or strings.':'',
'This operation would return:':'',
'Returns the size of a tensor.':'',
'This is a legacy version of the more general SpaceToBatchND.':'',
'T`h``e`` `s`h``a``p``e`` `of` ``t``h``e`` `ou`t``p`u`t`` ``w``i`ll` ``b``e`:':'',
'Som`e`` ``e`x`a`m`p`l`e`s:':'',
'SpaceToDepth for tensors of type T.':'',
'the operator will return the following tensor of shape [1 2 2 4]:':'',
'## Class SparseConditionalAccumulator':'',
'A conditional accumulator for aggregating sparse gradients.':'',
'Sparse gradients are represented by IndexedSlices.':'',
'Attempts to apply a sparse gradient to the accumulator.':'',
'An IndexedSlices holding the value of the average gradient.':'',
'## Class SparseTensorValue':'',
'The shapes of the two operands must match: broadcasting is not supported.':'',
'Concatenation is with respect to the dense versions of each sparse input. It is assumed that each inputs is a SparseTensor whose elements are ordered along increasing dimension number.':'',
'The output elements will be resorted to preserve the sort order along increasing dimension number.':'',
'then the output will be':'',
'Graphically this is equivalent to doing':'',
'A SparseTensor with the concatenated output.':'',
'Multiply matrix "a" by matrix "b".':'',
'The gradient computation of this operation will only take advantage of sparsity in the input gradient when that gradient comes from a Relu.':'',
'A Tensor of type float32.':'',
'The SparseTensor returned by this function has the following properties:':'',
'Inserts a placeholder for a sparse tensor that will be always fed.':'',
'    succeed.':'',
'The reduced Tensor.':'',
'The reduced SparseTensor.':'',
'Computes the mean along sparse segments of a tensor.':'',
'Computes the sum along sparse segments of a tensor divided by the sqrt(N).':'',
'N is the size of the segment being reduced.':'',
'Computes the sum along sparse segments of a tensor.':'',
'Graphically the output tensors are:':'',
'Let N be the size of source (typically N will be the batch size). Split each element of source based on delimiter and return a SparseTensor or RaggedTensor containing the split tokens. Empty tokens are ignored.':'',
'to the delimiter.  The first column of the indices corresponds to the row':'',
'in `source` and the second column corresponds to the index of the split':'',
'component in this row.':'',
'Converts each string in the input Tensor to its hash mod by a number of buckets.':'',
'The hash function is deterministic on the content of the string within the process.':'',
'A Tensor of type int64.':'',
'Converts each string in the input Tensor to the specified numeric type.':'',
'Return substrings from Tensor of strings.':'',
'A negative pos indicates distance within the string backwards from the end.':'',
'Examples':'',
'Using scalar pos and len:':'',
'Using pos and len with same shape as input:':'',
'Broadcasting pos and len onto input:':'',
'Broadcasting input onto pos and len:':'',
'## Class Summary':'',
'repeated Value value':'',
'## Class Audio':'',
'## Class Image':'',
'### colorspace':'',
'### height':'',
'### width':'',
'## Class Value':'',
'### audio':'',
'Audio audio':'',
'### histo':'',
'HistogramProto histo':'',
'### image':'',
'Image image':'',
'### metadata':'',
'SummaryMetadata metadata':'',
'### tag':'',
'string tag':'',
'## Class SummaryMetadata':'',
'## Class PluginData':'',
'### content':'',
'Returns an Op that initializes all tables of the default graph.':'',
'## Class TensorInfo':'',
'DataType dtype':'',
'## Class CooSparse':'',
'## Class TextLineReader':'',
'A Reader that outputs the lines of a file delimited by newlines.':'',
'Newlines are stripped from the output. See ReaderBase for supported methods.':'',
'## Class TFRecordReader':'',
'A Reader that outputs the records from a TFRecords file.':'',
'A Tensor or SparseTensor or IndexedSlices with same shape as x with type bfloat16.':'',
'A Tensor or SparseTensor or IndexedSlices with same shape as x with type complex128.':'',
'A Tensor or SparseTensor or IndexedSlices with same shape as x with type complex64.':'',
'A Tensor or SparseTensor or IndexedSlices with same shape as x with type float64.':'',
'A Tensor or SparseTensor or IndexedSlices with same shape as x with type float32.':'',
'A Tensor or SparseTensor or IndexedSlices with same shape as x with type int32.':'',
'A Tensor or SparseTensor or IndexedSlices with same shape as x with type int64.':'',
'Initializer that generates a truncated normal distribution.':'',
'Initializer that generates tensors without scaling variance.':'',
'#### References:':'',
'To use the replacement for variables which does not have these issues:':'',
'Alias of Variable.shape.':'',
'## Class VariableScope':'',
'Creates a new VariableScope with the given properties.':'',
'### partitioner':'',
'### regularizer':'',
'### reuse':'',
'Get this scope\'s variables.':'',
'Gets an existing variable with this name or create a new one.':'',
'Get this scope\'s global variables.':'',
'Get this scope\'s local variables.':'',
'Reuse variables in this scope.':'',
'Set custom getter for this scope.':'',
'Set data type for this scope.':'',
'Set initializer for this scope.':'',
'Set partitioner for this scope.':'',
'Set regularizer for this scope.':'',
'Sets whether to use ResourceVariables for this scope.':'',
'Get this scope\'s trainable variables.':'',
'Returns an Op that initializes a list of variables.':'',
'An Op that run the initializers of all the specified variables.':'',
'Deprecated: context manager for defining an op that creates variables.':'',
'A context manager for defining ops that creates variables (layers).':'',
'Simple example of how to create a new variable:':'',
'Simple example of how to reenter a premade variable scope safely:':'',
'  pass':'',
'Sharing a variable by capturing a scope and setting reuse:':'',
'A scope that can be captured and reused.':'',
'Assert that the tensor does not contain any NaN\'s or Inf\'s.':'',
'Same tensor as t.':'',
'## Class WholeFileReader':'',
'A Reader that outputs the entire contents of a file as a value.':'',
'Wraps the TF 1.x function fn into a graph function.':'',
'the wrapped graph function.':'',
'Generic entry point script.':'',
'Runs the program with an optional \'main\' function and \'argv\' list.':'',
'Public API for tf.config namespace.':'',
'Public API for tf.config.experimental namespace.':'',
'Public API for tf.config.optimizer namespace.':'',
'## Class Dataset':'',
'Represents a potentially large set of elements.':'',
'A Dataset can be used to represent an input pipeline as a collection of elements and a "logical plan" of transformations that act on those elements.':'',
'Creates a DatasetV2 object.':'',
'The type specification of an element of this dataset.':'',
'A nested structure of Python type objects corresponding to each component of an element of this dataset.':'',
'Creates an Iterator for enumerating the elements of this dataset.':'',
'The returned iterator implements the Python iterator protocol and therefore can only be used in eager mode.':'',
'An Iterator over the elements of this dataset.':'',
'### apply':'',
'Applies a transformation function to this dataset.':'',
'### batch':'',
'Combines consecutive elements of this dataset into batches.':'',
'### cache':'',
'Caches the elements in this dataset.':'',
'Creates a Dataset by concatenating the given dataset with this dataset.':'',
'### enumerate':'',
'Enumerates the elements of this dataset.':'',
'It is similar to python\'s enumerate.':'',
'### filter':'',
'Filters this dataset according to predicate.':'',
'NOTE: This is an escape hatch for existing uses of filter that do not work with V2 functions. New uses are strongly discouraged and existing uses should migrate to filter as this method will be removed in V2.':'',
'Creates a Dataset whose elements are generated by generator.':'',
'Creates a Dataset whose elements are slices of the given tensors.':'',
'### interleave':'',
'A dataset of all files matching one or more glob patterns.':'',
'### map':'',
'NOTE: This is an escape hatch for existing uses of map that do not work with V2 functions. New uses are strongly discouraged and existing uses should migrate to map as this method will be removed in V2.':'',
'### options':'',
'Returns the options for this dataset and its inputs.':'',
'Combines consecutive elements of this dataset into padded batches.':'',
'This transformation combines multiple consecutive elements of the input dataset into a single element.':'',
'### prefetch':'',
'Creates a Dataset that prefetches elements from this dataset.':'',
'### range':'',
'### reduce':'',
'Reduces the input dataset to a single element.':'',
'A dataset element corresponding to the final state of the transformation.':'',
'### repeat':'',
'Repeats this dataset count times.':'',
'### shard':'',
'#### Important caveats:':'',
'### shuffle':'',
'Randomly shuffles the elements of this dataset.':'',
'### skip':'',
'Creates a Dataset that skips count elements from this dataset.':'',
'### take':'',
'Creates a Dataset with at most count elements from this dataset.':'',
'### unbatch':'',
'Splits elements of a dataset into multiple elements.':'',
'### window':'',
'Combines (nests of) input elements into a dataset of (nests of) windows.':'',
'### zip':'',
'Creates a Dataset by zipping together the given datasets.':'',
'## Class FixedLengthRecordDataset':'',
'Creates a FixedLengthRecordDataset.':'',
'Returns the output classes of a Dataset or Iterator elements.':'',
'A nested structure of Python type objects matching the structure of the dataset / iterator elements and specifying the class of the individual components.':'',
'Returns the output shapes of a Dataset or Iterator elements.':'',
'## Class Iterator':'',
'Represents the state of iterating through a Dataset.':'',
'Creates a new iterator from the given iterator resource.':'',
'The type specification of an element of this iterator.':'',
'An Iterator.':'',
'The following is an example':'',
'  while True:':'',
'    except tf.errors.OutOfRangeError:':'',
'      break':'',
'    while True:':'',
'  except tf.errors.OutOfRangeError:':'',
'    pass':'',
'## Class TextLineDataset':'',
'A Dataset comprising lines from one or more text files.':'',
'Creates a TextLineDataset.':'',
'## Class TFRecordDataset':'',
'A Dataset comprising records from one or more TFRecord files.':'',
'Creates a TFRecordDataset to read one or more TFRecord files.':'',
'Experimental API for building input pipelines.':'',
'See [Importing Data](https://tensorflow.org/guide/datasets) for an overview.':'',
'Public API for tf.debugging namespace.':'',
'Assert tensor shapes and dimension size relationships between tensors.':'',
'This Op checks that a collection of tensors shape relationships satisfies given constraints.':'',
'Library for running a computation across multiple devices.':'',
'Glossary':'',
'This is used to decide whether loss should be scaled in optimizer (used only for estimator + v1 optimizer use case).':'',
'## Class MirroredStrategy':'',
'Mirrors vars to distribute across multiple devices and machines.':'',
'### extended':'',
'Returns number of replicas over which gradients are aggregated.':'',
'Distributes a tf.data.Dataset instance provided via dataset.':'',
'The following is an example:':'',
'Makes a tf.data.Dataset for input provided via a numpy array.':'',
'Makes an iterator for input provided via dataset.':'',
'DEPRECATED: This method is not available in TF 2.x.':'',
'An tf.distribute.InputIterator which returns inputs for each step of the computation. User should call initialize on the returned iterator.':'',
'Returns an iterator split across replicas created from an input function.':'',
'Reduce value across replicas.':'',
'### scope':'',
'Returns a context manager selecting this Strategy as current.':'',
'A context manager.':'',
'## Class OneDeviceStrategy':'',
'A distribution strategy for running on a single device.':'',
'Typical usage of this strategy could be testing your code with the tf.distribute.Strategy API before switching to other strategies which actually distribute to multiple devices/machines.':'',
'Creates a OneDeviceStrategy.':'',
'## Class Strategy':'',
'A list of devices with a state & compute distribution policy.':'',
'## Class StrategyExtended':'',
'Sync on read variables':'',
'Locality':'',
'How to update a variable':'',
'The standard pattern for updating variables is to:':'',
'This is expected to return a constant value that will not be changed throughout its life cycle.':'',
'Returns True if static shape is required; False otherwise.':'',
'Whether initialization is needed.':'',
'Returns the tuple of all devices used to place variables.':'',
'Whether checkpointing is needed.':'',
'Whether saving summaries is needed.':'',
'Returns the tuple of all devices used to for compute replica execution.':'',
'    destinations':'',
'Mirror a tensor on one device to all worker devices.':'',
'A value mirrored to destinations devices.':'',
'Run fn once per replica.':'',
'Merged return value of fn across all replicas.':'',
'Scope that controls which devices variables will be created on.':'',
'This may only be used inside self.scope().':'',
'Makes a dataset for input provided via a numpy array.':'',
'Run fn with input from iterator for iterations times.':'',
'This method can be used to run a step function for training a number of times using input from a dataset.':'',
'Reads the value of a variable.':'',
'Combine (via e.g. sum or mean) values across replicas.':'',
'A tensor or value mirrored to destinations.':'',
'### update':'',
'Run fn to update var using inputs mirrored to the same devices.':'',
'Tests whether v was created while this strategy scope was active.':'',
'Variables created inside the strategy scope are "owned" by it:':'',
'True':'',
'Variables created outside the strategy are not owned by it:':'',
'False':'',
'Core module for TensorFlow distribution objects and helpers.':'',
'## Class Bernoulli':'',
'Bernoulli distribution.':'',
'Python bool describing behavior when a stat is undefined.':'',
'Shape of a single sample from a single event index as a TensorShape.':'',
'May be partially defined or unknown.':'',
'The DType of Tensors handled by this Distribution.':'',
'Shape of a single sample from a single batch as a TensorShape.':'',
'### logits':'',
'Name prepended to all ops created by this Distribution.':'',
'### parameters':'',
'Dictionary of parameters used to instantiate this Distribution.':'',
'### probs':'',
'Describes how samples from the distribution are reparameterized.':'',
'An instance of ReparameterizationType.':'',
'Python bool indicating possibly expensive checks are enabled.':'',
'### cdf':'',
'Cumulative distribution function.':'',
'### copy':'',
'Creates a deep copy of the distribution.':'',
'### covariance':'',
'Covariance.':'',
'Computes the (Shannon) cross entropy.':'',
'### entropy':'',
'Shannon entropy in nats.':'',
'Log cumulative distribution function.':'',
'Log probability density/mass function.':'',
'Log survival function.':'',
'### mean':'',
'Mean.':'',
'### mode':'',
'Mode.':'',
'Additional documentation from Bernoulli:':'',
'Shapes of parameters given the desired shape of a call to sample().':'',
'This is a class method that describes what key/value arguments are required to instantiate the given Distribution so that a particular shape is returned for that instance\'s call to sample().':'',
'dict of parameter name to Tensor shapes.':'',
'This is a class method that describes what key/value arguments are required to instantiate the given Distribution so that a particular shape is returned for that instance\'s call to sample(). Assumes that the sample\'s shape is known statically.':'',
'dict of parameter name to TensorShape.':'',
'### prob':'',
'Probability density/mass function.':'',
'### quantile':'',
'Quantile function. Aka "inverse cdf" or "percent point function".':'',
'### sample':'',
'Generate samples of the specified shape.':'',
'Note that a call to sample() without arguments will generate a single sample.':'',
'### stddev':'',
'Standard deviation.':'',
'Survival function.':'',
'### variance':'',
'Variance.':'',
'## Class Beta':'',
'Beta distribution.':'',
'#### Mathematical Details':'',
'Distribution parameters are automatically broadcast in all functions; see examples for details.':'',
'Samples of this distribution are reparameterized (pathwise differentiable). The derivatives are computed using the approach described in the paper':'',
'#### Examples':'',
'Compute the gradients of samples w.r.t. the parameters:':'',
'### concentration1':'',
'Concentration parameter associated with a 1 outcome.':'',
'Sum of concentration parameters.':'',
'Additional documentation from Beta:':'',
'## Class Categorical':'',
'Categorical distribution.':'',
'#### Pitfalls':'',
'Scalar int32 tensor: the number of classes.':'',
'Vector of coordinatewise logits.':'',
'Vector of coordinatewise probabilities.':'',
'## Class Dirichlet':'',
'Dirichlet distribution.':'',
'### concentration':'',
'Concentration parameter; expected counts for that coordinate.':'',
'Sum of last dim of concentration parameter.':'',
'Additional documentation from Dirichlet:':'',
'## Class DirichletMultinomial':'',
'Concentration parameter; expected prior counts for that coordinate.':'',
'Number of trials used to construct a sample.':'',
'Additional documentation from DirichletMultinomial:':'',
'The covariance for each batch member is defined as the following:':'',
'The covariance between elements in a batch is defined as:':'',
'## Class Distribution':'',
'A generic probability distribution base class.':'',
'#### Subclassing':'',
'All distributions support batches of independent distributions of that type. The batch shape is determined by broadcasting together the parameters.':'',
'Using the Uniform distribution as an example:':'',
'#### Shapes':'',
'#### Parameter values leading to undefined statistics or distributions.':'',
'The user is given the option of raising an exception or returning NaN.':'',
'This is a private method for subclass use.':'',
'## Class Exponential':'',
'Exponential distribution.':'',
'The Exponential distribution is parameterized by an event rate parameter.':'',
'Concentration parameter.':'',
'### rate':'',
'Rate parameter.':'',
'Additional documentation from Gamma:':'',
'## Class Gamma':'',
'Gamma distribution.':'',
'The Gamma distribution is defined over positive real numbers using parameters concentration (aka "alpha") and rate (aka "beta").':'',
'The parameters concentration and rate must be shaped in a way that supports broadcasting (e.g. concentration + rate is a valid operation).':'',
'## Class Laplace':'',
'The Laplace distribution with location loc and scale parameters.':'',
'#### Mathematical details':'',
'### loc':'',
'Distribution parameter for the location.':'',
'### scale':'',
'Distribution parameter for scale.':'',
'## Class Multinomial':'',
'Multinomial distribution.':'',
'The distribution functions can be evaluated on counts.':'',
'Probability of drawing a 1 in that coordinate.':'',
'Additional documentation from Multinomial:':'',
'## Class Normal':'',
'The Normal distribution with location loc and scale parameters.':'',
'Examples of initialization of one or a batch of distributions.':'',
'Arguments are broadcast when possible.':'',
'The parameters loc and scale must be shaped in a way that supports broadcasting (e.g. loc + scale is a valid operation).':'',
'Distribution parameter for the mean.':'',
'Distribution parameter for standard deviation.':'',
'## Class RegisterKL':'',
'Decorator to register a KL divergence implementation function.':'',
'Perform the KL registration.':'',
'## Class ReparameterizationType':'',
'Instances of this class represent how sampling is reparameterized.':'',
'Determine if this ReparameterizationType is equal to another.':'',
'self is other.':'',
'## Class StudentT':'',
'### df':'',
'Degrees of freedom in these Student\'s t distribution(s).':'',
'Locations of these Student\'s t distribution(s).':'',
'Scaling factors of these Student\'s t distribution(s).':'',
'Additional documentation from StudentT:':'',
'The variance for Student\'s T equals':'',
'## Class Uniform':'',
'Uniform distribution with low and high parameters.':'',
'### high':'',
'Upper boundary of the output interval.':'',
'### low':'',
'Lower boundary of the output interval.':'',
'Public API for tf.dtypes namespace.':'',
'Exception types for TensorFlow errors.':'',
'Context manager to check for C API status.':'',
'Estimator: High level tools for working with models.':'',
'## Class BaselineClassifier':'',
'A classifier that can establish a simple baseline.':'',
'Constructs an Estimator instance.':'',
'Args:':'',
'Returns: `tf.estimator.EstimatorSpec`':'',
'         If the string filepath is provided instead of a':'',
'### config':'',
'### params':'',
'Shows the directory name where evaluation metrics are dumped.':'',
'A string which is the path of directory contains evaluation metrics.':'',
'### evaluate':'',
'Exports a SavedModel with tf.MetaGraphDefs for each requested mode.':'',
'The string path to the exported directory.':'',
'Exports inference graph as a SavedModel into the given dir.':'',
'Returns list of all variable names in this model.':'',
'List of names.':'',
'Returns value of the variable given by name.':'',
'The full path to the latest checkpoint or None if no checkpoint was found.':'',
'### predict':'',
'Yields predictions for given features.':'',
'A `tf.data.Dataset` object: Outputs of `Dataset` object must have same constraints as below.':'',
'Evaluated values of predictions tensors.':'',
'### train':'',
'## Class BaselineEstimator':'',
'An estimator that can establish a simple baseline.':'',
'## Class BaselineRegressor':'',
'A regressor that can establish a simple baseline.':'',
'This regressor ignores feature values and will learn to predict the average value of each label.':'',
'Example output of parsing spec:':'',
'Example usage with a classifier:':'',
'A dict mapping each feature key to a FixedLenFeature or VarLenFeature value.':'',
'## Class DNNClassifier':'',
'A classifier for TensorFlow DNN models.':'',
'Loss is calculated by using softmax cross entropy.':'',
'## Class DNNEstimator':'',
'Loss and predicted output are determined by the specified head.':'',
'## Class DNNLinearCombinedClassifier':'',
'An estimator for TensorFlow Linear and DNN joined classification models.':'',
'## Class DNNLinearCombinedEstimator':'',
'An estimator for TensorFlow Linear and DNN joined models with custom head.':'',
'Loss is calculated by using mean squared error.':'',
'## Class DNNLinearCombinedRegressor':'',
'An estimator for TensorFlow Linear and DNN joined models for regression.':'',
'## Class DNNRegressor':'',
'A regressor for TensorFlow DNN models.':'',
'## Class Estimator':'',
'Estimator class to train and evaluate TensorFlow models.':'',
'## Class LinearClassifier':'',
'Linear classifier model.':'',
'## Class LinearEstimator':'',
'Initializes a LinearEstimator instance.':'',
'## Class LinearRegressor':'',
'An estimator for TensorFlow Linear regression problems.':'',
'Train a linear regression model to predict label value given observation of feature values.':'',
'Example usage with a regressor:':'',
'Public API for tf.estimator.experimental namespace.':'',
'## Class KMeans':'',
'is equivalent to':'',
'Creates an Estimator for running KMeans training and inference.':'',
'which is the sq`u`are root o`f` the s`u`m o`f` the absol`u`te sq`u`ares o`f` the elements\' di`f``f`erence.':'',
'Returns the cluster centers.':'',
'Finds the index of the closest cluster center to each input point.':'',
'The index of the closest cluster center for each input point.':'',
'### score':'',
'Returns the sum of squared distances to nearest clusters.':'',
'Note that this function is different from the corresponding one in sklearn which returns the negative sum.':'',
'The sum of the squared distance from each point in the first batch of inputs to its nearest cluster center.':'',
'### transform':'',
'Transforms each input point to its distances to all cluster centers.':'',
'The distances from each input point to each cluster center.':'',
'All public utility methods for exporting Estimator to SavedModel.':'',
'Returns input function that would feed dict of numpy arrays into the model.':'',
'This returns a function outputting features and targets based on the dict of numpy arrays. The dict features has the same keys as the x. The dict targets has the same keys as the y if y is a dict.':'',
'Returns input function that would feed Pandas DataFrame into the model.':'',
'Public API for tf.estimator.tpu namespace.':'',
'## Class InputPipelineConfig':'',
'Please see the definition of these values in TPUConfig.':'',
'## Class RunConfig':'',
'RunConfig with TPU support.':'',
'Constructs a RunConfig.':'',
'### cluster':'',
'The global id in the training cluster.':'',
'  worker     | 1        |  2':'',
'  worker     | 2        |  3':'',
'  ps         | 1        |  5':'',
'An integer id.':'',
'### master':'',
'### protocol':'',
'Returns the optional protocol value.':'',
'### service':'',
'Returns a new instance of RunConfig replacing specified properties.':'',
'Only the properties in the following list are allowed to be replaced:':'',
'a new instance of RunConfig.':'',
'## Class TPUConfig':'',
'TPU related configuration required by TPUEstimator.':'',
'## Class TPUEstimator':'',
'Estimator with TPU support.':'',
'#### Current limitations:':'',
'## Example (MNIST):':'',
'There are two versions of the API: ExportSavedModelApiVersion.V1 and V2.':'',
'Constructs an TPUEstimator instance.':'',
'## Class TPUEstimatorSpec':'',
'Creates a validated TPUEstimatorSpec instance.':'',
'### predictions':'',
'### loss':'',
'Creates an equivalent EstimatorSpec used by CPU train/eval.':'',
'Public API for tf.estimator.tpu.experimental namespace.':'',
'## Class EmbeddingConfigSpec':'',
'Class to keep track of the specification for TPU embeddings.':'',
'Creates an EmbeddingConfigSpec instance.':'',
'An EmbeddingConfigSpec instance.':'',
'Public API for tf.experimental namespace.':'',
'Whether to output all intermediates from functional control flow ops.':'',
'A CategoricalColumn with a vocabulary file.':'',
'And to make an embedding with either:':'',
'This function generates a weighted sum based on output dimension units. Weighted sum refers to logits in classification problems. It refers to the prediction itself for linear regression problems.':'',
'#### Example of usage:':'',
'"sum": do not normalize `features` in the column':'',
'"mean": do l1 normalization on `features` in the column':'',
'"sqrtn": do l2 normalization on `features` in the column':'',
'#### Typical usage example:':'',
'Here is an example embedding of two features for a DNNClassifier model:':'',
'Declares that all flags key to a module are key to the current module.':'',
'Base class used to parse and convert arguments.':'',
'Returns a string representing the type of the flag.':'',
'### parse':'',
'Parses the string argument and returns the native value.':'',
'By default it returns its argument unmodified.':'',
'The parsed value in native type.':'',
'## Class ArgumentSerializer':'',
'Base class for generating string representations of a flag value.':'',
'### serialize':'',
'Returns a serialized string of the value.':'',
'Base class for a parser of lists of strings.':'',
'See base class.':'',
'Basic boolean flag.':'',
'Return self<value.':'',
'Returns a str that describes the type of the flag.':'',
'Parses string and sets flag value.':'',
'Serializes the flag.':'',
'### unparse':'',
'## Class BooleanParser':'',
'Parser of boolean values.':'',
'Raised when flagfile fails to open.':'',
'Serializes a list as a CSV string or unicode.':'',
'Declares one flag as key to the current module.':'',
'#### Sample usage:':'',
'Registers a generic Flag object.':'',
'Defines an alias flag for an existing one.':'',
'Registers a boolean flag.':'',
'Registers a flag whose value can be the name of enum members.':'',
'Registers a \'Flag\' object with a \'FlagValues\' object.':'',
'Registers a flag whose value must be a float.':'',
'Registers a flag whose value must be an integer.':'',
'The flag value is parsed with a CSV parser.':'',
'Registers a generic MultiFlag that parses its args with a given parser.':'',
'Auxiliary function. Normal users should NOT use it directly.':'',
'Developers who need to create their own \'Parser\' classes for options which can appear multiple times can call this module function to register their flags.':'',
'Registers a flag whose value can be a list of enum members.':'',
'Use the flag on the command line multiple times to place multiple enum values into the list.':'',
'Registers a flag whose value can be a list of arbitrary floats.':'',
'Registers a flag whose value can be a list of arbitrary integers.':'',
'Registers a flag whose value can be a list of any strings.':'',
'Any whitespace can be used as a separator.':'',
'Registers a flag whose value can be any string.':'',
'Declares that the current module will not define any more key flags.':'',
'Takes a doc string and reformats it as help.':'',
'Raised if there is a flag naming conflict.':'',
'Creates a DuplicateFlagError by providing flag name and values.':'',
'An instance of DuplicateFlagError.':'',
'## Class EnumClassFlag':'',
'Basic enum flag; its value is an enum class\'s member.':'',
'Parser of an Enum class member.':'',
'Initializes EnumParser.':'',
'Determines validity of argument and returns the correct element of enum.':'',
'The first matching Enum class member in Enum class.':'',
'Parser of a string enum value (a string value from a given set).':'',
'The base class for all flags errors.':'',
'## Class Flag':'',
'Raised when a flag name conflicts with FlagValues methods.':'',
'## Class FlagValues':'',
'Registry of \'Flag\' objects.':'',
'This class is heavily overloaded:':'',
'The str() operator of a \'FlagValues\' object provides help for all of the registered \'Flag\' objects.':'',
'Parses flags from argv; stores parsed flags into this FlagValues object.':'',
'All unparsed arguments are returned.':'',
'Returns True if name is a value (flag) in the dict.':'',
'Appends flags registered in another FlagValues instance.':'',
'Appends all flags assignments from this FlagInfo object to a file.':'',
'Output will be in the format of a flagfile.':'',
'NOTE: MUST mirror the behavior of the C++ AppendFlagsIntoFile from https://github.com/gflags/gflags.':'',
'Returns a dictionary that maps flag names to flag values.':'',
'A dictionary. Its keys are module names (strings). Its values are lists of Flag objects.':'',
'A dictionary. Its keys are module IDs (ints). Its values are lists of Flag objects.':'',
'Returns a string with the flags assignments from this FlagValues object.':'',
'This function ignores flags whose value is None. Each flag assignment is separated by a newline.':'',
'NOTE: MUST mirror the behavior of the C++ CommandlineFlagsIntoString from https://github.com/gflags/gflags.':'',
'Returns the value of a flag (if not None) or a default value.':'',
'Requested flag value or default.':'',
'Returns a help string for all known flags.':'',
'Returns the list of key flags for a module.':'',
'Returns whether flags were parsed.':'',
'Describes the key flags of the main module.':'',
'Explicitly marks flags as parsed.':'',
'Use this when the caller knows that this FlagValues has been parsed as if a call() invocation has happened. This is only a public method for use by things like appcommands which do additional command like parsing.':'',
'Describes the key flags of a module.':'',
'A new list which has the original list combined with what we read from any flagfile(s).':'',
'    flag':'',
'Records the module that defines a specific flag.':'',
'We keep track of which flag is defined by which module so that we can later sort the flags by module.':'',
'Specifies that a flag is a key flag for a module.':'',
'Remove flags that were previously appended from another FlagValues.':'',
'Changes the default value of the named flag object.':'',
'Sets whether or not to use GNU style scanning.':'',
'Unparses all flags to the point before any FLAGS(argv) was called.':'',
'Outputs flag documentation in XML format.':'',
'Convert a dict of values into process call parameters.':'',
'This method is used to convert a dictionary into a sequence of parameters for a binary that parses arguments using this module.':'',
'Everything else is converted to string an passed as such.':'',
'sequence of string suitable for a subprocess execution.':'',
'Parser of floating point values.':'',
'Parsed value may be bounded to a given upper and lower bound.':'',
'### convert':'',
'Returns the float value of argument.':'',
'Returns whether the value is outside the bounds or not.':'',
'Returns the integer width of help lines that is used in TextWrap.':'',
'Raised when the flag command line argument is illegal.':'',
'Parser of an integer value.':'',
'Returns the int value of argument.':'',
'## Class ListParser':'',
'Ensures that flags are not None during program execution.':'',
'#### Recommended usage:':'',
'Ensures that flag is not None during program execution.':'',
'It is recommended to call this method like this:':'',
'Parses one or more arguments with the installed parser.':'',
'See the doc for Flag for most behavior of this class. Only differences in behavior are described here:':'',
'A function decorator that registers its function argument as a validator.':'',
'Adds a constraint to multiple flags.':'',
'Wraps a given text to a maximum line length and returns it.':'',
'Raised when accessing the flag value from unparsed FlagValues.':'',
'## Class UnrecognizedFlagError':'',
'Raised when a flag is unrecognized.':'',
'Raised when flag validator constraint is not satisfied.':'',
'A function decorator for defining a flag validator.':'',
'Initializer.':'',
'Base TFDecorator class and utility functions for working with decorators.':'',
'Make a decorator from a wrapper and a target.':'',
'## Class TFDecorator':'',
'Base class for all TensorFlow decorators.':'',
'Call self as a function.':'',
'Unwraps an object into a list of TFDecorators and a final target.':'',
'Functions used to extract and analyze stacks. Faster than Python libs.':'',
'## Class CurrentModuleFilter':'',
'Filters stack frames from the module where this is used (best effort).':'',
'A list of FileAndLine objects corresponding to the call stack of the current thread.':'',
'## Class FileAndLine':'',
'    line':'',
'### file':'',
'### line':'',
'## Class StackTraceFilter':'',
'Allows filtering traceback information by removing superfluous frames.':'',
'## Class StackTraceMapper':'',
'Allows remapping traceback information to different source code.':'',
'## Class StackTraceTransform':'',
'Base class for stack trace transformation functions.':'',
'Copies data from oldpath to newpath.':'',
'Deletes everything under dirname recursively.':'',
'Determines whether a path exists or not.':'',
'## Class FastGFile':'',
'File I/O wrappers without thread locking.':'',
'Returns the mode in which the file was opened.':'',
'Returns the file name.':'',
'Make usable with "with" statement.':'',
'Closes FileIO. Should be called for the WritableFile to be flushed.':'',
'### flush':'',
'Flushes the Writable file.':'',
'This only ensures that the data has made its way out of the process without any guarantees on whether it\'s written to disk. This means that the data would survive an application crash but not necessarily an OS crash.':'',
'### next':'',
'Returns the contents of a file as a string.':'',
'Starts reading from current position in file.':'',
'### readline':'',
'Reads the next line from the file. Leaves the \'\n\' at the end.':'',
'### readlines':'',
'Returns all lines from the file in a list.':'',
'### seek':'',
'### seekable':'',
'Returns the size of the file.':'',
'### tell':'',
'Returns the current position in the file.':'',
'Returns a list of files that match the given pattern(s).':'',
'A list of strings containing filenames that match the given pattern(s).':'',
'Returns whether the path is a directory or not.':'',
'Returns a list of entries contained within a directory.':'',
'The list is in arbitrary order. It does not contain the special entries "." and "..".':'',
'errors.NotFoundError if directory doesn\'t exist':'',
'Creates a directory and all parent/intermediate directories.':'',
'It succeeds if dirname already exists and is writable.':'',
'Creates a directory with the name \'dirname\'.':'',
'Deletes the file located at \'filename\'.':'',
'Rename or move a file / directory.':'',
'Returns file statistics for a given path.':'',
'FileStatistics struct that contains information about the path':'',
'Recursive directory tree generator for directories.':'',
'Helpers to manipulate a tensor graph in python.':'',
'GraphDef containing a simplified version of the original.':'',
'A list of nodes with the unnecessary ones removed.':'',
'Image processing and decoding ops.':'',
'Extracts crops from the input image tensor and resizes them.':'',
'Draw bounding boxes on a batch of images.':'',
'Parts of the bounding box may fall outside the image.':'',
'Extracts a glimpse from the input tensor.':'',
'The argument normalized and centered controls how the windows are built:':'',
'#### Usage Example:':'',
'Resize images to size using the specified method.':'',
'## Class ResizeMethod':'',
'Resize images to size using area interpolation.':'',
'Input images can be of different types but output images are always float.':'',
'Resizes and pads an image to a target width and height.':'',
'Public API for tf.initializers namespace.':'',
'Public API for tf.io namespace.':'',
'## Class TFRecordCompressionType':'',
'The type of compression for the record.':'',
'Strings.':'',
'Public API for tf.io.gfile namespace.':'',
'DenseNet models for Keras.':'',
'Utilities for ImageNet data preprocessing & prediction decoding.':'',
'Inception V3 model for Keras.':'',
'MobileNet v1 models for Keras.':'',
'MobileNet v2 models for Keras.':'',
'Xception V1 model for Keras.':'',
'Keras backend API.':'',
'Returns the TF session to be used by the backend.':'',
'If no global Keras session exists at this point: we will create a new global session.':'',
'A TensorFlow session.':'',
'Sets the global TensorFlow session.':'',
'Callbacks: utilities called at certain points during model training.':'',
'## Class TensorBoard':'',
'Enable visualizations for TensorBoard.':'',
'TensorBoard is a visualization tool provided with TensorFlow.':'',
'Writes scalar summaries for metrics on every training batch.':'',
'Called at the beginning of a batch in predict methods.':'',
'Subclasses should override for any actions to run.':'',
'Called at the end of a batch in predict methods.':'',
'Called at the beginning of prediction.':'',
'Called at the end of prediction.':'',
'Called at the beginning of a batch in evaluate methods.':'',
'Called at the end of a batch in evaluate methods.':'',
'Called at the beginning of evaluation or validation.':'',
'Called at the end of evaluation or validation.':'',
'Called at the beginning of a training batch in fit methods.':'',
'Called at the end of a training batch in fit methods.':'',
'Called at the beginning of training.':'',
'Called at the end of training.':'',
'Sets Keras model and creates summary ops.':'',
'Constraints: functions that impose constraints on weight values.':'',
'Boston housing price regression dataset.':'',
'IMDB sentiment classification dataset.':'',
'MNIST handwritten digits dataset.':'',
'Reuters topic classification dataset.':'',
'Keras estimator API.':'',
'Constructs an Estimator instance from given keras model.':'',
'An Estimator from given keras model.':'',
'Public API for tf.keras.experimental namespace.':'',
'Keras initializer serialization / deserialization.':'',
'## Class Constant':'',
'He normal initializer.':'',
'An initializer.':'',
'He uniform variance scaling initializer.':'',
'## Class Identity':'',
'Initializer that generates the identity matrix.':'',
'Only use for 2D matrices.':'',
'## Class Initializer':'',
'Initializer base class: all initializers inherit from this class.':'',
'LeCun normal initializer.':'',
'LeCun uniform initializer.':'',
'## Class Ones':'',
'## Class Orthogonal':'',
'Initializer that generates an orthogonal matrix.':'',
'## Class RandomNormal':'',
'RandomNormal instance.':'',
'## Class RandomUniform':'',
'A RandomUniform instance.':'',
'## Class TruncatedNormal':'',
'A TruncatedNormal instance.':'',
'## Class VarianceScaling':'',
'Initializer capable of adapting its scale to the shape of weights tensors.':'',
'## Class Zeros':'',
'Keras layers API.':'',
'## Class BatchNormalization':'',
'#### Call arguments:':'',
'#### Input shape:':'',
'#### Output shape:':'',
'Same shape as input.':'',
'## Class CuDNNGRU':'',
'Fast GRU implementation backed by cuDNN.':'',
'### cell':'',
'### states':'',
'## Class CuDNNLSTM':'',
'Fast LSTM implementation backed by cuDNN.':'',
'## Class DenseFeatures':'',
'This layer can be called multiple times with different features.':'',
'Constructs a DenseFeatures layer.':'',
'### activation':'',
'### dropout':'',
'### implementation':'',
'### units':'',
'## Class GRUCell':'',
'Cell class for the GRU layer.':'',
'Get the dropout mask for RNN cell\'s input.':'',
'Get the recurrent dropout mask for RNN cell.':'',
'Reset the cached dropout masks if any.':'',
'Reset the cached recurrent dropout masks if any.':'',
'## Class LSTM':'',
'## Class LSTMCell':'',
'Cell class for the LSTM layer.':'',
'Public API for tf.keras.optimizers.schedules namespace.':'',
'Keras data preprocessing utils.':'',
'Utilities for preprocessing sequence data.':'',
'Utilities for text input preprocessing.':'',
'Keras utilities.':'',
'Public API for tf.layers namespace.':'',
'## Class AveragePooling1D':'',
'Average Pooling layer for 1D inputs.':'',
'Average pooling layer for 2D inputs (e.g. images).':'',
'## Class AveragePooling3D':'',
'Average pooling layer for 3D inputs (e.g. volumes).':'',
'Output tensor.':'',
'"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"':'',
'## Class Conv1D':'',
'## Class Conv2D':'',
'## Class Conv2DTranspose':'',
'Transposed 2D convolution layer (sometimes called 2D Deconvolution).':'',
'## Class Conv3D':'',
'## Class Conv3DTranspose':'',
'Transposed 3D convolution layer (sometimes called 3D Deconvolution).':'',
'## Class Dense':'',
'#### Properties:':'',
'## Class Dropout':'',
'Applies Dropout to the input.':'',
'## Class Flatten':'',
'## Class Layer':'',
'Base layer class.':'',
'#### Mutable properties:':'',
'## Class MaxPooling1D':'',
'Max Pooling layer for 1D inputs.':'',
'## Class MaxPooling2D':'',
'Max pooling layer for 2D inputs (e.g. images).':'',
'## Class MaxPooling3D':'',
'Max pooling layer for 3D inputs (e.g. volumes).':'',
'volumes).':'',
'## Class SeparableConv1D':'',
'Depthwise separable 1D convolution.':'',
'## Class SeparableConv2D':'',
'Depthwise separable 2D convolution.':'',
'Public API for tf.layers.experimental namespace.':'',
'The purpose of this scope is to allow users of existing layers to slowly transition to a Keras layers API without breaking existing functionality.':'',
'A keras layer style scope.':'',
'The purpose of this function is to allow users of existing layers to slowly transition to Keras layers API without breaking existing functionality.':'',
'Operations for linear algebra.':'',
'A Tensor with the same shape as x.':'',
'Public API for tf.lite namespace.':'',
'## Class OpHint':'',
'A class that helps build tflite function invocations.':'',
'Create a OpHint.':'',
'Add a wrapped input argument to the hint.':'',
'The wrapped input tensor.':'',
'Add a sequence of inputs to the function invocation.':'',
'Wrapped inputs (identity standins that have additional metadata). These are also are also tf.Tensor\'s.':'',
'Add a wrapped output argument to the hint.':'',
'The wrapped output tensor.':'',
'Add a sequence of outputs to the function invocation.':'',
'Wrapped outputs (identity standins that have additional metadata). These are also tf.Tensor\'s.':'',
'## Class OpHintArgumentTracker':'',
'Conceptually tracks indices of arguments of "OpHint functions".':'',
'The inputs and arguments of these functions both use an instance of the class so they can have independent numbering.':'',
'Initialize ophint argument.':'',
'### add':'',
'Return a wrapped tensor of an input tensor as an argument.':'',
'A tensor representing the wrapped argument.':'',
'## Class TFLiteConverter':'',
'Constructor for TFLiteConverter.':'',
'Converts a TensorFlow GraphDef based on instance variables.':'',
'Creates a TFLiteConverter class from a file containing a frozen GraphDef.':'',
'TFLiteConverter class.':'',
'Creates a TFLiteConverter class from a tf.keras model file.':'',
'Creates a TFLiteConverter class from a SavedModel.':'',
'Creates a TFLiteConverter class from a TensorFlow Session.':'',
'Returns a list of the names of the input tensors.':'',
'List of strings.':'',
'## Class TocoConverter':'',
'This class has been deprecated. Please use lite.TFLiteConverter instead.':'',
'Public API for tf.lite.constants namespace.':'',
'Public API for tf.lite.experimental namespace.':'',
'Converts a graphdef with LiteOp hints into stub operations.':'',
'A new graphdef with all ops contained in OpHints being replaced by a single op call with the right parameters.':'',
'Returns operations potentially supported by TensorFlow Lite.':'',
'A list of SupportedOp.':'',
'Public API for tf.lite.experimental.nn namespace.':'',
'Creates a recurrent neural network specified by RNNCell cell.':'',
'Performs fully dynamic unrolling of inputs.':'',
'## Class TFLiteLSTMCell':'',
'The peephole implementation is based on:':'',
'Initialize the parameters for an LSTM cell.':'',
'Integer or TensorShape: size of outputs produced by this cell.':'',
'size(s) of state(s) used by this cell.':'',
'## Class TfLiteRNNCell':'',
'The most basic RNN cell.':'',
'Initializes the parameters for an RNN cell.':'',
'Logging and Summary Operations.':'',
'Return how much logging output will be produced.':'',
'Log \'msg % args\' at level \'level\' once per \'n\' times.':'',
'Log \'msg % args\' at level \'level\' only first \'n\' times.':'',
'Not threadsafe.':'',
'Log \'msg % args\' at level \'level\' only if condition is fulfilled.':'',
'Sets the threshold for what messages will be logged.':'',
'Public API for tf.lookup namespace.':'',
'## Class StaticHashTable':'',
'A generic hash table that is immutable once initialized.':'',
'A HashTable object.':'',
'The default value of the table.':'',
'The table key dtype.':'',
'The name of the table.':'',
'Returns the resource handle associated with this Resource.':'',
'The table value dtype.':'',
'### export':'',
'Returns tensors of all keys and values in the table.':'',
'A pair of tensors with the first tensor containing all keys and the second tensors containing all values in the table.':'',
'### lookup':'',
'Compute the number of elements in this table.':'',
'A scalar tensor containing the number of elements in this table.':'',
'## Class StaticVocabularyTable':'',
'The Vocabulary object will performs the following mapping:':'',
'Construct a StaticVocabularyTable object.':'',
'Public API for tf.lookup.experimental namespace.':'',
'Loss operations for use in neural networks.':'',
'Adds an Absolute Difference loss to the training procedure.':'',
'Adds a externally defined loss to the collection of losses.':'',
'Computes the weighted loss.':'',
'#### Note:':'',
'a list of loss tensors.':'',
'Gets the total regularization loss.':'',
'A scalar regularization loss.':'',
'Gets the list of regularization losses.':'',
'A list of regularization losses as Tensors.':'',
'Returns a tensor whose value represents the total loss.':'',
'A Tensor whose value represents the total loss.':'',
'Adds a hinge loss to the training procedure.':'',
'Adds a Huber Loss term to the training procedure.':'',
'Adds a Log Loss term to the training procedure.':'',
'A scalar Tensor that returns the weighted loss.':'',
'## Class Reduction':'',
'Types of loss reduction.':'',
'Contains the following values:':'',
'### all':'',
'### validate':'',
'    key':'',
'Operators for manipulating tensors.':'',
'Math Operations.':'',
'TensorFlow provides a variety of math functions including:':'',
'## About Segmentation':'',
'Says whether the targets are in the top K predictions.':'',
'A Tensor of type bool. Computed Precision at k as a bool Tensor.':'',
'For each batch i and class j we have':'',
'A Tensor. Has the same type as logits. Same shape as logits.':'',
'This function performs the equivalent of':'',
'A Tensor. Has the same type and shape as logits.':'',
'Calculates how often predictions matches labels.':'',
'Computes the approximate AUC via a Riemann sum.':'',
'Computes average precision@k of predictions with respect to sparse labels.':'',
'Computes the total number of false negatives.':'',
'Computes false negatives at provided threshold values.':'',
'Sum the weights of false positives.':'',
'Computes false positives at provided threshold values.':'',
'Computes the (weighted) mean of the given values.':'',
'Computes the mean absolute error between the labels and predictions.':'',
'Computes the cosine distance between the labels and predictions.':'',
'Computes the mean relative error by normalizing with the given values.':'',
'Computes the mean squared error between the labels and predictions.':'',
'Computes the percentage of values less than the given threshold.':'',
'Computes the precision of the predictions with respect to the labels.':'',
'Computes precision@k of the predictions with respect to sparse labels.':'',
'Computes precision values for different thresholds on predictions.':'',
'Computes the recall of the predictions with respect to the labels.':'',
'Computes recall@k of the predictions with respect to sparse labels.':'',
'Computes various recall values for different thresholds on predictions.':'',
'Computes the root mean squared error between the labels and predictions.':'',
'Computes the specificity at a given sensitivity.':'',
'Computes true negatives at provided threshold values.':'',
'Computes true positives at provided threshold values.':'',
'Public API for tf.nest namespace.':'',
'Wrappers for primitive Neural Net (NN) Operations.':'',
'Performs the average pooling on the input.':'',
'Each entry in output is the mean of the corresponding size ksize window in value.':'',
'A Tensor with the same type as value. The average pooled output tensor.':'',
'Batch normalization.':'',
'Computes the gradients of convolution with respect to the filter.':'',
'Computes the gradients of convolution with respect to the input.':'',
'A Tensor. Has the same type as filter.':'',
'The transpose of conv2d.':'',
'A Tensor with the same type as value.':'',
'The transpose of conv3d.':'',
'a rank (N+2) filter Tensor of shape':'',
'                       q]':'',
'A Tensor with the same type as input of shape':'',
'Computes Concatenated ReLU.':'',
'A Tensor with the same type as features.':'',
'Performs beam search decoding on the logits given in input.':'',
'Computes the CTC (Connectionist Temporal Classification) Loss.':'',
'This op implements the CTC loss as presented in the article:':'',
'#### Input requirements:':'',
'Here is a table of the (roughly) expected first order behavior:':'',
'Untested. Very likely will not learn to output repeated classes.':'',
'                      c] +':'',
'A Tensor of the same shape of x.':'',
'Looks up ids in a list of embedding tensors.':'',
'A Tensor with the same type as the tensors in params.':'',
'Computes embeddings for the given ids and weights.':'',
'then':'',
'First we define the following:':'',
'Performs the max pooling on the input.':'',
'Performs max pooling on the input and outputs both max values and indices.':'',
'Calculate the mean and variance of x.':'',
'Two Tensor objects: mean and variance.':'',
'Produces the average pool of the input tensor for quantized types.':'',
'Computes a 2D convolution given quantized 4D input and filter tensors.':'',
'Produces the max pool of the input tensor for quantized types.':'',
'while not all(finished):':'',
'Computes and returns the sampled softmax training loss.':'',
'This is a faster way to train a softmax classifier over a huge number of classes.':'',
'This operation is for training only. It is generally an underestimate of the full softmax loss.':'',
'Computes sigmoid cross entropy given logits.':'',
'logits and labels must have the same type and shape.':'',
'A Tensor of the same shape as logits with the componentwise logistic losses.':'',
'Future major versions of TensorFlow will allow gradients to flow into the labels input on backprop by default.':'',
'A Tensor that contains the softmax cross entropy loss. Its type is the same as logits and its shape is the same as labels except that it does not have the last dimension of labels.':'',
'Computes sparse softmax cross entropy between logits and labels.':'',
'A Tensor of the same shape as labels and of the same type as logits with the softmax cross entropy loss.':'',
'The simplest form of RNN network generated is:':'',
'Calculate the sufficient statistics for the mean and variance of x.':'',
'Four Tensor objects of the same type as x:':'',
'A Tensor of the same shape as logits with the componentwise weighted logistic losses.':'',
'Module for constructing RNN Cells.':'',
'## Class BasicLSTMCell':'',
'Basic LSTM recurrent network cell.':'',
'## Class BasicRNNCell':'',
'Operator that ensures an RNNCell runs on a particular device.':'',
'Construct a DeviceWrapper for cell with device device.':'',
'## Class DropoutWrapper':'',
'Operator adding dropout to inputs and outputs of the given cell.':'',
'Otherwise a different dropout mask is applied at every time step.':'',
'Gated Recurrent Unit cell (cf.':'',
'## Class LSTMStateTuple':'',
'    h':'',
'### c':'',
'### h':'',
'## Class MultiRNNCell':'',
'RNN cell composed sequentially of multiple simple cells.':'',
'## Class ResidualWrapper':'',
'RNNCell wrapper that ensures cell inputs are added to the outputs.':'',
'Constructs a ResidualWrapper for cell.':'',
'## Class RNNCell':'',
'Abstract object representing an RNN cell.':'',
'Public API for tf.profiler namespace.':'',
'## Class AdviceProto':'',
'### checkers':'',
'repeated CheckersEntry checkers':'',
'## Class Checker':'',
'### reports':'',
'repeated string reports':'',
'## Class CheckersEntry':'',
'Checker value':'',
'Auto profile and advise.':'',
'Builds profiles and automatically check anomalies of various aspects. For more details: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/README.md':'',
'Returns AdviceProto proto':'',
'## Class GraphNodeProto':'',
'### children':'',
'repeated GraphNodeProto children':'',
'### devices':'',
'repeated string devices':'',
'### shapes':'',
'repeated TensorShapeProto shapes':'',
'## Class InputShapesEntry':'',
'TensorShapeProto value':'',
'## Class OpLogProto':'',
'## Class IdToStringEntry':'',
'string value':'',
'Profile model.':'',
'Tutorials and examples can be found in: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/README.md':'',
'## Class ProfileOptionBuilder':'',
'Option Builder for Profiling API.':'',
'Constructor.':'',
'Whether only account the statistics of displayed profiler nodes.':'',
'self':'',
'### build':'',
'Build a profiling option.':'',
'A dict of profiling options.':'',
'Options used to profile float operations.':'',
'Order the displayed profiler nodes based on a attribute.':'',
'### select':'',
'Select the attributes to display.':'',
'See https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/g3doc/options.md for supported attributes.':'',
'Show operation time and memory consumptions.':'',
'Options used to profile trainable variable parameters.':'',
'Normally used together with \'scope\' view.':'',
'Selectively counting statistics based on node types.':'',
'self.':'',
'Print the result to a file.':'',
'Set the maximum depth of display.':'',
'Regular expressions used to select profiler nodes to display.':'',
'Generate a pprof profile gzip file.':'',
'#### To use the pprof file:':'',
'Print the result to stdout.':'',
'Which profile step to use for profiling.':'',
'Generate a timeline json file.':'',
'## Class Profiler':'',
'https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/README.md':'',
' Typical use case:':'',
'Add statistics of a step.':'',
'### advise':'',
'Automatically detect problems and generate reports.':'',
'A Advise proto that conains the reports from all checkers.':'',
'a GraphNodeProto that records the results.':'',
'a MultiGraphNodeProto that records the results.':'',
'Profile the statistics of the Python codes.':'',
'Serialize the ProfileProto to a binary string.':'',
'Users can write it to file for offline analysis by tfprof commandline or graphical interface.':'',
'ProfileProto binary string.':'',
'Public API for tf.quantization namespace.':'',
'Public API for tf.queue namespace.':'',
'Ragged Tensors.':'',
'### Additional ops that support RaggedTensor':'',
'Arguments that accept RaggedTensors are marked in bold.':'',
'Constructs a RaggedTensorValue from a nested Python list.':'',
'## Class RaggedTensorValue':'',
'Represents the value of a RaggedTensor.':'',
'Creates a RaggedTensorValue.':'',
'The numpy dtype of values in this tensor.':'',
'The innermost values array for this ragged tensor value.':'',
'The number of ragged dimensions in this ragged tensor value.':'',
'The split indices for the ragged tensor value.':'',
'A tuple indicating the shape of this RaggedTensorValue.':'',
'The concatenated values for all rows in this tensor.':'',
'Returns this ragged tensor value as a nested Python list.':'',
'Public API for tf.random namespace.':'',
'Public API for tf.random.experimental namespace.':'',
'Resource management library.':'',
'Get a direct path to the data files colocated with the script.':'',
'Get the path to the specified file in the data dependencies.':'',
'The path is relative to tensorflow/':'',
'Get a root directory containing all the data attributes in the build rule.':'',
'The contents of that resource.':'',
'Readahead files not implemented; simply returns given path.':'',
'## Class Builder':'',
'Builds the SavedModel protocol buffer and saves variables and assets.':'',
'Typical usage for the SavedModelBuilder:':'',
'Adds the current meta graph to the SavedModel.':'',
'Adds the current meta graph to the SavedModel and saves variables.':'',
'### save':'',
'Writes a SavedModel protocol buffer to disk.':'',
'The function writes the SavedModel protocol buffer to the export directory in serialized format.':'',
'The path to which the SavedModel protocol buffer was written.':'',
'Utility function to build a SignatureDef protocol buffer.':'',
'A SignatureDef protocol buffer constructed based on the supplied arguments.':'',
'A TensorInfo protocol buffer constructed based on the supplied argument.':'',
'Creates classification signature from given examples and predictions.':'',
'    scores':'',
'Checks whether the provided export directory could contain a SavedModel.':'',
'Determine whether a SignatureDef can be served by TensorFlow Serving.':'',
'The set of ops to be run as part of the main op upon the load operation.':'',
'Creates prediction signature from given inputs and outputs.':'',
'    outputs':'',
'Creates regression signature from given examples and predictions.':'',
'    predictions':'',
'SavedModel builder.':'',
'#### Typical usage:':'',
'SavedModel main op.':'',
'Builds a main op that defines the sequence of ops to be run as part of the SavedModel load/restore operations.':'',
'Signature constants for SavedModel save and restore operations.':'',
'SignatureDef utility functions.':'',
'Utility functions for building and inspecting SignatureDef protos.':'',
'Common tags used for graphs in SavedModel.':'',
'SavedModel utility functions.':'',
'Utility functions to assist with setup and construction of the SavedModel proto.':'',
'Tensorflow set operations.':'',
'Signal processing operations.':'',
'Sparse Tensor Representation.':'',
'Public API for tf.spectral namespace.':'',
'Operations for working with string Tensors.':'',
'String lengths of input.':'',
'Computes the length of each string given in the input tensor.':'',
'Split elements of input based on sep.':'',
'Let N be the size of input (typically N will be the batch size). Split each element of input based on sep and return a SparseTensor or RaggedTensor containing the split tokens. Empty tokens are ignored.':'',
'result will contain no empty strings at the start or end if the string has':'',
'leading or trailing whitespace.':'',
'Note that the above mentioned behavior matches python\'s str.split.':'',
'according to the delimiter.':'',
'Outputs a Summary protocol buffer with audio.':'',
'A scalar Tensor of type string. The serialized Summary protocol buffer.':'',
'## Class FileWriter':'',
'Writes Summary protocol buffers to event files.':'',
'TensorBoard will pick the graph from the file and display it graphically so you can interactively explore the graph you built. You will usually pass the graph from the session in which you launched it:':'',
'Adds an event to the event file.':'',
'Adds a Graph to the event file.':'',
'The graph described by the protocol buffer will be displayed by TensorBoard. Most users pass a graph in the constructor instead.':'',
'Adds a MetaGraphDef to the event file.':'',
'Adds a metadata information for a single session.run() call.':'',
'Adds a SessionLog protocol buffer to the event file.':'',
'This method wraps the provided session in an Event protocol buffer and adds it to the event file.':'',
'Adds a Summary protocol buffer to the event file.':'',
'This method wraps the provided summary in an Event protocol buffer and adds it to the event file.':'',
'Flushes the event file to disk and close the file.':'',
'Call this method when you do not need the summary writer anymore.':'',
'Flushes the event file to disk.':'',
'Call this method to make sure that all pending events have been written to disk.':'',
'Returns the directory where event file will be written.':'',
'### reopen':'',
'Reopens the EventFileWriter.':'',
'Can be called after close() to add more events in the same directory. The events will go into a new events file.':'',
'Does nothing if the EventFileWriter was not closed.':'',
'## Class FileWriterCache':'',
'Cache for file writers.':'',
'### clear':'',
'Clear cached summary writers. Currently only used for unit tests.':'',
'### get':'',
'Returns the FileWriter for the specified directory.':'',
'A FileWriter.':'',
'Outputs a Summary protocol buffer with a histogram.':'',
'This op reports an InvalidArgument error if any value is not finite.':'',
'Outputs a Summary protocol buffer with images.':'',
'Initializes summary writing for graph execution mode.':'',
'Merges summaries.':'',
'A scalar Tensor of type string. The serialized Summary protocol buffer resulting from the merging.':'',
'Merges all summaries collected in the default graph.':'',
'Outputs a Summary protocol buffer containing a single scalar value.':'',
'The generated Summary has a Tensor.proto containing the input Tensor.':'',
'A scalar Tensor of type string. Which contains a Summary protobuf.':'',
'## Class SummaryDescription':'',
'## Class TaggedRunMetadata':'',
'Outputs a Summary protocol buffer with a serialized tensor.proto.':'',
'Summarizes textual data.':'',
'A TensorSummary op that is configured so that TensorBoard will recognize that it contains textual data. The TensorSummary is a scalar Tensor of type string which contains Summary protobufs.':'',
'System configuration library.':'',
'Testing.':'',
'Asserts that two GraphDefs are (mostly) the same.':'',
'Computes the maximum error for dy/dx between the computed Jacobian and the numerically estimated Jacobian.':'',
'This function will modify the tensors passed in as it adds more operations and hence changing the consumers of the operations of the input tensors.':'',
'The maximum error in between the two Jacobians.':'',
'Returns a temporary directory for use during tests.':'',
'There is no need to delete the directory after the test.':'',
'The temporary directory.':'',
'## Class StubOutForTesting':'',
'Support class for stubbing methods out for unit testing.':'',
'#### Sample Usage:':'',
'You want os.path.exists() to always return true during testing.':'',
'### CleanUp':'',
'### Set':'',
'### SmartSet':'',
'### SmartUnsetAll':'',
'This method is automatically called when the StubOutForTesting() object is deleted; there is no need to call it explicitly.':'',
'### UnsetAll':'',
'Creates an absolute test srcdir path given a relative path.':'',
'An absolute path to the linked in runfiles.':'',
'Ops related to Tensor Processing Units.':'',
'Shards computation along the batch dimension for parallel execution.':'',
'Convenience wrapper around shard().':'',
'A list of output tensors.':'',
'Scope class for bfloat16 variables so that the model uses custom getter.':'',
'Returns the device name for a core in a replicated TPU computation.':'',
'## Class CrossShardOptimizer':'',
'An optimizer that averages gradients across TPU shards.':'',
'Apply gradients to variables.':'',
'Return a slot named "name" created for "var" by the Optimizer.':'',
'Return a list of the names of slots created by the Optimizer.':'',
'A list of strings.':'',
'### minimize':'',
'Forwarding the variables from the underlying optimizer.':'',
'A Tensor which is summed across replicas.':'',
'Initializes a distributed TPU system for use with TensorFlow.':'',
'A serialized TopologyProto that describes the TPU system. Note: the topology must be evaluated using Session.run before it can be used.':'',
'Builds part of a computation outside any current TPU replicate scope.':'',
'The Tensors returned by computation.':'',
'Builds a graph operator that runs a replicated TPU computation.':'',
'Rewrites computation for execution on a TPU system.':'',
'Shards computation for parallel execution.':'',
'TODO(phawkins): consider adding support for broadcasting Tensors passed as inputs.':'',
'Shuts down a running a distributed TPU system.':'',
'Public API for tf.tpu.experimental namespace.':'',
'## Class AdagradParameters':'',
'Optimization parameters for Adagrad with TPU embeddings.':'',
'Optimization parameters for Adagrad.':'',
'## Class AdamParameters':'',
'Optimization parameters for Adam with TPU embeddings.':'',
'Optimization parameters for Adam.':'',
'## Class StochasticGradientDescentParameters':'',
'Optimization parameters for stochastic gradient descent for TPU embeddings.':'',
'Optimization parameters for stochastic gradient descent.':'',
'Support for training models.':'',
'## Class AdadeltaOptimizer':'',
'Optimizer that implements the Adadelta algorithm.':'',
'Construct a new Adadelta optimizer.':'',
'This is the second part of minimize(). It returns an Operation that applies gradients.':'',
'    name':'',
'Return a slot named name created for var by the Optimizer.':'',
'Some Optimizer subclasses use additional variables. For example Momentum and Adagrad use variables to accumulate updates. This method gives access to these Variable objects if for some reason you need them.':'',
'A list of variables which encode the current state of Optimizer.':'',
'Includes slot variables and additional global variables created by the optimizer in the current default graph.':'',
'A list of variables.':'',
'## Class AdagradDAOptimizer':'',
'Adagrad Dual Averaging algorithm for sparse linear models.':'',
'AdagradDA is typically used when there is a need for large sparsity in the trained model. This optimizer only guarantees sparsity for linear models. Be careful when using AdagradDA for deep networks as it will require careful initialization of the gradient accumulators for it to train.':'',
'Construct a new AdagradDA optimizer.':'',
'## Class AdagradOptimizer':'',
'Optimizer that implements the Adagrad algorithm.':'',
'Construct a new Adagrad optimizer.':'',
'## Class AdamOptimizer':'',
'Optimizer that implements the Adam algorithm.':'',
'Construct a new Adam optimizer.':'',
'#### Initialization:':'',
'The update rule for variable with gradient g uses an optimization described at the end of section 2 of the paper:':'',
'When building a complex model that uses many queues it is often difficult to gather all the queue runners that need to be run. This convenience function allows you to add a queue runner to a well known collection in the graph.':'',
'Basic loop to train a model.':'',
'The argument tensors can be a list or a dictionary of tensors. The value returned by the function will be of the same type as tensors.':'',
'The capacity argument controls the how long the prefetching is allowed to grow the queues.':'',
'## Class Checkpoint':'',
'Example usage when graph building:':'',
'Example usage with eager execution enabled:':'',
'Group objects into a training checkpoint.':'',
'An integer variable which starts at zero and is incremented on save.':'',
'Used to number checkpoints.':'',
'The save counter variable.':'',
'### restore':'',
'Restore a training checkpoint.':'',
'Restores this Checkpoint and any objects it depends on.':'',
'The returned status object has the following methods:':'',
'Saves a training checkpoint and provides basic checkpoint management.':'',
'The saved checkpoint includes variables created by this object and any trackable objects it depends on at the time Checkpoint.save() is called.':'',
'The full path to the checkpoint.':'',
'Writes a training checkpoint.':'',
'The checkpoint includes variables created by this object and any trackable objects it depends on at the time Checkpoint.write() is called.':'',
'## Class ChiefSessionCreator':'',
'Creates a tf.compat.v1.Session for a chief.':'',
'Initializes a chief session creator.':'',
'Applies cosine decay to the learning rate.':'',
'The function returns the decayed learning rate. It is computed as:':'',
'Applies cosine decay with restarts to the learning rate.':'',
'Create global step tensor in graph.':'',
'Global step tensor.':'',
'Applies exponential decay to the learning rate.':'',
'Returns MetaGraphDef proto.':'',
'Optionally writes it to filename.':'',
'A MetaGraphDef proto.':'',
'## Class FtrlOptimizer':'',
'Optimizer that implements the FTRL algorithm.':'',
'Construct a new FTRL optimizer.':'',
'Generates a checkpoint state proto.':'',
'A list of mtimes (in microseconds) of the found checkpoints.':'',
'Get the global step tensor.':'',
'Returns and create (if necessary) the global step tensor.':'',
'The global step tensor.':'',
'Small helper to get the global step.':'',
'The global step value.':'',
'## Class GradientDescentOptimizer':'',
'Optimizer that implements the gradient descent algorithm.':'',
'Construct a new gradient descent optimizer.':'',
'Recreates a Graph saved in a MetaGraphDef proto.':'',
'Later this model can be restored and contents loaded.':'',
'Exporting/importing meta graphs is not supported. No graph exists when eager execution is enabled.':'',
'Assignment map supports following syntax:':'',
'Applies inverse time decay to the initial learning rate.':'',
'tensor or OutOfRange.':'',
'Applies linear cosine decay to the learning rate.':'',
'Note that linear cosine decay is more aggressive than cosine decay and larger initial learning rates can typically be used.':'',
'## Class LooperThread':'',
'Before each run the thread checks if the coordinator has requested stop. In that case the looper thread terminates immediately.':'',
'You typically pass looper threads to the supervisor Join() method.':'',
'Create a LooperThread.':'',
'### daemon':'',
'A boolean value indicating whether this thread is a daemon thread.':'',
'### ident':'',
'Thread identifier of this thread or None if it has not been started.':'',
'A string used for identification purposes only.':'',
'It has no semantics. Multiple threads may be given the same name. The initial name is set by the constructor.':'',
'### getName':'',
'### isAlive':'',
'Return whether the thread is alive.':'',
'This method returns True just before the run() method starts until just after the run() method terminates. The module function enumerate() returns a list of all alive threads.':'',
'### isDaemon':'',
'### join':'',
'Wait until the thread terminates.':'',
'A thread can be join()ed many times.':'',
'join() raises a RuntimeError if an attempt is made to join the current thread as that would cause a deadlock. It is also an error to join() a thread before it has been started and attempts to do so raises the same exception.':'',
'### loop':'',
'Start a LooperThread that calls a function periodically.':'',
'The started thread.':'',
'Method representing the thread\'s activity.':'',
'### setDaemon':'',
'### setName':'',
'### start':'',
'Start the thread\'s activity.':'',
'It must be called at most once per thread object. It arranges for the object\'s run() method to be invoked in a separate thread of control.':'',
'This method will raise a RuntimeError if called more than once on the same thread object.':'',
'Called when the thread starts.':'',
'Called when the thread stops.':'',
'See docstring in batch for more details.':'',
'A list or dictionary of tensors with the same types as tensors.':'',
'A list or dictionary of tensors with the types as tensors.':'',
'## Class MomentumOptimizer':'',
'Optimizer that implements the Momentum algorithm.':'',
'Construct a new Momentum optimizer.':'',
'## Class MonitoredSession':'',
'Initialization: At creation time the monitored session does following things in given order:':'',
'See MonitoredTrainingSession for an example usage based on chief or worker.':'',
'A MonitoredSession object.':'',
'Sets up a Monitored or Hooked Session.':'',
'Run ops in the monitored session.':'',
'This method is completely compatible with the tf.Session.run() method.':'',
'Same as tf.Session.run().':'',
'Run ops using a step function.':'',
'## Class StepContext':'',
'### session':'',
'StopIteration':'',
'Same as MonitoredSession.run. Accepts the same arguments.':'',
'Creates a MonitoredSession for training.':'',
'Applies natural exponential decay to the initial learning rate.':'',
'Applies noisy linear cosine decay to the learning rate.':'',
'## Class Optimizer':'',
'Base class for optimizers.':'',
'### Usage':'',
'In the training program you will just have to run the returned Op.':'',
'### Processing gradients before applying them.':'',
'Calling minimize() takes care of both computing the gradients and applying them to the variables. If you want to process the gradients before applying them you can instead use the optimizer in three steps:':'',
'### Gating Gradients':'',
'### Slots':'',
'Create a new Optimizer.':'',
'This must be called by the constructors of subclasses.':'',
'Piecewise constant from boundaries and interval values.':'',
'Applies a polynomial decay to the learning rate.':'',
'## Class ProximalAdagradOptimizer':'',
'Optimizer that implements the Proximal Adagrad algorithm.':'',
'Construct a new ProximalAdagrad optimizer.':'',
'## Class ProximalGradientDescentOptimizer':'',
'Optimizer that implements the proximal gradient descent algorithm.':'',
'Construct a new proximal gradient descent optimizer.':'',
'## Class QueueRunner':'',
'On construction the QueueRunner adds an op to close the queue. That op will be run if the enqueue ops raise exceptions.':'',
'Exceptions raised but not handled by the QueueRunner threads.':'',
'The string name of the underlying Queue.':'',
'### queue':'',
'Create threads to run the enqueue ops for the given session.':'',
'A list of threads.':'',
'Converts this QueueRunner to a QueueRunnerDef protocol buffer.':'',
'Return a device function to use when building a Graph for replicas.':'',
'## Class RMSPropOptimizer':'',
'Optimizer that implements the RMSProp algorithm.':'',
'Construct a new RMSProp optimizer.':'',
'## Class Saver':'',
'Saves and restores variables.':'',
'The Saver class adds ops to save and restore variables to and from checkpoints. It also provides convenience methods to run these ops.':'',
'Checkpoints are binary files in a proprietary format which map variable names to tensor values. The best way to examine the contents of a checkpoint is to load it using a Saver.':'',
'Note that you still have to call the save() method to save the model. Passing these arguments to the constructor will not save variables automatically for you.':'',
'A training program that saves regularly looks like:':'',
'Creates a Saver.':'',
'The constructor adds ops to save and restore variables.':'',
'You can pass any of the returned values to restore().':'',
'Generates a SaverDef representation of this saver.':'',
'A SaverDef proto.':'',
'Recovers the internal saver state after a crash.':'',
'Restores previously saved variables.':'',
'Saves variables.':'',
'This method runs the ops added by the constructor for saving variables. It requires a session in which the graph was launched. The variables to save must also have been initialized.':'',
'The method returns the path prefix of the newly created checkpoint files. This string can be passed directly to a call to restore().':'',
'Sets the list of old checkpoint filenames.':'',
'Sets the list of old checkpoint filenames and timestamps.':'',
'Converts this Saver to a SaverDef protocol buffer.':'',
'A SaverDef protocol buffer.':'',
'## Class SaverDef':'',
'### sharded':'',
'CheckpointFormatVersion version':'',
'## Class Scaffold':'',
'Structure to create or gather pieces commonly needed to train a model.':'',
'The following pieces are directly accessible as attributes of the Scaffold object:':'',
'You can also pass the following additional pieces to the constructor:':'',
'Create a scaffold.':'',
'### saver':'',
'Returns an op that groups the default local init ops.':'',
'The default Scaffold local init op.':'',
'Creates operations if needed and finalizes the graph.':'',
'Get from cache or create a default operation.':'',
'Computes fingerprints of the input strings.':'',
'Distributed version of Stochastic Dual Coordinate Ascent (SDCA) optimizer for':'',
'Applies L1 regularization shrink step on the parameters.':'',
'## Class SessionCreator':'',
'A factory for tf.Session.':'',
'## Class SessionManager':'',
'Training helper that restores from checkpoint and creates session.':'',
'This class is a small wrapper that takes care of session creation and checkpoint recovery. It also provides functions that to facilitate coordination among multiple training threads or processes.':'',
'### Usage:':'',
'A second process could wait for the model to be ready by doing the following:':'',
'Creates a SessionManager.':'',
'Creates a Session. Makes sure the model is ready to be used.':'',
'A Session object that can be used to drive the model.':'',
'Creates a new Session and waits for model to be ready.':'',
'This function adds the following to the current Graph:':'',
'This version enqueues a different list of tensors in different threads. It adds the following to the current Graph:':'',
'## Class SingularMonitoredSession':'',
'To `run` without hooks.':'',
'To save and restore.':'',
'Initialization: At creation time the hooked session does following things in given order:':'',
'Creates a SingularMonitoredSession.':'',
'Returns underlying TensorFlow.Session object.':'',
'An iterator for reading Event protocol buffers from an event file.':'',
'You can use this function to read events written to an event file. It returns a Python iterator that yields Event protocol buffers.':'',
'Example: Print the contents of an events file.':'',
'Example: Print selected summary values.':'',
'Event protocol buffers.':'',
'## Class Supervisor':'',
'A training helper that checkpoints models and computes summaries.':'',
'#### Use for a single program':'',
'#### Use for multiple replicas':'',
'The only change you have to do to the single program code is to indicate if the program is running as the chief.':'',
'NOTE: This modified program still works fine as a single program. The single program marks itself as the chief.':'',
'#### What master string to use':'',
'#### Advanced use':'',
'##### Launching additional services':'',
'##### Launching fewer services':'',
'##### Custom model initialization':'',
'A Supervisor.':'',
'Supervisors are not supported when eager execution is enabled.':'',
'### coord':'',
'Return the Coordinator used by the Supervisor.':'',
'The Coordinator can be useful if you want to run multiple threads during your training.':'',
'A Coordinator object.':'',
'A feed dictionary or None.':'',
'Return the Init Op used by the supervisor.':'',
'An Op or None.':'',
'Return True if this is a chief supervisor.':'',
'A bool.':'',
'Return the Ready Op used by the supervisor.':'',
'Return the delay between checkpoints.':'',
'A timestamp.':'',
'Return the save path used by the supervisor.':'',
'A string.':'',
'Return the delay between summary computations.':'',
'Return the Saver used by the supervisor.':'',
'A Saver object.':'',
'Return the SessionManager used by the Supervisor.':'',
'A SessionManager object.':'',
'Return the Summary Tensor used by the chief supervisor.':'',
'A string Tensor for the summary or None.':'',
'Return the SummaryWriter used by the chief supervisor.':'',
'A SummaryWriter.':'',
'### Loop':'',
'The started thread is added to the list of threads managed by the supervisor so it does not need to be passed to the stop() method.':'',
'### PrepareSession':'',
'Make sure the model is ready to be used.':'',
'### RequestStop':'',
'Request that the coordinator stop the threads.':'',
'### ShouldStop':'',
'Check if the coordinator was told to stop.':'',
'### StartQueueRunners':'',
'Start threads for QueueRunners.':'',
'The list of threads started for the QueueRunners.':'',
'### StartStandardServices':'',
'Start the standard services for \'sess\'.':'',
'This starts services in the background. The services started depend on the parameters to the constructor and may include:':'',
'### Stop':'',
'Stop the services and the coordinator.':'',
'This does not close the session.':'',
'### StopOnException':'',
'Context handler to stop the supervisor when an exception is raised.':'',
'A context handler.':'',
'### SummaryComputed':'',
'Indicate that a summary was computed.':'',
'### WaitForStop':'',
'Block waiting for the coordinator to stop.':'',
'Returns a context manager for a managed session.':'',
'This context manager creates and automatically recovers a session. It optionally starts the standard services that handle checkpoints and summaries. It monitors exceptions raised from the with block or from the services and stops the supervisor as needed.':'',
'The context manager is typically used as follows:':'',
'        break':'',
'If you want to retry the training loop in case of preemption you can do it as follows:':'',
'  while True':'',
'    except tf.errors.Aborted:':'',
'      pass':'',
'A context manager that yields a Session restored from the latest checkpoint or initialized from scratch if not checkpoint exists. The session is closed when the with block exits.':'',
'### stop':'',
'## Class SyncReplicasOptimizer':'',
'The following accumulators/queue are created:':'',
'The optimizer adds nodes to the graph to collect gradients and pause the trainers until variables are updated. For the Parameter Server job:':'',
'#### For the replicas:':'',
'Returns the QueueRunner for the chief to execute.':'',
'A QueueRunner for chief to execute.':'',
'An op for the chief/sync replica to fill the token queue.':'',
'Creates a hook to handle SyncReplicasHook ops such as initialization.':'',
'Fetches a list of optimizer variables in the default graph.':'',
'This wraps variables() from the actual optimizer. It does not include the SyncReplicasOptimizer\'s local step.':'',
'This updates the checkpoint file containing a CheckpointState proto.':'',
'## Class WorkerSessionCreator':'',
'Creates a tf.compat.v1.Session for a worker.':'',
'Initializes a worker session creator.':'',
'Public API for tf.train.experimental namespace.':'',
'Disables the mixed precision graph rewrite.':'',
'Enable mixed precision via a graph rewrite.':'',
'A version of opt that will use loss scaling to prevent underflow.':'',
'## Class MixedPrecisionLossScaleOptimizer':'',
'An optimizer that applies loss scaling.':'',
'This adjusts the dynamic range of the gradient evaluation by scaling up the loss value. The gradient values are then scaled back down by the recipricol of the loss scale. This is useful in reduced precision training where small gradient values would otherwise underflow the representable range.':'',
'Example of overriding the generated code for an Op.':'',
'Public API for tf.version namespace.':'',
'Public API for tf.xla namespace.':'',
'Public API for tf.xla.experimental namespace.':'',
'Public API for tf.config.threading namespace.':'',
'## Glossary':'',
'##Modules':'',
'Library imports for ClusterResolvers.':'',
'Experimental Distribution Strategy library.':'',
'ResNet models for Keras.':'',
'ResNet v2 models for Keras.':'',
'VGG16 model for Keras.':'',
'VGG19 model for Keras.':'',
'Mixed precision API.':'',
'Connects to the given cluster.':'',
'Connects to a single machine to enable remote execution on it.':'',
'List the names of the available devices.':'',
'This can be useful for debugging or profiling.':'',
'Get if soft device placement is enabled.':'',
'If soft placement is enabled.':'',
'Set if soft device placement is enabled.':'',
'Gets the current device policy.':'',
'This function only gets the device policy for the current thread. Any subsequently started thread will again use the default policy.':'',
'Current thread device policy':'',
'Get if memory growth is enabled for a PhysicalDevice.':'',
'A PhysicalDevice with memory growth set will not allocate all memory on the device upfront.':'',
'Current memory growth setting.':'',
'Gets whether operations are executed synchronously or asynchronously.':'',
'Current thread execution mode':'',
'Get the virtual device configuration for a PhysicalDevice.':'',
'Get the list of visible physical devices.':'',
'Returns a list of PhysicalDevice objects that are current marked as visible to the runtime. Any visible devices will have LogicalDevices assigned to them once the runtime is initialized.':'',
'The following example verifies all visible GPUs have been disabled:':'',
'List of PhysicalDevice objects':'',
'Return a list of logical devices created by runtime.':'',
'Logical devices may correspond to physical devices or remote devices in the cluster. Operations and tensors may be placed on these devices by using the name of the LogicalDevice.':'',
'List of LogicalDevice objects':'',
'Return a list of physical devices visible to the runtime.':'',
'The following example ensures the machine can see at least 1 GPU.':'',
'Sets the current thread device policy.':'',
'This function only sets the device policy for the current thread. Any subsequently started thread will again use the default policy.':'',
'Set if memory growth should be enabled for a PhysicalDevice.':'',
'    enable':'',
'A PhysicalDevice with memory growth set will not allocate all memory on the device upfront. Memory growth cannot be configured on a PhysicalDevice with virtual devices configured.':'',
'Specifies whether operations are executed synchronously or asynchronously.':'',
'True: executes each operation synchronously.':'',
'False: executes each operation asynchronously.':'',
'Set the virtual device configuration for a PhysicalDevice.':'',
'A PhysicalDevice marked as visible will by default have a single LogicalDevice allocated to it once the runtime is configured. Specifying a list of tf.config.experimental.VirtualDeviceConfiguration objects allows multiple devices to be configured that utilize the same PhysicalDevice.':'',
'The following example splits the CPU into 2 virtual devices:':'',
'except:':'',
'Set the list of visible devices.':'',
'Sets the list of PhysicalDevices to be marked as visible to the runtime. Any devices that are not marked as visible means TensorFlow will not allocate memory on it and will not be able to place any operations on it as no LogicalDevice will be created on it. By default all discovered devices are marked as visible.':'',
'The following example demonstrates disabling the first GPU on the machine.':'',
'## Class VirtualDeviceConfiguration':'',
'Configuration class for virtual devices for a PhysicalDevice.':'',
'#### Fields:':'',
'Get experimental optimizer options.':'',
'Dictionary of configured experimental optimizer options':'',
'Get if JIT compilation is enabled.':'',
'If JIT compilation is enabled.':'',
'Set experimental optimizer options.':'',
'remapping: Remap subgraphs onto more efficient implementations.':'',
'Set if JIT compilation is enabled.':'',
'Get number of threads used for parallelism between independent operations.':'',
'Number of parallel threads':'',
'Get number of threads used within an individual op for parallelism.':'',
'Set number of threads used for parallelism between independent operations.':'',
'Set number of threads used within an individual op for parallelism.':'',
'#### Example elements:':'',
'## Class DatasetSpec':'',
'## Class Options':'',
'Represents options for tf.data.Dataset.':'',
'### merge':'',
'A transformation that buckets elements in a Dataset by length.':'',
'Elements of the Dataset are grouped together by length and then are padded and batched.':'',
'This is useful for sequence tasks in which the elements have variable length. Grouping together elements that have similar lengths reduces the total fraction of padding in a batch which increases training step efficiency.':'',
'Records the number of bytes produced by each element of the input dataset.':'',
'## Class CheckpointInputPipelineHook':'',
'Checkpoints input pipeline state every N steps or seconds.':'',
'Differences from CheckpointSaverHook: 1. Saves only the input pipelines in the "iterators" collection and not the global variables or other saveable objects. 2. Does not write the GraphDef and MetaGraphDef to the summary.':'',
'Example of checkpointing the training pipeline:':'',
'while True:':'',
'    break':'',
'Initializes a CheckpointInputPipelineHook.':'',
'    coord':'',
'Called when new TensorFlow session is created.':'',
'This is called to signal the hooks that a new session has been created. This has two essential differences with the situation in which begin is called:':'',
'Called after each call to run().':'',
'Called before each call to run().':'',
'You can return from this call a SessionRunArgs object indicating ops or tensors to add to the upcoming run() call. These ops/tensors will be run together with the ops/tensors originally passed to the original run() call. The run args you return can also contain feeds to be added to the run() call.':'',
'At this point graph is finalized and you can not add ops.':'',
'### begin':'',
'Called once before using the session.':'',
'### end':'',
'Called at the end of session.':'',
'Creates a dataset that deterministically chooses elements from datasets.':'',
'The elements of result will be:':'',
'Creates a Dataset that counts from start in steps of size step.':'',
'A Dataset of scalar dtype elements.':'',
'## Class CsvDataset':'',
'A Dataset comprising lines from one or more CSV files.':'',
'Creates a CsvDataset by reading and decoding CSV files.':'',
'We can construct a CsvDataset from it as follows:':'',
'The expected output of its iterations is:':'',
'## Class DistributeOptions':'',
'Represents options for distributed data processing.':'',
'The number of devices attached to this input pipeline. This will be automatically set by MultiDeviceIterator.':'',
'It is similar to python\'s enumerate. For example:':'',
'Constructs a dataset from the given variant and structure.':'',
'    structure':'',
'Returns an Optional that contains the next value from the iterator.':'',
'An Optional object representing the next value from the iterator (if it has one) or no value.':'',
'Returns the single element in dataset as a nested structure of tensors.':'',
'Returns the type specification of an element of a Dataset or Iterator.':'',
'A transformation that groups elements and performs a reduction.':'',
'    reducer':'',
'A transformation that groups windows of elements by key and reduces them.':'',
'Creates a Dataset from another Dataset and silently ignores any errors.':'',
'InvalidArgumentError.':'',
'Records the latency of producing each element of the input dataset.':'',
'Reads CSV files into a dataset.':'',
'Returns a SaveableObject for saving/restoring iterator state using Saver.':'',
'A SaveableObject for saving/restoring iterator state using Saver.':'',
'## Class MapVectorizationOptions':'',
'Represents options for the MapVectorization optimization.':'',
'### enabled':'',
'## Class OptimizationOptions':'',
'Represents options for dataset optimizations.':'',
'### autotune':'',
'Wraps a value that may/may not be present at runtime.':'',
'Optional can only be used by values that are convertible to Tensor or CompositeTensor.':'',
'The structure of the components of this optional.':'',
'A Structure object representing the structure of the components of this optional.':'',
'Returns an Optional that wraps the given value.':'',
'An Optional that wraps value.':'',
'Returns the value wrapped by this optional.':'',
'The wrapped value.':'',
'Returns a tensor that evaluates to True if this optional has a value.':'',
'Returns an Optional that has no value.':'',
'NOTE: This method takes an argument that defines the structure of the value that would be contained in the returned Optional if it had a value.':'',
'An Optional that has no value.':'',
'A transformation that parses Example protos into a dict of tensors.':'',
'A transformation that prefetches dataset values to the given device.':'',
'## Class RandomDataset':'',
'A Dataset of pseudorandom values.':'',
'## Class Reducer':'',
'A reducer is used for reducing a set of elements.':'',
'A transformation that resamples a dataset to achieve a target distribution.':'',
'NOTE Resampling is performed via rejection sampling; some fraction of the input values will be dropped.':'',
'Samples elements at random from the datasets in datasets.':'',
'A transformation that scans a function across an input dataset.':'',
'## Class SqlDataset':'',
'A Dataset consisting of the results from a SQL query.':'',
'Creates a SqlDataset.':'',
'SqlDataset allows a user to read data from the result set of a SQL query. For example:':'',
'## Class StatsAggregator':'',
'A stateful resource that aggregates statistics from one or more iterators.':'',
'## Class StatsOptions':'',
'Represents options for collecting dataset stats using StatsAggregator.':'',
'### aggregator':'',
'Associates the given statistics aggregator with the dataset pipeline.':'',
'Prefix for the statistics recorded as counter.':'',
'Whether to add latency measurements on all edges. Defaults to False.':'',
'### prefix':'',
'Prefix to prepend all statistics recorded for the input dataset with.':'',
'A transformation that stops dataset iteration based on a predicate.':'',
'## Class TFRecordWriter':'',
'Writes data to a TFRecord file.':'',
'To write a dataset to a single TFRecord file:':'',
'To shard a dataset across multiple TFRecord files:':'',
'## Class ThreadingOptions':'',
'Represents options for dataset threading.':'',
'Returns a variant representing the given dataset.':'',
'Use this transformation to produce a dataset that contains one instance of each unique element in the input. For example:':'',
'Asserts that the given condition is true.':'',
'Same tensor as x.':'',
'Static assert that values is a "proper" iterable.':'',
'Assert that x has rank equal to rank.':'',
'This Op checks that the rank of x is equal to rank.':'',
'Assert that x has rank of at least rank.':'',
'This Op checks that the rank of x is greater or equal to rank.':'',
'Assert that x has a rank in ranks.':'',
'This Op checks that the rank of x is in ranks.':'',
'Validate and return float type based on tensors and dtype.':'',
'Validated type.':'',
'Asserts that the given tensor is a scalar.':'',
'Asserts that the given Tensor is of the specified type.':'',
'Checks a tensor for NaN and Inf values.':'',
'Get if device placements are logged.':'',
'If device placements are logged.':'',
'Returns True if the elements of tensor are numbers.':'',
'Set if device placements should be logged.':'',
'## Class CrossDeviceOps':'',
'Reduce PerReplica objects in a batch.':'',
'a list of Mirrored objects.':'',
'Implementation of reduce PerReplica objects in a batch.':'',
'### broadcast':'',
'Broadcast the tensor to destinations.':'',
'a Mirrored object.':'',
'Implementation of broadcast the tensor to destinations.':'',
'#### Note that execution:':'',
'True if inside a with strategy.scope():.':'',
'## Class HierarchicalCopyAllReduce':'',
'Initializes the object.':'',
'## Class InputContext':'',
'A class wrapping information needed by an input function.':'',
'Initializes an InputContext object.':'',
'Returns the input pipeline ID.':'',
'Returns the number of input pipelines.':'',
'Returns the number of compute replicas in sync.':'',
'## Class InputReplicationMode':'',
'Replication mode for input function.':'',
'    axis':'',
'## Class NcclAllReduce':'',
'A "distributed Dataset" that the caller can iterate over.':'',
'Return value from running fn.':'',
'A context manager to use for creating variables with this strategy.':'',
'## Class ReduceOp':'',
'Indicates how a set of values should be reduced.':'',
'## Class ReductionToOneDevice':'',
'Always do reduction to one device first and then do broadcasting.':'',
'Batch reduction is done by reduction on each element one by one.':'',
'## Class ReplicaContext':'',
'Returns the id of the replica being defined.':'',
'### strategy':'',
'IMPORTANT: The ordering of communications must be identical in all replicas.':'',
'A Tensor nest with the reduced values from each replica.':'',
'## Class Server':'',
'Creates a new server with the given definition.':'',
'### target':'',
'A string containing a session target for this server.':'',
'Blocks until the server has shut down.':'',
'This method currently blocks forever.':'',
'Starts this server.':'',
'A state & compute distribution policy on a list of devices.':'',
'#### In short:':'',
'A custom training loop can be as simple as:':'',
'## Class ClusterResolver':'',
'Abstract class for all implementations of ClusterResolvers.':'',
'### environment':'',
'Returns the current environment which TensorFlow is running in.':'',
'Retrieve the current state of the cluster and return a ClusterSpec.':'',
'A ClusterSpec representing the state of the cluster at the moment this function is called.':'',
'Retrieves the name or URL of the session master.':'',
'The name or URL of the session master.':'',
'Returns the number of accelerator cores per worker.':'',
'This returns the number of accelerator cores (such as GPUs and TPUs) available per worker.':'',
'A map of accelerator types to number of cores.':'',
'## Class GCEClusterResolver':'',
'ClusterResolver for Google Compute Engine.':'',
'Creates a new GCEClusterResolver object.':'',
'This takes in a few parameters and creates a GCEClusterResolver project. It will then use these parameters to query the GCE API for the IP addresses of each instance in the instance group.':'',
'Returns a ClusterSpec object based on the latest instance group info.':'',
'This returns a ClusterSpec object for use based on information from the specified instance group. We will retrieve the information from the GCE APIs every time this method is called.':'',
'A ClusterSpec containing host information retrieved from GCE.':'',
'## Class KubernetesClusterResolver':'',
'ClusterResolver for Kubernetes.':'',
'Initializes a new KubernetesClusterResolver.':'',
'This initializes a new Kubernetes ClusterResolver. The ClusterResolver will attempt to talk to the Kubernetes master to retrieve all the instances of pods matching a label selector.':'',
'Returns a ClusterSpec object based on the latest info from Kubernetes.':'',
'We retrieve the information from the Kubernetes master every time this method is called.':'',
'A ClusterSpec containing host information returned from Kubernetes.':'',
'Returns the master address to use when creating a session.':'',
'## Class SimpleClusterResolver':'',
'Simple implementation of ClusterResolver that accepts a ClusterSpec.':'',
'Creates a SimpleClusterResolver from a ClusterSpec.':'',
'Returns the ClusterSpec passed into the constructor.':'',
'## Class SlurmClusterResolver':'',
'ClusterResolver for system with Slurm workload manager.':'',
'Creates a new SlurmClusterResolver object.':'',
'This takes in parameters and creates a SlurmClusterResolver object. It uses those parameters to check which nodes will processes reside on and resolves their hostnames. With the number of the GPUs on each node and number of GPUs for each task it offsets the port number for each process and allocates GPUs to tasks by setting environment variables. The resolver currently supports homogeneous tasks and default Slurm process allocation.':'',
'A ClusterResolver object which can be used with distributed TensorFlow.':'',
'A ClusterSpec containing host information retrieved from Slurm\'s environment variables.':'',
'A string specifying job name the process belongs to and an integner specifying the task index the process belongs to in that job.':'',
'Returns the master string for connecting to a TensorFlow master.':'',
'A connection string for connecting to a TensorFlow master.':'',
'## Class TFConfigClusterResolver':'',
'Creates a new TFConfigClusterResolver.':'',
'Returns the master address to use when creating a TensorFlow session.':'',
'The address of the master.':'',
'## Class TPUClusterResolver':'',
'Cluster Resolver for Google Cloud TPUs.':'',
'TPUClusterResolver supports the following distinct environments: Google Compute Engine Google Kubernetes Engine Google internal':'',
'Creates a new TPUClusterResolver object.':'',
'The ClusterResolver will then use the parameters to query the Cloud TPU APIs for the IP addresses and ports of each Cloud TPU listed.':'',
'Returns a ClusterSpec object based on the latest TPU information.':'',
'We retrieve the information from the GCE APIs every time this method is called.':'',
'Get the Master string to be used for the session.':'',
'Returns the number of TPU cores per worker.':'',
'## Class UnionResolver':'',
'Performs a union on underlying ClusterResolvers.':'',
'Initializes a UnionClusterResolver with other ClusterResolvers.':'',
'Returns a union of all the ClusterSpecs from the ClusterResolvers.':'',
'A ClusterSpec containing host information merged from all the underlying ClusterResolvers.':'',
'## Class CentralStorageStrategy':'',
'#### For Example:':'',
'The returned dataset is a wrapped strategy dataset which creates a multidevice iterator under the hood. It prefetches the input data to the specified devices on the worker. The returned distributed dataset can be iterated over similar to how regular datasets can.':'',
'In CentralStorageStrategy there is a single worker so the value returned will be all the values on that worker.':'',
'## Class CollectiveCommunication':'',
'Communication choices for CollectiveOps.':'',
'## Class MultiWorkerMirroredStrategy':'',
'A distribution strategy for synchronous training on multiple workers.':'',
'Creates the strategy.':'',
'## Class ParameterServerStrategy':'',
'This strategy requires two jobs: workers and parameter servers. Variables and updates to those variables will be assigned to parameter servers and other operations are assigned to workers.':'',
'## Class TPUStrategy':'',
'TPU distribution strategy implementation.':'',
'Initializes the TPUStrategy object.':'',
'Casts a tensor to a new type.':'',
'The operation casts x (in case of Tensor) or x.values (in case of SparseTensor or IndexedSlices) to dtype.':'',
'A Tensor or SparseTensor or IndexedSlices with same shape as x and same type as dtype.':'',
'Converts two real numbers to a complex number.':'',
'The input tensors real and imag must have the same shape.':'',
'A Tensor of type complex64 or complex128.':'',
'## Class DType':'',
'Represents the type of the elements in a Tensor.':'',
'The following DType objects are defined:':'',
'Creates a new DataType.':'',
'Returns a numpy.dtype based on this DType.':'',
'Returns whether this is a boolean data type':'',
'Returns whether this is a complex floating point type.':'',
'Returns whether this is a quantized data type.':'',
'Returns whether this type is unsigned.':'',
'Whether a DType is unsigned.':'',
'### limits':'',
'Returns the maximum representable value in this data type.':'',
'Returns the minimum representable value in this data type.':'',
'Returns the string name for this DType.':'',
'Returns the dtype correspond to this dtype\'s real part.':'',
'Returns True iff this DType refers to the same type as other.':'',
'Returns True if the other DType will be converted to this DType.':'',
'The conversion rules are as follows:':'',
'True if a Tensor of the other DType will be implicitly converted to this DType.':'',
'Performs a safe saturating cast of value to dtype.':'',
'value safely cast to dtype.':'',
'## Class AbortedError':'',
'    message':'',
'Creates an AbortedError.':'',
'The integer error code that describes the error.':'',
'The error message that describes the error.':'',
'The NodeDef proto representing the op that failed.':'',
'## Class AlreadyExistsError':'',
'Raised when an entity that we attempted to create already exists.':'',
'Creates an AlreadyExistsError.':'',
'## Class CancelledError':'',
'Raised when an operation or step is cancelled.':'',
'Creates a CancelledError.':'',
'## Class DataLossError':'',
'Raised when unrecoverable data loss or corruption is encountered.':'',
'Creates a DataLossError.':'',
'## Class DeadlineExceededError':'',
'Raised when a deadline expires before an operation could complete.':'',
'This exception is not currently used.':'',
'Creates a DeadlineExceededError.':'',
'## Class FailedPreconditionError':'',
'Operation was rejected because the system is not in a state to execute it.':'',
'Creates a FailedPreconditionError.':'',
'## Class InternalError':'',
'Raised when the system experiences an internal error.':'',
'This exception is raised when some invariant expected by the runtime has been broken. Catching this exception is not recommended.':'',
'Creates an InternalError.':'',
'## Class InvalidArgumentError':'',
'Raised when an operation receives an invalid argument.':'',
'Creates an InvalidArgumentError.':'',
'## Class NotFoundError':'',
'Creates a NotFoundError.':'',
'## Class OpError':'',
'A generic error that is raised when TensorFlow execution fails.':'',
'Creates a new OpError indicating that a particular op failed.':'',
'## Class OutOfRangeError':'',
'Raised when an operation iterates past the valid input range.':'',
'Creates an OutOfRangeError.':'',
'## Class PermissionDeniedError':'',
'Raised when the caller does not have permission to run an operation.':'',
'Creates a PermissionDeniedError.':'',
'## Class ResourceExhaustedError':'',
'Some resource has been exhausted.':'',
'Creates a ResourceExhaustedError.':'',
'## Class UnauthenticatedError':'',
'The request does not have valid authentication credentials.':'',
'Creates an UnauthenticatedError.':'',
'## Class UnavailableError':'',
'Raised when the runtime is currently unavailable.':'',
'Creates an UnavailableError.':'',
'## Class UnimplementedError':'',
'Raised when an operation has not been implemented.':'',
'Creates an UnimplementedError.':'',
'## Class UnknownError':'',
'Unknown error.':'',
'Creates an UnknownError.':'',
'Example usage of custom metric which uses features:':'',
'Args: can only have following four arguments in any order:':'',
'pre`dict`ions: Pre`dict`ions `Tensor` or `dict` of `Tensor` created by given `estimator`.':'',
'config: config attribute of the `estimator`.':'',
'Initializes a BaselineClassifier instance.':'',
'A BaselineClassifier estimator.':'',
'Initializes a BaselineEstimator instance.':'',
'Initializes a BaselineRegressor instance.':'',
'A BaselineRegressor estimator.':'',
'## Class BestExporter':'',
'This class exports the serving graph and checkpoints of the best models.':'',
'This class performs a model export everytime the new model is better than any existing model.':'',
'Example of creating a BestExporter for training and evaluation:':'',
'Directory name.':'',
'A directory name under the export base directory where exports of this type are written. Should not be None nor empty.':'',
'Exports the given Estimator to a specific format.':'',
'The string path to the exported directory or None if export is skipped.':'',
'## Class BinaryClassHead':'',
'Creates a Head for single label binary classification.':'',
'It is recommended to pass all args via name.':'',
'EstimatorSpec.':'',
'### metrics':'',
'A dict of predictions.':'',
'## Class BoostedTreesClassifier':'',
'A Classifier for Tensorflow Boosted Trees models.':'',
'Initializes a BoostedTreesClassifier instance.':'',
'Computes model explainability outputs per example along with predictions.':'',
'## Class BoostedTreesEstimator':'',
'An Estimator for Tensorflow Boosted Trees models.':'',
'Initializes a BoostedTreesEstimator instance.':'',
'## Class BoostedTreesRegressor':'',
'A Regressor for Tensorflow Boosted Trees models.':'',
'Initializes a BoostedTreesRegressor instance.':'',
'## Class CheckpointSaverHook':'',
'Saves checkpoints every N steps or seconds.':'',
'Initializes a CheckpointSaverHook.':'',
'## Class CheckpointSaverListener':'',
'Interface for listeners that take action before or after checkpoint save.':'',
'Initializes a DNNClassifier instance.':'',
'Initializes a DNNEstimator instance.':'',
'Initializes a DNNLinearCombinedClassifier instance.':'',
'Initializes a DNNLinearCombinedEstimator instance.':'',
'Initializes a DNNLinearCombinedRegressor instance.':'',
'Initializes a DNNRegressor instance.':'',
'## Class EstimatorSpec':'',
'EstimatorSpec fully defines the model to be run by an Estimator.':'',
'Creates a validated EstimatorSpec instance.':'',
'name: An arbitrary name for this output.':'',
'A validated EstimatorSpec object.':'',
'### scaffold':'',
'## Class EvalSpec':'',
'EvalSpec combines details of evaluation of the trained model as well as its export. Evaluation consists of computing metrics to judge the performance of the trained model. Export writes out the trained model on to external storage.':'',
'Creates a validated EvalSpec instance.':'',
'A validated EvalSpec object.':'',
'### steps':'',
'### hooks':'',
'### exporters':'',
'## Class Exporter':'',
'A class representing a type of model export.':'',
'## Class FeedFnHook':'',
'Initializes a FeedFnHook.':'',
'## Class FinalExporter':'',
'This class exports the serving graph and checkpoints at the end.':'',
'This class performs a single export at the end of training.':'',
'## Class FinalOpsHook':'',
'A hook which evaluates Tensors at the end of a session.':'',
'Initializes FinalOpHook with ops to run at the end of the session.':'',
'## Class GlobalStepWaiterHook':'',
'Initializes a GlobalStepWaiterHook.':'',
'## Class Head':'',
'Interface for the head/top of a model.':'',
'#### Common usage:':'',
'Size of the last dimension of the logits Tensor.':'',
'The expected size of the logits tensor.':'',
'The type of loss reduction used in the head.':'',
'The name of this head.':'',
'Returns a loss Tensor from provided arguments.':'',
'A scalar Tensor representing regularized training loss used in train and eval.':'',
'Returns a dict of metric objects.':'',
'A dict of metrics keyed by string name. The value is an instance of Metric class.':'',
'Returns a dict of predictions from provided logits.':'',
'A dict of predicted Tensor keyed by prediction name.':'',
'Updates metric objects and returns a dict of the updated metrics.':'',
'A dict of updated metrics keyed by name. The value is an instance of Metric class.':'',
'## Class LatestExporter':'',
'This class regularly exports the serving graph and checkpoints.':'',
'Construct a LinearClassifier estimator object.':'',
'A LinearClassifier estimator.':'',
'Initializes a LinearRegressor instance.':'',
'## Class LoggingTensorHook':'',
'Initializes a LoggingTensorHook.':'',
'## Class LogisticRegressionHead':'',
'Creates a Head for logistic regression.':'',
'The head can be used with a canned estimator. Example:':'',
'## Class MultiClassHead':'',
'Creates a Head for multi class classification.':'',
'## Class MultiHead':'',
'This class merges the output of multiple Head objects. Specifically:':'',
'Usage:':'',
'## Class MultiLabelHead':'',
'#### Labels can be:':'',
'## Class NanLossDuringTrainingError':'',
'## Class NanTensorHook':'',
'Monitors the loss tensor and stops training if loss is NaN.':'',
'Can either fail with exception or just stop training.':'',
'Initializes a NanTensorHook.':'',
'## Class PoissonRegressionHead':'',
'## Class ProfilerHook':'',
'Captures CPU/GPU profiling information every N steps or seconds.':'',
'Initializes a hook that takes periodic profiling snapshots.':'',
'## Class RegressionHead':'',
'This class specifies the configurations for an Estimator run.':'',
'#### Example of chief node:':'',
'Example of evaluator node (evaluator is not part of training cluster):':'',
'## Class SecondOrStepTimer':'',
'Timer that triggers at most once every N seconds or once every N steps.':'',
'Returns the last triggered time step or None if never triggered.':'',
'Resets the timer.':'',
'Return true if the timer should trigger for the specified step.':'',
'Update the last triggered time and step number.':'',
'## Class SessionRunArgs':'',
'Represents arguments to be added to a Session.run() call.':'',
'### fetches':'',
'## Class SessionRunContext':'',
'Provides information about the session.run() call being made.':'',
'    session':'',
'Initializes SessionRunContext.':'',
'A SessionRunArgs object holding the original arguments of run().':'',
'A SessionRunArgs object':'',
'A TensorFlow session object which will execute the run.':'',
'Returns whether a stop is requested or not.':'',
'Sets stop requested field.':'',
'Hooks can use this function to request stop of iterations. MonitoredSession checks whether this is called or not.':'',
'## Class SessionRunHook':'',
'Hook to extend calls to MonitoredSession.run().':'',
'## Class SessionRunValues':'',
'Contains the results of Session.run().':'',
'In the future we may use this object to add more information about result of run without changing the Hook API.':'',
'### results':'',
'## Class StepCounterHook':'',
'Hook that counts steps per second.':'',
'## Class StopAtStepHook':'',
'Hook that requests stop at a specified step.':'',
'Initializes a StopAtStepHook.':'',
'This hook requests stop after either a number of steps have been executed or a last step has been reached. Only one of the two options can be specified.':'',
'## Class SummarySaverHook':'',
'Saves summaries every N steps.':'',
'Initializes a SummarySaverHook.':'',
'## Class TrainSpec':'',
'Creates a validated TrainSpec instance.':'',
'A validated TrainSpec object.':'',
'Train and evaluate the estimator.':'',
'Example of distributed training:':'',
'    "cluster": {':'',
'## Class VocabInfo':'',
'   Example Usage:':'',
'### axis':'',
'## Class WarmStartSettings':'',
'THIS FUNCTION IS EXPERIMENTAL. Keras layers/models are the recommended APIs for logit and model composition.':'',
'## Class InMemoryEvaluatorHook':'',
'Hook to run evaluation in training without a checkpoint.':'',
'Current limitations of this approach are:':'',
'Initializes a InMemoryEvaluatorHook.':'',
'Does first run which shows the eval metrics before training.':'',
'Runs evaluator.':'',
'Build eval graph and restoring op.':'',
'Runs evaluator for final model.':'',
'## Class LinearSDCA':'',
'Stochastic Dual Coordinate Ascent helper for linear estimators.':'',
'SDCA can only be used with LinearClassifier and LinearRegressor under the following conditions:':'',
'Construct a new SDCA optimizer for linear estimators.':'',
'Returns the training operation of an SdcaModel optimizer.':'',
'#### Usage example:':'',
'Creates a proper StopAtCheckpointStepHook based on chief status.':'',
'## Class RNNClassifier':'',
'A classifier for TensorFlow RNN models.':'',
'Trains a recurrent neural network model to classify instances into one of multiple classes.':'',
'Estimators are not compatible with eager execution.':'',
'Initializes a RNNClassifier instance.':'',
'## Class RNNEstimator':'',
'Initializes a RNNEstimator instance.':'',
'Creates hook to stop if the given metric is higher than the threshold.':'',
'Creates hook to stop if the given metric is lower than the threshold.':'',
'Creates hook to stop if metric does not decrease within given max steps.':'',
'Creates hook to stop if metric does not increase within given max steps.':'',
'Represents the output of a classification head.':'',
'Either classes or scores or both must be set.':'',
'Constructor for ClassificationOutput.':'',
'### classes':'',
'### scores':'',
'Generate a SignatureDef proto for inclusion in a MetaGraphDef.':'',
'## Class ExportOutput':'',
'Represents an output of a model that can be served.':'',
'These typically correspond to model heads.':'',
'## Class PredictOutput':'',
'Represents the output of a generic prediction head.':'',
'A generic prediction need not be either a classification or a regression.':'',
'Constructor for PredictOutput.':'',
'## Class RegressionOutput':'',
'Represents the output of a regression head.':'',
'Constructor for RegressionOutput.':'',
'## Class ServingInputReceiver':'',
'### features':'',
'## Class TensorServingInputReceiver':'',
'Context manager for setting the executor of eager defined functions.':'',
'Eager defined functions are functions decorated by tf.contrib.eager.defun.':'',
'Represents discretized dense input.':'',
'    boundaries':'',
'A BucketizedColumn.':'',
'Represents sparse feature where ids are set by hashing.':'',
'A HashedCategoricalColumn.':'',
'A CategoricalColumn that returns identity values.':'',
'#### Linear model:':'',
'Embedding for a DNN model:':'',
'Returns a column for performing crosses of categorical features.':'',
'then crossed feature will look like:':'',
'Here is an example to create a linear model with crosses of string features:':'',
'You could also use vocabulary lookup before crossing:':'',
'string: Will use the corresponding feature which must be of string type.':'',
'A CrossedColumn.':'',
'DenseColumn that converts from sparse input.':'',
'An IndicatorColumn.':'',
'Represents real valued or numerical features.':'',
'A NumericColumn.':'',
'A sequence of categorical terms where ids are set by hashing.':'',
'A SequenceCategoricalColumn.':'',
'Returns a feature column that represents sequences of integers.':'',
'A sequence of categorical terms where ids use a vocabulary file.':'',
'Returns a feature column that represents sequences of numeric data.':'',
'A SequenceNumericColumn.':'',
'Applies weight values to a CategoricalColumn.':'',
'Input tf.Example objects:':'',
'    feature {':'',
'      key: "terms"':'',
'      key: "frequencies"':'',
'Adjust the brightness of RGB or Grayscale images.':'',
'    delta':'',
'Adjust contrast of RGB or grayscale images.':'',
'Contrast is adjusted independently for each channel of each image.':'',
'Performs Gamma Correction on the input image.':'',
'Adjust hue of RGB images.':'',
'image is an RGB image. The image hue is adjusted by converting the image(s) to HSV and rotating the hue channel (H) by delta. The image is then converted back to RGB.':'',
'Adjust jpeg encoding quality of an RGB image.':'',
'This is a convenience method that adjusts jpeg encoding quality of an RGB image.':'',
'Adjust saturation of RGB images.':'',
'Crop the central region of the image(s).':'',
'|        |':'',
'|  XXXX  |':'',
'Greedily selects a subset of bounding boxes in descending order of score.':'',
'Crops an image to a specified bounding box.':'',
'Extract patches from images.':'',
'   + 52  + 54  +  o 57  o 59  o':'',
'   + 72  + 74  +  o 77  o 79  o':'',
'   + 92  + 94  +  o 97  o 99  o':'',
'Flip an image horizontally (left to right).':'',
'Outputs the contents of image flipped along the width dimension.':'',
'See also reverse().':'',
'A tensor of the same type and shape as image.':'',
'Flip an image vertically (upside down).':'',
'Outputs the contents of image flipped along the height dimension.':'',
'A Tensor of the same type and shape as image.':'',
'Converts one or more images from Grayscale to RGB.':'',
'The converted grayscale image(s).':'',
'Convert one or more images from HSV to RGB.':'',
'Pad image with zeros to the specified height and width.':'',
'A Tensor with same shape and dtype as image.':'',
'This is intended to be used on signals (or images). Produces a PSNR value for each image in batch.':'',
'Adjust the brightness of images by a random factor.':'',
'Adjust the contrast of an image or images by a random factor.':'',
'Randomly crops a tensor to a given size.':'',
'A cropped tensor of the same rank as value and shape size.':'',
'Randomly flip an image horizontally (left to right).':'',
'Randomly flips an image vertically (upside down).':'',
'Adjust the hue of RGB images by a random factor.':'',
'Randomly changes jpeg encoding quality for inducing jpeg noise.':'',
'Adjust the saturation of RGB images by a random factor.':'',
'Crops and/or pads an image to a target width and height.':'',
'Resizes an image to a target width and height by either centrally cropping the image or padding it evenly with zeros.':'',
'Converts one or more images from RGB to Grayscale.':'',
'Converts one or more images from RGB to HSV.':'',
'Converts one or more images from RGB to YIQ.':'',
'Converts one or more images from RGB to YUV.':'',
'A rotated tensor of the same type and shape as image.':'',
'Generate a single randomly distorted bounding box for an image.':'',
'Returns a tensor holding Sobel edge maps.':'',
'Computes SSIM index between img1 and img2.':'',
'#### Details:':'',
'The image sizes must be at least 11x11 because of the filter size.':'',
'Calculate and return the total variation for one or more images.':'',
'The total variation of images.':'',
'Transpose image(s) by swapping the height and width dimension.':'',
'Converts one or more images from YIQ to RGB.':'',
'Converts one or more images from YUV to RGB.':'',
'The attr channels indicates the desired number of color channels for the decoded image.':'',
'#### Accepted values are:':'',
'A Tensor of type uint8.':'',
'Decompress strings.':'',
'A Tensor of type dtype.':'',
'The op extracts fields from a serialized protocol buffers message into tensors.':'',
'Convert raw byte strings into tensors.':'',
'Deserialize and concatenate SparseTensors from a serialized minibatch.':'',
'then the final deserialized SparseTensor will be:':'',
'All of the serialized SparseTensors must have had the same rank and type.':'',
'The attr format can be used to override the color format of the encoded output. Values can be:':'',
'The op serializes protobuf messages provided in the input tensors.':'',
'The sizes tensor specifies repeat counts for each field. The repeat count (last dimension) of a each tensor in values must be greater than or equal to corresponding repeat count in sizes.':'',
'## Class FixedLenFeature':'',
'## Class FixedLenSequenceFeature':'',
'Convenience function to check if the \'contents\' encodes a JPEG image.':'',
'Returns the set of files matching one or more glob patterns.':'',
'NOTE: The order of the files returned is deterministic.':'',
'A variable that is initialized to the list of files matching the pattern(s).':'',
'Parses a batch of SequenceExample protos.':'',
'Parses a single SequenceExample proto.':'',
'Transforms a serialized tensorflow.TensorProto proto into a Tensor.':'',
'Reads and outputs the entire contents of the input filename.':'',
'Transforms a Tensor into a serialized TensorProto proto.':'',
'## Class SparseFeature':'',
'Configuration for parsing a sparse input feature from an Example.':'',
' features {':'',
'## Class TFRecordOptions':'',
'Options used for manipulating TFRecord files.':'',
'Creates a TFRecordOptions instance.':'',
'A TFRecordOptions object.':'',
'    options':'',
'Convert various option types to a unified string.':'',
'A class to write records to a TFRecords file.':'',
'Opens file path and creates a TFRecordWriter writing to it.':'',
'Enter a with block.':'',
'Close the file.':'',
'Flush the file.':'',
'Write a string record to the file.':'',
'## Class VarLenFeature':'',
'Writes contents to the file at input filename. Creates file and recursively':'',
'creates directory if not existing.':'',
'Copies data from src to dst.':'',
'## Class GFile':'',
'It succeeds if path already exists and is writable.':'',
'Creates a directory with the name given by \'path\'.':'',
'Deletes the path located at \'path\'.':'',
'Deletes everything under path recursively.':'',
'Input() is used to instantiate a Keras tensor.':'',
'A tensor.':'',
'## Class Model':'',
'Model groups layers into an object with training and inference features.':'',
'There are two ways to instantiate a Model:':'',
'### layers':'',
'Returns the model\'s display labels for all outputs.':'',
'Settable attribute indicating whether the model should run eagerly.':'',
'Returns the updates from all layers that are stateful.':'',
'A list of update ops.':'',
'### stateful':'',
'### compile':'',
'Configures the model for training.':'',
'Returns the loss value & metrics values for the model in test mode.':'',
'Computation is done in batches.':'',
'A `tf.data` dataset.':'',
'A generator or `keras.utils.Sequence` instance.':'',
'Evaluates the model on a data generator.':'',
'### fit':'',
'Trains the model for a fixed number of epochs (iterations on a dataset).':'',
'a `generator` for the validation data':'',
'A History object.':'',
'        while 1:':'',
'Raises: ValueError: In case the generator yields data in an invalid format.':'',
'Retrieves a layer based on either its name (unique) or index.':'',
'A layer instance.':'',
'Generates output predictions for the input samples.':'',
'Numpy array(s) of predictions.':'',
'Generates predictions for the input samples from a data generator.':'',
'Returns predictions for a single batch of samples.':'',
'Resets the state of metrics.':'',
'Saves the model to Tensorflow SavedModel or a single HDF5 file.':'',
'#### The savefile includes:':'',
'This allows you to save the entirety of the state of a model in a single file.':'',
'del model  # deletes the existing model':'',
'Saves all layer weights.':'',
'Prints a string summary of the network.':'',
'Test the model on a single batch of samples.':'',
'Returns a JSON string containing the network configuration.':'',
'A JSON string.':'',
'Returns a yaml string containing the network configuration.':'',
'A YAML string.':'',
'Runs a single gradient update on a single batch of data.':'',
'## Class Sequential':'',
'Linear stack of layers.':'',
'model.weights  # returns []':'',
'model.weights  # returns list of length 4':'',
'Adds a layer instance on top of the layer stack.':'',
'### pop':'',
'Removes the last layer in the model.':'',
'Generate class predictions for the input samples.':'',
'The input samples are processed batch by batch.':'',
'A numpy array of class predictions.':'',
'Generates class probability predictions for the input samples.':'',
'A Numpy array of probability predictions.':'',
'Exponential linear unit.':'',
'#### Reference:':'',
'Exponential activation function.':'',
'The exponential activation: exp(x).':'',
'Hard sigmoid activation function.':'',
'Faster to compute than sigmoid activation.':'',
'Linear activation function.':'',
'The linear activation: x.':'',
'Rectified Linear Unit.':'',
'Scaled Exponential Linear Unit (SELU).':'',
'#### Example Usage:':'',
'Sigmoid.':'',
'Sigmoid activation function.':'',
'The softmax activation function transforms the outputs so that all values are in':'',
'Softplus activation function.':'',
'The softplus activation: log(exp(x) + 1).':'',
'Softsign activation function.':'',
'The softplus activation: x / (abs(x) + 1).':'',
'Hyperbolic Tangent (tanh) activation function.':'',
'Arguments: x: Input tensor.':'',
'Bitwise reduction (logical AND).':'',
'Bitwise reduction (logical OR).':'',
'Creates a 1D tensor containing a sequence of integers.':'',
'The default type of the returned tensor is \'int32\' to match TensorFlow\'s default.':'',
'An integer tensor.':'',
'Returns the index of the maximum value along an axis.':'',
'Returns the index of the minimum value along an axis.':'',
'Publicly accessible method for determining the current backend.':'',
'The string "tensorflow".':'',
'Batchwise dot product.':'',
'Flattening a 3D tensor to 2D by collapsing the last dimension.':'',
'Returns the value of more than one tensor variable.':'',
'A list of Numpy arrays.':'',
'Sets the values of many tensor variables at once.':'',
'Adds a bias vector to a tensor.':'',
'Binary crossentropy between an output tensor and a target tensor.':'',
'Casts a tensor to a different dtype and returns it.':'',
'You can cast a Keras variable but it still returns a Keras tensor.':'',
'Keras tensor with dtype dtype.':'',
'Cast a float32 variable to a float64 tensor':'',
'Cast a Numpy array to the default Keras float type.':'',
'Categorical crossentropy between an output tensor and a target tensor.':'',
'    from tensorflow.keras import backend as K':'',
'Destroys the current TF graph and creates a new one.':'',
'Useful to avoid clutter from old models / layers.':'',
'Concatenates a list of tensors alongside the specified axis.':'',
'transposed convolution).':'',
'Returns the static number of elements in a variable or tensor.':'',
'Runs CTC loss algorithm on each batch element.':'',
'Tensor with shape (samples,1) containing the CTC loss of each element.':'',
'Decodes the output of a softmax.':'',
'Can use either greedy search (also known as best path) or a constrained dictionary search.':'',
'Converts CTC labels from dense to sparse.':'',
'A sparse tensor representation of the labels.':'',
'A tensor of the cumulative product of values of x along axis.':'',
'A tensor of the cumulative sum of values of x along axis.':'',
'Multiplies 2 tensors (and/or variables) and returns a tensor.':'',
'Returns the value of the fuzz factor used in numeric expressions.':'',
'A float.':'',
'A bool tensor.':'',
'Evaluates the value of a variable.':'',
'A Numpy array.':'',
'A tensor with expanded dimensions.':'',
'Instantiate an identity matrix and returns it.':'',
'Flatten a tensor.':'',
'    &gt;&gt;&gt; b':'',
' keras.backend.floatx() >>> \'float32\'':'',
'Reduce elems using fn to combine them from left to right.':'',
'Tensor with same type and shape as initializer.':'',
'Reduce elems using fn to combine them from right to left.':'',
'Same type and shape as initializer':'',
'Instantiates a Keras function.':'',
'Output values as Numpy arrays.':'',
'Retrieves the elements of indices indices in the tensor reference.':'',
'    indices':'',
'A tensor of same type as reference.':'',
'Associates a string prefix with an integer counter in a TensorFlow graph.':'',
'Unique integer ID.':'',
'Returns the value of a variable.':'',
'Returns the gradients of loss w.r.t. variables.':'',
'    variables':'',
'A gradients tensor.':'',
'Returns the default image data format convention.':'',
'Returns the shape of tensor or variable as a tuple of int or None entries.':'',
'A tuple of integers (or None entries).':'',
'Note that alt should have the same shape as x.':'',
'Returns whether the targets are in the top k predictions.':'',
'    k':'',
'Returns whether x is a Keras tensor.':'',
'A boolean: Whether the argument is a Keras tensor.':'',
'    ValueError':'',
'    keras is not a Keras tensor.':'',
'    False':'',
'    backend is not a Keras tensor.':'',
'    tensor.':'',
'    True':'',
'    Keras tensor.':'',
'Returns whether a tensor is a sparse tensor.':'',
'A boolean.':'',
'Normalizes a tensor wrt the L2 norm alongside the specified axis.':'',
'Returns the learning phase flag.':'',
'Learning phase (scalar integer tensor or Python integer).':'',
'Provides a scope within which the learning phase is equal to value.':'',
'The learning phase gets restored to its original value upon exiting the scope.':'',
'Sets the manual variable initialization flag.':'',
'Map the function fn over the elements elems and return the outputs.':'',
'Tensor with dtype dtype.':'',
'Maximum value in a tensor.':'',
'A tensor with maximum values of x.':'',
'A tensor with the element wise maximum value(s) of x and y.':'',
'A tensor with the mean of elements of x.':'',
'Minimum value in a tensor.':'',
'A tensor with minimum values of x.':'',
'Compute the moving average of a variable.':'',
'    momentum':'',
'An Operation to update the variable.':'',
'Name scope context manager.':'',
'A Keras variable with the shape of x filled with ones.':'',
'Permutes axes in a tensor.':'',
'    pattern':'',
'    &gt;&gt;&gt; a':'',
'Instantiates a placeholder tensor and returns it.':'',
'Tensor instance (with Keras metadata included).':'',
'    a':'',
'Prints message and the tensor value when evaluated.':'',
'   ':'',
'A tensor with the product of elements of x.':'',
'Returns a tensor with random binomial distribution of values.':'',
'Returns a tensor with normal distribution of values.':'',
'Instantiates a variable with values drawn from a normal distribution.':'',
'Returns a tensor with uniform distribution of values.':'',
'Instantiates a variable with values drawn from a uniform distribution.':'',
'Rectified linear unit.':'',
'Repeats a 2D tensor.':'',
'    n':'',
'Resets graph identifiers.':'',
'Reshapes a tensor to the specified shape.':'',
'    shape':'',
'Resizes the images contained in a 4D tensor.':'',
'Resizes the volume contained in a 5D tensor.':'',
'Reverse a tensor along the specified axes.':'',
'    axes':'',
'Iterates over the time dimension of a tensor.':'',
'Sets the value of the fuzz factor used in numeric expressions.':'',
'Sets the default float type.':'',
'Sets the value of the image data format convention.':'',
'Sets the learning phase to a fixed value.':'',
'Returns the symbolic shape of a tensor or variable.':'',
'A symbolic shape (which is itself a tensor).':'',
'Softmax of a tensor.':'',
'Softplus of a tensor.':'',
'Softsign of a tensor.':'',
'Categorical crossentropy with integer targets.':'',
'Pads the 2nd and 3rd dimensions of a 4D tensor.':'',
'A padded 4D tensor.':'',
'A padded 5D tensor.':'',
'A tensor with the same data as x but reduced dimensions.':'',
'Stacks a list of rank R tensors into a rank R+1 tensor.':'',
'A tensor with the standard deviation of elements of x.':'',
'Returns variables but with zero gradient w.r.t. every other variable.':'',
'A single tensor or a list of tensors (depending on the passed argument) that has no gradient with respect to any other variable.':'',
'A tensor with sum of x.':'',
'Switches between two operations depending on a scalar value.':'',
'The selected tensor.':'',
'Pads the middle dimension of a 3D tensor.':'',
'A padded 3D tensor.':'',
'Creates a tensor by tiling x by n.':'',
'A tiled tensor.':'',
'Converts a sparse tensor into a dense tensor and returns it.':'',
'A dense tensor.':'',
'Transposes a tensor and returns it.':'',
'Returns a tensor with truncated random normal distribution of values.':'',
'Update the value of x by adding increment.':'',
'    increment':'',
'The variable x updated.':'',
'Update the value of x by subtracting decrement.':'',
'    decrement':'',
'A tensor with the variance of elements of x.':'',
'Instantiates a variable and returns it.':'',
'A variable instance (with Keras metadata included).':'',
' from tensorflow.keras import backend as K':'',
'A Keras variable with the shape of x filled with zeros.':'',
'## Class BaseLogger':'',
'Callback that accumulates epoch averages of metrics.':'',
'This callback is automatically applied to every Keras model.':'',
'Called at the start of an epoch.':'',
'Subclasses should override for any actions to run. This function should only be called during TRAIN mode.':'',
'Called at the end of an epoch.':'',
'## Class Callback':'',
'Abstract base class used to build new callbacks.':'',
'The logs dictionary that callback methods take as argument will contain keys for quantities relevant to the current batch or epoch.':'',
'    (if validation and accuracy monitoring are enabled).':'',
'    the number of samples in the current batch.':'',
'    (if accuracy monitoring is enabled).':'',
'## Class CSVLogger':'',
'Callback that streams epoch results to a csv file.':'',
'## Class EarlyStopping':'',
'Stop training when a monitored quantity has stopped improving.':'',
'## Class History':'',
'Callback that records events into a History object.':'',
'This callback is automatically applied to every Keras model. The History object gets returned by the fit method of models.':'',
'## Class LambdaCallback':'',
'## Class LearningRateScheduler':'',
'Learning rate scheduler.':'',
'## Class ModelCheckpoint':'',
'Save the model after every epoch.':'',
'## Class ProgbarLogger':'',
'Callback that prints metrics to stdout.':'',
'## Class ReduceLROnPlateau':'',
'Reduce learning rate when a metric has stopped improving.':'',
'## Class RemoteMonitor':'',
'Callback used to stream events to a server.':'',
'Runs metrics and histogram summaries at epoch end.':'',
'Sets Keras model and writes graph if specified.':'',
'## Class TerminateOnNaN':'',
'Callback that terminates training when a NaN loss is encountered.':'',
'## Class Constraint':'',
'## Class MaxNorm':'',
'MaxNorm weight constraint.':'',
'Constrains the weights incident to each hidden unit to have a norm less than or equal to a desired value.':'',
'## Class MinMaxNorm':'',
'MinMaxNorm weight constraint.':'',
'Constrains the weights incident to each hidden unit to have the norm between a lower bound and an upper bound.':'',
'## Class NonNeg':'',
'## Class RadialConstraint':'',
'Constrains Conv2D kernel weights to be the same for each radius.':'',
'is this::':'',
'## Class UnitNorm':'',
'Constrains the weights incident to each hidden unit to have unit norm.':'',
'Loads the Boston Housing dataset.':'',
'#### License:':'',
'Loads the IMDB dataset.':'',
'Loads the MNIST dataset.':'',
'Retrieves the dictionary mapping word indices back to words.':'',
'The word index dictionary.':'',
'Loads the Reuters newswire classification dataset.':'',
'Functions':'',
'Return an Initializer object from its config.':'',
'## Class GlorotNormal':'',
'## Class GlorotUniform':'',
'## Class AbstractRNNCell':'',
'This is the base class for implementing RNN cells with custom behavior.':'',
'## Class Activation':'',
'Applies an activation function to an output.':'',
'## Class ActivityRegularization':'',
'Layer that applies an update to the cost function based input activity.':'',
'## Class Add':'',
'Layer that adds a list of inputs.':'',
'## Class AdditiveAttention':'',
'#### Call Arguments:':'',
'Here is a code example for using AdditiveAttention in a CNN+Attention network:':'',
'## Class AlphaDropout':'',
'Applies Alpha Dropout to the input.':'',
'## Class Attention':'',
'Here is a code example for using Attention in a CNN+Attention network:':'',
'## Class Average':'',
'Layer that averages a list of inputs.':'',
'Average pooling for temporal data.':'',
'## Class AveragePooling2D':'',
'Average pooling operation for spatial data.':'',
'## Class Bidirectional':'',
'Bidirectional wrapper for RNNs.':'',
'The call arguments for this layer are the same as those of the wrapped RNN layer.':'',
'### constraints':'',
'## Class Concatenate':'',
'Layer that concatenates a list of inputs.':'',
'Transposed convolution layer (sometimes called Deconvolution).':'',
'## Class ConvLSTM2D':'',
'Convolutional LSTM.':'',
'### filters':'',
'### padding':'',
'### strides':'',
'## Class Cropping1D':'',
'Cropping layer for 1D input (e.g. temporal sequence).':'',
'It crops along the time dimension (axis 1).':'',
'## Class Cropping2D':'',
'Cropping layer for 2D input (e.g. picture).':'',
'If int: the same symmetric `cropping` is applied to height and width.':'',
'## Class Cropping3D':'',
'Creates a DenseFeatures object.':'',
'## Class DepthwiseConv2D':'',
'Instantiates a layer from a config dictionary.':'',
'## Class Dot':'',
'Layer that computes a dot product between samples in two tensors.':'',
'## Class ELU':'',
'Exponential Linear Unit.':'',
'#### It follows:':'',
'Same shape as the input.':'',
'## Class Embedding':'',
'Turns positive integers (indexes) into dense vectors of fixed size.':'',
'This layer can only be used as the first layer in a model.':'',
'Flattens the input. Does not affect the batch size.':'',
'## Class GaussianDropout':'',
'## Class GaussianNoise':'',
'This is useful to mitigate overfitting (you could see it as a form of random data augmentation). Gaussian Noise (GS) is a natural choice as corruption process for real valued inputs.':'',
'## Class GlobalAveragePooling1D':'',
'Global average pooling operation for temporal data.':'',
'## Class GlobalAveragePooling2D':'',
'Global average pooling operation for spatial data.':'',
'## Class GlobalAveragePooling3D':'',
'Global Average pooling operation for 3D data.':'',
'## Class GlobalMaxPool1D':'',
'Global max pooling operation for temporal data.':'',
'## Class GlobalMaxPool2D':'',
'Global max pooling operation for spatial data.':'',
'## Class GlobalMaxPool3D':'',
'Global Max pooling operation for 3D data.':'',
'## Class GRU':'',
'The requirements to use the cuDNN implementation are:':'',
'## Class InputLayer':'',
'Layer to be used as an entry point into a Network (a graph of layers).':'',
'## Class InputSpec':'',
'## Class Lambda':'',
'Wraps arbitrary expressions as a Layer object.':'',
'Example of variable creation:':'',
'Note that creating two instances of Lambda using the same function will not share Variables between the two instances. Each instance of Lambda will create and manage its own weights.':'',
'This is the class from which all layers inherit.':'',
'Users will just instantiate a layer and then treat it as a callable.':'',
'We recommend that descendants of Layer implement the following methods:':'',
'### Dtypes and casting':'',
'#### Running models in float64 in TensorFlow 2':'',
'Optional regularizer function for the output of this layer.':'',
'### dynamic':'',
'Retrieves the input tensor(s) of a layer.':'',
'Input tensor or list of input tensors.':'',
'Retrieves the input mask tensor(s) of a layer.':'',
'Input mask tensor (potentially None) or list of input mask tensors.':'',
'Retrieves the input shape(s) of a layer.':'',
'### losses':'',
'Losses which are associated with this Layer.':'',
'A list of tensors.':'',
'### output':'',
'Retrieves the output tensor(s) of a layer.':'',
'Output tensor or list of output tensors.':'',
'Retrieves the output mask tensor(s) of a layer.':'',
'Output mask tensor (potentially None) or list of output mask tensors.':'',
'Retrieves the output shape(s) of a layer.':'',
'### updates':'',
'Returns the list of all layer variables/weights.':'',
'Alias of self.weights.':'',
'### weights':'',
'Output tensor(s).':'',
'Adds metric tensor to the layer.':'',
'Adds a new variable to the layer.':'',
'This is typically used to create the weights of Layer subclasses.':'',
'### call':'',
'This is where the layer\'s logic lives.':'',
'A tensor or list/tuple of tensors.':'',
'Computes an output mask tensor.':'',
'Computes the output shape of the layer.':'',
'An input shape tuple.':'',
'Compute the output tensor signature of the layer based on the inputs.':'',
'Count the total number of scalars composing the weights.':'',
'An integer count.':'',
'Creates a layer from its config.':'',
'Returns the config of the layer.':'',
'A layer config is a Python dictionary (serializable) containing the configuration of a layer. The same layer can be reinstantiated later (without its trained weights) from this configuration.':'',
'Python dictionary.':'',
'Retrieves the input tensor(s) of a layer at a given node.':'',
'A tensor (or list of tensors if the layer has multiple inputs).':'',
'Retrieves the input mask tensor(s) of a layer at a given node.':'',
'A mask tensor (or list of tensors if the layer has multiple inputs).':'',
'Retrieves the input shape(s) of a layer at a given node.':'',
'A shape tuple (or list of shape tuples if the layer has multiple inputs).':'',
'Retrieves losses relevant to a specific set of inputs.':'',
'List of loss tensors of the layer that depend on inputs.':'',
'Retrieves the output tensor(s) of a layer at a given node.':'',
'A tensor (or list of tensors if the layer has multiple outputs).':'',
'Retrieves the output mask tensor(s) of a layer at a given node.':'',
'A mask tensor (or list of tensors if the layer has multiple outputs).':'',
'Retrieves the output shape(s) of a layer at a given node.':'',
'A shape tuple (or list of shape tuples if the layer has multiple outputs).':'',
'Retrieves updates relevant to a specific set of inputs.':'',
'List of update ops of the layer that depend on inputs.':'',
'Returns the current weights of the layer.':'',
'Weights values as a list of numpy arrays.':'',
'## Class LayerNormalization':'',
'## Class LeakyReLU':'',
'Leaky version of a Rectified Linear Unit.':'',
'## Class LocallyConnected1D':'',
'How to choose:':'',
'## Class LocallyConnected2D':'',
'    parameters':'',
'## Class Masking':'',
'Masks a sequence by using a mask value to skip timesteps.':'',
'## Class Maximum':'',
'## Class MaxPool1D':'',
'Max pooling operation for temporal data.':'',
'## Class MaxPool2D':'',
'Max pooling operation for spatial data.':'',
'## Class MaxPool3D':'',
'## Class Minimum':'',
'## Class Multiply':'',
'## Class Permute':'',
'Permutes the dimensions of the input according to a given pattern.':'',
'Useful for e.g. connecting RNNs and convnets together.':'',
'## Class PReLU':'',
'Parametric Rectified Linear Unit.':'',
'## Class ReLU':'',
'Rectified Linear Unit activation function.':'',
'## Class RepeatVector':'',
'Repeats the input n times.':'',
'## Class Reshape':'',
'Reshapes an output to a certain shape.':'',
'## Class RNN':'',
'Base class for recurrent layers.':'',
'#### Masking:':'',
'## Class SimpleRNN':'',
'## Class SimpleRNNCell':'',
'Cell class for SimpleRNN.':'',
'## Class Softmax':'',
'Softmax activation function.':'',
'## Class SpatialDropout1D':'',
'Spatial 1D version of Dropout.':'',
'Same as input.':'',
'## Class SpatialDropout2D':'',
'Spatial 2D version of Dropout.':'',
'## Class SpatialDropout3D':'',
'Spatial 3D version of Dropout.':'',
'## Class StackedRNNCells':'',
'Wrapper allowing a stack of RNN cells to behave as a single cell.':'',
'Used to implement efficient stacked RNNs.':'',
'## Class Subtract':'',
'Layer that subtracts two inputs.':'',
'## Class ThresholdedReLU':'',
'Thresholded Rectified Linear Unit.':'',
'## Class TimeDistributed':'',
'This wrapper allows to apply a layer to every temporal slice of an input.':'',
'## Class UpSampling1D':'',
'Upsampling layer for 1D inputs.':'',
'Repeats each temporal step size times along the time axis.':'',
'## Class UpSampling2D':'',
'Upsampling layer for 2D inputs.':'',
'## Class UpSampling3D':'',
'Upsampling layer for 3D inputs.':'',
'## Class Wrapper':'',
'Abstract wrapper base class.':'',
'## Class ZeroPadding1D':'',
'If int: How many zeros to add at the beginning and end of the `padding` dimension (axis 1).':'',
'## Class ZeroPadding2D':'',
'If int: the same symmetric `padding` is applied to height and width.':'',
'## Class ZeroPadding3D':'',
'## Class BinaryCrossentropy':'',
'Invokes the Loss instance.':'',
'A Loss instance.':'',
'## Class CategoricalCrossentropy':'',
'Computes the crossentropy loss between the labels and predictions.':'',
'Usage with the compile API:':'',
'## Class CategoricalHinge':'',
'Computes the categorical crossentropy loss.':'',
'Categorical crossentropy loss value.':'',
'## Class CosineSimilarity':'',
'Computes the cosine similarity between labels and predictions.':'',
'Cosine similarity tensor.':'',
'## Class Hinge':'',
'## Class Huber':'',
'A Tensor with loss.':'',
'## Class KLDivergence':'',
'## Class LogCosh':'',
'Computes the logarithm of the hyperbolic cosine of the prediction error.':'',
'## Class Loss':'',
'Loss base class.':'',
'Example subclass implementation:':'',
'## Class MeanAbsoluteError':'',
'Computes the mean of absolute difference between labels and predictions.':'',
'## Class MeanAbsolutePercentageError':'',
'## Class MeanSquaredError':'',
'Computes the mean of squares of errors between labels and predictions.':'',
'## Class MeanSquaredLogarithmicError':'',
'## Class Poisson':'',
'## Class SparseCategoricalCrossentropy':'',
'## Class SquaredHinge':'',
'Tensor with one scalar loss entry per sample.':'',
'## Class Accuracy':'',
'Usage with tf.keras API:':'',
'Creates a MeanMetricWrapper instance.':'',
'Create and return a new object. See help(type) for accurate signature.':'',
'Resets all of the metric state variables.':'',
'### result':'',
'Computes and returns the metric value tensor.':'',
'Result computation is an idempotent operation that simply calculates the metric value using the state variables.':'',
'Accumulates metric statistics.':'',
'Update op.':'',
'## Class AUC':'',
'Computes the approximate AUC (Area under the curve) via a Riemann sum.':'',
'Creates an AUC instance.':'',
'https://www.biostat.wisc.edu/~page/rocpr.pdf':'',
'Note here we derive & use a closed formula not present in the paper as follows:':'',
'Accumulates confusion matrix statistics.':'',
'## Class BinaryAccuracy':'',
'Creates a BinaryAccuracy instance.':'',
'Computes the crossentropy metric between the labels and predictions.':'',
'Creates a BinaryCrossentropy instance.':'',
'## Class CategoricalAccuracy':'',
'Creates a CategoricalAccuracy instance.':'',
'Computes the cosine similarity between the labels and predictions.':'',
'This metric keeps the average cosine similarity between predictions and labels over a stream of data.':'',
'Creates a CosineSimilarity instance.':'',
'## Class FalseNegatives':'',
'Calculates the number of false negatives.':'',
'Creates a FalseNegatives instance.':'',
'Accumulates the given confusion matrix condition statistics.':'',
'Calculates the number of false positives.':'',
'Creates a FalsePositives instance.':'',
'## Class LogCoshError':'',
'## Class Mean':'',
'Creates a Mean instance.':'',
'Accumulates statistics for computing the reduction metric.':'',
'## Class MeanIoU':'',
'Creates a MeanIoU instance.':'',
'Accumulates the confusion matrix statistics.':'',
'## Class MeanRelativeError':'',
'Creates a MeanRelativeError instance.':'',
'## Class MeanTensor':'',
'Creates a MeanTensor instance.':'',
'### count':'',
'### total':'',
'## Class Metric':'',
'Encapsulates metric logic and state.':'',
'Adds state variable. Only for use by subclasses.':'',
'Accumulates statistics for the metric.':'',
'## Class Precision':'',
'Creates a Precision instance.':'',
'Accumulates true positive and false positive statistics.':'',
'## Class Recall':'',
'Creates a Recall instance.':'',
'Accumulates true positive and false negative statistics.':'',
'## Class RootMeanSquaredError':'',
'Accumulates root mean squared error statistics.':'',
'## Class SensitivityAtSpecificity':'',
'Computes the sensitivity at a given specificity.':'',
'Sensitivity measures the proportion of actual positives that are correctly identified as such (tp / (tp + fn)). Specificity measures the proportion of actual negatives that are correctly identified as such (tn / (tn + fp)).':'',
'Creates a SensitivityAtSpecificity instance.':'',
'## Class SparseCategoricalAccuracy':'',
'Calculates how often predictions matches integer labels.':'',
'## Class SparseTopKCategoricalAccuracy':'',
'Computes how often integer targets are in the top K predictions.':'',
'Creates a SparseTopKCategoricalAccuracy instance.':'',
'## Class SpecificityAtSensitivity':'',
'Creates a SpecificityAtSensitivity instance.':'',
'## Class Sum':'',
'Computes the (weighted) sum of the given values.':'',
'Creates a Sum instance.':'',
'## Class TopKCategoricalAccuracy':'',
'Computes how often targets are in the top K predictions.':'',
'Creates a TopKCategoricalAccuracy instance.':'',
'## Class TrueNegatives':'',
'Calculates the number of true negatives.':'',
'Creates a TrueNegatives instance.':'',
'## Class TruePositives':'',
'Calculates the number of true positives.':'',
'Creates a TruePositives instance.':'',
'Returns the global Policy.':'',
'The global Policy.':'',
'## Class LossScaleOptimizer':'',
'Initializes this loss scale optimizer.':'',
'### iterations':'',
'Variable. The number of training steps this Optimizer has run.':'',
'The LossScale instance associated with this optimizer.':'',
'### lr':'',
'Returns variables of this Optimizer based on the order created.':'',
'Add a new slot variable for var.':'',
'Creates an optimizer from its config.':'',
'An optimizer instance.':'',
'Returns the config of the optimimizer.':'',
'An optimizer config is a Python dictionary (serializable) containing the configuration of an optimizer. The same optimizer can be reinstantiated later (without any saved state) from this configuration.':'',
'    params':'',
'Returns gradients of loss with respect to params.':'',
'List of gradient tensors.':'',
'Scales the loss by the loss scale.':'',
'A list of names for this optimizer\'s slots.':'',
'Unscales the gradients by the loss scale.':'',
'## Class Policy':'',
'A dtype policy for a Keras layer.':'',
'### How to use mixed precision in layers with Policies':'',
'### The deprecated "infer" policy':'',
'Constructs the policy.':'',
'The compute dtype of this policy.':'',
'This is the dtype layers will do their computations in.':'',
'Returns the loss scale of this Policy.':'',
'Returns the name of this policy.':'',
'Returns True if variables should be casted.':'',
'This is true if the variable dtype is not the same as the compute dtype.':'',
'The variable dtype of this policy.':'',
'Sets the global Policy.':'',
'Clone any Model instance.':'',
'Instantiates a Keras model from its config.':'',
'A Keras model instance (uncompiled).':'',
'Parses a JSON model configuration file and returns a model instance.':'',
'Parses a yaml model configuration file and returns a model instance.':'',
'Saves a model as a TensorFlow SavedModel or HDF5 file.':'',
'## Class Adadelta':'',
'Adadelta optimization is a stochastic gradient descent method that is based on adaptive learning rate per dimension to address two drawbacks: 1) the continual decay of learning rates throughout training 2) the need for a manually selected global learning rate':'',
'## Class Adagrad':'',
'#### Update step:':'',
'## Class Adam':'',
'## Class Adamax':'',
'Optimizer that implements the Adamax algorithm.':'',
'Construct a new Adamax optimizer.':'',
'The update rule for variable with gradient g uses an optimization described at the end of section 7.1 of the paper:':'',
'Inverse of the serialize function.':'',
'A Keras Optimizer instance.':'',
'## Class Ftrl':'',
'Retrieves a Keras Optimizer instance.':'',
'String: name of an optimizer':'',
'## Class Nadam':'',
'Optimizer that implements the NAdam algorithm.':'',
'#### Computes:':'',
'Construct a new Nadam optimizer.':'',
'Updated base class for optimizers.':'',
'### Custom training loop with Keras models':'',
'### Use with tf.distribute.Strategy.':'',
'### Variable Constraint':'',
'### Thread Compatibility':'',
'### Hyper parameters':'',
'Hyper parameters can be overwritten through user code:':'',
'### Write a customized optimizer.':'',
'## Class RMSprop':'',
'Optimizer that implements the RMSprop algorithm.':'',
'A detailed description of rmsprop.':'',
'Construct a new RMSprop optimizer.':'',
'## Class SGD':'',
'Stochastic gradient descent and momentum optimizer.':'',
'gradient is evaluated at theta(t).':'',
'  http://jmlr.org/proceedings/papers/v28/sutskever13.pdf).':'',
'Construct a new Stochastic Gradient Descent or Momentum optimizer.':'',
'## Class ExponentialDecay':'',
'A LearningRateSchedule that uses an exponential decay schedule.':'',
'Instantiates a LearningRateSchedule from its config.':'',
'A LearningRateSchedule instance.':'',
'## Class InverseTimeDecay':'',
'A LearningRateSchedule that uses an inverse time decay schedule.':'',
'## Class LearningRateSchedule':'',
'A serializable learning rate decay schedule.':'',
'## Class PiecewiseConstantDecay':'',
'A LearningRateSchedule that uses a piecewise constant decay schedule.':'',
'## Class PolynomialDecay':'',
'A LearningRateSchedule that uses a polynomial decay schedule.':'',
'It requires a step value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.':'',
'Applies an affine transformation specified by the parameters given.':'',
'theta: Rotation angle in degrees.':'',
'tx: Width shift.':'',
'ty: Heigh shift.':'',
'shear: Shear angle in degrees.':'',
'zx: Zoom in x direction.':'',
'zy: Zoom in y direction':'',
'    are filled according to the given mode':'',
'cval: Value used for points outside the boundaries':'',
' The transformed version of the input.':'',
'Performs a brightness shift.':'',
'    brightness':'',
' x: Input tensor. Must be 3D.':'',
'brightness: Float. The new brightness value.':'',
' Numpy image tensor.':'',
'Performs a channel shift.':'',
'intensity: Transformation intensity.':'',
'Converts a 3D Numpy array to a PIL Image instance.':'',
'A PIL Image instance.':'',
'## Class DirectoryIterator':'',
'Iterator capable of reading images from a directory on disk.':'',
'### filepaths':'',
'List of absolute paths to image files':'',
'### labels':'',
'Class labels of every observation':'',
'Gets batch at position index.':'',
'A batch':'',
'Create a generator that iterate over the Sequence.':'',
'Number of batch in the Sequence.':'',
'The number of batches in the Sequence.':'',
'For python 2.x.':'',
' The next batch.':'',
'Method called at the end of every epoch.':'',
'    interpolation':'',
'Sets attributes to use later for processing files into a batch.':'',
'    to use for random transformations and normalization.':'',
'    Color mode to read images.':'',
'subset: Subset of data (`"training"` or `"validation"`) if':'',
'interpolation: Interpolation method used to resample the image if the':'',
'    target size is different from that of the loaded image.':'',
'## Class ImageDataGenerator':'',
'            break':'',
'Example of transforming images and masks together.':'',
'Applies a transformation to an image according to given parameters.':'',
'    describing the transformation.':'',
'    from the dictionary are used:':'',
' A transformed version of the input (same shape).':'',
'Fits the data generator to some sample data.':'',
' x: Sample data. Should have rank 4.':'',
'augment: Boolean (default: False).':'',
'    Whether to fit on randomly augmented samples.':'',
'rounds: Int (default: 1).':'',
'    this is how many augmentation passes over the data to use.':'',
'seed: Int (default: None). Random seed.':'',
' x: Input data. Numpy array of rank 4 or a tuple.':'',
'    should contain the images and the second element':'',
'    another numpy array or a list of numpy arrays':'',
'    that gets passed to the output':'',
'    Can be used to feed the model miscellaneous data':'',
'    along with the images.':'',
'y: Labels.':'',
'shuffle: Boolean (default: True).':'',
'seed: Int (default: None).':'',
'    This allows you to optionally specify a directory':'',
'    to which to save the augmented pictures being generated':'',
'    (useful for visualizing what you are doing).':'',
'    Prefix to use for filenames of saved pictures':'',
'    (in the case of a single image input) or a list':'',
'    of numpy arrays (in the case with':'',
'    additional inputs) and `y` is a numpy array':'',
'Takes the dataframe and the path to a directory and generates batches of augmented/normalized data.':'',
' dataframe: Pandas dataframe containing the filepaths relative to':'',
'    images in a string column. It should include other column/s':'',
'        Values in column can be string/list/tuple if a single class':'',
'        or list/tuple if multiple classes.':'',
'    absolute paths if `directory` is `None`).':'',
'    weights. Default: `None`.':'',
'    The dimensions to which all images found will be resized.':'',
'    Whether the images will be converted to have 1 or 3 color channels.':'',
'    The dictionary containing the mapping from class names to class':'',
'    Mode for yielding the targets:':'',
'seed: optional random seed for shuffling and transformations.':'',
'    (default: False).':'',
'    Default: `True`.':'',
'Takes the path to a directory & generates batches of augmented data.':'',
'    It should contain one subdirectory per class.':'',
'    inside each of the subdirectories directory tree':'',
'    will be included in the generator.':'',
'    Whether the images will be converted to':'',
'    inferred from the subdirectory names/structure':'',
'    be treated as a different class':'',
'    Determines the type of label arrays that are returned:':'',
'        to input images (mainly used to work with autoencoders).':'',
'      the data still needs to reside in a subdirectory':'',
'      of `directory` for it to work correctly.':'',
'seed: Optional random seed for shuffling and transformations.':'',
'    This allows you to optionally specify':'',
'    a directory to which to save':'',
'    the augmented pictures being generated':'',
'interpolation: Interpolation method used to':'',
'    resample the image if the':'',
'Generates random parameters for a transformation.':'',
' seed: Random seed.':'',
'    Shape of the image that is transformed.':'',
' A dictionary containing randomly chosen parameters describing the':'',
'transformation.':'',
'Applies a random transformation to an image.':'',
'seed: Random seed.':'',
' A randomly transformed version of the input (same shape).':'',
'### standardize':'',
' x: Batch of inputs to be normalized.':'',
'Converts a PIL Image instance to a Numpy array.':'',
'A 3D Numpy array.':'',
'Base class for image data iterators.':'',
'seed: Random seeding for data shuffling.':'',
'    seed':'',
'Loads an image into PIL format.':'',
' path: Path to image file.':'',
'    The desired image format.':'',
' A PIL Image instance.':'',
' ImportError: if PIL is not available.':'',
'ValueError: if interpolation method is not supported.':'',
'## Class NumpyArrayIterator':'',
'Iterator yielding data from a Numpy array.':'',
'Performs a random brightness shift.':'',
'Performs a random channel shift.':'',
'Performs a random rotation of a Numpy image tensor.':'',
' Rotated Numpy image tensor.':'',
'Performs a random spatial shear of a Numpy image tensor.':'',
'intensity: Transformation intensity in degrees.':'',
' Sheared Numpy image tensor.':'',
'Performs a random spatial shift of a Numpy image tensor.':'',
' Shifted Numpy image tensor.':'',
'Performs a random spatial zoom of a Numpy image tensor.':'',
' Zoomed Numpy image tensor.':'',
'Saves an image stored as a Numpy array to a path or file object.':'',
'The sampling probabilities are generated according to the sampling distribution used in word2vec:':'',
' A 1D Numpy array of length `size` where the ith entry':'',
'is the probability that a word of rank i should be sampled.':'',
'Pads sequences to the same length.':'',
'dtype: Type of the output sequences.':'',
'    pad either before or after each sequence.':'',
'    remove values from sequences larger than':'',
'    or in case of invalid shape for a `sequences` entry.':'',
'Generates skipgram word pairs.':'',
'This function transforms a sequence of word indexes (list of integers) into tuples of words of the form:':'',
'    word indices are expected to match the rank':'',
'shuffle: Whether to shuffle the word couples before returning them.':'',
'    encodes the probability to sample a word of rank i.':'',
'## Class TimeseriesGenerator':'',
'Utility class for generating batches of temporal data.':'',
'    containing consecutive data points (timesteps).':'',
'    to be the time dimension.':'',
'targets: Targets corresponding to timesteps in `data`.':'',
'    It should have same length as `data`.':'',
'length: Length of the output sequences (in number of timesteps).':'',
'    are used for create a sample sequence.':'',
'stride: Period between successive output sequences.':'',
'    in the output sequences. This is useful to reserve part of the':'',
'    data for test or validation.':'',
'    or instead draw them in chronological order.':'',
'    in reverse chronological order.':'',
'    (except maybe the last one).':'',
' from keras.preprocessing.sequence import TimeseriesGenerator':'',
'Returns the TimeseriesGenerator configuration as Python dictionary.':'',
' A Python dictionary with the TimeseriesGenerator configuration.':'',
'    to be passed to `json.dumps()`.':'',
' A JSON string containing the tokenizer configuration.':'',
' text: Input text (string).':'',
'n: Dimension of the hashing space.':'',
'    any function that takes in input a string and returns a int.':'',
'    is a stable hashing function.':'',
'lower: boolean. Whether to set the text to lowercase.':'',
'split: str. Separator for word splitting.':'',
'n: int. Size of vocabulary.':'',
'Converts a text to a sequence of words (or tokens).':'',
'lower: boolean. Whether to convert the input to lowercase.':'',
' A list of words (or tokens).':'',
'## Class Tokenizer':'',
'Text tokenization utility class.':'',
'    be kept.':'',
'filters: a string where each element is a character that will be':'',
'lower: boolean. Whether to convert the texts to lowercase.':'',
'Updates internal vocabulary based on a list of sequences.':'',
' sequences: A list of sequence.':'',
'    A "sequence" is a list of integer word indices.':'',
'Updates internal vocabulary based on a list of texts.':'',
'    or a list of list of strings.':'',
' A Python dictionary with the tokenizer configuration.':'',
'Converts a list of sequences into a Numpy matrix.':'',
' sequences: list of sequences':'',
'    (a sequence is a list of integer word indices).':'',
' A Numpy matrix.':'',
'    or if the Tokenizer requires to be fit to sample data.':'',
'Transforms each sequence into a list of text.':'',
' sequences: A list of sequences (list of integers).':'',
'Transforms each sequence in sequences to a list of texts(strings).':'',
' sequences: A list of sequences.':'',
' Yields individual texts.':'',
'Convert a list of texts to a Numpy matrix.':'',
' texts: list of strings.':'',
'Transforms each text in texts to a sequence of integers.':'',
' texts: A list of texts (strings).':'',
' A list of sequences.':'',
' Yields individual sequences.':'',
'## Class L1L2':'',
'Regularizer for L1 and L2 regularization.':'',
'## Class Regularizer':'',
'Regularizer base class.':'',
'Converts all convolution kernels in a model from Theano to TensorFlow.':'',
'Also works from TensorFlow to Theano.':'',
'## Class CustomObjectScope':'',
'Consider a custom object MyObject (e.g. a class):':'',
'Consider a custom object MyObject':'',
'Object of type CustomObjectScope.':'',
'## Class GeneratorEnqueuer':'',
'Builds a queue out of a data generator.':'',
'The provided generator can be finite in which case the class will throw a StopIteration exception.':'',
'Creates a generator to extract data from the queue.':'',
'Skip the data if it is None.':'',
'Starts the handler\'s workers.':'',
'Should be called by the same thread which called start().':'',
'Retrieves a live reference to the global dictionary of custom objects.':'',
'Downloads a file from a URL if it not already in the cache.':'',
'Path to the downloaded file':'',
'Returns the list of input tensors necessary to compute tensor.':'',
'Output will always be a list of tensors (potentially with 1 element).':'',
'List of input tensors.':'',
'## Class HDF5Matrix':'',
'Representation of HDF5 dataset to be used instead of a Numpy array.':'',
'Providing start and end allows use of a slice of the dataset.':'',
'Gets the datatype of the dataset.':'',
'A numpy dtype string.':'',
'### ndim':'',
'Gets the number of dimensions (rank) of the dataset.':'',
'An integer denoting the number of dimensions (rank) of the dataset.':'',
'Gets the total dataset size (number of elements).':'',
'An integer denoting the number of elements in the dataset.':'',
'Convert a Keras model to dot format.':'',
'This function is only available with the TensorFlow backend for the time being.':'',
'Example 1: Training models with weights merge on CPU':'',
'    from keras.applications import Xception':'',
'     except:':'',
'Normalizes a Numpy array.':'',
'A normalized copy of the array.':'',
'## Class OrderedEnqueuer':'',
'Builds a Enqueuer from a Sequence.':'',
'Converts a Keras model to dot format and save to a file.':'',
'## Class Progbar':'',
'Displays a progress bar.':'',
'Updates the progress bar.':'',
'## Class Sequence':'',
'Sequence are a safer way to do multiprocessing. This structure guarantees that the network will only train once on each sample per epoch which is not the case with generators.':'',
'     from skimage.io import imread':'',
'    from skimage.transform import resize':'',
'## Class SequenceEnqueuer':'',
'Base class to enqueue inputs.':'',
'The task of an Enqueuer is to use parallelism to speed up preprocessing. This is done with processes or threads.':'',
'The enqueuer.get() should be an infinite stream of datas.':'',
'Converts a class vector (integers) to binary class matrix.':'',
'A binary matrix representation of the input. The classes axis is placed last.':'',
'## Class KerasClassifier':'',
'Checks for user typos in params.':'',
'Gets parameters for this estimator.':'',
'Dictionary of parameter names mapped to their values.':'',
'Returns the class predictions for the given test data.':'',
'Returns class probability estimates for the given test data.':'',
'Returns the mean accuracy on the given test data and labels.':'',
'Sets the parameters of this estimator.':'',
'## Class KerasRegressor':'',
'Returns predictions for the given test data.':'',
'Returns the mean loss on the given test data and labels.':'',
'Transposes the last two dimensions of and conjugates tensor matrix.':'',
'The adjoint (a.k.a. Hermitian transpose a.k.a. conjugate transpose) of matrix.':'',
'Copy a tensor setting everything outside a central band in each innermost matrix':'',
'to zero.':'',
'The indicator function':'',
'#### Useful special cases:':'',
'Computes the Cholesky decomposition of one or more square matrices.':'',
'Note: The gradient computation on GPU is faster for large matrices but not for large batch dimensions when the submatrices are small. In this case it might be faster to use the CPU.':'',
'Compute the pairwise cross product.':'',
'A Tensor. Has the same type as a.':'',
'Computes the determinant of one or more square matrices.':'',
'Returns a batched diagonal tensor with given batched diagonal values.':'',
'A Tensor. Has the same type as diagonal.':'',
'Returns the batched diagonal part of a batched tensor.':'',
'The input must be at least a matrix.':'',
'A Tensor containing diagonals of input. Has the same type as input.':'',
'Computes the matrix exponential of one or more square matrices.':'',
'the matrix exponential of the input.':'',
'#### Scipy Compatibility':'',
'Equivalent to scipy.linalg.expm':'',
'Computes the global norm of multiple tensors.':'',
'Computes the inverse of one or more square invertible matrices or their':'',
'adjoints (conjugate transposes).':'',
'The op uses LU decomposition with partial pivoting to compute the inverses.':'',
'If a matrix is not invertible there is no guarantee what the op does. It may detect the condition and raise an exception or it may simply return a garbage result.':'',
'## Class LinearOperator':'',
'#### Performance contract':'',
'#### Shape compatibility':'',
'LinearOperator subclasses should operate on a [batch] matrix with compatible shape. Class docstrings should define what is meant by compatible shape. Some subclasses may not support batching.':'',
'x is a batch matrix with compatible shape for matmul if':'',
'rhs is a batch matrix with compatible shape for solve if':'',
'#### Example docstring for subclasses.':'',
'This operator acts on batch matrices with compatible shape. FILL IN WHAT IS MEANT BY COMPATIBLE SHAPE':'',
'#### Performance':'',
'FILL THIS IN':'',
'#### Matrix property hints':'',
'Initialize the LinearOperator.':'',
'### H':'',
'Returns the adjoint of the current LinearOperator.':'',
'LinearOperator which represents the adjoint of this LinearOperator.':'',
'TensorShape of batch dimensions of this LinearOperator.':'',
'Dimension (in the sense of vector spaces) of the domain of this operator.':'',
'Dimension object.':'',
'The DType of Tensors handled by this LinearOperator.':'',
'List of graph dependencies of this LinearOperator.':'',
'Return True/False depending on if this operator is square.':'',
'Dimension (in the sense of vector spaces) of the range of this operator.':'',
'TensorShape of this LinearOperator.':'',
'Rank (in the sense of tensors) of matrix corresponding to this operator.':'',
'Add matrix represented by this operator to x. Equivalent to A + x.':'',
'A Tensor with broadcast shape and same dtype as self.':'',
'### adjoint':'',
'Returns an Op that asserts this operator is non singular.':'',
'Returns an Op that asserts this operator is positive definite.':'',
'Here we check that this operator is exactly equal to its hermitian transpose.':'',
'### cholesky':'',
'Returns a Cholesky factor as a LinearOperator.':'',
'LinearOperator which represents the lower triangular matrix in the Cholesky decomposition.':'',
'### determinant':'',
'Determinant for every batch member.':'',
'Efficiently get the [batch] diagonal part of this operator.':'',
'Determined at runtime.':'',
'### inverse':'',
'Returns the Inverse of this LinearOperator.':'',
'LinearOperator representing inverse of this matrix.':'',
'Log absolute value of determinant for every batch member.':'',
'### matmul':'',
'Y.shape':'',
'### matvec':'',
'### solve':'',
'The returned Tensor will be close to an exact solution if A is well conditioned. Otherwise closeness will vary. See class docstring for details.':'',
'### solvevec':'',
'Tensor with shape [...,N] and same dtype as rhs.':'',
'Return a dense (batch) matrix representing this operator.':'',
'### trace':'',
'Shape [B1,...,Bb] Tensor of same dtype as self.':'',
'## Class LinearOperatorAdjoint':'',
'LinearOperator representing the adjoint of another operator.':'',
'This operator represents the adjoint of another operator.':'',
'The performance of LinearOperatorAdjoint depends on the underlying operators performance.':'',
'Initialize a LinearOperatorAdjoint.':'',
'LinearOperatorAdjoint is initialized with an operator A. The solve and matmul methods effectively flip the adjoint argument. E.g.':'',
'### operator':'',
'The operator before taking the adjoint.':'',
'## Class LinearOperatorBlockDiag':'',
'Combines one or more LinearOperators in to a Block Diagonal matrix.':'',
'operator.shape':'',
'The performance of LinearOperatorBlockDiag on any operation is equal to the sum of the individual operators\' operations.':'',
'Initialize a LinearOperatorBlockDiag.':'',
'### operators':'',
'## Class LinearOperatorCirculant':'',
'LinearOperator acting like a circulant matrix.':'',
'#### Description in terms of circulant matrices':'',
'    |x w z y|':'',
'    |y x w z|':'',
'    |z y x w|':'',
'See http://ee.stanford.edu/~gray/toeplitz.pdf':'',
'#### Description in terms of the frequency spectrum':'',
'#### Operator properties deduced from the spectrum.':'',
'A general property of Fourier transforms is the correspondence between Hermitian functions and real valued transforms.':'',
'#### Example of defining in terms of a real convolution kernel':'',
'#### Example of Hermitian spectrum':'',
'#### Example of forcing real dtype when spectrum is Hermitian':'',
'Initialize an LinearOperatorCirculant.':'',
'Depth of recursively defined circulant blocks defining this Operator.':'',
'    |X W Z Y|':'',
'    |Y X W Z|':'',
'    |Z Y X W|':'',
'Python integer.':'',
'### spectrum':'',
'Returns an Op that asserts this operator has Hermitian spectrum.':'',
'An Op that asserts this operator has Hermitian spectrum.':'',
'Shape of the block dimensions of self.spectrum.':'',
'Convolution kernel corresponding to self.spectrum.':'',
'The D dimensional DFT of this kernel is the frequency domain spectrum of this operator.':'',
'Tensor with dtype self.dtype.':'',
'## Class LinearOperatorCirculant2D':'',
'LinearOperator acting like a block circulant matrix.':'',
'#### Description in terms of block circulant matrices':'',
'Note that A itself will not in general be circulant.':'',
'Initialize an LinearOperatorCirculant2D.':'',
'## Class LinearOperatorCirculant3D':'',
'LinearOperator acting like a nested block circulant matrix.':'',
'### Examples':'',
'See LinearOperatorCirculant and LinearOperatorCirculant2D for examples.':'',
'## Class LinearOperatorComposition':'',
'Composes one or more LinearOperators.':'',
'The performance of LinearOperatorComposition on any operation is equal to the sum of the individual operators\' operations.':'',
'Initialize a LinearOperatorComposition.':'',
'## Class LinearOperatorDiag':'',
'LinearOperator acting like a [batch] square diagonal matrix.':'',
'LinearOperatorDiag is initialized with a (batch) vector.':'',
'This operator acts on [batch] matrix with compatible shape. x is a batch matrix with compatible shape for matmul and solve if':'',
'Initialize a LinearOperatorDiag.':'',
'### diag':'',
'## Class LinearOperatorFullMatrix':'',
'LinearOperator that wraps a [batch] matrix.':'',
'LinearOperatorFullMatrix has exactly the same performance as would be achieved by using standard TensorFlow matrix ops. Intelligent choices are made based on the following initialization hints.':'',
'Initialize a LinearOperatorFullMatrix.':'',
'## Class LinearOperatorHouseholder':'',
'LinearOperator acting like a [batch] of Householder transformations.':'',
'LinearOperatorHouseholder is initialized with a (batch) vector.':'',
'This operator acts on [batch] matrix with compatible shape.':'',
' #### Matrix property hints':'',
'These have the following meaning:':'',
'  in these promises being violated.':'',
'  way.':'',
'Initialize a LinearOperatorHouseholder.':'',
'## Class LinearOperatorIdentity':'',
'LinearOperator acting like a [batch] square identity matrix.':'',
'### Shape compatibility':'',
'### Performance':'',
'Initialize a LinearOperatorIdentity.':'',
'The LinearOperatorIdentity is initialized with arguments defining dtype and shape.':'',
'Add matrix represented by this operator to mat. Equiv to I + mat.':'',
'## Class LinearOperatorInversion':'',
'LinearOperator representing the inverse of another operator.':'',
'This operator represents the inverse of another operator.':'',
'Initialize a LinearOperatorInversion.':'',
'LinearOperatorInversion is initialized with an operator A. The solve and matmul methods are effectively swapped. E.g.':'',
'The operator before inversion.':'',
'## Class LinearOperatorKronecker':'',
'Kronecker product between two LinearOperators.':'',
'The performance of LinearOperatorKronecker on any operation is equal to the sum of the individual operators\' operations.':'',
'Initialize a LinearOperatorKronecker.':'',
'## Class LinearOperatorLowerTriangular':'',
'LinearOperator acting like a [batch] square lower triangular matrix.':'',
'Initialize a LinearOperatorLowerTriangular.':'',
'## Class LinearOperatorLowRankUpdate':'',
'Perturb a LinearOperator with a rank K update.':'',
'V^H is the Hermitian transpose (adjoint) of V.':'',
'Initialize a LinearOperatorLowRankUpdate.':'',
'### u':'',
'### v':'',
'## Class LinearOperatorScaledIdentity':'',
'Initialize a LinearOperatorScaledIdentity.':'',
'This operator is able to broadcast the leading (batch) dimensions.':'',
'### multiplier':'',
'## Class LinearOperatorToeplitz':'',
'LinearOperator acting like a [batch] of toeplitz matrices.':'',
'#### Description in terms of toeplitz matrices':'',
'Below is a 4 x 4 example:':'',
'    |e a b c|':'',
'    |f e a b|':'',
'    |g f e a|':'',
'#### Example of a Toeplitz operator.':'',
'Initialize a LinearOperatorToeplitz.':'',
'### col':'',
'### row':'',
'## Class LinearOperatorZeros':'',
'LinearOperator acting like a [batch] zero matrix.':'',
'Initialize a LinearOperatorZeros.':'',
'The LinearOperatorZeros is initialized with arguments defining dtype and shape.':'',
'Computes log of the determinant of a hermitian positive definite matrix.':'',
'underflow:':'',
'The natural log of the determinant of matrix.':'',
'Computes the matrix logarithm of one or more square matrices:':'',
'Computes the LU decomposition of one or more square matrices.':'',
'The input has to be invertible.':'',
'Transposes last two dimensions of tensor a.':'',
'A transposed batch matrix Tensor.':'',
'Matrix a can be transposed or adjointed (conjugated and transposed) on the fly by setting one of the corresponding flag to True. These are False by default.':'',
'Normalizes tensor along dimension axis using specified norm.':'',
'Computes the QR decompositions of one or more matrices.':'',
'Returns a batched matrix tensor with new batched diagonal values.':'',
'Computes the sign and the log of the absolute value of the determinant of':'',
'one or more square matrices.':'',
'Solves systems of linear equations.':'',
'A Tensor. Has the same type as matrix.':'',
'Computes the matrix square root of one or more square matrices:':'',
'Computes the singular value decompositions of one or more matrices.':'',
'as the third output argument.':'',
'Returns a diagonal tensor with a given diagonal values.':'',
'Returns the diagonal part of the tensor.':'',
'This operation returns a tensor with the diagonal part of the input. The diagonal part is computed as follows:':'',
'Compute the trace of a tensor x.':'',
'The trace of input tensor.':'',
'Solves systems of linear equations with upper or lower triangular matrices by backsubstitution.':'',
'x':'',
'Multiplies tridiagonal matrix by matrix.':'',
'The sequence format is recommended as the one with the best performance.':'',
'Solves tridiagonal systems of equations.':'',
'## Class Interpreter':'',
'Interpreter interface for TensorFlow Lite Models.':'',
'Gets model input details.':'',
'A list of input details.':'',
'Gets model output details.':'',
'A list of output details.':'',
'Gets the value of the input tensor (get a copy).':'',
'a numpy array.':'',
'Gets tensor details for every tensor with valid tensor details.':'',
'Tensors where required information about the tensor is not found are not added to the list. This includes temporary tensors without a name.':'',
'A list of dictionaries containing tensor information.':'',
'### invoke':'',
'Invoke the interpreter.':'',
'Resizes an input tensor.':'',
'Sets the value of the input tensor. Note this copies data in value.':'',
'Returns function that gives a numpy view of the current tensor buffer.':'',
'#### WRONG:':'',
'## Class OpsSet':'',
'Enum class defining the sets of ops available to generate TFLite models.':'',
'## Class Optimize':'',
'Enum defining the optimizations to apply when generating tflite graphs.':'',
'Some optimizations may come at the cost of accuracy.':'',
'## Class RepresentativeDataset':'',
'Representative dataset to evaluate optimizations.':'',
'Creates a representative dataset.':'',
'## Class TargetSpec':'',
'Specification of target device.':'',
'Details about target device. Converter optimizes the generated model for specific device.':'',
'Converts a TensorFlow model into TensorFlow Lite model.':'',
'The converted data in serialized format.':'',
'    funcs':'',
'Creates a TFLiteConverter object from ConcreteFunctions.':'',
'TFLiteConverter object.':'',
'Invalid input type.':'',
'    model':'',
'Creates a TFLiteConverter object from a Keras model.':'',
'Creates a TFLiteConverter object from a SavedModel directory.':'',
'Invalid signature keys.':'',
'Returns loaded Delegate object.':'',
'Delegate object.':'',
'## Class KeyValueTensorInitializer':'',
'Table initializers given keys and values tensors.':'',
'Constructs a table initializer object based on keys and values tensors.':'',
'The expected table key dtype.':'',
'The expected table value dtype.':'',
'### initialize':'',
'Initializes the given table with keys and values tensors.':'',
'The operation that initializes the table.':'',
'## Class TextFileIndex':'',
'The key and value content to get from each line.':'',
'This class defines the key and value used for tf.lookup.TextFileInitializer.':'',
'## Class TextFileInitializer':'',
'Table initializers from a text file.':'',
'This initializer assigns one entry in the table for each line in the file.':'',
'For example if we have a file with the following content:':'',
'The following snippet initializes a table with the first column as keys and second column as values:':'',
'Similarly to initialize the whole line as keys and the line number as values.':'',
'Constructs a table initializer object to populate from a text file.':'',
'Initializes the table from a text file.':'',
'## Class DenseHashTable':'',
'A generic mutable hash table implementation using tensors as backing store.':'',
'Data can be inserted by calling the insert method and removed by calling the remove method. It does not support initialization via the init method.':'',
'Creates an empty DenseHashTable object.':'',
'A DenseHashTable object.':'',
'### erase':'',
'Removes keys and its associated values from the table.':'',
'### insert':'',
'Associates keys with values.':'',
'A tensor containing the values in the same shape as keys using the table\'s value type.':'',
'### remove':'',
'A Tensor of same shape and type as the elements of inputs.':'',
'Converts IndexedSlices objects into dense tensors prior to adding.':'',
'The argument returned by this function is of the form':'',
'A Tensor of type float32 or float64.':'',
'Returns the index with the largest value across axes of a tensor.':'',
'Returns the index with the smallest value across axes of a tensor.':'',
'A Tensor. Has the same type as y.':'',
'Modified Bessel function of order 1.':'',
'It is preferable to use the numerically stabler function i1e(x) instead.':'',
'Equivalent to scipy.special.i1':'',
'Compute the regularized incomplete beta integral Ix(a,b).':'',
'The regularized incomplete beta integral is defined as:':'',
'is the incomplete beta function and':'',
'is the complete beta function.':'',
'InvalidArgumentError if negative values are provided as an input.':'',
'Returns the complex conjugate of a complex number.':'',
'The complex conjugate returned by this operation is of the form .':'',
'A Tensor that is the conjugate of x (with the same type).':'',
'Computes number of nonzero elements across dimensions of a tensor.':'',
'Compute the cumulative product of the tensor x along axis.':'',
'Compute the cumulative sum of the tensor x along axis.':'',
'The reverse and exclusive kwargs can also be combined:':'',
'A Tensor. Has the same shape and type as x.':'',
'Computes Python style division of x by y.':'',
'The lower regularized incomplete Gamma function is defined as:':'',
'is the lower incomplete Gamma function.':'',
'The upper regularized incomplete Gamma function is defined as:':'',
'is the upper incomplete Gama function.':'',
'Returns the imaginary part of a complex (or real) tensor.':'',
'Computes the inverse permutation of a tensor.':'',
'Returns which elements of x are finite.':'',
'Equivalent to np.isfinite':'',
'Returns which elements of x are Inf.':'',
'Equivalent to np.isinf':'',
'Returns which elements of x are NaN.':'',
'Equivalent to np.isnan':'',
'Returns True if x is strictly increasing.':'',
'Normalizes along dimension axis using an L2 norm.':'',
'The logarithm of':'',
'reducing along the last dimension.':'',
'A Tensor with the same type as x.':'',
'This operation returns the same result as the C++ std::nextafter function.':'',
'It can also return a subnormal number.':'',
'A Tensor. Has the same type as x1.':'',
'#### Cpp Compatibility':'',
'Equivalent to C++ std::nextafter function.':'',
'Compute the polygamma function ψ(n)(x).':'',
'The polygamma function is defined as:':'',
'Computes the elementwise value of a polynomial.':'',
'Equivalent to numpy.polyval.':'',
'Returns the real part of a complex (or real) tensor.':'',
'A Tensor of same shape and type as x.':'',
'Computes the "logical or" of elements across dimensions of a tensor.':'',
'Computes the Euclidean norm of elements across dimensions of a tensor.':'',
'Computes log(sum(exp(elements across dimensions of a tensor))).':'',
'Computes the maximum of elements across dimensions of a tensor.':'',
'Computes the minimum of elements across dimensions of a tensor.':'',
'Computes the product of elements across dimensions of a tensor.':'',
'Computes the standard deviation of elements across dimensions of a tensor.':'',
'Equivalent to np.std':'',
'Computes the sum of elements across dimensions of a tensor.':'',
'Computes the variance of elements across dimensions of a tensor.':'',
'Equivalent to np.var':'',
'Rounds half to even. Also known as bankers rounding. If you want to round according to the current system rounding mode use tf::cint. For example:':'',
'Computes the maximum along segments of a tensor.':'',
'Computes the mean along segments of a tensor.':'',
'Computes the minimum along segments of a tensor.':'',
'Computes the product along segments of a tensor.':'',
'Computes the sum along segments of a tensor.':'',
'Computes a tensor such that':'',
'Equivalent to scipy.special.expit':'',
'Computes softplus: log(exp(features) + 1).':'',
'A Tensor. Has the same type as features.':'',
'Finds values and indices of the k largest entries for the last dimension.':'',
'Computes the sum along segments of a tensor divided by the sqrt(N).':'',
'Returns the fraction of zeros in value.':'',
'Compute the Hurwitz zeta function':'',
'The Hurwitz zeta function is defined as:':'',
'Asserts that two structures are nested in the same way.':'',
'Returns a flat list from a given nested structure.':'',
'Users must not modify any collections used in nest while this function is running.':'',
'Returns true if its input is a collections.abc.Sequence (except strings).':'',
'True if the sequence is a not a string and is a collections.abc.Sequence or a dict.':'',
'Applies func to each entry in structure and returns a new structure.':'',
'Returns a given flattened sequence packed into a given structure.':'',
'Atrous convolution (a.k.a. convolution with holes or dilated convolution).':'',
'#### More specifically:':'',
'There are many different ways to implement atrous convolution (see the refs above). The implementation here reduces':'',
'to the following three operations:':'',
'can be equivalently performed cheaper in terms of computation and memory as:':'',
'A Tensor with the same type as value. Output shape with \'VALID\' padding is:':'',
'Output shape with \'SAME\' padding is:':'',
'Performs the avg pooling on the input.':'',
'Note internally this op reshapes and uses the underlying 2d operation.':'',
'Adds bias to value.':'',
'Merge repeated labels into single labels.':'',
'Usage with distribution strategy and custom training loop:':'',
'Scalar loss value.':'',
'The transpose of conv1d.':'',
'A Tensor with the same type as input.':'',
'a rank (N+2) filters Tensor of shape':'',
'The transpose of convolution.':'',
'Performs greedy decoding on the logits given in input (best path).':'',
'Computes CTC (Connectionist Temporal Classification) loss.':'',
'Computes the gradients of depthwise convolution with respect to the filter.':'',
'Computes the gradients of depthwise convolution with respect to the input.':'',
'Computes dropout.':'',
'Performs fractional average pooling on the input.':'',
'Performs fractional max pooling on the input.':'',
'L2 Loss.':'',
'Computes half the L2 norm of a tensor without the sqrt:':'',
'A Tensor. Has the same type as t.':'',
'Compute the Leaky ReLU activation function.':'',
'The activation value.':'',
'Local Response Normalization.':'',
'Computes log softmax activations.':'',
'Calculates the mean and variance of x.':'',
'Calculate the mean and variance of based on the sufficient statistics.':'',
'## Class RNNCellDeviceWrapper':'',
'## Class RNNCellDropoutWrapper':'',
'## Class RNNCellResidualWrapper':'',
'Scales the sum of the given regularization losses by number of replicas.':'',
'Computes softmax activations.':'',
'Computes softmax cross entropy between logits and labels.':'',
'Computes softsign: features / (abs(features) + 1).':'',
'Computes a weighted cross entropy.':'',
'Dequantize the \'input\' tensor into a float Tensor.':'',
'SCALED mode Example':'',
'SCALED mode matches the quantization approach used in QuantizeAndDequantize{V2|V3}.':'',
'Now we can dequantize the elements of our tensor:':'',
'Quantization is called fake since the output is still in floating point.':'',
'Compute gradients for a FakeQuantWithMinMaxArgs operation.':'',
'This operation has a gradient and thus allows for training min and max values.':'',
'Compute gradients for a FakeQuantWithMinMaxVars operation.':'',
'Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.':'',
'Quantize the \'input\' tensor of type float to \'output\' tensor of type \'T\'.':'',
'Now we can quantize the elements of our tensor:':'',
'Concatenates quantized tensors along one dimension.':'',
'Quantizes then dequantizes a tensor.':'',
'A Tensor. Each element is the result of quantizing and dequantizing the corresponding element of input.':'',
'## Class FIFOQueue':'',
'### dtypes':'',
'The list of dtypes for each component of a queue element.':'',
'The name of the underlying queue.':'',
'### names':'',
'The list of names for each component of a queue element.':'',
'The underlying queue reference.':'',
'The list of shapes for each component of a queue element.':'',
'Closes this queue.':'',
'The operation that closes the queue.':'',
'### dequeue':'',
'Dequeues one element from this queue.':'',
'The tuple of tensors that was dequeued.':'',
'Dequeues and concatenates n elements from this queue.':'',
'The list of concatenated tensors that was dequeued.':'',
'The tuple of concatenated tensors that was dequeued.':'',
'### enqueue':'',
'Enqueues one element to this queue.':'',
'The operation that enqueues a new tuple of tensors to the queue.':'',
'Enqueues zero or more elements to this queue.':'',
'The operation that enqueues a batch of tuples of tensors to the queue.':'',
'    queues':'',
'A QueueBase object.':'',
'Returns true if queue is closed.':'',
'This operation returns true if the queue is closed and false if the queue is open.':'',
'True if the queue is closed and false if the queue is open.':'',
'Compute the number of elements in this queue.':'',
'A scalar tensor containing the number of elements in this queue.':'',
'## Class PaddingFIFOQueue':'',
'## Class PriorityQueue':'',
'A queue implementation that dequeues elements in prioritized order.':'',
'## Class QueueBase':'',
'Base class for queue implementations.':'',
'Constructs a queue object from a queue reference.':'',
'## Class RandomShuffleQueue':'',
'A queue implementation that dequeues elements in a random order.':'',
'Create a queue that dequeues elements in a random order.':'',
'Applies a boolean mask to data without flattening the mask dimensions.':'',
'Returns a potentially ragged tensor that is formed by retaining the elements in data where the corresponding value in mask is True.':'',
'A potentially ragged tensor that is formed by retaining the elements in data where the corresponding value in mask is True.':'',
'Constructs a constant RaggedTensor from a nested Python list.':'',
'Applies op to the values of one or more RaggedTensors.':'',
'Returns a RaggedTensor containing the specified sequences of numbers.':'',
'Each row of the returned RaggedTensor contains a single sequence:':'',
'Stacks dynamic partitions of a Tensor or RaggedTensor.':'',
'Generate the set of all classes.':'',
'Draws samples from a categorical distribution.':'',
'Samples a set of classes using the provided (fixed) base distribution.':'',
'Draws shape samples from each of the given Gamma distribution(s).':'',
'The samples are differentiable w.r.t. alpha and beta. The derivatives are computed using the approach described in the paper':'',
'Samples a set of classes from a distribution learned during training.':'',
'Outputs random values from a normal distribution.':'',
'A tensor of the specified shape filled with random normal values.':'',
'Randomly shuffles a tensor along its first dimension.':'',
'Draws deterministic pseudorandom samples from a categorical distribution.':'',
'Outputs deterministic pseudorandom values from a normal distribution.':'',
'A tensor of the specified shape filled with random truncated normal values.':'',
'Outputs deterministic pseudorandom values from a uniform distribution.':'',
'A tensor of the specified shape filled with random uniform values.':'',
'Outputs random values from a truncated normal distribution.':'',
'Outputs random values from a uniform distribution.':'',
'Samples a set of classes using a uniform base distribution.':'',
'Creates a RNG state.':'',
'    algorithm':'',
'## Class Generator':'',
'Creates a generator.':'',
'### algorithm':'',
'The RNG algorithm.':'',
'### state':'',
'The internal state of the RNG.':'',
'### binomial':'',
'Outputs random values from a binomial distribution.':'',
'The generated values follow a binomial distribution with specified count and probability of success parameters.':'',
'    alg':'',
'Creates a generator from a key and a counter.':'',
'The new generator.':'',
'Creates a generator from a seed.':'',
'Creates a generator from a state.':'',
'Generates seeds for stateless random ops.':'',
'### normal':'',
'Resets the generator by a new state.':'',
'    counter':'',
'Resets the generator by a new seed.':'',
'Returns a list of independent Generator objects.':'',
'A list (length count) of Generator objects independent of each other. The new generators have the same RNG algorithm as the old one.':'',
'### uniform':'',
'Uniform distribution on an integer type\'s entire range.':'',
'A tensor of random numbers of the required shape.':'',
'Replaces the global generator with another Generator object.':'',
'Compute set difference of elements in last dimension of a and b.':'',
'All but the last dimension of a and b must match.':'',
'  #':'',
'Compute set intersection of elements in last dimension of a and b.':'',
'Compute number of unique elements along last dimension of a.':'',
'Compute set union of elements in last dimension of a and b.':'',
'Fast Fourier transform.':'',
'Equivalent to numpy.fft.fftshift. https://docs.scipy.org/doc/numpy/reference/generated/numpy.fft.fftshift.html':'',
'Inverse fast Fourier transform.':'',
'Inverse 2D fast Fourier transform.':'',
'Inverse 3D fast Fourier transform.':'',
'The inverse of fftshift.':'',
'Equivalent to numpy.fft.ifftshift. https://docs.scipy.org/doc/numpy/reference/generated/numpy.fft.ifftshift.html':'',
'Reconstructs a signal from a framed representation.':'',
'A Tensor of type complex64.':'',
'Generates sparse cross from a list of sparse and dense tensors.':'',
'then the output will be:':'',
'A SparseTensor of type string.':'',
'Generates hashed sparse cross from a list of sparse and dense tensors.':'',
'A SparseTensor of type int64.':'',
'This op also returns an indicator vector such that':'',
'Converts a dense tensor into a sparse tensor.':'',
'Only elements not equal to zero will be present in the result. The resulting SparseTensor has the same dtype and shape as the input.':'',
'The SparseTensor.':'',
'Masks elements of IndexedSlices.':'',
'This is useful when you need to extract a subset of slices in an IndexedSlices object.':'',
'The masked IndexedSlices instance.':'',
'Computes the max of elements across dimensions of a SparseTensor.':'',
'Computes the sum of elements across dimensions of a SparseTensor.':'',
'Reordering does not affect the shape of the SparseTensor.':'',
'Resets the shape of a SparseTensor with indices and values unchanged.':'',
'Reshapes a SparseTensor to represent values in a new dense shape.':'',
'Slice a SparseTensor based on the start and `size.':'',
'A SparseTensor objects resulting from splicing.':'',
'## Class SparseTensor':'',
'Represents a sparse tensor.':'',
'The corresponding dense tensor satisfies:':'',
'Example: The sparse tensor':'',
'represents the dense tensor':'',
'Creates a SparseTensor.':'',
'Get the TensorShape representing the shape of the dense tensor.':'',
'A TensorShape object.':'',
'Evaluates this sparse tensor in a Session.':'',
'A SparseTensorValue object.':'',
'Multiply SparseTensor (of rank 2) "A" by dense matrix "B".':'',
'#### Benchmark system:':'',
'#### Compiled with:':'',
'Converts a SparseTensor into a dense tensor.':'',
'Converts a SparseTensor of ids into a dense bool indicator tensor.':'',
'Note that repeats are allowed in the input SparseTensor. This op is useful for converting SparseTensors into dense formats for compatibility with ops that expect dense tensors.':'',
'A dense bool indicator tensor representing the indices with specified value.':'',
'Transposes a SparseTensor':'',
'A transposed SparseTensor.':'',
'Converts each entry in the given tensor to strings.':'',
'Supports many numeric types and boolean.':'',
'Split string elements of input into bytes.':'',
'A RaggedTensor of rank N+1: the bytes that make up the source strings.':'',
'Formats a string template using a list of tensors.':'',
'          " ...\n"':'',
'A scalar Tensor of type string.':'',
'Joins the strings in the given list of string tensors into one tensor;':'',
'TODO: add doc.':'',
'Check if the input matches the regex pattern.':'',
'The input is a string tensor of any shape. The pattern is a scalar string tensor which is applied to every element of the input tensor. The boolean values (True or False) of the output tensor indicate if the input matches the regex pattern provided.':'',
'Replace elements of input matching regex pattern with rewrite.':'',
'string Tensor of the same shape as input with specified replacements.':'',
'Split elements of input based on sep into a RaggedTensor.':'',
'Strip leading and trailing whitespaces from the Tensor.':'',
'Decodes each string in input into a sequence of Unicode code points.':'',
'Decodes each string into a sequence of code points with start offsets.':'',
'Encodes each sequence of Unicode code points in input into a string.':'',
'Determine the script codes of a given tensor of Unicode integer code points.':'',
'Splits each string in input into a sequence of Unicode code points.':'',
'Splits each string into a sequence of code points with start offsets.':'',
'Transcode the input text from a source encoding to a destination encoding.':'',
'Example usage with legacy TF 1.x graph execution:':'',
'Write an audio summary.':'',
'Creates a summary file writer for the given log directory.':'',
'A SummaryWriter object.':'',
'Returns a summary writer that does nothing.':'',
'This is useful as a placeholder in code that expects a context manager.':'',
'Forces summary writer to send any buffered data to storage.':'',
'This operation blocks until that finishes.':'',
'Write a histogram summary.':'',
'Write an image summary.':'',
'Sets summary recording on or off per the provided boolean value.':'',
'Returns a context manager that sets this value on enter and restores the previous value on exit.':'',
'Write a scalar summary.':'',
'## Class SummaryWriter':'',
'Interface representing a stateful summary writer object.':'',
'Returns a context manager that enables summary writing.':'',
'Flushes and closes the summary writer.':'',
'Flushes any buffered data.':'',
'### init':'',
'Initializes the summary writer.':'',
'Enables this summary writer for the current thread.':'',
'Write a text summary.':'',
'Stops and exports the active trace as a Summary and/or profile file.':'',
'Stops the current trace and discards any collected information.':'',
'Starts a trace to record computation graphs and profiling information.':'',
'Must be invoked in eager mode.':'',
'Writes a generic summary to the default SummaryWriter if one exists.':'',
'Public API for tf.summary.experimental namespace.':'',
'Returns the default summary step for the current thread.':'',
'Sets the default summary step for the current thread.':'',
'Experimental context manager for use when defining a custom summary op.':'',
'This makes the summary tag more predictable and consistent for the user.':'',
'Get the compilation flags for custom operators.':'',
'The compilation flags.':'',
'Get the directory containing the TensorFlow C++ header files.':'',
'The directory as string.':'',
'Get the directory containing the TensorFlow framework library.':'',
'Get the link flags for custom operators.':'',
'The link flags.':'',
'    actual':'',
'## Class Benchmark':'',
'Abstract class that provides helpers for TensorFlow benchmarks.':'',
'Evaluates tensors and returns numpy values.':'',
'tensors numpy values.':'',
'Report a benchmark.':'',
'Run an op or tensor in the given session. Report the results.':'',
'Returns a tf.compat.v1.ConfigProto for disabling the dependency optimizer.':'',
'A TensorFlow ConfigProto object.':'',
'Computes the theoretical and numeric Jacobian of f.':'',
'Create and start local servers and return the associated Server objects.':'',
'Read more at https://www.tensorflow.org/guide/extend/architecture':'',
'Returns the name of a GPU device if available or the empty string.':'',
'Returns whether TensorFlow was built with CUDA (GPU) support.':'',
'Returns whether TensorFlow was built with GPU (i.e. CUDA or ROCm) support.':'',
'Returns whether TensorFlow was built with ROCm (GPU) support.':'',
'Returns whether TensorFlow can access a GPU.':'',
'True if a GPU device of the requested kind is available.':'',
'Runs all unit tests.':'',
'## Class TestCase':'',
'Base class for tests that need to test TensorFlow.':'',
'Create an instance of the class that will use the named test method when executed. Raises a ValueError if the instance does not have a method with the specified name.':'',
'### addCleanup':'',
'Cleanup items are called even if setUp fails (unlike tearDown).':'',
'### addTypeEqualityFunc':'',
'    function':'',
'Add a type specific assertEqual style function to compare a type.':'',
'This method is for use by TestCase subclasses that need to register their own type equality functions to provide nicer error messages.':'',
'### assertAllClose':'',
'### assertAllCloseAccordingToType':'',
'### assertAllEqual':'',
'Asserts that two numpy arrays or Tensors have the same values.':'',
'### assertAllGreater':'',
'Assert element values are all greater than a target value.':'',
'### assertAllGreaterEqual':'',
'Assert element values are all greater than or equal to a target value.':'',
'### assertAllInRange':'',
'Assert that elements in a Tensor are all in a given range.':'',
'### assertAllInSet':'',
'Assert that elements of a Tensor are all in a given closed set.':'',
'### assertAllLess':'',
'Assert element values are all less than a target value.':'',
'### assertAllLessEqual':'',
'Assert element values are all less than or equal to a target value.':'',
'### assertAlmostEqual':'',
'Note that decimal places (from zero) are usually not the same as significant digits (measured from the most signficant digit).':'',
'If the two objects compare equal then they will automatically compare almost equal.':'',
'### assertAlmostEquals':'',
'### assertArrayNear':'',
'Asserts that two float arrays are near each other.':'',
'### assertBetween':'',
'Asserts that value is between minv and maxv (inclusive).':'',
'### assertCommandFails':'',
'Asserts a shell command fails and the error matches a regex in a list.':'',
'### assertCommandSucceeds':'',
'### assertContainsExactSubsequence':'',
'Asserts that "container" contains "subsequence" as an exact subsequence.':'',
'### assertContainsInOrder':'',
'Asserts that the strings provided are found in the target in order.':'',
'This may be useful for checking HTML output.':'',
'### assertContainsSubsequence':'',
'Asserts that "container" contains "subsequence" as a subsequence.':'',
'### assertContainsSubset':'',
'Checks whether actual iterable is a superset of expected iterable.':'',
'### assertCountEqual':'',
'### assertDTypeEqual':'',
'Assert ndarray data type is equal to expected.':'',
'### assertDeviceEqual':'',
'Asserts that the two given devices are the same.':'',
'### assertDictContainsSubset':'',
'Checks whether dictionary is a superset of subset.':'',
'### assertDictEqual':'',
'Raises AssertionError if a and b are not equal dictionaries.':'',
'### assertEmpty':'',
'Asserts that an object has zero length.':'',
'### assertEndsWith':'',
'### assertEqual':'',
'### assertEquals':'',
'### assertFalse':'',
'Check that the expression is false.':'',
'### assertGreater':'',
'### assertGreaterEqual':'',
'### assertIn':'',
'### assertIs':'',
'### assertIsInstance':'',
'### assertIsNone':'',
'### assertIsNot':'',
'### assertIsNotNone':'',
'Included for symmetry with assertIsNone.':'',
'### assertItemsEqual':'',
'### assertJsonEqual':'',
'Asserts that the JSON objects defined in two strings are equal.':'',
'A summary of the differences will be included in the failure message using assertSameStructure.':'',
'### assertLen':'',
'Asserts that an object has the expected length.':'',
'### assertLess':'',
'### assertLessEqual':'',
'### assertListEqual':'',
'### assertLogs':'',
'Example::':'',
'### assertMultiLineEqual':'',
'### assertNDArrayNear':'',
'Asserts that two numpy arrays have near values.':'',
'### assertNear':'',
'Asserts that two floats are near each other.':'',
'### assertNoCommonElements':'',
'Checks whether actual iterable and expected iterable are disjoint.':'',
'### assertNotAllClose':'',
'### assertNotAllEqual':'',
'Asserts that two numpy arrays or Tensors do not have the same values.':'',
'### assertNotAlmostEqual':'',
'Objects that are equal automatically fail.':'',
'### assertNotAlmostEquals':'',
'### assertNotEmpty':'',
'### assertNotEndsWith':'',
'### assertNotEqual':'',
'### assertNotEquals':'',
'### assertNotIn':'',
'### assertNotIsInstance':'',
'Included for symmetry with assertIsInstance.':'',
'### assertNotRegex':'',
'Fail the test if the text matches the regular expression.':'',
'### assertNotRegexpMatches':'',
'### assertNotStartsWith':'',
'### assertProtoEquals':'',
'### assertProtoEqualsVersion':'',
'### assertRaises':'',
'An optional keyword argument \'msg\' can be provided when assertRaises is used as a context object.':'',
'The context manager keeps a reference to the exception as the \'exception\' attribute. This allows you to inspect the exception after the assertion::':'',
'### assertRaisesOpError':'',
'### assertRaisesRegex':'',
'Asserts that the message in a raised exception matches a regex.':'',
'### assertRaisesRegexp':'',
'### assertRaisesWithLiteralMatch':'',
'Asserts that the message in a raised exception equals the given string.':'',
'### assertRaisesWithPredicateMatch':'',
'Returns a context manager to enclose code expected to raise an exception.':'',
'A context manager to surround code that is expected to raise an exception.':'',
'### assertRegex':'',
'Fail the test unless the text matches the regular expression.':'',
'### assertRegexMatch':'',
'Asserts that at least one regex in regexes matches str.':'',
'### assertRegexpMatches':'',
'### assertSameElements':'',
'Asserts that two sequences have the same elements (in any order).':'',
'### assertSameStructure':'',
'Asserts that two values contain the same structural content.':'',
'### assertSequenceAlmostEqual':'',
'An approximate equality assertion for ordered sequences.':'',
'Note that decimal places (from zero) are usually not the same as significant digits (measured from the most significant digit).':'',
'If the two sequences compare equal then they will automatically compare almost equal.':'',
'### assertSequenceEqual':'',
'An equality assertion for ordered sequences (like lists and tuples).':'',
'### assertSequenceStartsWith':'',
'An equality assertion for the beginning of ordered sequences.':'',
'### assertSetEqual':'',
'### assertShapeEqual':'',
'Asserts that a Numpy ndarray and a TensorFlow tensor have the same shape.':'',
'### assertStartsWith':'',
'### assertTotallyOrdered':'',
'Asserts that total ordering has been implemented correctly.':'',
'### assertTrue':'',
'Check that the expression is true.':'',
'### assertTupleEqual':'',
'### assertUrlEqual':'',
'### assertWarns':'',
'An optional keyword argument \'msg\' can be provided when assertWarns is used as a context object.':'',
'### assertWarnsRegex':'',
'Asserts that the message in a triggered warning matches a regexp. Basic functioning is similar to assertWarns() with the addition that only warnings whose messages also match the regular expression are considered successful matches.':'',
'Returns a TensorFlow Session for use in executing tests.':'',
'A Session object that should be used as a context manager to surround the graph building and execution code in a test case.':'',
'### captureWritesToStream':'',
'A context manager that captures the writes to a given stream.':'',
'A CapturedWrites object that contains all writes to the specified stream made during this context.':'',
'### checkedThread':'',
'Returns a Thread wrapper that asserts \'target\' completes successfully.':'',
'A wrapper for threading.Thread that supports start() and join() methods.':'',
'### countTestCases':'',
'Create a temporary directory specific to the test.':'',
'Create a temporary file specific to the test.':'',
'### debug':'',
'Run the test without collecting errors in a TestResult':'',
'### defaultTestResult':'',
'### doCleanups':'',
'Execute all cleanup functions. Normally called for you after tearDown.':'',
'### fail':'',
'### failIf':'',
'### failIfAlmostEqual':'',
'### failIfEqual':'',
'### failUnless':'',
'### failUnlessAlmostEqual':'',
'### failUnlessEqual':'',
'### failUnlessRaises':'',
'Returns a unique temporary directory for the test to use.':'',
'### id':'',
'Note that this will set this session and the graph as global defaults.':'',
'### setUp':'',
'Hook method for setting up the test fixture before exercising it.':'',
'### setUpClass':'',
'Hook method for setting up class fixture before running tests in the class.':'',
'### shortDescription':'',
'Formats both the test method name and the first line of its docstring.':'',
'### skipTest':'',
'Skip this test.':'',
'### subTest':'',
'### tearDown':'',
'Hook method for deconstructing the test fixture after testing it.':'',
'### tearDownClass':'',
'Hook method for deconstructing the class fixture after running all tests in the class.':'',
'Assertion failed.':'',
'## Class DeviceAssignment':'',
'Mapping from logical cores in a computation to the physical TPU topology.':'',
'Constructs a DeviceAssignment object.':'',
'The logical to physical core mapping.':'',
'The number of cores per replica.':'',
'The number of replicas of the computation.':'',
'### topology':'',
'A Topology that describes the TPU topology.':'',
'### coordinates':'',
'Returns the physical topology coordinates of a logical core.':'',
'Returns the CPU device attached to a logical core.':'',
'Lookup replica ids by task number and logical core.':'',
'Returns the name of the TPU device assigned to a logical core.':'',
'Returns the ordinal of the TPU device assigned to a logical core.':'',
'Initialize the TPU devices.':'',
'The tf.tpu.Topology object for the topology of the TPU cluster.':'',
'## Class BytesList':'',
'repeated bytes value':'',
'## Class CheckpointManager':'',
'Deletes old checkpoints.':'',
'Configure a CheckpointManager for use in directory.':'',
'### checkpoints':'',
'A list of managed checkpoints.':'',
'The prefix of the most recent checkpoint in directory.':'',
'Creates a new checkpoint and manages it.':'',
'Continuously yield new checkpoint files as they appear.':'',
'String paths to latest checkpoint files as they arrive.':'',
'## Class ClusterDef':'',
'repeated JobDef job':'',
'## Class ClusterSpec':'',
'Each job may also be specified as a sparse mapping from task indices to network addresses. This enables a server to be configured without needing to know the identity of (for example) all other worker tasks:':'',
'Creates a ClusterSpec.':'',
'### jobs':'',
'Returns a list of job names in this cluster.':'',
'Returns a dictionary from job names to their tasks.':'',
'A dictionary mapping job names to lists or dictionaries describing the tasks in those jobs.':'',
'Returns a mapping from task ID to address in the given job.':'',
'Returns the number of tasks defined in the given job.':'',
'The number of tasks defined in the given job.':'',
'Returns the address of the given task in the given job.':'',
'The address of the given task in the given job.':'',
'Returns a list of valid task indices in the given job.':'',
'A list of valid task indices in the given job.':'',
'## Class Coordinator':'',
'A coordinator for threads.':'',
'This class implements a simple mechanism to coordinate the termination of a set of threads.':'',
'A typical thread running with a coordinator will do something like:':'',
'#### Exception handling:':'',
'#### Thread code:':'',
'except Exception as e:':'',
'#### Main code:':'',
'#### Grace period for stopping:':'',
'except RuntimeError:':'',
'except Exception:':'',
'Create a new Coordinator.':'',
'### joined':'',
'Clears the stop flag.':'',
'Wait for threads to terminate.':'',
'Register a thread to join.':'',
'Request that the threads stop.':'',
'Check if stop was requested.':'',
'True if a stop was requested.':'',
'Context manager to request stop when an Exception is raised.':'',
'This context handler simplifies the exception handling. Use it as follows:':'',
'This is completely equivalent to the slightly longer code:':'',
'nothing.':'',
'Wait till the Coordinator is told to stop.':'',
'## Class Example':'',
'Features features':'',
'## Class ExponentialMovingAverage':'',
'Maintains moving averages of variables by employing an exponential decay.':'',
'Example usage when creating a training model:':'',
'There are two ways to use the moving averages for evaluations:':'',
'Example of restoring the shadow variable values:':'',
'Creates a new ExponentialMovingAverage object.':'',
'The apply() method has to be called to create shadow variables and add ops to maintain moving averages.':'',
'The name of this ExponentialMovingAverage object.':'',
'Maintains moving averages of variables.':'',
'Returns an op that updates all shadow variables from the current value of their associated variables.':'',
'An Operation that updates the moving averages.':'',
'### average':'',
'Returns the Variable holding the average of var.':'',
'A Variable object or None if the moving average of var is not maintained.':'',
'Returns the name of the Variable holding the average for var.':'',
'A string: The name of the variable that will be used or was used by the ExponentialMovingAverage class to hold the moving average of var.':'',
'Returns a map of names to Variables to restore.':'',
'Below is an example of such mapping:':'',
'## Class FeatureList':'',
'### feature':'',
'repeated Feature feature':'',
'## Class FeatureLists':'',
'## Class FeatureListEntry':'',
'FeatureList value':'',
'## Class Features':'',
'repeated FeatureEntry feature':'',
'## Class FeatureEntry':'',
'Feature value':'',
'## Class FloatList':'',
'repeated float value':'',
'Returns CheckpointState proto from the "checkpoint" file.':'',
'## Class Int64List':'',
'repeated int64 value':'',
'## Class JobDef':'',
'### tasks':'',
'repeated TasksEntry tasks':'',
'## Class TasksEntry':'',
'Finds the filename of latest saved checkpoint file.':'',
'Returns list of all variables in the checkpoint.':'',
'CheckpointReader object.':'',
'Returns the tensor value of the given variable in the checkpoint.':'',
'## Class SequenceExample':'',
'### context':'',
'Features context':'',
'## Class ServerDef':'',
'ClusterDef cluster':'',
'string protocol':'',
'## Class DynamicLossScale':'',
'Loss scale that dynamically adjusts itself.':'',
'Creates the dynamic loss scale.':'',
'Returns the current loss scale as a scalar float32 tensor.':'',
'Creates the LossScale from its config.':'',
'Returns the config of this loss scale.':'',
'Updates loss scale based on if gradients are finite in current step.':'',
'## Class FixedLossScale':'',
'Loss scale with a fixed value.':'',
'The loss scale is not updated for the lifetime of instances of this class. A given instance of this class always returns the same number when called.':'',
'Creates the fixed loss scale.':'',
'Updates the value of the loss scale.':'',
'## Class LossScale':'',
'Loss scale base class.':'',
'Initializes the loss scale class.':'',
'## Class PythonState':'',
'### deserialize':'',
'Callback to deserialize the object.':'',
'Callback to serialize the object. Returns a string.':'',
'Builds an operator that compiles and runs computation with XLA.':'',
'All `Operation`s returned from `computation` will be executed when evaluating any of the returned output tensors.':'',
'Enable or disable JIT compilation of operators within the scope.':'',
'NOTE: This is an experimental feature.':'',
'## Primary symbols':'',
'## Compat v2 symbols':'',
'## Compat v1 symbols':''
}