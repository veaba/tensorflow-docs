i18n={
# '## TensorFlow':'## Tensorflow ',
# ' pip install tensorflow':'pip安装tensorflow',
'## Modules':'## 模块',
'## Classes':'## Class ',
'## Functions':'## 功能',
'## Other Members':'## 其他成员',
'## Class AggregationMethod':'## 聚合法',
'A class listing aggregation methods used to combine gradients.':'不可抗力',
'### Aliases:':'### 别名：',
'Computing partial derivatives can require aggregating gradient contributions. This class lists the various methods that can be used to combine gradients in the graph.':'计算偏导数可能需要聚合梯度贡献。这个类列出了可以用来在图中组合渐变的各种方法。',
'The following aggregation methods are part of the stable API for aggregating gradients:':'以下聚合方法是聚合渐变的稳定API的一部分：',
'The following aggregation methods are experimental and may not be supported in future releases:':'以下聚合方法是实验性的，在将来的版本中可能不受支持：',
'## Class Members':'## Class 成员',
'## Class AggregationMethod':'## 类聚合方法',
'A class listing aggregation methods used to combine gradients.':'列出用于组合渐变的聚合方法的类。',
'Returns the indices of a tensor that give its sorted order along an axis.':'返回按轴排序的张量的索引。',
'#### Usage:':'#### 用法：',
'#### Args:':'#### 参数：',
'#### Returns:':'#### 返回：',
'An int32 Tensor with the same shape as values. The indices that would sort each slice of the given values along the given axis.':'具有与值相同形状的Int32张量。沿给定轴对给定值的每个切片进行排序的索引。',
'#### Raises:':'#### 加薪：',
'A Tensor. Has the same type as input.':'张量与输入类型相同。',
'Bitcasts a tensor from one type to another without copying data.':'位将张量从一种类型转换到另一种类型，而不复制数据。',
'#### Example 1:':'#### 例1：',
'Example 2:':'例2：',
'Example 3:':'例3：',
'A Tensor of type type.':'类型的张量。',
'Apply boolean mask to tensor.':'对张量应用布尔掩码。',
'#### Examples:':'#### 示例：',
'Computes the shape of a broadcast given symbolic shapes.':'计算给定符号形状的广播形状。',
'This is useful when validating the result of a broadcasting operation when the tensors do not have statically known shapes.':'当张量没有静态已知形状时，这在验证广播操作的结果时非常有用。',
'A rank 1 integer Tensor representing the broadcasted shape.':'表示广播形状的秩1整数张量。',
'Computes the shape of a broadcast given known shapes.':'根据已知形状计算广播的形状。',
'This is useful when validating the result of a broadcasting operation when the tensors have statically known shapes.':'当张量具有静态已知形状时，这在验证广播操作的结果时非常有用。',
'A TensorShape representing the broadcasted shape.':'表示广播形状的张量形状。',
'Broadcast an array for a compatible shape.':'广播兼容形状的数组。',
'Create a case operation.':'创建案例操作。',
'Example 1:':'例1：',
'#### Pseudocode:':'#### 伪码：',
'#### Expressions:':'#### 表达式：',
'#### V2 Compatibility':'####v2兼容性',
'Clips values of multiple tensors by the ratio of the sum of their norms.':'将多个张量的值按其范数之和的比率截取。',
'### Used in the guide:':'### 在指南中使用：',
'This operation is typically used to clip gradients before applying them with an optimizer.':'此操作通常用于在使用优化器应用渐变之前剪裁渐变。',
'A clipped Tensor or IndexedSlices.':'剪断的张量或索引线。',
'Clips tensor values to a specified min and max.':'将张量值剪裁为指定的最小值和最大值。',
'### Used in the tutorials:':'### 在教程中使用：',
'#### For example:':'#### 例如：',
'Concatenates tensors along one dimension.':'沿一维连接张量。',
'would produce:':'会产生：',
'can be rewritten as':'可以重写为',
'A Tensor resulting from concatenation of the input tensors.':'由输入张量串联而成的张量。',
'#### Example:':'#### 示例：',
'Creates a constant tensor.':'创建常量张量。',
'A Constant Tensor.':'恒定张量',
'Initializer that generates tensors with constant values.':'生成具有常量值的张量的初始值设定项。',
# '    &gt;&gt;&gt; import tensorflow as tf':'&gt>>>将TensorFlow导入为tf',
#'  ':'',
'Initialize self. See help(type(self)) for accurate signature.':'初始化自身。请参阅帮助（键入（self））以获取准确的签名。',
'## Methods':'## 方法',
'Returns a tensor object initialized as specified by the initializer.':'返回按初始值设定项指定初始化的张量对象。',
# '    config':'配置',
'Instantiates an initializer from a configuration dictionary.':'从配置字典实例化初始值设定项。',
'An Initializer instance.':'初始化器实例。',
'A context manager that specifies control dependencies for all operations constructed within the context.':'上下文管理器，指定上下文中构造的所有操作的控件依赖项。',
'Converts the given value to a Tensor.':'将给定值转换为张量。',
'A Tensor based on value.':'基于值的张量。',
'## Class CriticalSection':'## 类关键节',
'Critical section.':'关键部分。',
'A CriticalSection object is a resource in the graph which executes subgraphs in serial order. A common example of a subgraph one may wish to run exclusively is the one given by the following function:':'criticalsection对象是图中按顺序执行子图的资源。希望以独占方式运行的子图的一个常见示例是由以下函数给出的子图：',
'The solution is to ensure any access to the underlying resource v is only processed through a critical section:':'解决方案是确保对底层资源v的任何访问仅通过关键部分进行处理：',
'NOTES':'笔记',
'Creates a critical section.':'创建关键节。',
'## Properties':'## 属性',
'### name':'### 姓名',
'### execute':'### 执行',
'Execute function fn() inside the critical section.':'在关键部分内执行函数fn（）。',
'The tensors returned from fn().':'从fn（）返回的张量。',
'Decorator to define a function with a custom gradient.':'decorator定义具有自定义渐变的函数。',
'The gradient expression can be analytically simplified to provide numerical stability:':'可以对梯度表达式进行解析简化，以提供数值稳定性：',
'Specifies the device for ops created/executed in this context.':'指定在此上下文中创建/执行操作的设备。',
'A context manager that specifies the default device to use for newly created ops.':'上下文管理器，指定用于新创建的操作的默认设备。',
'## Class DeviceSpec':'## 类设备规范',
'Represents a (possibly partial) specification for a TensorFlow device.':'表示TensorFlow设备的（可能是部分）规范。',
'Create a new DeviceSpec object.':'创建一个新的devicespec对象。',
'### job':'### 工作',
'### replica':'### 复制品',
'### task':'### 任务',
'same value for all the internal fields.':'所有内部字段的值都相同。',
'Return True if other is also a DeviceSpec instance and has same value as the current instance. Return False otherwise.':'如果other也是devicespec实例，并且与当前实例具有相同的值，则返回true。否则返回false。',
# '    spec':'规格',
'Construct a DeviceSpec from a string.':'从字符串构造一个devicespec。',
'A DeviceSpec.':'恶魔啄食者',
'Returns a new DeviceSpec which incorporates dev.':'返回一个包含dev的新devicespec。',
'is equivalent to:':'相当于：',
'A new DeviceSpec which combines self and dev':'一种结合了self和dev的新设备pec',
'Parse a DeviceSpec name into its components.':'将devicespec名称解析为其组件。',
'Recommended:':'推荐：',
'Will work in 1.x and 2.x (though deprecated in 2.x):':'将在1.x和2.x中工作（尽管在2.x中已弃用）：',
'Will NOT work in 2.x:':'在2.x中不起作用：',
'The DeviceSpec.':'魔鬼佩克。',
'### replace':'### 替换',
'Convenience method for making a new DeviceSpec by overriding fields.':'通过重写字段来生成新的devicespec的方便方法。',
'#### For instance:':'#### 例如：',
'A DeviceSpec with the fields specified in kwargs overridden.':'具有在kwargs中指定的字段的devicespec被重写。',
'Return a string representation of this DeviceSpec.':'返回此设备规范的字符串表示形式。',
'a string of the form /job:/replica:/task:/device::.':'表单/job:/replica:/task:/device:：的字符串。',
'data.shape must start with partitions.shape.':'data.shape必须以partitions.shape开头。',
'Interleave the values from the data tensors into a single tensor.':'将数据张量中的值交错到单个张量中。',
'Builds a merged tensor such that':'建立一个合并的张量',
'A Tensor. Has the same type as data.':'张量与数据类型相同。',
'Computes the Levenshtein distance between sequences.':'计算序列之间的levenshtein距离。',
'This operation would return the following:':'此操作将返回以下内容：',
'A generalized contraction between tensors of arbitrary dimension.':'任意维张量之间的广义收缩。',
'The corresponding equation is:':'相应的方程式为：',
'Many common operations can be expressed in this way. For example:':'许多常见的操作都可以用这种方式表示。例如：',
'the input shapes are inconsistent along a particular axis.':'输入形状沿特定轴不一致。',
'Updates the shape of a tensor and checks at runtime that the shape holds.':'更新张量的形状，并在运行时检查形状是否保持不变。',
'Returns True if the current thread has eager execution enabled.':'如果当前线程已启用紧急执行，则返回true。',
'Inserts a dimension of 1 into a tensor\'s shape.':'在张量的形状中插入尺寸1。',
'#### Other examples:':'#### 其他示例：',
'This operation requires that:':'此操作要求：',
'Creates a tensor filled with a scalar value.':'创建填充标量值的张量。',
'This operation creates a tensor of shape dims and fills it with value.':'此操作将创建形状变暗的张量并用值填充它。',
'A Tensor. Has the same type as value.':'张量与值具有相同的类型。',
'Generates fingerprint values.':'生成指纹值。',
'Generates fingerprint values of data.':'生成数据的指纹值。',
'Creates a callable TensorFlow graph from a Python function.':'从python函数创建可调用的tensorflow图。',
'Example Usage':'示例用法',
'function can be applied to methods of an object. For example:':'函数可以应用于对象的方法。例如：',
'Input Signatures':'输入签名',
'Tracing and staging':'跟踪和分期',
'Retracing':'回溯',
'Gather slices from params axis axis according to indices.':'根据索引从params轴收集切片。',
'Where':'在哪里？',
'The shape of the output tensor is:':'输出张量的形状为：',
'A Tensor. Has the same type as params.':'张量具有与params相同的类型。',
'Gather slices from params into a Tensor with shape specified by indices.':'将参数中的切片聚集到由索引指定形状的张量中。',
'The last dimension of indices can be at most the rank of params:':'索引的最后一个维度最多可以是参数的秩：',
'Some examples below.':'下面是一些例子。',
'Simple indexing into a matrix:':'矩阵的简单索引：',
'Slice indexing into a matrix:':'将索引切片到矩阵中：',
'Batched indexing into a matrix:':'批量索引到矩阵：',
'Batched slice indexing into a matrix:':'批量切片索引到矩阵：',
'Examples with batched \'params\' and \'indices\':':'带有成批“params”和“index”的示例：',
'Return TF logger instance.':'返回tf logger实例。',
'Constructs symbolic derivatives of sum of ys w.r.t. x in xs.':'构造xs中ys w.r.t.x和的符号导数。',
'gradients() adds ops to the graph to output the derivatives of ys with respect to xs. It returns a list of Tensor of length len(xs) where each tensor is the sum(dy/dx) for y in ys.':'gradients（）将ops添加到图中，以输出ys相对于xs的导数。它返回长度len（xs）的张量列表，其中每个张量是y在ys中的和（dy/dx）。',
'A list of sum(dy/dx) for each x in xs.':'xs中每个x的和（dy/dx）的列表。',
'## Class GradientTape':'## 类渐变磁带',
'Record operations for automatic differentiation.':'记录操作以便自动区分。',
'Operations are recorded if they are executed within this context manager and at least one of their inputs is being "watched".':'如果操作在此上下文管理器中执行，并且至少有一个输入被“监视”，则会记录这些操作。',
'del g  # Drop the reference to the tape':'删除对磁带的引用',
'Note that only tensors with real or complex dtypes are differentiable.':'注意，只有实型或复型张量是可微的。',
'Creates a new GradientTape.':'创建新的GradientTape。',
'Enters a context inside which operations are recorded on this tape.':'输入在此磁带上记录操作的上下文。',
#'    traceback':'回溯',
'#### Example usage:':'#### 示例用法：',
'### gradient':'### 梯度',
'Computes the gradient using operations recorded in context of this tape.':'使用此磁带上下文中记录的操作计算渐变。',
'### jacobian':'### 雅可比',
'Computes the jacobian using operations recorded in context of this tape.':'使用此磁带上下文中记录的操作计算雅可比。',
'### reset':'### 重置',
'Clears all information stored in this tape.':'清除此磁带中存储的所有信息。',
'Temporarily stops recording operations on this tape.':'暂时停止在此磁带上录制操作。',
'Operations executed while this context manager is active will not be recorded on the tape. This is useful for reducing the memory used by tracing all computations.':'此上下文管理器处于活动状态时执行的操作不会记录在磁带上。这对于减少跟踪所有计算所用的内存非常有用。',
'#### Yields:':'#### 收益率：',
'### watch':'### 监视',
'Ensures that tensor is being traced by this tape.':'确保张量被这个带子追踪。',
'Returns variables watched by this tape in order of construction.':'返回此磁带按构造顺序监视的变量。',
'A function h(x) which returns the same values as f(x) and whose gradients are the same as those of an identity function.':'一种函数h（x），它返回与f（x）相同的值，其梯度与恒等函数的梯度相同。',
'## Class Graph':'## 类图',
'Returns True iff this graph represents a function.':'如果此图表示函数，则返回true。',
'### collections':'### 收藏',
'Returns the names of the collections known to this graph.':'返回此图已知的集合的名称。',
'### finalized':'### 定稿',
'True if this graph has been finalized.':'如果此图已完成，则为true。',
'The GraphDef version information of this graph.':'此图的graphdef版本信息。',
'A VersionDef.':'变形金刚',
'### seed':'### 种子',
'### version':'### 版本',
'Returns a version number that increases as ops are added to the graph.':'返回一个版本号，该版本号随着操作添加到图中而增加。',
'An integer version that increases as ops are added to the graph.':'一个整数版本，当操作添加到图中时会增加。',
# '    value':'价值',
'Stores value in the collection with the given name.':'使用给定的名称存储集合中的值。',
'Stores value in the collections given by names.':'存储按名称给定的集合中的值。',
'Returns a context manager that makes this Graph the default graph.':'返回使此图成为默认图的上下文管理器。',
'The following code examples are equivalent:':'以下代码示例是等效的：',
'If eager execution is enabled ops created under this context manager will be added to the graph instead of executed eagerly.':'如果启用了紧急执行，则在此上下文管理器下创建的操作将添加到图表中，而不是紧急执行。',
'A context manager for using this graph as the default graph.':'用于将此图用作默认图的上下文管理器。',
'Returns a serialized GraphDef representation of this graph.':'返回此图的序列化graphdef表示形式。',
'This function is the canonical way to get/validate an object of one of the allowed types from an external argument reference in the Session API.':'此函数是从会话api中的外部参数引用获取/验证允许类型之一的对象的规范方法。',
'This method may be called concurrently from multiple threads.':'此方法可以从多个线程并发调用。',
'The Tensor or Operation in the Graph corresponding to obj.':'图中与obj对应的张量或运算。',
'Clears all values in a collection.':'清除集合中的所有值。',
'Returns a context manager that specifies an op to colocate with.':'返回一个上下文管理器，该上下文管理器指定要与之并置的操作。',
'NOTE Using a colocation scope resets any existing device constraints.':'注意：使用托管作用域会重置任何现有的设备约束。',
'A context manager that specifies the op with which to colocate newly created ops.':'一种上下文管理器，指定与新创建的操作并列的操作。',
'### container':'### 集装箱',
'Returns a context manager that specifies the resource container to use.':'返回指定要使用的资源容器的上下文管理器。',
'Returns a context manager that specifies control dependencies.':'返回指定控件依赖项的上下文管理器。',
'You can pass None to clear the control dependencies:':'您可以传递“无”以清除控件依赖项：',
'N.B. The control dependencies context applies only to ops that are constructed within the context. Merely using an op or tensor in the context does not add a control dependency. The following example illustrates this point:':'注意：控件依赖关系上下文仅适用于在上下文中构造的操作。仅在上下文中使用op或tensor不会添加控件依赖项。以下示例说明了这一点：',
'This is because evaluating the gradient graph does not require evaluating the constant(1) op created in the forward pass.':'这是因为计算渐变图不需要计算在正向过程中创建的常量（1）op。',
'An Operation object.':'一个操作对象。',
'### device':'### 设备',
'Returns a context manager that specifies the default device to use.':'返回指定要使用的默认设备的上下文管理器。',
'### finalize':'### 定稿',
'Returns a list of collections used in this graph.':'返回此图中使用的集合的列表。',
'Returns a list of values in the collection with the given name.':'返回集合中具有给定名称的值的列表。',
'Returns the current name scope.':'返回当前名称范围。',
'would print the string scope1/scope2.':'将打印字符串scope1/scope2。',
'A string representing the current name scope.':'表示当前名称作用域的字符串。',
'Returns the Operation with the given name.':'返回具有给定名称的操作。',
'The Operation with the given name.':'具有给定名称的操作。',
'Return the list of operations in the graph.':'返回图形中的操作列表。',
'A list of Operations.':'操作列表。',
'Returns the Tensor with the given name.':'返回给定名称的张量。',
'The Tensor with the given name.':'具有给定名称的张量。',
'EXPERIMENTAL: A context manager for overriding gradient functions.':'实验性的：用于覆盖渐变函数的上下文管理器。',
'This context manager can be used to override the gradient function that will be used for ops within the scope of the context.':'此上下文管理器可用于重写将用于上下文范围内的操作的渐变函数。',
'A context manager that sets the alternative op type to be used for one or more ops created in that context.':'一种上下文管理器，它将可选操作类型设置为用于在该上下文中创建的一个或多个操作。',
'Returns True if and only if tensor is feedable.':'当且仅当张量可馈送时返回true。',
'Returns a context manager that creates hierarchical names for operations.':'返回为操作创建分层名称的上下文管理器。',
'The name argument will be interpreted as follows:':'name参数的解释如下：',
'NOTE: This constructor validates the given name. Valid scope names match one of the following regular expressions:':'注意：此构造函数验证给定的名称。有效的作用域名称与下列正则表达式之一匹配：',
'A context manager that installs name as a new name scope.':'将名称安装为新名称作用域的上下文管理器。',
'Marks the given tensor as unfeedable in this graph.':'将给定的张量标记为此图中不需要的张量。',
'Marks the given op as unfetchable in this graph.':'在此图中将给定操作标记为不可蚀刻。',
'Return a unique operation name for name.':'为name返回唯一的操作名。',
'Create an op that groups multiple operations.':'创建对多个操作进行分组的操作。',
'An Operation that executes all its inputs.':'执行其所有输入的操作。',
'Gives a guarantee to the TF runtime that the input tensor is a constant.':'向tf运行时保证输入张量是常量。',
'The runtime is then free to make optimizations based on this.':'然后，运行库可以在此基础上自由进行优化。',
'Only accepts value typed tensors as inputs and rejects resource variable handles as input.':'只接受值类型的张量作为输入，拒绝资源变量句柄作为输入。',
'Returns the input tensor without modification.':'返回未经修改的输入张量。',
'Constructs the Hessian of sum of ys with respect to x in xs.':'在xs中构造y的和相对于x的hessian。',
'hessians() adds ops to the graph to output the Hessian matrix of ys with respect to xs. It returns a list of Tensor of length len(xs) where each tensor is the Hessian of sum(ys).':'hessians（）将ops添加到图中，以输出ys相对于xs的hessian矩阵。它返回长度len（xs）的张量列表，其中每个张量都是sum（ys）的hessian。',
'A list of Hessian matrices of sum(ys) for each x in xs.':'xs中每个x的hessian和矩阵（ys）的列表。',
'Return histogram of values.':'返回值的直方图。',
'Bins the given values for use in a histogram.':'在直方图中使用的给定值。',
'A Tensor holding the indices of the binned values whose shape matches values.':'一种张量，用于保存形状与值匹配的二进制值的索引。',
'Return a tensor with the same shape and contents as input.':'返回与输入形状和内容相同的张量。',
'Returns a list of tensors with the same shapes and contents as the input':'返回与输入形状和内容相同的张量列表',
'tensors.':'张量。',
'A list of Tensor objects. Has the same type as input.':'张量对象的列表。与输入类型相同。',
'## Class IndexedSlices':'## 类索引',
'A sparse representation of a set of tensor slices at given indices.':'给定索引处一组张量切片的稀疏表示。',
'This class is a simple wrapper for a pair of Tensor objects:':'此类是一对张量对象的简单包装：',
'The dense tensor dense represented by an IndexedSlices slices has':'由indexedlices切片表示的稠密张量稠密',
'Creates an IndexedSlices.':'创建indexedlices。',
'### dtype':'### 数据类型',
'The DType of elements in this tensor.':'这个张量中元素的数据类型。',
'### graph':'### 图表',
'### indices':'### 指数',
'The name of this IndexedSlices.':'此索引的名称。',
'### op':'### 操作',
'The Operation that produces values as an output.':'作为输出产生值的操作。',
'### values':'### 价值观',
'A Tensor containing the values of the slices.':'包含切片值的张量。',
'### consumers':'### 消费者',
'## Class IndexedSlicesSpec':'## 类索引ICESSPEC',
'Returns the most specific TypeSpec compatible with self and other.':'返回与self和other兼容的最具体的typespec。',
'(3) The gradient tape is paused while the scope is active.':'（3）当作用域处于活动状态时，渐变带暂停。',
'Generates values in an interval.':'以间隔生成值。',
'A Tensor. Has the same type as start.':'张量具有与start相同的类型。',
'Loads a TensorFlow plugin.':'加载TensorFlow插件。',
'A python module containing the Python wrappers for Ops defined in the plugin.':'一个python模块，包含插件中定义的用于操作的python包装器。',
'Create a numpy ndarray from a tensor.':'从张量创建一个numpy-ndarray。',
'Create a numpy ndarray with the same shape and data as the tensor.':'创建一个与张量具有相同形状和数据的numpy ndarray。',
'A numpy array with the tensor contents.':'具有张量内容的numpy数组。',
'Create a TensorProto.':'创建一个tensorproto。',
'instead.':'相反。',
'#### Notes:':'#### 注：',
'## Class Module':'## 类模块',
'Base neural network module class.':'基本神经网络模块类。',
'You can use the Dense layer as you would expect:':'可以按预期使用密集层：',
' d.variables':'d.变量',
'Returns the name of this module as passed or determined in the ctor.':'返回在ctor中传递或确定的此模块的名称。',
'### submodules':'### 子模块',
'A sequence of all submodules.':'所有子模块的序列。',
'Sequence of variables owned by this module and it\'s submodules.':'此模块及其子模块拥有的变量序列。',
'A sequence of variables for the current module (sorted by attribute name) followed by variables from all submodules recursively (breadth first).':'当前模块的变量序列（按属性名排序），后跟所有子模块的变量递归（广度优先）。',
'### variables':'### 变量',
'Decorator to automatically enter the module name scope.':'decorator自动输入模块名作用域。',
'mod.w':'W型',
'The original method wrapped such that it enters the module\'s name scope.':'原来的方法被包装成进入模块的名称范围。',
'A context manager for use when defining a Python op.':'定义python操作时使用的上下文管理器。',
'Initialize the context manager.':'初始化上下文管理器。',
'Start the scope block.':'启动范围块。',
'The scope name.':'作用域名称。',
'Batches the computation done by the decorated function.':'批处理修饰函数完成的计算。',
'Assumes that all arguments of the decorated function are Tensors which will be batched along their first dimension.':'假设修饰函数的所有参数都是张量，这些张量将沿着它们的第一个维度进行批处理。',
'SparseTensor is not supported. The return value of the decorated function must be a Tensor or a list/tuple of Tensors.':'不支持Sparsetensor。修饰函数的返回值必须是张量或张量的列表/元组。',
'The decorated function will return the unbatched computation output Tensors.':'修饰函数将返回未匹配的计算输出张量。',
'#### Numpy Compatibility':'####numpy兼容性',
'Does nothing. Only useful as a placeholder for control edges.':'什么都不做。仅用作控制边的占位符。',
'The created Operation.':'创建的操作。',
'Wraps a python function and uses it as a TensorFlow op.':'包装python函数并将其用作tensorflow操作。',
'A list of Tensor or a single Tensor which func computes.':'func计算的张量或单个张量的列表。',
'Creates a tensor with all elements set to 1.':'创建所有元素都设置为1的张量。',
'This operation returns a tensor of type dtype with shape shape and all elements set to 1.':'此操作返回dtype类型的张量，其shape shape和所有元素都设置为1。',
'A Tensor with all elements set to 1.':'所有元素都设为1的张量。',
'Initializer that generates tensors initialized to 1.':'生成初始化为1的张量的初始值设定项。',
'Creates a tensor with all elements set to one.':'创建所有元素都设置为一的张量。',
'A Tensor with all elements set to one.':'所有元素都设为一的张量。',
'If indices is a scalar the output shape will be a vector of length depth':'如果索引是标量，则输出形状将是长度深度向量',
'## Class Operation':'## Class 作业',
'Represents a graph node that performs computation on tensors.':'表示对张量执行计算的图形节点。',
'Creates an Operation.':'创建操作。',
'The Operation objects on which this op has a control dependency.':'此操作对其具有控件依赖关系的操作对象。',
'A list of Operation objects.':'操作对象的列表。',
'The Graph that contains this operation.':'包含此操作的图表。',
'### inputs':'### 输入',
'The list of Tensor objects representing the data inputs of this op.':'表示此操作的数据输入的张量对象列表。',
'The full name of this operation.':'此操作的全名。',
'Returns the NodeDef representation of this operation.':'返回此操作的nodededf表示形式。',
'Returns the OpDef proto that represents the type of this op.':'返回表示此操作类型的opdef proto。',
'### outputs':'### 输出',
'The list of Tensor objects representing the outputs of this op.':'表示此操作输出的张量对象列表。',
'### traceback':'### 回溯',
'Returns the call stack from when this operation was constructed.':'返回构造此操作时的调用堆栈。',
'Same as traceback but includes start line of function definition.':'与回溯相同，但包含函数定义的起始行。',
'### type':'### 类型',
'The type of the op (e.g. "MatMul").':'OP的类型（例如“matmul”）。',
'Returns the list of colocation groups of the op.':'返回操作的托管组列表。',
'Returns the value of the attr of this op with the given name.':'返回具有给定名称的此操作的attr的值。',
'### run':'### 跑步',
'Runs this operation in a Session.':'在会话中运行此操作。',
'Calling this method will execute all preceding operations that produce the inputs needed for this operation.':'调用此方法将执行生成此操作所需输入的所有前面的操作。',
'DEPRECATED: Use outputs.':'不推荐：使用输出。',
'## Class OptionalSpec':'## 类选项规范',
'Represents an optional potentially containing a structured value.':'表示可能包含结构化值的可选值。',
'The Python type for values that are compatible with this TypeSpec.':'与此类型规范兼容的值的python类型。',
'Pads a tensor.':'垫张量。',
'The padded size of each dimension D of the output is:':'输出的每个维度d的填充大小为：',
'A Tensor. Has the same type as tensor.':'张量与张量类型相同。',
'Requires that the shape of inputs be known at graph construction time.':'要求在图构造时知道输入的形状。',
'This is the opposite of unstack. The numpy equivalent is':'这与不后退相反。纽比当量是',
'Print the specified inputs.':'打印指定的输入。',
'Changing the input separator:':'更改输入分隔符：',
'Compatibility usage in TF 1.x graphs:':'tf 1.x图中的兼容性用法：',
'#### Python2 Compatibility':'####python2相容性',
'Wraps a python function into a TensorFlow op that executes it eagerly.':'将python函数包装成tensorflow op，tensorflow op急切地执行它。',
'A list of Tensor or a single Tensor which func computes; an empty list if func returns None.':'func计算的张量或单个张量的列表；如果func不返回任何值，则为空列表。',
'## Class RaggedTensor':'## 类RaggedSensor',
'Represents a ragged tensor.':'表示不规则的张量。',
'### Potentially Ragged Tensors':'### 潜在不规则张量',
'### Documenting RaggedTensor Shapes':'### 记录RaggedSensor形状',
'### Component Tensors':'### 分量张量',
'### Multiple Ragged Dimensions':'### 多个不规则尺寸',
'RaggedTensors with multiple ragged dimensions can be defined by using a nested RaggedTensor for the values tensor. Each nested RaggedTensor adds a single ragged dimension.':'对于值张量，可以使用嵌套的ragged tensor定义具有多个ragged维度的raggedtensor。每个嵌套的raggedtensor都添加一个不规则维度。',
'### Uniform Inner Dimensions':'### 内部尺寸一致',
'RaggedTensors with uniform inner dimensions can be defined by using a multidimensional Tensor for values.':'内尺寸一致的raggedtensors可以通过对值使用多维张量来定义。',
'### RaggedTensor Shape Restrictions':'###RaggedSensor形状限制',
'The shape of a RaggedTensor is currently restricted to have the following form:':'RaggedSensor的形状目前仅限于以下形式：',
'This restriction follows from the fact that each nested RaggedTensor replaces the uniform outermost dimension of its values with a uniform dimension followed by a ragged dimension.':'此限制源于这样一个事实：每个嵌套的raggedtensor将其值的统一最外层维度替换为统一维度，后跟一个不规则维度。',
'Creates a RaggedTensor with a specified partitioning for values.':'创建具有指定值分区的raggedtensor。',
'The DType of values in this tensor.':'此张量中值的数据类型。',
'The innermost values tensor for this ragged tensor.':'这个不规则张量的最里面的值张量。',
'A Tensor.':'张量',
'The number of ragged dimensions in this ragged tensor.':'不规则张量中不规则维数的数目。',
'A Python int indicating the number of ragged dimensions in this ragged tensor. The outermost dimension is not considered ragged.':'表示此不规则张量中不规则维度数的python int。最外层的尺寸不被认为是粗糙的。',
'### shape':'### 形状',
'The statically known shape of this ragged tensor.':'这个参差不齐的张量的静态已知形状。',
'A TensorShape containing the statically known shape of this ragged tensor. Ragged dimensions have a size of None.':'一种包含这种不规则张量的静态已知形状的张量形状。参差不齐的维度的大小为“无”。',
'The concatenated rows for this ragged tensor.':'这个参差不齐的张量的连接行。',
'rt.values is a potentially ragged tensor formed by flattening the two outermost dimensions of rt into a single dimension.':'值是一种潜在的不规则张量，通过将rt的两个最外层维度展平为一个维度而形成。',
'A potentially ragged tensor.':'一种可能参差不齐的张量。',
'Computes the absolute value of a tensor.':'计算张量的绝对值。',
'A Tensor. Has the same type as x.':'张量与x的类型相同。',
'A Tensor of type bool.':'布尔型张量。',
'Dummy method to prevent a RaggedTensor from being used as a Python bool.':'防止raggedtensor用作python bool的伪方法。',
'NOTE: Prefer using the Tensor division operator or tf.divide which obey Python 3 division operator semantics.':'注意：最好使用符合python 3除法运算符语义的张量除法运算符或tf.divide。',
'x / y returns the quotient of x and y.':'x/y返回x和y的商。',
'x / y rounded down.':'X/Y向下舍入。',
'Returns the specified piece of this RaggedTensor.':'返回此RaggedSensor的指定部分。',
'Scalar `int`eger `Tensor`':'标量`int`eger`张量`',
'A Tensor or RaggedTensor object. Values that include at least one ragged dimension are returned as RaggedTensor. Values that include no ragged dimensions are returned as Tensor. See above for examples of expressions that return Tensors vs RaggedTensors.':'张量张量或拉格传感器物体包含至少一个不规则维度的值将作为raggedtensor返回。不包含不规则维度的值将作为张量返回。有关返回张量与raggedtensors的表达式示例，请参见上文。',
'Computes the power of one value to another.':'计算一个值对另一个值的幂。',
'Divides x / y elementwise (using Python 3 division operator semantics).':'按元素划分x/y（使用python 3除法运算符语义）。',
'NOTE: Prefer using the Tensor operator or tf.divide which obey Python division operator semantics.':'注意：最好使用符合python除法运算符语义的张量运算符或tf.divide。',
'x / y evaluated in floating point.':'x/y以浮点计算。',
'Logical XOR function.':'逻辑异或函数。',
'A Tensor of type bool with the same size as that of x or y.':'bool型张量，其大小与x或y相同。',
'Returns the tight bounding box shape for this RaggedTensor.':'返回此RaggedSensor的紧边界框形状。',
'#### Equivalent to:':'#### 相当于：',
'The returned RaggedTensor corresponds with the python list defined by:':'返回的raggedtensor对应于由定义的python列表：',
' #### Args:':'#### 参数：',
#'  higher.':'较高的。',
#'  will be used as nested row lengths to construct a ragged tensor with':'将用作嵌套行长度来构造不规则张量',
#'  multiple ragged dimensions.':'多个不规则尺寸。',
#'  consisting entirely of `padding` will be excluded from the returned':'将从返回的',
#'  RaggedTensor.  `padding` is a `Tensor` with the same dtype as `tensor`':'拉格传感器。` padding`是与'tensor'具有相同数据类型的'tensor'`',
'### nrows':'###NROWS公司',
'Returns the number of rows in this ragged tensor.':'返回此不规则张量中的行数。',
'Returns the lengths of the rows in this ragged tensor.':'返回此不规则张量中行的长度。',
'Returns the limit indices for rows in this ragged tensor.':'返回此不规则张量中行的限制索引。',
'Returns the start indices for rows in this ragged tensor.':'返回此不规则张量中行的开始索引。',
'Returns a nested Python list with the values for this RaggedTensor.':'返回一个嵌套的python列表，其中包含此raggedtensor的值。',
'Requires that rt was constructed in eager execution mode.':'要求RT是在紧急执行模式下构造的。',
'A nested Python list.':'嵌套的python列表。',
'A SparseTensor with the same values as self.':'与self值相同的sparsetensor。',
'Returns the row indices for the values in this ragged tensor.':'返回此不规则张量中值的行索引。',
'## Class RaggedTensorSpec':'##RaggedSensorSpec类',
'Initializer that generates tensors with a normal distribution.':'生成正态分布张量的初始值设定项。',
'Initializer that generates tensors with a uniform distribution.':'生成具有均匀分布的张量的初始值设定项。',
'Creates a sequence of numbers.':'创建一个数字序列。',
'Creates a sequence of numbers that begins at start and extends by increments of delta up to but not including limit.':'创建一个数字序列，该序列从开始处开始，并以增量增量扩展到限制，但不包括限制。',
'The dtype of the resulting tensor is inferred from the inputs unless it is provided explicitly.':'除非显式提供，否则将从输入推断出结果张量的dtype。',
'Equivalent to np.arange':'相当于np.arange',
'Returns the rank of a tensor.':'返回张量的秩。',
'A Tensor of type int32.':'int32型张量。',
'Equivalent to np.ndim':'等同于np.ndim',
'Computes the "logical and" of elements across dimensions of a tensor.':'计算元素在张量维度上的“逻辑和”。',
'The reduced tensor.':'简化张量。',
'Equivalent to np.all':'相当于np.all',
'## Class RegisterGradient':'## 类registergradient',
'A decorator for registering the gradient function for an op type.':'用于为操作类型注册渐变函数的修饰程序。',
'The conversion function must have the following signature:':'转换函数必须具有以下签名：',
'Raises: ValueError if called with incompatible shapes.':'如果使用不兼容的形状调用，则引发：valueerror。',
'Reshapes a tensor.':'重塑张量。',
'Reverses specific dimensions of a tensor.':'反转张量的特定维度。',
'Reverses variable length slices.':'反转可变长度切片。',
'Rolls the elements of a tensor along an axis.':'沿轴旋转张量的元素。',
'The elements are shifted positively (towards larger indices) by the offset of shift along the dimension of axis. Negative shift values will shift elements in the opposite direction. Elements that roll passed the last position will wrap around to the first and vice versa. Multiple shifts along multiple axes may be specified.':'元素正移（向更大的索引）通过偏移沿轴的维度移动。负偏移值将使元素向相反方向偏移。滚过最后一个位置的元素将绕到第一个位置，反之亦然。可以指定沿多个轴的多个位移。',
'Scatter updates into a new tensor according to indices.':'根据索引将更新分散到新的张量中。',
'indices is an integer tensor containing indices into a new tensor of shape shape. The last dimension of indices can be at most the rank of shape:':'指数是一个整数张量，包含一个新的形状张量的指数。索引的最后一个维度最多可以是形状的秩：',
'The resulting tensor would look like this:':'生成的张量如下所示：',
'A Tensor. Has the same type as updates.':'张量与更新类型相同。',
'Searches input tensor for values on the innermost dimension.':'在输入张量中搜索最内层维度上的值。',
'Returns a mask tensor representing the first N positions of each cell.':'返回表示每个单元格的前n个位置的掩码张量。',
'Returns the shape of a tensor.':'返回张量的形状。',
'Returns shape of tensors.':'返回张量的形状。',
'Extracts a slice from a tensor.':'从张量中提取一片。',
'Sorts a tensor.':'对张量排序。',
'Th`i`s` `operat`i`on` ``i`s` `equ`i`valent` `to` `the` `follow`i`ng` `steps:':'在``i`s``equi`i`valent``上的``i`operat`i`到``follow`i`ng`步骤：',
'Some` `examples:':'一些“例子：',
'## Class SparseTensorSpec':'##SparsetensorSpec类',
'Splits a tensor into sub tensors.':'将张量拆分为子张量。',
'Removes dimensions of size 1 from the shape of a tensor.':'从张量的形状中删除大小为1的尺寸。',
'Stops gradient computation.':'停止渐变计算。',
'This is useful any time you want to compute a value with TensorFlow but need to pretend that the value was a constant. Some examples include:':'当你想用tensorflow计算一个值，但需要假设这个值是一个常量时，这是很有用的。一些例子包括：',
'Extracts a strided slice of a tensor (generalized python array indexing).':'提取张量的一个跨步片（通用python数组索引）。',
'A Tensor the same type as input.':'与输入类型相同的张量。',
'Example:':'例子：',
'or':'或',
'## Class Tensor':'## 类张量',
'Represents one of the outputs of an Operation.':'表示操作的输出之一。',
'This class has two primary purposes:':'这个类有两个主要目的：',
#'    dtype':'数据类型',
'Creates a new Tensor.':'创建新的张量。',
'The Graph that contains this tensor.':'包含这个张量的图。',
'The string name of this tensor.':'这个张量的字符串名。',
'The Operation that produces this tensor as an output.':'产生这个张量作为输出的操作。',
'Returns the TensorShape that represents the shape of this tensor.':'返回表示此张量形状的张量形状。',
'A TensorShape representing the shape of this tensor.':'代表这个张量形状的张量形状。',
'The index of this tensor in the outputs of its Operation.':'这个张量在其运算输出中的指数。',
#'    y':'是的',
'Dummy method to prevent a tensor from being used as a Python bool.':'防止张量用作python bool的伪方法。',
'Divide two values using Python 2 semantics.':'使用python 2语义划分两个值。',
'Used for Tensor.div.':'用于tensor.div。',
'Overload for Tensor.getitem.':'tensor.getitem的重载。',
'#### Some useful examples:':'#### 一些有用的例子：',
'Either matrix can be transposed or adjointed (conjugated and transposed) on the fly by setting one of the corresponding flag to True. These are False by default.':'通过将相应的标志之一设置为true，可以动态地对矩阵进行转置或伴随（共轭和转置）。默认情况下这些是错误的。',
'Dispatches cwise mul for "DenseDense" and "DenseSparse".':'为“densedense”和“densesparse”分派cwise mul。',
#'    x':'十',
'Returns a list of Operations that consume this tensor.':'返回使用此张量的操作列表。',
'### eval':'### 评估',
'Evaluates this tensor in a Session.':'在会话中计算此张量。',
'Calling this method will execute all preceding operations that produce the inputs needed for the operation that produces this tensor.':'调用此方法将执行所有前面的操作，这些操作将生成生成此张量的操作所需的输入。',
'A numpy array corresponding to the value of this tensor.':'对应于这个张量值的numpy数组。',
'Returns a hashable reference object to this Tensor.':'返回此张量的哈希引用对象。',
'Alias of Tensor.shape.':'张量的别名。',
'Updates the shape of this tensor.':'更新此张量的形状。',
'## Class TensorArray':'## 类张量阵列',
'Construct a new TensorArray or wrap an existing TensorArray handle.':'构造新的tensorray或包装现有的tensorray句柄。',
'A note about the parameter name:':'关于参数名的说明：',
'The data type of this TensorArray.':'张量阵列的数据类型。',
'Python bool; if True the TensorArray can grow dynamically.':'python bool；如果为true，tensorarray可以动态增长。',
'### flow':'### 流量',
'The flow Tensor forcing ops leading to this TensorArray state.':'导致这种张量阵列状态的流张量强迫ops。',
'### handle':'### 把手',
'The reference to the TensorArray.':'对张量排列的引用。',
'### close':'### 关闭',
'Close the current TensorArray.':'关闭当前张力阵列。',
'### concat':'### 康卡',
'Return the values in the TensorArray as a concatenated Tensor.':'将tensorarray中的值作为连接的张量返回。',
'All the tensors in the TensorArray concatenated into one tensor.':'张量数组中的所有张量连接成一个张量。',
'### gather':'### 收集',
'Return selected values in the TensorArray as a packed Tensor.':'以压缩张量的形式返回张量数组中的选定值。',
'All of selected values must have been written and their shapes must all match.':'所有选定的值必须已写入，并且其形状必须全部匹配。',
'### grad':'### 毕业生',
'### identity':'### 身份',
'Returns a TensorArray with the same content and properties.':'返回具有相同内容和属性的Tensorarray。',
'### read':'### 阅读',
'Read the value at location index in the TensorArray.':'读取tensorray中位置索引处的值。',
'The tensor at index index.':'指数处的张量。',
'### scatter':'### 分散',
'Scatter the values of a Tensor in specific indices of a TensorArray.':'将张量的值分散在张量阵列的特定索引中。',
'Returns: A new TensorArray object with flow that ensures the scatter occurs. Use this object all for subsequent operations.':'返回：一个新的TensorArray对象，该对象具有确保发生散布的流。将此对象全部用于后续操作。',
'Raises: ValueError: if the shape inference fails.':'引发：valueerror:如果形状推断失败。',
'### size':'### 大小',
'Return the size of the TensorArray.':'返回Tensorarray的大小。',
'### split':'### 分裂',
'Split the values of a Tensor into the TensorArray.':'把张量的值分成张量数组。',
'Returns: A new TensorArray object with flow that ensures the split occurs. Use this object all for subsequent operations.':'返回：一个新的TensorArray对象，该对象具有确保拆分发生的流。将此对象全部用于后续操作。',
'### stack':'### 堆叠',
'Return the values in the TensorArray as a stacked Tensor.':'将张量数组中的值作为堆叠张量返回。',
'All the tensors in the TensorArray stacked into one tensor.':'张量阵列中的所有张量叠加成一个张量。',
'### unstack':'### 不后退',
'Unstack the values of a Tensor in the TensorArray.':'取消对张量数组中张量值的堆栈。',
'Returns: A new TensorArray object with flow that ensures the unstack occurs. Use this object all for subsequent operations.':'返回：一个新的Tensorarray对象，该对象具有确保取消堆栈发生的流。将此对象全部用于后续操作。',
'### write':'### 写',
'Write value into index index of the TensorArray.':'将值写入Tensorarray的索引索引中。',
'A new TensorArray object with flow that ensures the write occurs. Use this object all for subsequent operations.':'一个新的TensorArray对象，该对象具有确保写入发生的流。将此对象全部用于后续操作。',
'## Class TensorArraySpec':'## 类tensorarrayspec',
'Tensor contraction of a and b along specified axes.':'a和b沿指定轴的张量收缩。',
'Example 3: Suppose that':'例3：假设',
'whose entry corresponding to the indices':'其条目对应于索引',
'is given by:':'给出者：',
'A Tensor with the same type as a.':'与a类型相同的张量。',
'## Class TensorShape':'## 类张量形状',
'Represents the shape of a Tensor.':'表示张量的形状。',
'Creates a new TensorShape with the given dimensions.':'创建具有给定维度的新张量形状。',
'### dims':'### 昏暗',
'### ndims':'### 新吉布提国际机场',
'Deprecated accessor for rank.':'已弃用的列组访问器。',
'### rank':'### 等级',
'Returns True if self is equivalent to other.':'如果self与other等价，则返回true。',
'Returns True if self is known to be different from other.':'如果知道self与other不同，则返回true。',
'Returns a list of integers or None for each dimension.':'返回每个维度的整数列表或无整数。',
'A list of integers or None for each dimension.':'每个维度的整数或无整数的列表。',
'Returns this shape as a TensorShapeProto.':'将此形状返回为TensorShapeProto。',
'Raises an exception if self is not compatible with the given rank.':'如果self与给定列组不兼容，则引发异常。',
'Raises exception if self and other do not represent the same shape.':'如果self和other不表示同一形状，则引发异常。',
'This method can be used to assert that there exists a shape that both self and other represent.':'这个方法可以用来断言存在一个self和other都表示的形状。',
'Raises an exception if self is not fully defined in every dimension.':'如果在每个维度中未完全定义self，则引发异常。',
'Raises an exception if self and other do not have compatible ranks.':'如果self和other没有兼容的列组，则引发异常。',
'### concatenate':'### 连接',
'Returns the concatenation of the dimension in self and other.':'返回self和other中维度的连接。',
'A TensorShape whose dimensions are the concatenation of the dimensions in self and other.':'一种张量形状，其维数是自维数和其它维数的连接。',
'Returns True iff self is compatible with other.':'如果self与other兼容，则返回true。',
'True iff self is compatible with other.':'真正的自我与他人相容。',
'Returns True iff self is fully defined in every dimension.':'返回真iff self在每个维度中完全定义。',
'Returns a TensorShape combining the information in self and other.':'返回一个将self和other中的信息组合在一起的tensorshape。',
'A TensorShape containing the combined information of self and other.':'包含自我和他者信息的张量形状。',
'Returns the most specific TensorShape compatible with self and other.':'返回与self和other兼容的最具体的tensorShape。',
'A TensorShape which is the most specific compatible shape of self and other.':'一种张量形状，是自我和他人最具体的相容形状。',
'Returns a shape based on self with the given rank.':'返回基于具有给定秩的self的形状。',
'This method promotes a completely unknown shape to one with a known rank.':'这种方法将一个完全未知的形状提升为一个具有已知秩的形状。',
'A shape that is at least as specific as self with the given rank.':'一种至少和自我一样具有特定等级的形状。',
'Returns a shape based on self with at least the given rank.':'返回基于self的至少具有给定秩的形状。',
'A shape that is at least as specific as self with at least the given rank.':'一种至少和自身一样特殊的形状，至少具有给定的等级。',
'Returns a shape based on self with at most the given rank.':'返回基于self的形状，最多具有给定的秩。',
'A shape that is at least as specific as self with at most the given rank.':'一种至少和自我一样具体的形状，至多有给定的等级。',
'## Class TensorSpec':'## 类tensorspec',
'Describes a tf.Tensor.':'描述一个tf.tensor。',
'Creates a TensorSpec.':'创建TensorSpec。',
'Returns the dtype of elements in the tensor.':'返回张量中元素的数据类型。',
'Returns the (optionally provided) name of the described tensor.':'返回描述的张量的名称（可选）。',
'Returns the TensorShape that represents the shape of the tensor.':'返回表示张量形状的张量形状。',
'Adds sparse updates to an existing tensor according to indices.':'根据索引向现有张量添加稀疏更新。',
'Subtracts sparse updates from an existing tensor according to indices.':'根据索引从现有张量减去稀疏更新。',
'Scatter updates into an existing tensor according to indices.':'根据索引将更新分散到现有的张量中。',
'Constructs a tensor by tiling a given tensor.':'通过平铺给定的张量来构造张量。',
'Provides the time since epoch in seconds.':'提供自纪元以来的时间（秒）。',
'Returns the timestamp as a float64 for seconds since the Unix epoch.':'以float64形式返回时间戳，从unix纪元开始持续秒数。',
'A Tensor of type float64.':'float64型张量。',
'Transposes a.':'转置a。',
'Permutes the dimensions according to perm.':'根据perm排列尺寸。',
'A transposed Tensor.':'转置张量',
'Group tensors together.':'把张量组合在一起。',
'Same as tensors.':'和张量一样。',
'## Class TypeSpec':'## 类类型规范',
'Specifies a TensorFlow value type.':'指定TensorFlow值类型。',
'## Class UnconnectedGradients':'## 类非连接半径',
'Controls how gradient computation behaves when y does not depend on x.':'控制Y不依赖于X时渐变计算的行为。',
'This operation returns a tensor y containing all of the unique elements of x sorted in the same order that they occur in x. This operation also returns a tensor idx the same size as x that contains the index of each value of x in the unique output y. In other words:':'此操作返回一个张量y，其中包含x的所有唯一元素，按它们在x中出现的顺序排序。此操作还返回一个张量idx，其大小与x相同，包含唯一输出y中x的每个值的索引。换句话说：',
'Converts a flat index or array of flat indices into a tuple of':'将平面索引或平面索引数组转换为',
'coordinate arrays.':'坐标数组。',
'A Tensor. Has the same type as indices.':'张量具有与索引相同的类型。',
'This is the opposite of stack.':'这与stack相反。',
'The list of Tensor objects unstacked from value.':'未从值返回的张量对象列表。',
'## Class Variable':'## 类变量',
'A variable maintains state in the graph across calls to run(). You add a variable to the graph by constructing an instance of the class Variable.':'变量在调用run（）时保持图形中的状态。通过构造类变量的实例，可以将变量添加到图中。',
'This constructor creates both a variable Op and an assign Op to set the variable to its initial value.':'这个构造函数创建一个变量op和一个赋值op来将变量设置为其初始值。',
'## Child Classes':'## 儿童班',
'### aggregation':'### 聚合',
'### constraint':'### 约束',
'Returns the constraint function associated with this variable.':'返回与此变量关联的约束函数。',
'The constraint function that was passed to the variable constructor. Can be None if no constraint was passed.':'传递给变量构造函数的约束函数。如果未传递任何约束，则可以为“无”。',
'The device of this variable.':'这个变量的装置。',
'The DType of this variable.':'此变量的数据类型。',
'The Graph of this variable.':'这个变量的图形。',
'Returns the Tensor used as the initial value for the variable.':'返回用作变量初始值的张量。',
'### initializer':'### 初始值设定项',
'The initializer operation for this variable.':'此变量的初始值设定项操作。',
'The name of this variable.':'此变量的名称。',
'The Operation of this variable.':'此变量的操作。',
'The TensorShape of this variable.':'这个变量的张量形状。',
'A TensorShape.':'张角形',
'### synchronization':'### 同步',
'### trainable':'### 可训练的',
'Creates a slice helper object given a variable.':'创建给定变量的切片辅助对象。',
'Note that assignments currently do not support NumPy broadcasting semantics.':'请注意，赋值当前不支持numpy广播语义。',
'Dummy method to prevent iteration.':'防止迭代的虚拟方法。',
'Do not call.':'不要打电话。',
'### assign':'### 分配',
'Assigns a new value to the variable.':'为变量指定一个新值。',
'A Tensor that will hold the new value of this variable after the assignment has completed.':'赋值完成后将保留此变量新值的张量。',
'Adds a value to this variable.':'向此变量添加值。',
'A Tensor that will hold the new value of this variable after the addition has completed.':'一种在加法完成后保留该变量新值的张量。',
'Subtracts a value from this variable.':'从这个变量中减去一个值。',
'A Tensor that will hold the new value of this variable after the subtraction has completed.':'一种在减法完成后保留该变量新值的张量。',
'And the operation performed can be expressed as:':'所进行的操作可以表示为：',
'A Tensor that will hold the new value of this variable after the scattered assignment has completed.':'散乱赋值完成后将保留此变量新值的张量。',
'When that Op is run it tries to increment the variable by 1. If incrementing the variable would bring it above limit then the Op raises the exception OutOfRangeError.':'当运行该操作时，它会尝试将变量增加1。如果递增变量会使其超过限制，则操作会引发OutOfRangeError异常。',
'A numpy ndarray with a copy of the value of this variable.':'带有此变量值副本的numpy ndarray。',
'Returns a hashable reference object to this Variable.':'返回对此变量的哈希引用对象。',
'You should use this instead of the variable itself to initialize another variable with a value that depends on the value of this variable.':'您应该使用这个而不是变量本身来初始化另一个变量，该变量的值取决于该变量的值。',
'A Tensor holding the value of this variable after its initializer has run.':'在初始值设定项运行后保存该变量值的张量。',
'### load':'### 装载',
'Writes new value to variable\'s memory. Doesn\'t add ops to the graph.':'将新值写入变量的内存。不向图表添加操作。',
'A Tensor containing the value of the variable.':'包含变量值的张量。',
'A Tensor that will hold the new value of this variable after the scattered addition has completed.':'散乱加法完成后，将保持该变量新值的张量。',
'A Tensor that will hold the new value of this variable after the scattered division has completed.':'一种张量，在散乱的除法完成后，它将保持这个变量的新值。',
'A Tensor that will hold the new value of this variable after the scattered maximization has completed.':'散乱最大化完成后将保持该变量新值的张量。',
'A Tensor that will hold the new value of this variable after the scattered minimization has completed.':'散乱极小化完成后，将保持该变量新值的张量。',
'A Tensor that will hold the new value of this variable after the scattered multiplication has completed.':'散乱乘法完成后将保留此变量新值的张量。',
'Applies sparse addition to individual values or slices in a Variable.':'对变量中的单个值或切片应用稀疏加法。',
'The Variable has rank P and indices is a Tensor of rank Q.':'变量的秩为p，指数为q的张量。',
'The resulting update to v would look like this:':'对v的更新结果如下：',
'Applies sparse subtraction to individual values or slices in a Variable.':'对变量中的单个值或切片应用稀疏减法。',
'Assuming the variable has rank P and indices is a Tensor of rank Q.':'假设变量的秩为p，指数为q的张量。',
'A Tensor that will hold the new value of this variable after the scattered subtraction has completed.':'散乱减法完成后将保留此变量新值的张量。',
'Applies sparse assignment to individual values or slices in a Variable.':'对变量中的单个值或切片应用稀疏赋值。',
'Overrides the shape for this variable.':'重写此变量的形状。',
'Converts a Variable to a VariableDef protocol buffer.':'将变量转换为variabledef协议缓冲区。',
'### value':'### 价值',
'Returns the last snapshot of this variable.':'返回此变量的最后一个快照。',
'Returns a Tensor which holds the value of the variable. You can not assign a new value to this tensor as it is not a reference to the variable.':'返回包含变量值的张量。不能将新值赋给此张量，因为它不是对变量的引用。',
'## Class SaveSliceInfo':'## 类savesliceinfo',
'Information on how to save this Variable as a slice.':'有关如何将此变量保存为切片的信息。',
'Provides internal support for saving variables as slices of a larger variable. This API is not public and is subject to change.':'为将变量保存为较大变量的切片提供内部支持。此API不是公共的，可能会更改。',
'#### Available properties:':'#### 可用属性：',
'Create a SaveSliceInfo.':'创建保存切片信息。',
'### spec':'### 规格',
'Computes the spec string used for saving.':'计算用于保存的规范字符串。',
'Returns a SaveSliceInfoDef() proto.':'返回saveSliceInfoDef（）协议。',
'## Class VariableAggregation':'## 类变量聚合',
'Indicates how a distributed variable will be aggregated.':'指示如何聚合分布式变量。',
'## Class VariableSynchronization':'## 类变量同步',
'Indicates when a distributed variable will be synced.':'指示何时同步分布式变量。',
'Scope which defines a variable creation function to be used by variable().':'定义变量创建函数以供variable（）使用的范围。',
'Custom getters in the variable scope will eventually resolve down to these custom creators when they do create variables.':'变量作用域中的自定义getter在创建变量时最终将解析为这些自定义创建者。',
'A scope in which the creator is active':'创建者处于活动状态的作用域',
#'    elems':'元素',
'Repeat body while the condition cond is true.':'在条件cond为真时重复body。',
'Example with nesting and a namedtuple:':'嵌套和namedtuple的示例：',
'Creates a tensor with all elements set to zero.':'创建所有元素都设置为零的张量。',
'This operation returns a tensor of type dtype with shape shape and all elements set to zero.':'此操作返回dtype类型的张量，其shape shape和所有元素都设置为零。',
'A Tensor with all elements set to zero.':'所有元素都设为零的张量。',
'Public API for tf.audio namespace.':'tf.audio命名空间的公共api。',
'Encode audio data using the WAV file format.':'使用wav文件格式对音频数据进行编码。',
'A Tensor of type string.':'弦型张量。',
'Conversion of plain Python into TensorFlow graph code.':'将普通python转换为tensorflow图形代码。',
'Sets the AutoGraph verbosity level.':'设置签名详细级别。',
'Debug logging in AutoGraph':'调试登录签名',
'There are two means to control the logging verbosity:':'有两种方法可以控制日志记录的详细程度：',
'The converted code as string.':'转换后的代码为字符串。',
'Converts a Python entity into a TensorFlow graph.':'将python实体转换为tensorflow图。',
'Functions are converted into new functions with converted code.':'使用转换后的代码将函数转换为新函数。',
'Classes are converted by generating a new class whose methods use converted code.':'类是通过生成一个新类来转换的，该类的方法使用转换后的代码。',
'Methods are converted into unbound function that have an additional first argument called self.':'方法被转换为具有名为self的附加第一个参数的未绑定函数。',
'Traces argument information at compilation time.':'在编译时跟踪参数信息。',
'Example usage':'示例用法',
'Public API for tf.autograph.experimental namespace.':'tf.autograph.experimental命名空间的公共api。',
'Decorator that suppresses the conversion of a function.':'禁止函数转换的修饰程序。',
'## Class Feature':'## 类特征',
'This enumeration represents optional conversion options.':'此枚举表示可选的转换选项。',
'These conversion options are experimental. They are subject to change without notice and offer no guarantees.':'这些转换选项是实验性的。如有变更，恕不另行通知，也不提供任何担保。',
'#### Attributes:':'#### 属性：',
'Operations for manipulating the binary representations of integers.':'操作整数的二进制表示的操作。',
'Elementwise computes the bitwise AND of x and y.':'elementwise计算x和y的按位与。',
'Elementwise computes the bitwise OR of x and y.':'elementwise计算x和y的按位或。',
'Elementwise computes the bitwise XOR of x and y.':'elementwise计算x和y的按位异或。',
'Functions for Python 2 vs. 3 compatibility.':'与Python2和Python3兼容的函数。',
'## Conversion routines':'## 转换例程',
'## Types':'## 类型',
'The compatibility module also provides the following types:':'兼容性模块还提供以下类型：',
'A bytes object.':'字节对象。',
'Converts input to str type.':'将输入转换为str类型。',
'A str object.':'str对象。',
'A unicode (Python 2) or str (Python 3) object.':'Unicode（Python2）或Str（Python3）对象。',
'Compatibility utility required to allow for both V1 and V2 behavior in TF.':'在tf中同时允许v1和v2行为所需的兼容性实用程序。',
#'    index':'指数',
'#### Arguments:':'#### 参数：',
'A dimension object.':'一个维度对象。',
'Context manager for testing forward compatibility of generated graphs.':'用于测试生成的图的前向兼容性的上下文管理器。',
#'    day':'白天',
' from tensorflow.python.compat import compat':'从tensorflow.python.compat导入compat',
'Nothing.':'没有什么。',
'Return true if the forward compatibility window has expired.':'如果转发兼容性窗口已过期，则返回true。',
'to:':'致：',
'Converts input which is a PathLike object to str type.':'将类路径对象的输入转换为str类型。',
'In case a simplified str version of the path is needed from an os.PathLike object':'如果需要从os.pathlike对象获得路径的简化str版本',
'Bring in all of the public TensorFlow interface into this module.':'将所有公共tensorflow接口引入此模块。',
'#### Eager Compatibility':'#### 迫切的兼容性',
'Collections are only supported in eager when variables are created inside an EagerVariableStore (e.g. as part of a layer or template).':'仅当在eagervariablestore中创建变量时（例如，作为层或模板的一部分），eagervariablestore才支持集合。',
'Note that in case of ties the identity of the return value is not guaranteed.':'请注意，如果是关系，则不保证返回值的标识。',
'Returns the index with the largest value across dimensions of a tensor.':'返回在张量的各个维度上具有最大值的索引。',
'Returns the index with the smallest value across dimensions of a tensor.':'返回张量维度上具有最小值的索引。',
'Example of adding a dependency to an operation:':'向操作添加依赖项的示例：',
'Op that raises InvalidArgumentError if x > y is False.':'如果x>y为false，则引发invalidArgumenterRor的操作。',
'Assert that x is of integer dtype.':'断言x是整数类型。',
'Op that raises InvalidArgumentError if x < y is False.':'如果x<y为false，则引发invalidArgumenterRor的操作。',
'Op that raises InvalidArgumentError if x and y are not close enough.':'如果x和y不够接近，则引发invalidArgumenterRor的操作。',
'Op raising InvalidArgumentError unless x is all negative.':'除非x全为负，否则op将引发invalidArgumenterRor。',
'Op raising InvalidArgumentError unless x is all positive.':'除非X全部为正，否则OP将引发InvalidArgumenterRor。',
'Assert x has rank equal to rank.':'断言x的秩等于秩。',
'Assert x has rank equal to rank or higher.':'断言x的秩等于或高于秩。',
'Assert x has rank in ranks.':'断言x在列中具有列。',
'This function raises ValueError unless it can be certain that the given tensor is a scalar. ValueError is also raised if the shape of tensor is unknown.':'除非可以确定给定的张量是标量，否则此函数将引发valueerror。如果张量的形状未知，也会引发valueerror。',
'The input tensor (potentially converted to a Tensor).':'输入张量（可能转换成张量）。',
'Statically asserts that the given Tensor is of the specified type.':'静态地断言给定的张量是指定的类型。',
'Returns an Op to check if variables are initialized.':'返回一个op以检查变量是否已初始化。',
'Update ref by assigning value to it.':'通过给ref赋值来更新它。',
'This operation outputs a Tensor that holds the new value of ref after the value has been assigned. This makes it easier to chain operations that need to use the reset value.':'此操作输出一个张量，该张量在赋值后保留ref的新值。这使得链接需要使用重置值的操作更容易。',
'A Tensor that will hold the new value of ref after the assignment has completed.':'在赋值完成后保留ref新值的张量。',
'Update ref by adding value to it.':'通过向ref添加值来更新ref。',
'Same as "ref". Returned as a convenience for operations that want to use the new value after the variable has been updated.':'与“ref”相同。为便于在变量更新后使用新值的操作而返回。',
'Update ref by subtracting value from it.':'通过从ref中减去值来更新ref。',
'## Class AttrValue':'## 类属性',
'A ProtocolMessage':'原始信息',
'### b':'### 乙',
'### f':'###F型',
'### func':'### 功能',
'NameAttrList func':'名称属性列表函数',
'### i':'### 我',
'### list':'### 列表',
'ListValue list':'列表值列表',
'### placeholder':'### 占位符',
'string placeholder':'字符串占位符',
'### s':'###S公司',
'TensorShapeProto shape':'张角形',
'### tensor':'### 张量',
'TensorProto tensor':'张量',
'DataType type':'数据类型',
'## Class ListValue':'## 类ListValue',
'repeated bool b':'重复乳房',
'repeated float f':'重复浮动f',
'repeated NameAttrList func':'重复的nameattrlist func',
'repeated int64 i':'重复Int64 i',
'repeated bytes s':'重复字节',
'repeated TensorShapeProto shape':'重复张量形状',
'repeated TensorProto tensor':'重复张量',
'repeated DataType type':'重复数据类型',
'Ref to variable after it has been modified.':'变量修改后的引用。',
'This is a legacy version of the more general BatchToSpaceND.':'这是更通用的batchtospacend的遗留版本。',
'Counts the number of occurrences of each value in an integer array.':'计算整数数组中每个值的出现次数。',
'A vector with the same dtype as weights or the given dtype. The bin values.':'与权重或给定数据类型具有相同数据类型的向量。bin值。',
'A clipped Tensor.':'紧绷的张量',
'DEPRECATED FUNCTION':'不推荐的函数',
'A conditional accumulator for aggregating gradients.':'用于聚合渐变的条件累加器。',
'Extraction of the average gradient is blocked until the required number of gradients has been accumulated.':'在累积所需的梯度数之前，平均梯度的提取被阻塞。',
'Creates a new ConditionalAccumulator.':'创建新的条件累加器。',
'The underlying accumulator reference.':'基础累加器引用。',
'The datatype of the gradients accumulated by this accumulator.':'此累加器累积的渐变的数据类型。',
'The name of the underlying accumulator.':'基础累加器的名称。',
'Attempts to apply a gradient to the accumulator.':'尝试对累加器应用渐变。',
'The operation that (conditionally) applies a gradient to the accumulator.':'（有条件地）对累加器应用梯度的操作。',
'Number of gradients that have currently been aggregated in accumulator.':'当前已在累加器中聚合的渐变数。',
'Number of accumulated gradients currently in accumulator.':'累加器中当前累积的渐变数。',
'Sets the global time step of the accumulator.':'设置累加器的全局时间步长。',
'The operation logs a warning if we attempt to set to a time step that is lower than the accumulator\'s own time step.':'如果我们试图设置一个低于累加器自身时间步的时间步，则该操作将记录一个警告。',
'Operation that sets the accumulator\'s time step.':'设置累加器时间步长的操作。',
'Attempts to extract the average gradient from the accumulator.':'尝试从累加器中提取平均梯度。',
'The operation blocks until sufficient number of gradients have been successfully applied to the accumulator.':'操作将阻塞，直到成功地将足够数量的渐变应用到累加器。',
'A tensor holding the value of the average gradient.':'保持平均梯度值的张量。',
'## Class ConditionalAccumulatorBase':'## 类条件累积基',
'## Class ConfigProto':'## 类configproto',
'### experimental':'### 实验的',
'Experimental experimental':'实验性实验',
'### key':'### 钥匙',
'string key':'字符串键',
'## Class Experimental':'## 课堂实验',
'Computes the confusion matrix from predictions and labels.':'根据预测和标签计算混淆矩阵。',
'Wrapper for Graph.container() using the default graph.':'使用默认图的graph.container（）包装器。',
'A context manager that specifies the default container to use for newly created stateful ops.':'上下文管理器，指定用于新创建的有状态操作的默认容器。',
'Returns True if v2 control flow is enabled.':'如果启用v2控制流，则返回true。',
'Converts the given object to a Tensor or an IndexedSlices.':'将给定对象转换为张量或indexedlices。',
'Converts value to a SparseTensor or Tensor.':'将值转换为sparsetensor或张量。',
'A SparseTensor or Tensor based on value.':'基于值的sparsetensor或张量。',
'NOTE Floating point comparison to zero is done by exact floating point equality check. Small values are not rounded to zero for purposes of the nonzero check.':'注意浮点与零的比较是通过精确的浮点相等性检查完成的。对于非零值检查，小值不舍入为零。',
'The reduced tensor (number of nonzero values).':'约化张量（非零值的数目）。',
'A list of Variables corresponding to the slicing.':'与切片相对应的变量列表。',
'Convert CSV records to tensors. Each column maps to one tensor.':'将csv记录转换为张量。每列映射到一个张量。',
'A Tensor object storing the decoded bytes.':'存储解码字节的张量对象。',
'Delete the tensor for the given tensor handle.':'删除给定张量句柄的张量。',
'This is EXPERIMENTAL and subject to change.':'这是实验性的，随时可能改变。',
'Delete the tensor of a given tensor handle. The tensor is produced in a previous run() and stored in the state of the session.':'删除给定张量句柄的张量。张量在前一次run（）中生成，并存储在会话的状态中。',
'A pair of graph elements. The first is a placeholder for feeding a tensor handle and the second is a deletion operation.':'一对图形元素。第一个是提供张量句柄的占位符，第二个是删除操作。',
'DepthToSpace for tensors of type T.':'t型张量的深度空间。',
'the operator will return the following tensor of shape [1 4 4 1]:':'运算符将返回以下形状张量[1 4 4 1]：',
'Wrapper for Graph.device() using the default graph.':'使用默认图形的graph.device（）包装器。',
'Merge the properties of "dev" into this DeviceSpec.':'将“dev”的属性合并到此devicespec中。',
'## Class Dimension':'## 类维度',
'Represents the value of one dimension in a TensorShape.':'表示张量形状中一维的值。',
'Creates a new Dimension with the given value.':'创建具有给定值的新维度。',
'Returns the sum of self and other.':'返回self和other的和。',
'Dimensions are summed as follows:':'尺寸汇总如下：',
'A Dimension whose value is the sum of self and other.':'价值是自我与他人之和的维度。',
'A Dimension whose value is the integer quotient of self and other.':'一种维数，其值是自我与他人的整数商。',
'Returns true if other has the same known value as this Dimension.':'如果其他维度与此维度具有相同的已知值，则返回true。',
'Returns the quotient of self and other rounded down.':'返回自和其他四舍五入的商。',
'Dimensions are divided as follows:':'尺寸划分如下：',
'Returns True if self is known to be greater than or equal to other.':'如果已知self大于或等于other，则返回true。',
'Dimensions are compared as follows:':'尺寸比较如下：',
'Returns True if self is known to be greater than other.':'如果已知self大于other，则返回true。',
'Returns True if self is known to be less than or equal to other.':'如果已知self小于或等于other，则返回true。',
'Returns True if self is known to be less than other.':'如果已知self小于other，则返回true。',
'Returns self modulo other.':'返回自模other。',
'Dimension moduli are computed as follows:':'尺寸模数计算如下：',
'A Dimension whose value is self modulo other.':'值为自模other的维数。',
'Returns the product of self and other.':'返回self和other的乘积。',
'A Dimension whose value is the product of self and other.':'价值是自我和他人的乘积的维度。',
'Returns true if other has a different known value from self.':'如果other与self具有不同的已知值，则返回true。',
'Returns the sum of other and self.':'返回他者和自我的总和。',
'Returns the quotient of other and self rounded down.':'返回other和self四舍五入的商。',
'Returns other modulo self.':'返回其他模自身。',
'A Dimension whose value is other modulo self.':'其值为另一个模自身的维数。',
'Returns the subtraction of self from other.':'返回自与其他的相减。',
'A Dimension whose value is the subtraction of self from other.':'一个维度，其值是自我与他人的相减。',
'Returns the subtraction of other from self.':'从self返回other的减法。',
'Dimensions are subtracted as follows:':'尺寸减去如下：',
'A Dimension whose value is the subtraction of other from self.':'一种维数，其值是他者与自身的相减。',
'Raises an exception if other is not compatible with this Dimension.':'如果其他维度与此维度不兼容，则引发异常。',
'Returns true if other is compatible with this Dimension.':'如果其他维度与此维度兼容，则返回true。',
'Two known Dimensions are compatible if they have the same value. An unknown Dimension is compatible with all other Dimensions.':'如果两个已知维度具有相同的值，则它们是兼容的。未知维度与所有其他维度兼容。',
'True if this Dimension and other are compatible.':'如果此维度与其他维度兼容，则为true。',
'Returns a Dimension that combines the information in self and other.':'返回将self和other中的信息组合在一起的维度。',
'Dimensions are combined as follows:':'尺寸组合如下：',
'A Dimension containing the combined information of self and other.':'包含自我和他人信息的维度。',
'Opts out of control flow v2.':'选择脱离控制流v2。',
'Disables eager execution.':'禁用紧急执行。',
'Compare Tensors by their id and be hashable.':'根据张量的id比较它们，并且可以散列。',
'This is a legacy behaviour of TensorFlow and is highly discouraged.':'这是TensorFlow的遗留行为，非常不受欢迎。',
'Disables TensorFlow 2.x behaviors.':'禁用TensorFlow 2.x行为。',
'User can call this function to disable 2.x behavior during complex migrations.':'用户可以调用此函数来禁用复杂迁移期间的2.x行为。',
'Disables the V2 TensorShape behavior and reverts to V1 behavior.':'禁用v2 tensorShape行为并还原为v1行为。',
'Use control flow v2.':'使用控制流v2。',
'Enables eager execution for the lifetime of this program.':'在此程序的生存期内启用紧急执行。',
'Eager execution cannot be enabled after TensorFlow APIs have been used to create or execute graphs. It is typically recommended to invoke this function at program startup and not in a library (as most libraries should be usable both with and without eager execution).':'在使用TensorFlow API创建或执行图之后，无法启用紧急执行。通常建议在程序启动时调用此函数，而不是在库中调用（因为大多数库在执行和不执行时都应该是可用的）。',
'Creates resource variables by default.':'默认情况下创建资源变量。',
'Enables TensorFlow 2.x behaviors.':'启用TensorFlow 2.x行为。',
'This enables the new behavior.':'这将启用新行为。',
#' #######################':'#######################',
#'#######################':'#######################',
'## Class Event':'## Class 活动',
'### step':'### 台阶',
'### summary':'### 摘要',
'Summary summary':'摘要',
'Extract patches from images and put them in the "depth" output dimension.':'从图像中提取面片并将其放入“深度”输出维度。',
'A Tensor. Has the same type as images.':'张量与图像具有相同的类型。',
'## Class FixedLengthRecordReader':'## 类FixedLengthRecordReader',
'See ReaderBase for supported methods.':'有关支持的方法，请参阅readerbase。',
'Op that implements the reader.':'实现读取器的操作。',
'Whether the Reader implementation can serialize its state.':'读取器实现是否可以序列化其状态。',
'Returns the number of records this reader has produced.':'返回此读取器生成的记录数。',
'This is the same as the number of Read executions that have succeeded.':'这与成功的读取执行数相同。',
'An int64 Tensor.':'int64张量。',
'Returns the number of work units this reader has finished processing.':'返回此读取器已完成处理的工作单元数。',
'Will dequeue a work unit from queue if necessary (e.g. when the Reader needs to start reading from a new file since it has finished with the previous file).':'如果需要，将工作单元从队列中出列（例如，当读卡器需要从新文件开始读取时，因为它已经完成了前一个文件）。',
'Restore a reader to its initial clean state.':'将读取器还原到其初始干净状态。',
'Restore a reader to a previously saved state.':'将读取器还原到以前保存的状态。',
'Produce a string tensor that encodes the state of a reader.':'产生一个字符串张量来编码读卡器的状态。',
'A string Tensor.':'弦张量',
'Partitioner to specify a fixed number of shards along given axis.':'指定给定轴上固定数量的碎片。',
'Collections are not supported when eager execution is enabled.':'启用紧急执行时不支持集合。',
'Returns the default graph for the current thread.':'返回当前线程的默认图表。',
'The default Graph being used in the current thread.':'当前线程中使用的默认图形。',
'Returns the default session for the current thread.':'返回当前线程的默认会话。',
'The default Session being used in the current thread.':'当前线程中使用的默认会话。',
'Gets an existing local variable or creates a new one.':'获取现有的局部变量或创建新的局部变量。',
'A tuple of two integers that should be used for the local seed of this operation.':'应该用于此操作的本地种子的两个整数的元组。',
'Return the handle of data.':'返回数据句柄。',
'A scalar string tensor representing a unique handle for data.':'表示数据唯一句柄的标量字符串张量。',
'Get the tensor of type dtype by feeding a tensor handle.':'通过给张量手柄来获得dtype类型的张量。',
'Get the value of the tensor from a tensor handle. The tensor is produced in a previous run() and stored in the state of the session.':'从张量句柄获取张量的值。张量在前一次run（）中生成，并存储在会话的状态中。',
'A pair of tensors. The first is a placeholder for feeding a tensor handle and the second is the tensor in the session state keyed by the tensor handle.':'一对张量。第一个是用于馈送张量句柄的占位符，第二个是由张量句柄键入的会话状态中的张量。',
'Gets an existing variable with these parameters or create a new one.':'获取具有这些参数的现有变量或创建新变量。',
'Returns the current variable scope.':'返回当前变量范围。',
'Returns global variables.':'返回全局变量。',
'A list of Variable objects.':'变量对象的列表。',
'Returns an Op that initializes global variables.':'返回初始化全局变量的操作。',
'An Op that initializes global variables in the graph.':'初始化图中全局变量的操作。',
'## Class GPUOptions':'##G类选项',
'## Class VirtualDevices':'## 类虚拟设备',
'## Class GraphDef':'## 类GraphDef',
'### library':'### 图书馆',
'FunctionDefLibrary library':'函数库',
'### node':'### 节点',
'repeated NodeDef node':'重复节点def node',
'### versions':'### 版本',
'VersionDef versions':'版本',
'## Class GraphKeys':'## 类图',
'Standard names to use for graph collections.':'用于图形集合的标准名称。',
'The following standard keys are defined:':'定义了以下标准键：',
'## Class GraphOptions':'## 类图形',
'## Class HistogramProto':'## 类历史记录',
'### bucket':'### 水桶',
'repeated double bucket':'重复双桶',
'### max':'### 最大值',
'### min':'### 最小值',
'### num':'### 数字',
'### sum':'### 总和',
'## Class IdentityReader':'## 类标识符',
'A Reader that outputs the queued work as both the key and value.':'将排队的工作作为键和值输出的读取器。',
'An Op that initializes all tables. Note that if there are not tables the returned Op is a NoOp.':'初始化所有表的操作。注意，如果没有表，返回的op就是noop。',
'## Class InteractiveSession':'## 类交互会话',
'Creates a new interactive TensorFlow session.':'创建一个新的交互式TensorFlow会话。',
'The graph that was launched in this session.':'在此会话中启动的图表。',
'A serializable version of the underlying TensorFlow graph.':'底层tensorflow图的可序列化版本。',
'The TensorFlow process to which this session will connect.':'此会话将连接到的tensorflow进程。',
'Returns a context manager that makes this object the default session.':'返回使此对象成为默认会话的上下文管理器。',
'A context manager using this session as the default session.':'使用此会话作为默认会话的上下文管理器。',
'Closes an InteractiveSession.':'关闭交互会话。',
'Lists available devices in this session.':'列出此会话中的可用设备。',
'#### Where:':'#### 其中：',
'Each element in the list has the following properties':'列表中的每个元素都具有以下属性',
'A list of devices in the session.':'会话中设备的列表。',
'Returns a Python callable that runs a particular step.':'返回运行特定步骤的可调用python。',
'Continues the execution with more feeds and fetches.':'用更多的feed和fetch继续执行。',
'Below is a simple example:':'下面是一个简单的例子：',
'Sets up a graph with feeds and fetches for partial run.':'为部分运行设置带有源和获取的图形。',
'A handle for partial run.':'用于部分运行的句柄。',
'Runs operations and evaluates tensors in fetches.':'在获取中运行操作并计算张量。',
'The optional options argument expects a [RunOptions] proto. The options allow controlling the behavior of this particular step (e.g. turning tracing on).':'optional options参数需要一个[runoptions]proto。这些选项允许控制此特定步骤的行为（例如打开跟踪）。',
'Tests if a variable has been initialized.':'测试变量是否已初始化。',
'## Class LMDBReader':'##LMDBReader类',
'A Reader that outputs the records from a LMDB file.':'从lmdb文件输出记录的读取器。',
'Returns local variables.':'返回局部变量。',
'A list of local Variable objects.':'局部变量对象的列表。',
'Returns an Op that initializes all local variables.':'返回初始化所有局部变量的操作。',
'An Op that initializes all local variables in the graph.':'初始化图中所有局部变量的操作。',
'## Class LogMessage':'## 类日志消息',
'### level':'### 水平',
'Level level':'水平面',
'### message':'### 消息',
'string message':'字符串消息',
'## Class MetaGraphDef':'## 类metagraphdef',
'## Class CollectionDefEntry':'## 集体防御',
'CollectionDef value':'集合定义值',
'## Class MetaInfoDef':'## 类metainfodef',
'### tags':'### 标签',
'repeated string tags':'重复的字符串标记',
'## Class SignatureDefEntry':'## Class 签名',
'SignatureDef value':'signaturedef值',
'Partitioner to allocate minimum size per slice.':'要为每个切片分配最小大小的分区程序。',
'Returns all variables that maintain their moving averages.':'返回保持其移动平均值的所有变量。',
'## Class NameAttrList':'## 类名称属性列表',
'### attr':'### 属性',
'repeated AttrEntry attr':'重复属性属性',
'string name':'字符串名称',
'## Class AttrEntry':'## 类属性',
'AttrValue value':'属性值',
'## Class NodeDef':'##nodedef类',
'string device':'字符串设备',
'### input':'### 输入',
'repeated string input':'重复字符串输入',
'string op':'字符串操作',
'## Class ExperimentalDebugInfo':'## 类实验aldebuginfo',
'Use this function to prevent regularization of variables.':'使用此函数可防止变量正则化。',
'## Class OptimizerOptions':'## 类优化',
'Parses Example protos into a dict of tensors.':'将示例原型解析为一组张量。',
#'  features':'特征',
#']':']',
'then the output will look like:':'然后输出如下：',
'Given two Example input protos in serialized:':'给定两个序列化的示例输入协议：',
#'  features {':'功能{',
#'    feature { key: "gps" value { } }':'功能{键：“GPS”值{}',
'And arguments':'和争论',
'features: {':'功能：{',
'Then the output is a dictionary:':'然后输出一个字典：',
'For dense results in two serialized Examples:':'对于两个序列化示例中的密集结果：',
#'   features {':'功能{',
'#### We can use arguments:':'#### 我们可以使用参数：',
'And the expected output is:':'预期产量为：',
'A dict mapping feature keys to Tensor and SparseTensor values.':'dict映射的特征键是tensor和sparsetensor值。',
'Parses a single Example proto.':'解析单个示例原型。',
'Inserts a placeholder for a tensor that will be always fed.':'插入将始终馈送的张量的占位符。',
'Placeholders are not compatible with eager execution.':'占位符与紧急执行不兼容。',
'A placeholder op that passes through input when its output is not fed.':'一种占位符操作，当输入的输出不被输入时，它就通过输入。',
'DEPRECATED FUNCTION ARGUMENTS':'不推荐使用的函数参数',
'Draws shape samples from each of the given Poisson distribution(s).':'从每个给定的泊松分布中绘制形状样本。',
'lam is the rate parameter describing the distribution(s).':'lam是描述分布的速率参数。',
'## Class ReaderBase':'## 类readerbase',
'Therefore we introduce some decoupling using a queue. The queue contains the work units and the Reader dequeues from the queue when it is asked to produce a record (via Read()) but it has finished the last work unit.':'因此，我们引入了一些使用队列的解耦。当请求队列（通过read（））生成记录但它已完成最后一个工作单元时，该队列包含工作单元和队列中的读取器解队列。',
'Creates a new ReaderBase.':'创建新的ReaderBase。',
'Equivalent to np.any':'相当于np.any',
'Joins a string Tensor across the given dimensions.':'在给定维度上连接字符串张量。',
'This function is more numerically stable than log(sum(exp(input))). It avoids overflows caused by taking the exp of large inputs and underflows caused by taking the log of small inputs.':'这个函数在数值上比log（sum（exp（input））更稳定。它避免了大输入的exp引起的溢出和小输入的log引起的下溢。',
'Equivalent to np.max':'相当于np.max',
'Computes the mean of elements across dimensions of a tensor.':'计算元素在张量维度上的平均值。',
'Equivalent to np.mean':'相当于np.mean',
'Equivalent to np.min':'相当于np.min',
'Equivalent to np.prod':'相当于np.prod',
'Equivalent to np.sum apart the fact that numpy upcast uint8 and int32 to int64 while tensorflow returns the same dtype as the input.':'与np.sum等价，但numpy将uint8和int32向上转换为int64，而tensorflow返回与输入相同的数据类型。',
'Adds ops to list the names of uninitialized variables.':'添加ops以列出未初始化变量的名称。',
'Clears the default graph stack and resets the global default graph.':'清除默认图形堆栈并重置全局默认图形。',
'Returns True if resource variables are enabled.':'如果启用了资源变量，则返回true。',
'## Class RunMetadata':'## 类runmetadata',
'## Class FunctionGraphs':'## 类函数图',
'## Class RunOptions':'## Class 流失',
'Multiplies a scalar times a Tensor or IndexedSlices object.':'将标量乘以张量或indexedlices对象。',
'Adds sparse updates to the variable referenced by resource.':'向资源引用的变量添加稀疏更新。',
'This operation computes':'此操作计算',
'Same as ref. Returned as a convenience for operations that want to use the updated values after the update is done.':'与ref.returned相同，这是为了便于在更新完成后使用更新值的操作。',
'Divides a variable reference by sparse updates.':'通过稀疏更新划分变量引用。',
'This operation outputs ref after the update is done. This makes it easier to chain operations that need to use the reset value.':'此操作在更新完成后输出ref。这使得链接需要使用重置值的操作更容易。',
'A mutable Tensor. Has the same type as ref.':'可变张量具有与ref相同的类型。',
'Reduces sparse updates into a variable reference using the max operation.':'使用max操作将稀疏更新减少为变量引用。',
'Reduces sparse updates into a variable reference using the min operation.':'使用min操作将稀疏更新减少为变量引用。',
'Multiplies sparse updates into a variable reference.':'将稀疏更新乘以变量引用。',
'ref is a Tensor with rank P and indices is a Tensor of rank Q.':'ref是秩为p的张量，index是秩为q的张量。',
'The resulting update to ref would look like this:':'ref的结果更新如下：',
'Applies sparse updates to individual values or slices in a Variable.':'对变量中的单个值或切片应用稀疏更新。',
'The value of the variable after the update.':'更新后变量的值。',
'Subtracts sparse updates to a variable reference.':'减去对变量引用的稀疏更新。',
'Applies sparse updates to a variable reference.':'对变量引用应用稀疏更新。',
'## Class Session':'## Class 会议',
'A class for running TensorFlow operations.':'运行tensorflow操作的类。',
'Creates a new TensorFlow session.':'创建新的tensorflow会话。',
'Closes this session.':'关闭此会话。',
'Calling this method frees all resources associated with the session.':'调用此方法将释放与会话关联的所有资源。',
'#### NOTE:':'#### 注：',
'(i) reset() is currently only implemented for distributed sessions. (ii) Any sessions on the master named by target will be closed.':'（i）reset（）目前只为分布式会话实现。（ii）目标指定的主机上的任何会话都将关闭。',
'## Class SessionLog':'## 类sessionlog',
'### msg':'### 味精',
'string msg':'字符串消息',
'### status':'### 地位',
'SessionStatus status':'会话状态',
'Computes the difference between two lists of numbers or strings.':'计算两个数字或字符串列表之间的差异。',
'This operation would return:':'此操作将返回：',
'Returns the size of a tensor.':'返回张量的大小。',
'This is a legacy version of the more general SpaceToBatchND.':'这是更通用的spacetobatchnd的遗留版本。',
'T`h``e`` `s`h``a``p``e`` `of` ``t``h``e`` `ou`t``p`u`t`` ``w``i`ll` ``b``e`:':'t`h``e``s`h``a``p``e``of``t``h``e``ou`t``p`u`t``w``i`b``e`：',
'Som`e`` ``e`x`a`m`p`l`e`s:':'som`e```e`x`a`m`p`l`e`的：',
'SpaceToDepth for tensors of type T.':'t型张量的空间深度。',
'the operator will return the following tensor of shape [1 2 2 4]:':'运算符将返回以下形状张量[1 2 2 4]：',
'## Class SparseConditionalAccumulator':'## 类稀疏累加器',
'A conditional accumulator for aggregating sparse gradients.':'聚集稀疏梯度的条件累加器。',
'Sparse gradients are represented by IndexedSlices.':'稀疏渐变由indexedlices表示。',
'Attempts to apply a sparse gradient to the accumulator.':'尝试对累加器应用稀疏渐变。',
'An IndexedSlices holding the value of the average gradient.':'包含平均梯度值的索引。',
'## Class SparseTensorValue':'##Sparsetenservalue类',
'The shapes of the two operands must match: broadcasting is not supported.':'两个操作数的形状必须匹配：不支持广播。',
'Concatenation is with respect to the dense versions of each sparse input. It is assumed that each inputs is a SparseTensor whose elements are ordered along increasing dimension number.':'连接是关于每个稀疏输入的密集版本。假设每个输入都是一个sparsetensor，其元素按维数的增加顺序排列。',
'The output elements will be resorted to preserve the sort order along increasing dimension number.':'输出元素将被重新排序，以保持沿维度数增加的排序顺序。',
'then the output will be':'然后输出将是',
'Graphically this is equivalent to doing':'从图形上看，这相当于',
'A SparseTensor with the concatenated output.':'具有串联输出的sparsetensor。',
'Multiply matrix "a" by matrix "b".':'将矩阵“a”乘以矩阵“b”。',
'The gradient computation of this operation will only take advantage of sparsity in the input gradient when that gradient comes from a Relu.':'此操作的梯度计算仅在该梯度来自relu时利用输入梯度的稀疏性。',
'A Tensor of type float32.':'float32型张量。',
'The SparseTensor returned by this function has the following properties:':'此函数返回的SparSetensor具有以下属性：',
'Inserts a placeholder for a sparse tensor that will be always fed.':'插入将始终馈送的稀疏张量的占位符。',
#'    succeed.':'成功。',
'The reduced Tensor.':'简化张量。',
'The reduced SparseTensor.':'简化的Sparsetensor。',
'Computes the mean along sparse segments of a tensor.':'计算张量稀疏段的平均值。',
'Computes the sum along sparse segments of a tensor divided by the sqrt(N).':'计算张量稀疏段的和除以sqrt（n）。',
'N is the size of the segment being reduced.':'n是要缩小的段的大小。',
'Computes the sum along sparse segments of a tensor.':'计算张量稀疏段的和。',
'Graphically the output tensors are:':'从图形上看，输出张量为：',
'Let N be the size of source (typically N will be the batch size). Split each element of source based on delimiter and return a SparseTensor or RaggedTensor containing the split tokens. Empty tokens are ignored.':'设n为源的大小（通常n为批处理大小）。基于分隔符拆分源的每个元素，并返回包含拆分标记的sparsetensor或raggedtensor。忽略空标记。',
'to the delimiter.  The first column of the indices corresponds to the row':'到分隔符。索引的第一列对应于行',
'in `source` and the second column corresponds to the index of the split':'在“source”中，第二列对应于拆分的索引',
'component in this row.':'此行中的组件。',
'Converts each string in the input Tensor to its hash mod by a number of buckets.':'将输入张量中的每个字符串转换为其hash mod（按桶数）。',
'The hash function is deterministic on the content of the string within the process.':'哈希函数对进程中字符串的内容是确定的。',
'A Tensor of type int64.':'int64型张量。',
'Converts each string in the input Tensor to the specified numeric type.':'将输入张量中的每个字符串转换为指定的数值类型。',
'Return substrings from Tensor of strings.':'从字符串的张量返回子字符串。',
'A negative pos indicates distance within the string backwards from the end.':'负pos表示字符串内从末端向后的距离。',
'Examples':'实例',
'Using scalar pos and len:':'使用标量pos和len：',
'Using pos and len with same shape as input:':'使用与输入形状相同的pos和len：',
'Broadcasting pos and len onto input:':'将pos和len广播到输入端：',
'Broadcasting input onto pos and len:':'将输入广播到POS和LEN：',
'## Class Summary':'## Class 总结',
'repeated Value value':'重复值',
'## Class Audio':'## 类音频',
'## Class Image':'## Class 形象',
'### colorspace':'### 色彩空间',
'### height':'### 高度',
'### width':'### 宽度',
'## Class Value':'## 阶级价值',
'### audio':'### 音频',
'Audio audio':'音频',
'### histo':'### 历史',
'HistogramProto histo':'组织gramproto histo',
'### image':'### 图像',
'Image image':'图像',
'### metadata':'### 元数据',
'SummaryMetadata metadata':'摘要元数据',
'### tag':'### 标签',
'string tag':'字符串标记',
'## Class SummaryMetadata':'## 类摘要元数据',
'## Class PluginData':'## 类plugindata',
'### content':'### 内容',
'Returns an Op that initializes all tables of the default graph.':'返回初始化默认图的所有表的操作。',
'## Class TensorInfo':'## 类tensorinfo',
'DataType dtype':'数据类型DTYPE',
'## Class CooSparse':'## 类Coosparse',
'## Class TextLineReader':'## 类TextLineReader',
'A Reader that outputs the lines of a file delimited by newlines.':'输出由换行符分隔的文件行的读取器。',
'Newlines are stripped from the output. See ReaderBase for supported methods.':'新行从输出中剥离。有关支持的方法，请参阅readerbase。',
'## Class TFRecordReader':'## 类tfrecordreader',
'A Reader that outputs the records from a TFRecords file.':'从tfrecords文件输出记录的读取器。',
'A Tensor or SparseTensor or IndexedSlices with same shape as x with type bfloat16.':'张量或sparsetensor或indexedlices，其形状与bfloat16型x相同。',
'A Tensor or SparseTensor or IndexedSlices with same shape as x with type complex128.':'与x形状相同、类型为complex128的张量或sparsetensor或indexedlices。',
'A Tensor or SparseTensor or IndexedSlices with same shape as x with type complex64.':'与x形状相同的张量、sparsetensor或indexedlices，类型为complex64。',
'A Tensor or SparseTensor or IndexedSlices with same shape as x with type float64.':'一种张量或sparsetensor或indexedlices，其形状与float64类型的x相同。',
'A Tensor or SparseTensor or IndexedSlices with same shape as x with type float32.':'一种张量或sparsetensor或indexedlices，其形状与x相同，类型为float32。',
'A Tensor or SparseTensor or IndexedSlices with same shape as x with type int32.':'一种张量或sparsetensor或indexedlices，其形状与x相同，类型为int32。',
'A Tensor or SparseTensor or IndexedSlices with same shape as x with type int64.':'一种张量或sparsetensor或indexedlices，其形状与int64类型的x相同。',
'Initializer that generates a truncated normal distribution.':'生成截断正态分布的初始值设定项。',
'Initializer that generates tensors without scaling variance.':'生成张量而不缩放方差的初始值设定项。',
'#### References:':'#### 参考文献：',
'To use the replacement for variables which does not have these issues:':'要对不存在这些问题的变量使用替换：',
'Alias of Variable.shape.':'variable.shape的别名。',
'## Class VariableScope':'## 类变量作用域',
'Creates a new VariableScope with the given properties.':'创建具有给定属性的新variablescope。',
'### partitioner':'### 分割器',
'### regularizer':'### 正则化子',
'### reuse':'### 再利用',
'Get this scope\'s variables.':'获取此作用域的变量。',
'Gets an existing variable with this name or create a new one.':'获取具有此名称的现有变量或创建新变量。',
'Get this scope\'s global variables.':'获取此作用域的全局变量。',
'Get this scope\'s local variables.':'获取此作用域的局部变量。',
'Reuse variables in this scope.':'在此范围内重用变量。',
'Set custom getter for this scope.':'为此作用域设置自定义getter。',
'Set data type for this scope.':'为此作用域设置数据类型。',
'Set initializer for this scope.':'为此作用域设置初始值设定项。',
'Set partitioner for this scope.':'为此作用域设置分区程序。',
'Set regularizer for this scope.':'为此范围设置正则化器。',
'Sets whether to use ResourceVariables for this scope.':'设置是否为此作用域使用资源变量。',
'Get this scope\'s trainable variables.':'获取此作用域的可训练变量。',
'Returns an Op that initializes a list of variables.':'返回初始化变量列表的操作。',
'An Op that run the initializers of all the specified variables.':'运行所有指定变量的初始值设定项的操作。',
'Deprecated: context manager for defining an op that creates variables.':'不推荐：用于定义创建变量的操作的上下文管理器。',
'A context manager for defining ops that creates variables (layers).':'用于定义创建变量（层）的操作的上下文管理器。',
'Simple example of how to create a new variable:':'创建新变量的简单示例：',
'Simple example of how to reenter a premade variable scope safely:':'如何安全地重新输入预先定义的变量作用域的简单示例：',
#'  pass':'通过',
'Sharing a variable by capturing a scope and setting reuse:':'通过捕获作用域和设置重用来共享变量：',
'A scope that can be captured and reused.':'可以捕获和重用的作用域。',
'Assert that the tensor does not contain any NaN\'s or Inf\'s.':'断言张量不包含任何nan或inf。',
'Same tensor as t.':'张量与t相同。',
'## Class WholeFileReader':'## 全班朗读者',
'A Reader that outputs the entire contents of a file as a value.':'将文件的全部内容作为值输出的读取器。',
'Wraps the TF 1.x function fn into a graph function.':'将tf 1.x函数fn包装成一个图形函数。',
'the wrapped graph function.':'包装图函数。',
'Generic entry point script.':'通用入口点脚本。',
'Runs the program with an optional \'main\' function and \'argv\' list.':'使用可选的“main”函数和“argv”列表运行程序。',
'Public API for tf.config namespace.':'tf.config命名空间的公共API。',
'Public API for tf.config.experimental namespace.':'tf.config.experimental命名空间的公共API。',
'Public API for tf.config.optimizer namespace.':'tf.config.optimizer命名空间的公共API。',
'## Class Dataset':'## 类数据集',
'Represents a potentially large set of elements.':'表示一组潜在的大型元素。',
'A Dataset can be used to represent an input pipeline as a collection of elements and a "logical plan" of transformations that act on those elements.':'数据集可用于将输入管道表示为元素集合和作用于这些元素的转换的“逻辑计划”。',
'Creates a DatasetV2 object.':'创建datasetv2对象。',
'The type specification of an element of this dataset.':'此数据集元素的类型规范。',
'A nested structure of Python type objects corresponding to each component of an element of this dataset.':'python类型对象的嵌套结构，对应于此数据集元素的每个组件。',
'Creates an Iterator for enumerating the elements of this dataset.':'创建用于枚举此数据集元素的迭代器。',
'The returned iterator implements the Python iterator protocol and therefore can only be used in eager mode.':'返回的迭代器实现python迭代器协议，因此只能在紧急模式下使用。',
'An Iterator over the elements of this dataset.':'此数据集元素上的迭代器。',
'### apply':'### 应用',
'Applies a transformation function to this dataset.':'将转换函数应用于此数据集。',
'### batch':'### 批量',
'Combines consecutive elements of this dataset into batches.':'将此数据集的连续元素组合成批。',
'### cache':'### 缓存',
'Caches the elements in this dataset.':'缓存此数据集中的元素。',
'Creates a Dataset by concatenating the given dataset with this dataset.':'通过将给定数据集与此数据集连接来创建数据集。',
'### enumerate':'### 列举',
'Enumerates the elements of this dataset.':'枚举此数据集的元素。',
'It is similar to python\'s enumerate.':'它类似于python的枚举。',
'### filter':'### 过滤器',
'Filters this dataset according to predicate.':'根据谓词筛选此数据集。',
'NOTE: This is an escape hatch for existing uses of filter that do not work with V2 functions. New uses are strongly discouraged and existing uses should migrate to filter as this method will be removed in V2.':'注意：这是一个转义图案填充，用于不使用v2函数的现有过滤器。强烈禁止新的使用，现有的使用应迁移到筛选器，因为此方法将在v2中删除。',
'Creates a Dataset whose elements are generated by generator.':'创建其元素由生成器生成的数据集。',
'Creates a Dataset whose elements are slices of the given tensors.':'创建一个数据集，其元素是给定张量的切片。',
'### interleave':'### 交错',
'A dataset of all files matching one or more glob patterns.':'与一个或多个全局模式匹配的所有文件的数据集。',
'### map':'### 地图',
'NOTE: This is an escape hatch for existing uses of map that do not work with V2 functions. New uses are strongly discouraged and existing uses should migrate to map as this method will be removed in V2.':'注意：这是一个转义图案填充，用于不使用v2函数的地图的现有用途。强烈禁止新的使用，现有的使用应该迁移到map，因为此方法将在v2中被删除。',
'### options':'### 选项',
'Returns the options for this dataset and its inputs.':'返回此数据集及其输入的选项。',
'Combines consecutive elements of this dataset into padded batches.':'将此数据集的连续元素合并到填充的批中。',
'This transformation combines multiple consecutive elements of the input dataset into a single element.':'此转换将输入数据集的多个连续元素合并为一个元素。',
'### prefetch':'### 预取',
'Creates a Dataset that prefetches elements from this dataset.':'创建从该数据集中预取元素的数据集。',
'### range':'### 范围',
'### reduce':'### 减少',
'Reduces the input dataset to a single element.':'将输入数据集缩减为单个元素。',
'A dataset element corresponding to the final state of the transformation.':'与转换的最终状态相对应的数据集元素。',
'### repeat':'### 重复',
'Repeats this dataset count times.':'重复此数据集计数次。',
'### shard':'### 碎片',
'#### Important caveats:':'#### 重要注意事项：',
'### shuffle':'### 洗牌',
'Randomly shuffles the elements of this dataset.':'随机洗牌此数据集的元素。',
'### skip':'### 跳过',
'Creates a Dataset that skips count elements from this dataset.':'创建从该数据集中跳过计数元素的数据集。',
'### take':'### 采取',
'Creates a Dataset with at most count elements from this dataset.':'创建一个数据集，该数据集最多包含count个元素。',
'### unbatch':'### 解开',
'Splits elements of a dataset into multiple elements.':'将数据集的元素拆分为多个元素。',
'### window':'### 窗口',
'Combines (nests of) input elements into a dataset of (nests of) windows.':'将（嵌套的）输入元素合并到（嵌套的）窗口的数据集中。',
'### zip':'### 拉链',
'Creates a Dataset by zipping together the given datasets.':'通过压缩给定的数据集创建数据集。',
'## Class FixedLengthRecordDataset':'## 类FixedLengthRecordDataSet',
'Creates a FixedLengthRecordDataset.':'创建FixedLengthRecordDataSet。',
'Returns the output classes of a Dataset or Iterator elements.':'返回数据集或迭代器元素的输出类。',
'A nested structure of Python type objects matching the structure of the dataset / iterator elements and specifying the class of the individual components.':'python类型对象的嵌套结构，与dataset/iterator元素的结构匹配，并指定各个组件的类。',
'Returns the output shapes of a Dataset or Iterator elements.':'返回数据集或迭代器元素的输出形状。',
'## Class Iterator':'## 类迭代器',
'Represents the state of iterating through a Dataset.':'表示遍历数据集的状态。',
'Creates a new iterator from the given iterator resource.':'从给定的迭代器资源创建新的迭代器。',
'The type specification of an element of this iterator.':'此迭代器的元素的类型规范。',
'An Iterator.':'迭代器。',
'The following is an example':'下面是一个例子',
#'  while True:':'如果是真的：',
#'    except tf.errors.OutOfRangeError:':'除了tf.errors.outofrangeerror：',
#'      break':'打破',
#'    while True:':'如果是真的：',
#'  except tf.errors.OutOfRangeError:':'除了tf.errors.outofrangeerror：',
#'    pass':'通过',
'## Class TextLineDataset':'## 类textlinedataset',
'A Dataset comprising lines from one or more text files.':'由一个或多个文本文件的行组成的数据集。',
'Creates a TextLineDataset.':'创建textlinedataset。',
'## Class TFRecordDataset':'## 类tfrecorddataset',
'A Dataset comprising records from one or more TFRecord files.':'由一个或多个tfrecord文件中的记录组成的数据集。',
'Creates a TFRecordDataset to read one or more TFRecord files.':'创建tfrecorddataset以读取一个或多个tfrecord文件。',
'Experimental API for building input pipelines.':'用于构建输入管道的实验api。',
'See [Importing Data](https://tensorflow.org/guide/datasets) for an overview.':'有关概述，请参见[导入数据]（https://tensorflow.org/guide/datasets）。',
'Public API for tf.debugging namespace.':'tf.debugging命名空间的公共api。',
'Assert tensor shapes and dimension size relationships between tensors.':'断言张量形状和张量之间的维度大小关系。',
'This Op checks that a collection of tensors shape relationships satisfies given constraints.':'此操作检查张量形状关系的集合是否满足给定的约束。',
'Library for running a computation across multiple devices.':'用于跨多个设备运行计算的库。',
'Glossary':'词汇表',
'This is used to decide whether loss should be scaled in optimizer (used only for estimator + v1 optimizer use case).':'这用于决定是否应在优化器中缩放损失（仅用于Estimator+v1优化器用例）。',
'## Class MirroredStrategy':'## Class 镜像策略',
'Mirrors vars to distribute across multiple devices and machines.':'镜像VAR以分布在多个设备和机器上。',
'### extended':'### 扩展的',
'Returns number of replicas over which gradients are aggregated.':'返回聚合渐变的副本数。',
'Distributes a tf.data.Dataset instance provided via dataset.':'分发通过数据集提供的tf.data.dataset实例。',
'The following is an example:':'下面是一个例子：',
'Makes a tf.data.Dataset for input provided via a numpy array.':'为通过numpy数组提供的输入生成tf.data.dataset。',
'Makes an iterator for input provided via dataset.':'为通过数据集提供的输入生成迭代器。',
'DEPRECATED: This method is not available in TF 2.x.':'已弃用：此方法在tf 2.x中不可用。',
'An tf.distribute.InputIterator which returns inputs for each step of the computation. User should call initialize on the returned iterator.':'一个tf.distribute.inputiterator，它返回计算每个步骤的输入。用户应该对返回的迭代器调用initialize。',
'Returns an iterator split across replicas created from an input function.':'返回在从输入函数创建的副本之间拆分的迭代器。',
'Reduce value across replicas.':'减少复制副本的价值。',
'### scope':'### 范围',
'Returns a context manager selecting this Strategy as current.':'返回选择此策略为当前策略的上下文管理器。',
'A context manager.':'上下文管理器。',
'## Class OneDeviceStrategy':'## 一级设备策略',
'A distribution strategy for running on a single device.':'在单一设备上运行的一种分配策略。',
'Typical usage of this strategy could be testing your code with the tf.distribute.Strategy API before switching to other strategies which actually distribute to multiple devices/machines.':'此策略的典型用法可能是在切换到实际分发到多个设备/机器的其他策略之前，使用tf.distribute.strategy api测试代码。',
'Creates a OneDeviceStrategy.':'创建OneDeviceStrategy。',
'## Class Strategy':'## 阶级策略',
'A list of devices with a state & compute distribution policy.':'具有状态和计算分发策略的设备列表。',
'## Class StrategyExtended':'## Class 策略扩展',
'Sync on read variables':'读取变量时同步',
'Locality':'地点',
'How to update a variable':'如何更新变量',
'The standard pattern for updating variables is to:':'更新变量的标准模式是：',
'This is expected to return a constant value that will not be changed throughout its life cycle.':'这将返回一个在其整个生命周期内不会改变的恒定值。',
'Returns True if static shape is required; False otherwise.':'如果需要静态形状，则返回true；否则返回false。',
'Whether initialization is needed.':'是否需要初始化。',
'Returns the tuple of all devices used to place variables.':'返回用于放置变量的所有设备的元组。',
'Whether checkpointing is needed.':'是否需要检查点。',
'Whether saving summaries is needed.':'是否需要保存摘要。',
'Returns the tuple of all devices used to for compute replica execution.':'返回用于计算副本执行的所有设备的元组。',
#'    destinations':'目的地',
'Mirror a tensor on one device to all worker devices.':'将一个设备上的张量镜像到所有工作设备。',
'A value mirrored to destinations devices.':'镜像到目标设备的值。',
'Run fn once per replica.':'每个副本运行一次fn。',
'Merged return value of fn across all replicas.':'所有副本中fn的合并返回值。',
'Scope that controls which devices variables will be created on.':'控制将在其上创建哪些设备变量的作用域。',
'This may only be used inside self.scope().':'这只能在self.scope（）中使用。',
'Makes a dataset for input provided via a numpy array.':'为通过numpy数组提供的输入生成数据集。',
'Run fn with input from iterator for iterations times.':'使用迭代器的输入运行fn以获得迭代次数。',
'This method can be used to run a step function for training a number of times using input from a dataset.':'此方法可用于运行步骤函数，以便使用数据集的输入进行多次培训。',
'Reads the value of a variable.':'读取变量的值。',
'Combine (via e.g. sum or mean) values across replicas.':'在复制品之间合并（例如通过总和或平均值）。',
'A tensor or value mirrored to destinations.':'映射到目的地的张量或值。',
'### update':'### 更新',
'Run fn to update var using inputs mirrored to the same devices.':'运行fn以使用镜像到相同设备的输入更新var。',
'Tests whether v was created while this strategy scope was active.':'测试此策略作用域处于活动状态时是否创建了v。',
'Variables created inside the strategy scope are "owned" by it:':'在战略范围内创建的变量由其“拥有”：',
'True':'真的',
'Variables created outside the strategy are not owned by it:':'在策略之外创建的变量不属于它：',
'False':'假',
'Core module for TensorFlow distribution objects and helpers.':'TensorFlow分发对象和帮助程序的核心模块。',
'## Class Bernoulli':'## 伯努利类',
'Bernoulli distribution.':'伯努利分布。',
'Python bool describing behavior when a stat is undefined.':'描述未定义stat时的行为的python bool。',
'Shape of a single sample from a single event index as a TensorShape.':'单个事件索引中单个样本的形状，如张量形状。',
'May be partially defined or unknown.':'可能部分定义或未知。',
'The DType of Tensors handled by this Distribution.':'此分布处理的张量的数据类型。',
'Shape of a single sample from a single batch as a TensorShape.':'从一批样品中提取的单个样品的形状。',
'### logits':'### 登录',
'Name prepended to all ops created by this Distribution.':'此分发所创建的所有操作的前一个名称。',
'### parameters':'### 参数',
'Dictionary of parameters used to instantiate this Distribution.':'用于实例化此分发的参数字典。',
'### probs':'### 问题',
'Describes how samples from the distribution are reparameterized.':'描述如何重新参数化分布中的样本。',
'An instance of ReparameterizationType.':'重新参数化类型的实例。',
'Python bool indicating possibly expensive checks are enabled.':'python bool表示可能会启用昂贵的检查。',
'### cdf':'###CDF公司',
'Cumulative distribution function.':'累积分布函数。',
'### copy':'### 复制',
'Creates a deep copy of the distribution.':'创建分发的深层副本。',
'### covariance':'### 协方差',
'Covariance.':'协方差。',
'Computes the (Shannon) cross entropy.':'计算（香农）交叉熵。',
'### entropy':'### 熵',
'Shannon entropy in nats.':'nats中的香农熵。',
'Log cumulative distribution function.':'对数累积分布函数。',
'Log probability density/mass function.':'对数概率密度/质量函数。',
'Log survival function.':'日志生存函数。',
'### mean':'### 平均',
'Mean.':'卑鄙。',
'### mode':'### 模式',
'Mode.':'模式。',
'Additional documentation from Bernoulli:':'伯努利的其他文件：',
'Shapes of parameters given the desired shape of a call to sample().':'给定对sample（）调用所需形状的参数形状。',
'This is a class method that describes what key/value arguments are required to instantiate the given Distribution so that a particular shape is returned for that instance\'s call to sample().':'这是一个类方法，描述实例化给定分布所需的键/值参数，以便为该实例调用sample（）返回特定形状。',
'dict of parameter name to Tensor shapes.':'张量形状的参数名称。',
'This is a class method that describes what key/value arguments are required to instantiate the given Distribution so that a particular shape is returned for that instance\'s call to sample(). Assumes that the sample\'s shape is known statically.':'这是一个类方法，描述实例化给定分布所需的键/值参数，以便为该实例调用sample（）返回特定形状。假设样品的形状是静态已知的。',
'dict of parameter name to TensorShape.':'参数名到tensorShape的dict。',
'### prob':'### 探针',
'Probability density/mass function.':'概率密度/质量函数。',
'### quantile':'### 分位数',
'Quantile function. Aka "inverse cdf" or "percent point function".':'分位数函数。又称“逆CDF”或“百分点函数”。',
'### sample':'### 样品',
'Generate samples of the specified shape.':'生成指定形状的示例。',
'Note that a call to sample() without arguments will generate a single sample.':'注意，不带参数的sample（）调用将生成单个示例。',
'### stddev':'###stddev公司',
'Standard deviation.':'标准偏差。',
'Survival function.':'生存功能。',
'### variance':'### 方差',
'Variance.':'方差。',
'## Class Beta':'## 测试级',
'Beta distribution.':'β分布。',
'#### Mathematical Details':'#### 数学细节',
'Distribution parameters are automatically broadcast in all functions; see examples for details.':'分布参数在所有功能中自动广播；有关详细信息，请参见示例。',
'Samples of this distribution are reparameterized (pathwise differentiable). The derivatives are computed using the approach described in the paper':'这个分布的样本被重新参数化（路径可微）。导数是用文中描述的方法计算的',
'#### Examples':'#### 实例',
'Compute the gradients of samples w.r.t. the parameters:':'计算样品的梯度w.r.t.参数：',
'### concentration1':'### 浓度1',
'Concentration parameter associated with a 1 outcome.':'与1结果相关的浓度参数。',
'Sum of concentration parameters.':'浓度参数之和。',
'Additional documentation from Beta:':'测试版的其他文档：',
'## Class Categorical':'## 分类的',
'Categorical distribution.':'分类分布。',
'#### Pitfalls':'#### 陷阱',
'Scalar int32 tensor: the number of classes.':'标量Int32张量：类的数目。',
'Vector of coordinatewise logits.':'协调逻辑向量。',
'Vector of coordinatewise probabilities.':'协调概率向量。',
'## Class Dirichlet':'## 迪里克莱类',
'Dirichlet distribution.':'dirichlet分布。',
'### concentration':'### 集中',
'Concentration parameter; expected counts for that coordinate.':'浓度参数；该坐标的预期计数。',
'Sum of last dim of concentration parameter.':'浓度参数最后一个维度的总和。',
'Additional documentation from Dirichlet:':'Dirichlet提供的其他文档：',
'## Class DirichletMultinomial':'## 类dirichlet多项式',
'Concentration parameter; expected prior counts for that coordinate.':'浓度参数；该坐标的预期优先计数。',
'Number of trials used to construct a sample.':'用于构建样本的试验次数。',
'Additional documentation from DirichletMultinomial:':'Dirichlett多项式的附加文档：',
'The covariance for each batch member is defined as the following:':'每个批处理成员的协方差定义如下：',
'The covariance between elements in a batch is defined as:':'批处理中元素之间的协方差定义为：',
'## Class Distribution':'## 阶级分布',
'A generic probability distribution base class.':'一般概率分布基类。',
'#### Subclassing':'#### 子类化',
'All distributions support batches of independent distributions of that type. The batch shape is determined by broadcasting together the parameters.':'所有发行版都支持该类型的独立发行版批处理。批处理形状是通过将参数一起广播来确定的。',
'Using the Uniform distribution as an example:':'以均匀分布为例：',
'#### Shapes':'#### 形状',
'#### Parameter values leading to undefined statistics or distributions.':'#### 导致未定义统计或分布的参数值。',
'The user is given the option of raising an exception or returning NaN.':'用户可以选择引发异常或返回nan。',
'This is a private method for subclass use.':'这是一个用于子类的私有方法。',
'## Class Exponential':'## 类指数',
'Exponential distribution.':'指数分布。',
'The Exponential distribution is parameterized by an event rate parameter.':'指数分布由事件率参数参数化。',
'Concentration parameter.':'浓度参数。',
'### rate':'### 费率',
'Rate parameter.':'速率参数。',
'Additional documentation from Gamma:':'gamma提供的其他文档：',
'## Class Gamma':'## 伽马类',
'Gamma distribution.':'伽马分布。',
'The Gamma distribution is defined over positive real numbers using parameters concentration (aka "alpha") and rate (aka "beta").':'伽马分布是在正实数上使用参数浓度（aka“alpha”）和速率（aka“beta”）定义的。',
'The parameters concentration and rate must be shaped in a way that supports broadcasting (e.g. concentration + rate is a valid operation).':'参数“浓度”和“速率”的形状必须支持广播（例如，“浓度+速率”是有效的操作）。',
'## Class Laplace':'## 拉普拉斯类',
'The Laplace distribution with location loc and scale parameters.':'具有位置、位置和尺度参数的拉普拉斯分布。',
'#### Mathematical details':'#### 数学细节',
'### loc':'### 位置',
'Distribution parameter for the location.':'位置的分布参数。',
'### scale':'### 比例尺',
'Distribution parameter for scale.':'比例分布参数。',
'## Class Multinomial':'## 类多项式',
'Multinomial distribution.':'多项式分布。',
'The distribution functions can be evaluated on counts.':'分布函数可以按计数计算。',
'Probability of drawing a 1 in that coordinate.':'在那个坐标系中画1的概率。',
'Additional documentation from Multinomial:':'多项式的附加文档：',
'## Class Normal':'## 类标准',
'The Normal distribution with location loc and scale parameters.':'位置、位置和尺度参数的正态分布。',
'Examples of initialization of one or a batch of distributions.':'初始化一个或一批分布的示例。',
'Arguments are broadcast when possible.':'尽可能广播参数。',
'The parameters loc and scale must be shaped in a way that supports broadcasting (e.g. loc + scale is a valid operation).':'参数loc和scale的形状必须支持广播（例如loc+scale是有效的操作）。',
'Distribution parameter for the mean.':'平均值的分布参数。',
'Distribution parameter for standard deviation.':'标准差分布参数。',
'## Class RegisterKL':'## 类寄存器kl',
'Decorator to register a KL divergence implementation function.':'decorator注册kl发散实现函数。',
'Perform the KL registration.':'执行KL注册。',
'## Class ReparameterizationType':'## 类重新参数化类型',
'Instances of this class represent how sampling is reparameterized.':'此类的实例表示如何重新参数化采样。',
'Determine if this ReparameterizationType is equal to another.':'确定此重新参数化类型是否等于另一个。',
'self is other.':'自我是另一种。',
'## Class StudentT':'## Class 学生',
'### df':'### 数据框',
'Degrees of freedom in these Student\'s t distribution(s).':'这些学生t分布的自由度。',
'Locations of these Student\'s t distribution(s).':'这些学生t分布的位置。',
'Scaling factors of these Student\'s t distribution(s).':'学生t分布的标度因子。',
'Additional documentation from StudentT:':'studentt提供的其他文档：',
'The variance for Student\'s T equals':'学生t等于的方差',
'## Class Uniform':'## 校服',
'Uniform distribution with low and high parameters.':'低参数和高参数的均匀分布。',
'### high':'### 高',
'Upper boundary of the output interval.':'输出间隔的上边界。',
'### low':'### 低',
'Lower boundary of the output interval.':'输出间隔的下边界。',
'Public API for tf.dtypes namespace.':'tf.dtypes命名空间的公共API。',
'Exception types for TensorFlow errors.':'TensorFlow错误的异常类型。',
'Context manager to check for C API status.':'上下文管理器检查C API状态。',
'Estimator: High level tools for working with models.':'估计器：处理模型的高级工具。',
'## Class BaselineClassifier':'## 类基线分类器',
'A classifier that can establish a simple baseline.':'可以建立简单基线的分类器。',
'Constructs an Estimator instance.':'构造估计器实例。',
'Args:':'参数：',
'Returns: `tf.estimator.EstimatorSpec`':'返回：`tf.estimator.estimatorSpec`',
#'         If the string filepath is provided instead of a':'如果提供了字符串filepath而不是',
'### config':'### 配置',
'### params':'### 参数',
'Shows the directory name where evaluation metrics are dumped.':'显示转储评估指标的目录名。',
'A string which is the path of directory contains evaluation metrics.':'作为目录路径的字符串包含评估度量。',
'### evaluate':'### 评价',
'Exports a SavedModel with tf.MetaGraphDefs for each requested mode.':'为每个请求的模式导出带有tf.metagraphdefs的savedModel。',
'The string path to the exported directory.':'导出目录的字符串路径。',
'Exports inference graph as a SavedModel into the given dir.':'将推理图作为savedModel导出到给定的目录中。',
'Returns list of all variable names in this model.':'返回此模型中所有变量名的列表。',
'List of names.':'名单。',
'Returns value of the variable given by name.':'返回按名称给定的变量的值。',
'The full path to the latest checkpoint or None if no checkpoint was found.':'最新检查点的完整路径，如果找不到检查点，则为“无”。',
'### predict':'### 预测',
'Yields predictions for given features.':'生成给定特征的预测。',
'A `tf.data.Dataset` object: Outputs of `Dataset` object must have same constraints as below.':'“tf.data.dataset”对象：“dataset”对象的输出必须具有与下面相同的约束。',
'Evaluated values of predictions tensors.':'预测张量的评估值。',
'### train':'### 火车',
'## Class BaselineEstimator':'## 类基线估计器',
'An estimator that can establish a simple baseline.':'能建立简单基线的估计器。',
'## Class BaselineRegressor':'## 类基线回归器',
'A regressor that can establish a simple baseline.':'可以建立简单基线的回归器。',
'This regressor ignores feature values and will learn to predict the average value of each label.':'此回归器忽略特征值，并将学习预测每个标签的平均值。',
'Example output of parsing spec:':'解析规范的示例输出：',
'Example usage with a classifier:':'使用分类器的示例：',
'A dict mapping each feature key to a FixedLenFeature or VarLenFeature value.':'将每个功能键映射到fixedlenfeature或varlenfeature值的dict。',
'## Class DNNClassifier':'## 类dnnclassifier',
'A classifier for TensorFlow DNN models.':'Tensorflow dnn模型的分类器。',
'Loss is calculated by using softmax cross entropy.':'利用软最大交叉熵计算损耗。',
'## Class DNNEstimator':'##DNnestImator类',
'Loss and predicted output are determined by the specified head.':'损失和预计产量由指定水头决定。',
'## Class DNNLinearCombinedClassifier':'## 类DNNLinearCombinedClassifier',
'An estimator for TensorFlow Linear and DNN joined classification models.':'Tensorflow 线性和dnn连接分类模型的估计量。',
'## Class DNNLinearCombinedEstimator':'##DNNLinearCombinedEstimator类',
'An estimator for TensorFlow Linear and DNN joined models with custom head.':'具有自定义头的Tensorflow 线性和dnn连接模型的估计量。',
'Loss is calculated by using mean squared error.':'损耗用均方误差计算。',
'## Class DNNLinearCombinedRegressor':'##DNNLinearCombinedRegressor类',
'An estimator for TensorFlow Linear and DNN joined models for regression.':'回归Tensorflow 线性模型和dnn连接模型的估计量。',
'## Class DNNRegressor':'##DnnRegressor类',
'A regressor for TensorFlow DNN models.':'Tensorflow dnn模型的回归器。',
'## Class Estimator':'## 类估计量',
'Estimator class to train and evaluate TensorFlow models.':'训练和评估Tensorflow 模型的估计类。',
'## Class LinearClassifier':'## 类线性助手',
'Linear classifier model.':'线性分类器模型。',
'## Class LinearEstimator':'## 类线性映射器',
'Initializes a LinearEstimator instance.':'初始化linearestimator实例。',
'## Class LinearRegressor':'## 班主任',
'An estimator for TensorFlow Linear regression problems.':'Tensorflow 线性回归问题的估计量。',
'Train a linear regression model to predict label value given observation of feature values.':'训练一个线性回归模型来预测给定特征值的标签值。',
'Example usage with a regressor:':'使用回归器的示例：',
'Public API for tf.estimator.experimental namespace.':'tf.estimator.experimental命名空间的公共api。',
'## Class KMeans':'##Kmeans班',
'is equivalent to':'相当于',
'Creates an Estimator for running KMeans training and inference.':'创建用于运行KMeans训练和推断的估计器。',
'which is the sq`u`are root o`f` the s`u`m o`f` the absol`u`te sq`u`ares o`f` the elements\' di`f``f`erence.':'这是sq`u`是s`u`m o`f`the absoll`u`te sq`u`ares o`f`the elements'di`f`f erence的根。',
'Returns the cluster centers.':'返回群集中心。',
'Finds the index of the closest cluster center to each input point.':'查找距离每个输入点最近的簇中心的索引。',
'The index of the closest cluster center for each input point.':'每个输入点最近的簇中心的索引。',
'### score':'### 得分',
'Returns the sum of squared distances to nearest clusters.':'返回最近簇的平方距离之和。',
'Note that this function is different from the corresponding one in sklearn which returns the negative sum.':'注意，这个函数不同于sklearn中返回负和的对应函数。',
'The sum of the squared distance from each point in the first batch of inputs to its nearest cluster center.':'从第一批输入中的每个点到其最近的簇中心的平方距离之和。',
'### transform':'### 变换',
'Transforms each input point to its distances to all cluster centers.':'将每个输入点转换为其到所有簇中心的距离。',
'The distances from each input point to each cluster center.':'从每个输入点到每个簇中心的距离。',
'All public utility methods for exporting Estimator to SavedModel.':'用于将估计器导出到savedModel的所有公用程序方法。',
'Returns input function that would feed dict of numpy arrays into the model.':'返回将numpy数组的dict馈送到模型中的输入函数。',
'This returns a function outputting features and targets based on the dict of numpy arrays. The dict features has the same keys as the x. The dict targets has the same keys as the y if y is a dict.':'这将返回一个基于numpy数组的dict输出特性和目标的函数。dict特性与x具有相同的键。如果y是dict，dict目标与y具有相同的键。',
'Returns input function that would feed Pandas DataFrame into the model.':'返回将熊猫数据帧馈送到模型中的输入函数。',
'Public API for tf.estimator.tpu namespace.':'tf.estimator.tpu命名空间的公共api。',
'## Class InputPipelineConfig':'## 类inputpipelineconfig',
'Please see the definition of these values in TPUConfig.':'请参阅tpuconfig中这些值的定义。',
'## Class RunConfig':'## 类runconfig',
'RunConfig with TPU support.':'支持tpu的runconfig。',
'Constructs a RunConfig.':'构造runconfig。',
'### cluster':'### 集群',
'The global id in the training cluster.':'训练群集中的全局ID。',
#'  worker     | 1        |  2':'工人1 2',
#'  worker     | 2        |  3':'工人2 3',
#'  ps         | 1        |  5':'PS 1 5',
'An integer id.':'整数id。',
'### master':'### 主人',
'### protocol':'### 协议',
'Returns the optional protocol value.':'返回可选协议值。',
'### service':'### 服务',
'Returns a new instance of RunConfig replacing specified properties.':'返回替换指定属性的runconfig的新实例。',
'Only the properties in the following list are allowed to be replaced:':'仅允许替换以下列表中的属性：',
'a new instance of RunConfig.':'runconfig的新实例。',
'## Class TPUConfig':'##TPUConfig类',
'TPU related configuration required by TPUEstimator.':'TPUestimator所需的TPU相关配置。',
'## Class TPUEstimator':'##TPuestimator类',
'Estimator with TPU support.':'有TPU支持的估计器。',
'#### Current limitations:':'#### 当前限制：',
'## Example (MNIST):':'## 示例（mnist）：',
'There are two versions of the API: ExportSavedModelApiVersion.V1 and V2.':'api有两个版本：exportsavedmodelapiversion.v1和v2。',
'Constructs an TPUEstimator instance.':'构造一个tpuestimator实例。',
'## Class TPUEstimatorSpec':'##TPuestimatorSpec类',
'Creates a validated TPUEstimatorSpec instance.':'创建已验证的tpuestimatorspec实例。',
'### predictions':'### 预测',
'### loss':'### 损失',
'Creates an equivalent EstimatorSpec used by CPU train/eval.':'创建CPU训练/评估使用的等效估计器规范。',
'Public API for tf.estimator.tpu.experimental namespace.':'tf.estimator.tpu.实验命名空间的公共api。',
'## Class EmbeddingConfigSpec':'## 类嵌入配置规范',
'Class to keep track of the specification for TPU embeddings.':'类以跟踪TPU嵌入的规范。',
'Creates an EmbeddingConfigSpec instance.':'创建embeddingconfigspec实例。',
'An EmbeddingConfigSpec instance.':'embeddingconfigspec实例。',
'Public API for tf.experimental namespace.':'tf.experimental命名空间的公共api。',
'Whether to output all intermediates from functional control flow ops.':'是否从功能控制流操作输出所有中间产物。',
'A CategoricalColumn with a vocabulary file.':'带有词汇表文件的分类列。',
'And to make an embedding with either:':'并嵌入：',
'This function generates a weighted sum based on output dimension units. Weighted sum refers to logits in classification problems. It refers to the prediction itself for linear regression problems.':'此函数基于输出维度单位生成加权和。加权和是指分类问题中的对数。它是指线性回归问题的预测本身。',
'#### Example of usage:':'#### 用法示例：',
'"sum": do not normalize `features` in the column':'“sum”：不规范列中的“features”',
'"mean": do l1 normalization on `features` in the column':'“mean”：对列中的“features”进行l1规范化',
'"sqrtn": do l2 normalization on `features` in the column':'“sqrtn”：对列中的“features”进行二级规范化',
'#### Typical usage example:':'#### 典型用法示例：',
'Here is an example embedding of two features for a DNNClassifier model:':'下面是为dnnclassifier模型嵌入两个功能的示例：',
'Declares that all flags key to a module are key to the current module.':'声明模块的所有标志键都是当前模块的键。',
'Base class used to parse and convert arguments.':'用于分析和转换参数的基类。',
'Returns a string representing the type of the flag.':'返回表示标志类型的字符串。',
'### parse':'### 解析',
'Parses the string argument and returns the native value.':'分析字符串参数并返回本机值。',
'By default it returns its argument unmodified.':'默认情况下，它返回未修改的参数。',
'The parsed value in native type.':'本机类型中的已分析值。',
'## Class ArgumentSerializer':'## 类ArgumentSerializer',
'Base class for generating string representations of a flag value.':'用于生成标志值的字符串表示形式的基类。',
'### serialize':'### 序列化',
'Returns a serialized string of the value.':'返回值的序列化字符串。',
'Base class for a parser of lists of strings.':'字符串列表分析器的基类。',
'See base class.':'见基类。',
'Basic boolean flag.':'基本布尔标志。',
'Return self<value.':'返回self<value。',
'Returns a str that describes the type of the flag.':'返回描述标志类型的str。',
'Parses string and sets flag value.':'分析字符串并设置标志值。',
'Serializes the flag.':'序列化标志。',
'### unparse':'### 解开',
'## Class BooleanParser':'## 类布尔分析器',
'Parser of boolean values.':'布尔值分析器。',
'Raised when flagfile fails to open.':'当flagfile无法打开时引发。',
'Serializes a list as a CSV string or unicode.':'将列表序列化为CSV字符串或Unicode。',
'Declares one flag as key to the current module.':'将一个标志声明为当前模块的键。',
'#### Sample usage:':'#### 示例用法：',
'Registers a generic Flag object.':'注册泛型标志对象。',
'Defines an alias flag for an existing one.':'定义现有别名标志。',
'Registers a boolean flag.':'注册布尔标志。',
'Registers a flag whose value can be the name of enum members.':'注册一个标志，其值可以是枚举成员的名称。',
'Registers a \'Flag\' object with a \'FlagValues\' object.':'用“flagValues”对象注册“flag”对象。',
'Registers a flag whose value must be a float.':'注册一个标志，其值必须是浮点数。',
'Registers a flag whose value must be an integer.':'注册一个标志，其值必须是整数。',
'The flag value is parsed with a CSV parser.':'标志值由csv解析器解析。',
'Registers a generic MultiFlag that parses its args with a given parser.':'注册一个通用的多重标记，用给定的解析器解析其参数。',
'Auxiliary function. Normal users should NOT use it directly.':'辅助功能。普通用户不应直接使用。',
'Developers who need to create their own \'Parser\' classes for options which can appear multiple times can call this module function to register their flags.':'需要为可能多次出现的选项创建自己的“解析器”类的开发人员可以调用此模块函数来注册其标志。',
'Use the flag on the command line multiple times to place multiple enum values into the list.':'多次使用命令行上的标志将多个枚举值放入列表中。',
'Registers a flag whose value can be a list of arbitrary floats.':'注册一个标志，其值可以是任意浮点数的列表。',
'Registers a flag whose value can be a list of arbitrary integers.':'注册一个标志，其值可以是任意整数的列表。',
'Registers a flag whose value can be a list of any strings.':'注册一个标志，其值可以是任何字符串的列表。',
'Any whitespace can be used as a separator.':'任何空格都可以用作分隔符。',
'Registers a flag whose value can be any string.':'注册一个标志，其值可以是任何字符串。',
'Declares that the current module will not define any more key flags.':'声明当前模块将不再定义任何键标志。',
'Takes a doc string and reformats it as help.':'获取文档字符串并将其重新格式化为帮助。',
'Raised if there is a flag naming conflict.':'如果存在标志命名冲突，则引发。',
'Creates a DuplicateFlagError by providing flag name and values.':'通过提供标志名称和值创建重复的鞭毛错误。',
'An instance of DuplicateFlagError.':'重复鞭毛错误的实例。',
'## Class EnumClassFlag':'## 类EnumClassFlag',
'Basic enum flag; its value is an enum class\'s member.':'基本枚举标志；其值是枚举类的成员。',
'Parser of an Enum class member.':'枚举类成员的分析器。',
'Initializes EnumParser.':'初始化枚举分析器。',
'Determines validity of argument and returns the correct element of enum.':'确定参数的有效性并返回枚举的正确元素。',
'The first matching Enum class member in Enum class.':'枚举类中第一个匹配的枚举类成员。',
'Parser of a string enum value (a string value from a given set).':'字符串枚举值（给定集合中的字符串值）的分析器。',
'The base class for all flags errors.':'所有标志错误的基类。',
'## Class Flag':'## Class 标志',
'Raised when a flag name conflicts with FlagValues methods.':'当标志名称与标志值方法冲突时引发。',
'## Class FlagValues':'## 类标志值',
'Registry of \'Flag\' objects.':'“标记”对象的注册表。',
'This class is heavily overloaded:':'该类重载严重：',
'The str() operator of a \'FlagValues\' object provides help for all of the registered \'Flag\' objects.':'“flagValues”对象的str（）运算符为所有注册的“flag”对象提供帮助。',
'Parses flags from argv; stores parsed flags into this FlagValues object.':'分析argv中的标志；将已分析的标志存储到此FlagValues对象中。',
'All unparsed arguments are returned.':'将返回所有未分析的参数。',
'Returns True if name is a value (flag) in the dict.':'如果name是dict中的值（标志），则返回true。',
'Appends flags registered in another FlagValues instance.':'追加在另一个FlagValues实例中注册的标志。',
'Appends all flags assignments from this FlagInfo object to a file.':'将此flaginfo对象中的所有标志分配附加到文件。',
'Output will be in the format of a flagfile.':'输出将采用标记文件的格式。',
'NOTE: MUST mirror the behavior of the C++ AppendFlagsIntoFile from https://github.com/gflags/gflags.':'注意：必须镜像来自https://github.com/gflags/gflags的c++appendflagsintofile的行为。',
'Returns a dictionary that maps flag names to flag values.':'返回将标志名称映射到标志值的字典。',
'A dictionary. Its keys are module names (strings). Its values are lists of Flag objects.':'一本字典。它的键是模块名（字符串）。它的值是标志对象的列表。',
'A dictionary. Its keys are module IDs (ints). Its values are lists of Flag objects.':'一本字典。它的键是模块id（ints）。它的值是标志对象的列表。',
'Returns a string with the flags assignments from this FlagValues object.':'返回具有来自此FlagValues对象的标志分配的字符串。',
'This function ignores flags whose value is None. Each flag assignment is separated by a newline.':'此函数忽略值为“无”的标志。每个标志分配都由换行符分隔。',
'NOTE: MUST mirror the behavior of the C++ CommandlineFlagsIntoString from https://github.com/gflags/gflags.':'注意：必须镜像来自https://github.com/gflags/gflags的C++命令行标记的行为。',
'Returns the value of a flag (if not None) or a default value.':'返回标志值（如果不是无）或默认值。',
'Requested flag value or default.':'请求的标志值或默认值。',
'Returns a help string for all known flags.':'返回所有已知标志的帮助字符串。',
'Returns the list of key flags for a module.':'返回模块的键标志列表。',
'Returns whether flags were parsed.':'返回是否分析了标志。',
'Describes the key flags of the main module.':'描述主模块的键标志。',
'Explicitly marks flags as parsed.':'显式地将标志标记为已分析。',
'Use this when the caller knows that this FlagValues has been parsed as if a call() invocation has happened. This is only a public method for use by things like appcommands which do additional command like parsing.':'当调用方知道此标志值已被解析为调用（）时，使用此选项。这只是一个公共方法，供appcommands等执行附加命令（如解析）的对象使用。',
'Describes the key flags of a module.':'描述模块的键标志。',
'A new list which has the original list combined with what we read from any flagfile(s).':'一个新列表，其中包含原始列表和我们从任何标记文件中读取的内容。',
#'    flag':'旗帜',
'Records the module that defines a specific flag.':'记录定义特定标志的模块。',
'We keep track of which flag is defined by which module so that we can later sort the flags by module.':'我们跟踪由哪个模块定义的标志，以便以后可以按模块对标志进行排序。',
'Specifies that a flag is a key flag for a module.':'指定标志是模块的键标志。',
'Remove flags that were previously appended from another FlagValues.':'删除以前从另一个标志值附加的标志。',
'Changes the default value of the named flag object.':'更改命名标志对象的默认值。',
'Sets whether or not to use GNU style scanning.':'设置是否使用GNU样式扫描。',
'Unparses all flags to the point before any FLAGS(argv) was called.':'在调用任何标志（argv）之前，断开所有标志的连接。',
'Outputs flag documentation in XML format.':'以XML格式输出标记文档。',
'Convert a dict of values into process call parameters.':'将一组值转换为进程调用参数。',
'This method is used to convert a dictionary into a sequence of parameters for a binary that parses arguments using this module.':'此方法用于将字典转换为使用此模块解析参数的二进制文件的参数序列。',
'Everything else is converted to string an passed as such.':'其他所有内容都转换为字符串。',
'sequence of string suitable for a subprocess execution.':'适合子进程执行的字符串序列。',
'Parser of floating point values.':'浮点值分析器。',
'Parsed value may be bounded to a given upper and lower bound.':'解析后的值可以限定为给定的上下限。',
'### convert':'### 转换',
'Returns the float value of argument.':'返回参数的浮点值。',
'Returns whether the value is outside the bounds or not.':'返回值是否在边界之外。',
'Returns the integer width of help lines that is used in TextWrap.':'返回文本包装中使用的帮助行的整数宽度。',
'Raised when the flag command line argument is illegal.':'当标志命令行参数非法时引发。',
'Parser of an integer value.':'整数值的分析器。',
'Returns the int value of argument.':'返回参数的int值。',
'## Class ListParser':'## 类列表分析器',
'Ensures that flags are not None during program execution.':'确保在程序执行期间标志不是“无”。',
'#### Recommended usage:':'#### 推荐用法：',
'Ensures that flag is not None during program execution.':'确保在程序执行期间标志不是none。',
'It is recommended to call this method like this:':'建议这样调用此方法：',
'Parses one or more arguments with the installed parser.':'使用安装的分析器分析一个或多个参数。',
'See the doc for Flag for most behavior of this class. Only differences in behavior are described here:':'有关此类的大多数行为，请参见doc for标志。此处仅描述行为差异：',
'A function decorator that registers its function argument as a validator.':'将其函数参数注册为验证器的函数装饰器。',
'Adds a constraint to multiple flags.':'向多个标志添加约束。',
'Wraps a given text to a maximum line length and returns it.':'将给定文本包装为最大行长度并返回它。',
'Raised when accessing the flag value from unparsed FlagValues.':'从未分析的标志值访问标志值时引发。',
'## Class UnrecognizedFlagError':'## 类无法识别的标记错误',
'Raised when a flag is unrecognized.':'当无法识别标志时引发。',
'Raised when flag validator constraint is not satisfied.':'不满足标志验证器约束时引发。',
'A function decorator for defining a flag validator.':'用于定义标志验证器的函数装饰器。',
'Initializer.':'初始值设定项。',
'Base TFDecorator class and utility functions for working with decorators.':'用于处理装饰器的基本tfdecorator类和实用程序函数。',
'Make a decorator from a wrapper and a target.':'从包装器和目标生成装饰器。',
'## Class TFDecorator':'## 类tfdecorator',
'Base class for all TensorFlow decorators.':'所有TensorFlow装饰程序的基类。',
'Call self as a function.':'作为函数调用self。',
'Unwraps an object into a list of TFDecorators and a final target.':'将对象展开到tfdecorators和最终目标的列表中。',
'Functions used to extract and analyze stacks. Faster than Python libs.':'用于提取和分析堆栈的函数。比python libs快。',
'## Class CurrentModuleFilter':'## 类电流模块滤波器',
'Filters stack frames from the module where this is used (best effort).':'从使用此功能的模块中筛选堆栈帧（尽最大努力）。',
'A list of FileAndLine objects corresponding to the call stack of the current thread.':'与当前线程的调用堆栈相对应的文件和行对象的列表。',
'## Class FileAndLine':'## 类文件行',
#'    line':'线',
'### file':'### 文件',
'### line':'### 生产线',
'## Class StackTraceFilter':'##StackTraceFilter类',
'Allows filtering traceback information by removing superfluous frames.':'允许通过删除多余的帧来过滤回溯信息。',
'## Class StackTraceMapper':'##StackTraceMapper类',
'Allows remapping traceback information to different source code.':'允许将回溯信息重新映射到不同的源代码。',
'## Class StackTraceTransform':'##StackTraceTransform类',
'Base class for stack trace transformation functions.':'堆栈跟踪转换函数的基类。',
'Copies data from oldpath to newpath.':'将数据从oldpath复制到newpath。',
'Deletes everything under dirname recursively.':'递归删除dirname下的所有内容。',
'Determines whether a path exists or not.':'确定路径是否存在。',
'## Class FastGFile':'## 类快速文件',
'File I/O wrappers without thread locking.':'无线程锁定的文件I/O包装器。',
'Returns the mode in which the file was opened.':'返回打开文件的模式。',
'Returns the file name.':'返回文件名。',
'Make usable with "with" statement.':'使用“with”语句。',
'Closes FileIO. Should be called for the WritableFile to be flushed.':'关闭文件IO。应该调用以刷新可写文件。',
'### flush':'### 冲洗',
'Flushes the Writable file.':'刷新可写文件。',
'This only ensures that the data has made its way out of the process without any guarantees on whether it\'s written to disk. This means that the data would survive an application crash but not necessarily an OS crash.':'这只会确保数据已经离开进程，而不保证是否写入磁盘。这意味着数据可以在应用程序崩溃时存活，但不一定是操作系统崩溃。',
'### next':'### 下一个',
'Returns the contents of a file as a string.':'以字符串形式返回文件的内容。',
'Starts reading from current position in file.':'开始读取文件中的当前位置。',
'### readline':'### 阅读线',
'### readlines':'### 阅读线',
'Returns all lines from the file in a list.':'返回列表中文件的所有行。',
'### seek':'### 寻找',
'### seekable':'### 看似',
'Returns the size of the file.':'返回文件的大小。',
'### tell':'### 告诉',
'Returns the current position in the file.':'返回文件中的当前位置。',
'Returns a list of files that match the given pattern(s).':'返回与给定模式匹配的文件列表。',
'A list of strings containing filenames that match the given pattern(s).':'包含与给定模式匹配的文件名的字符串列表。',
'Returns whether the path is a directory or not.':'返回路径是否为目录。',
'Returns a list of entries contained within a directory.':'返回目录中包含的条目列表。',
'The list is in arbitrary order. It does not contain the special entries "." and "..".':'列表是任意顺序的。它不包含特殊条目“.”和“..”。',
'errors.NotFoundError if directory doesn\'t exist':'errors.notfounderror如果目录不存在',
'Creates a directory and all parent/intermediate directories.':'创建一个目录和所有父/中间目录。',
'It succeeds if dirname already exists and is writable.':'如果dirname已经存在并且是可写的，它将成功。',
'Creates a directory with the name \'dirname\'.':'创建名为“dirname”的目录。',
'Deletes the file located at \'filename\'.':'删除位于“filename”的文件。',
'Rename or move a file / directory.':'重命名或移动文件/目录。',
'Returns file statistics for a given path.':'返回给定路径的文件统计信息。',
'FileStatistics struct that contains information about the path':'包含路径信息的文件统计结构',
'Recursive directory tree generator for directories.':'目录的递归目录树生成器。',
'Helpers to manipulate a tensor graph in python.':'在python中操作张量图的帮助程序。',
'GraphDef containing a simplified version of the original.':'包含原始版本的简化版本的graphdef。',
'A list of nodes with the unnecessary ones removed.':'删除了不必要节点的节点列表。',
'Image processing and decoding ops.':'图像处理和解码操作。',
'Extracts crops from the input image tensor and resizes them.':'从输入图像张量中提取作物并调整其大小。',
'Draw bounding boxes on a batch of images.':'在一批图像上绘制边界框。',
'Parts of the bounding box may fall outside the image.':'边界框的某些部分可能落在图像之外。',
'Extracts a glimpse from the input tensor.':'从输入张量中提取一瞥。',
'The argument normalized and centered controls how the windows are built:':'参数normalized和centered控制如何构建窗口：',
'#### Usage Example:':'#### 用法示例：',
'Resize images to size using the specified method.':'使用指定的方法调整图像的大小。',
'## Class ResizeMethod':'## 类resizemethod',
'Resize images to size using area interpolation.':'使用区域插值调整图像大小。',
'Input images can be of different types but output images are always float.':'输入图像可以是不同类型的，但输出图像总是浮动的。',
'Resizes and pads an image to a target width and height.':'调整图像大小并将其填充到目标宽度和高度。',
'Public API for tf.initializers namespace.':'tf.initializers命名空间的公共api。',
'Public API for tf.io namespace.':'tf.io命名空间的公共api。',
'## Class TFRecordCompressionType':'## 类tfrecordcompressiontype',
'The type of compression for the record.':'记录的压缩类型。',
'Strings.':'串。',
'Public API for tf.io.gfile namespace.':'tf.io.gfile命名空间的公共API。',
'DenseNet models for Keras.':'Densenet Keras模型。',
'Utilities for ImageNet data preprocessing & prediction decoding.':'ImageNet数据预处理和预测解码实用程序。',
'Inception V3 model for Keras.':'用于Keras的Inception V3模型。',
'MobileNet v1 models for Keras.':'用于Keras的Mobilenet v1型号。',
'MobileNet v2 models for Keras.':'用于Keras的Mobilenet V2型号。',
'Xception V1 model for Keras.':'Keras的例外v1模型。',
'Keras backend API.':'Keras后端API。',
'Returns the TF session to be used by the backend.':'返回要由后端使用的tf会话。',
'If no global Keras session exists at this point: we will create a new global session.':'如果此时不存在全局keras会话：我们将创建一个新的全局会话。',
'A TensorFlow session.':'Tensorflow 会话。',
'Sets the global TensorFlow session.':'设置全局TensorFlow会话。',
'Callbacks: utilities called at certain points during model training.':'回调：模型训练期间在某些点调用的实用程序。',
'## Class TensorBoard':'## 类张力板',
'Enable visualizations for TensorBoard.':'启用TensorBoard的可视化。',
'TensorBoard is a visualization tool provided with TensorFlow.':'TensorBoard是TensorFlow提供的可视化工具。',
'Writes scalar summaries for metrics on every training batch.':'为每个培训批次的指标编写标量摘要。',
'Called at the beginning of a batch in predict methods.':'在预测方法的批处理开始时调用。',
'Subclasses should override for any actions to run.':'子类应该重写以运行任何操作。',
'Called at the end of a batch in predict methods.':'在预测方法中在批处理结束时调用。',
'Called at the beginning of prediction.':'在预测开始时调用。',
'Called at the end of prediction.':'在预测结束时调用。',
'Called at the beginning of a batch in evaluate methods.':'在求值方法的批处理开始时调用。',
'Called at the end of a batch in evaluate methods.':'在求值方法的批处理结束时调用。',
'Called at the beginning of evaluation or validation.':'在评估或验证开始时调用。',
'Called at the end of evaluation or validation.':'在评估或验证结束时调用。',
'Called at the beginning of a training batch in fit methods.':'在Fit方法的训练批开始时调用。',
'Called at the end of a training batch in fit methods.':'在Fit方法的训练批结束时调用。',
'Called at the beginning of training.':'在训练开始时打电话来。',
'Called at the end of training.':'训练结束时打电话来。',
'Sets Keras model and creates summary ops.':'设置Keras模型并创建摘要操作。',
'Constraints: functions that impose constraints on weight values.':'约束：对权重值施加约束的函数。',
'Boston housing price regression dataset.':'波士顿房价回归数据集。',
'IMDB sentiment classification dataset.':'情绪分类数据集。',
'MNIST handwritten digits dataset.':'mnist手写数字数据集。',
'Reuters topic classification dataset.':'路透社主题分类数据集。',
'Keras estimator API.':'Keras估计器API。',
'Constructs an Estimator instance from given keras model.':'从给定的keras模型构造一个估计实例。',
'An Estimator from given keras model.':'来自给定keras模型的估计量。',
'Public API for tf.keras.experimental namespace.':'tf.keras.experimental命名空间的公共api。',
'Keras initializer serialization / deserialization.':'Keras初始值设定项序列化/反序列化。',
'## Class Constant':'## 类常量',
'He normal initializer.':'他是正常的初始化程序。',
'An initializer.':'初始值设定项。',
'He uniform variance scaling initializer.':'均匀方差标度初始值设定项。',
'## Class Identity':'## 阶级认同',
'Initializer that generates the identity matrix.':'生成标识矩阵的初始值设定项。',
'Only use for 2D matrices.':'仅用于二维矩阵。',
'## Class Initializer':'## 类初始值设定项',
'Initializer base class: all initializers inherit from this class.':'初始化器基类：所有初始化器都继承自该类。',
'LeCun normal initializer.':'Lecun标准初始值设定项。',
'LeCun uniform initializer.':'Lecun统一初始值设定项。',
'## Class Ones':'## 一级',
'## Class Orthogonal':'## 类正交',
'Initializer that generates an orthogonal matrix.':'生成正交矩阵的初始值设定项。',
'## Class RandomNormal':'## 类随机正规',
'RandomNormal instance.':'随机正常实例。',
'## Class RandomUniform':'## 类随机均匀',
'A RandomUniform instance.':'随机均匀的例子。',
'## Class TruncatedNormal':'## 类截断正常',
'A TruncatedNormal instance.':'截断的普通实例。',
'## Class VarianceScaling':'## 类别差异校准',
'Initializer capable of adapting its scale to the shape of weights tensors.':'初始值设定项能够调整其比例以适应权重张量的形状。',
'## Class Zeros':'## 类零',
'Keras layers API.':'Keras层API。',
'## Class BatchNormalization':'## 类批处理规范化',
'#### Call arguments:':'#### 调用参数：',
'#### Input shape:':'#### 输入形状：',
'#### Output shape:':'#### 输出形状：',
'Same shape as input.':'与输入形状相同。',
'## Class CuDNNGRU':'##Cudnngru类',
'Fast GRU implementation backed by cuDNN.':'由cudnn支持的快速gru实现。',
'### cell':'### 细胞',
'### states':'### 国家',
'## Class CuDNNLSTM':'##Cudnnlstm类',
'Fast LSTM implementation backed by cuDNN.':'由cudnn支持的快速lstm实现。',
'## Class DenseFeatures':'## 类DenseFeatures',
'This layer can be called multiple times with different features.':'这个层可以用不同的特性多次调用。',
'Constructs a DenseFeatures layer.':'构造DenseFeatures层。',
'### activation':'### 激活',
'### dropout':'### 辍学',
'### implementation':'### 实施',
'### units':'### 单位',
'## Class GRUCell':'## 格鲁塞尔类',
'Cell class for the GRU layer.':'GRU层的单元格类。',
'Get the dropout mask for RNN cell\'s input.':'获取RNN单元输入的退出掩码。',
'Get the recurrent dropout mask for RNN cell.':'获取RNN细胞的复发性脱落面具。',
'Reset the cached dropout masks if any.':'重置缓存的退出掩码（如果有）。',
'Reset the cached recurrent dropout masks if any.':'如果存在，则重置缓存的重复退出掩码。',
'## Class LSTM':'##LSTM级',
'## Class LSTMCell':'##lstmcell类',
'Cell class for the LSTM layer.':'LSTM层的单元格类。',
'Public API for tf.keras.optimizers.schedules namespace.':'tf.keras.optimizers.schedules命名空间的公共API。',
'Keras data preprocessing utils.':'Keras数据预处理实用程序。',
'Utilities for preprocessing sequence data.':'用于预处理序列数据的实用程序。',
'Utilities for text input preprocessing.':'文本输入预处理实用程序。',
'Keras utilities.':'凯拉斯公用事业公司。',
'Public API for tf.layers namespace.':'tf.layers命名空间的公共api。',
'## Class AveragePooling1D':'## 类平均池1d',
'Average Pooling layer for 1D inputs.':'1D输入的平均池层。',
'Average pooling layer for 2D inputs (e.g. images).':'二维输入（如图像）的平均池层。',
'## Class AveragePooling3D':'## 类平均池3d',
'Average pooling layer for 3D inputs (e.g. volumes).':'3D输入的平均池层（如卷）。',
'Output tensor.':'输出张量。',
'"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"':'“批量规范化：通过减少内部协变量变化加快深度网络训练”',
'## Class Conv1D':'##Conv1D级',
'## Class Conv2D':'##Conv2d类',
'## Class Conv2DTranspose':'##Conv2Transpose类',
'Transposed 2D convolution layer (sometimes called 2D Deconvolution).':'转置二维卷积层（有时称为二维反卷积）。',
'## Class Conv3D':'##Conv3D类',
'## Class Conv3DTranspose':'##Conv3dTranspose类',
'Transposed 3D convolution layer (sometimes called 3D Deconvolution).':'转置三维卷积层（有时称为三维反卷积）。',
'## Class Dense':'## 类密集',
'#### Properties:':'#### 属性：',
'## Class Dropout':'## 辍学',
'Applies Dropout to the input.':'对输入应用辍学。',
'## Class Flatten':'## 类扁平化',
'## Class Layer':'## 类层',
'Base layer class.':'基本层类。',
'#### Mutable properties:':'#### 可变属性：',
'## Class MaxPooling1D':'## 类MaxPooling1d',
'Max Pooling layer for 1D inputs.':'1D输入的最大池层。',
'## Class MaxPooling2D':'## 类maxpooling2d',
'Max pooling layer for 2D inputs (e.g. images).':'二维输入（如图像）的最大池层。',
'## Class MaxPooling3D':'## 类MaxPooling3D',
'Max pooling layer for 3D inputs (e.g. volumes).':'3D输入的最大池层（如卷）。',
'volumes).':'卷）。',
'## Class SeparableConv1D':'##SeparableConv1d类',
'Depthwise separable 1D convolution.':'可分离的一维反褶积。',
'## Class SeparableConv2D':'##SeparableConv2D类',
'Depthwise separable 2D convolution.':'可分离二维卷积。',
'Public API for tf.layers.experimental namespace.':'tf.layers.experimental命名空间的公共api。',
'The purpose of this scope is to allow users of existing layers to slowly transition to a Keras layers API without breaking existing functionality.':'此作用域的目的是允许现有层的用户在不破坏现有功能的情况下缓慢过渡到keras layers api。',
'A keras layer style scope.':'路缘石图层样式范围。',
'The purpose of this function is to allow users of existing layers to slowly transition to Keras layers API without breaking existing functionality.':'此函数的目的是允许现有层的用户在不破坏现有功能的情况下缓慢过渡到keras layers api。',
'Operations for linear algebra.':'线性代数的运算。',
'A Tensor with the same shape as x.':'与x形状相同的张量。',
'Public API for tf.lite namespace.':'tf.lite命名空间的公共api。',
'## Class OpHint':'## 蛇形纲',
'A class that helps build tflite function invocations.':'帮助构建tflite函数调用的类。',
'Create a OpHint.':'创造一个蛇夫。',
'Add a wrapped input argument to the hint.':'向提示中添加包装输入参数。',
'The wrapped input tensor.':'包装输入张量。',
'Add a sequence of inputs to the function invocation.':'向函数调用添加一系列输入。',
'Wrapped inputs (identity standins that have additional metadata). These are also are also tf.Tensor\'s.':'包装输入（具有附加元数据的标识标准）。这些也是tf。张量。',
'Add a wrapped output argument to the hint.':'向提示中添加包装输出参数。',
'The wrapped output tensor.':'包装输出张量。',
'Add a sequence of outputs to the function invocation.':'向函数调用添加一系列输出。',
'Wrapped outputs (identity standins that have additional metadata). These are also tf.Tensor\'s.':'包装输出（具有附加元数据的标识标准）。这些也是tf。张量的。',
'## Class OpHintArgumentTracker':'## 类OphinTargumentTracker',
'Conceptually tracks indices of arguments of "OpHint functions".':'概念上跟踪“ophint函数”参数的索引。',
'The inputs and arguments of these functions both use an instance of the class so they can have independent numbering.':'这些函数的输入和参数都使用类的实例，因此它们可以有独立的编号。',
'Initialize ophint argument.':'初始化ophint参数。',
'### add':'### 添加',
'Return a wrapped tensor of an input tensor as an argument.':'返回输入张量的换行张量作为参数。',
'A tensor representing the wrapped argument.':'表示包装参数的张量。',
'## Class TFLiteConverter':'## 类tflitecoverter',
'Constructor for TFLiteConverter.':'tflitecoverter的构造函数。',
'Converts a TensorFlow GraphDef based on instance variables.':'基于实例变量转换tensorflow graphdef。',
'Creates a TFLiteConverter class from a file containing a frozen GraphDef.':'从包含冻结graphdef的文件创建tflitecoverter类。',
'TFLiteConverter class.':'TFLiteConverter类。',
'Creates a TFLiteConverter class from a tf.keras model file.':'从tf.keras模型文件创建tflitecoverter类。',
'Creates a TFLiteConverter class from a SavedModel.':'从savedModel创建tfLiteConverter类。',
'Creates a TFLiteConverter class from a TensorFlow Session.':'从tensorflow会话创建tflitecoverter类。',
'Returns a list of the names of the input tensors.':'返回输入张量的名称列表。',
'List of strings.':'字符串列表。',
'## Class TocoConverter':'## 类ToCoConverter',
'This class has been deprecated. Please use lite.TFLiteConverter instead.':'这个类已被弃用。请改用lite.tflitecoverter。',
'Public API for tf.lite.constants namespace.':'tf.lite.constants命名空间的公共API。',
'Public API for tf.lite.experimental namespace.':'tf.lite.experimental命名空间的公共api。',
'Converts a graphdef with LiteOp hints into stub operations.':'将带有liteop提示的graphdef转换为存根操作。',
'A new graphdef with all ops contained in OpHints being replaced by a single op call with the right parameters.':'一个新的graphdef，ophints中包含的所有操作都被一个具有正确参数的操作调用所替换。',
'Returns operations potentially supported by TensorFlow Lite.':'返回TensorFlow Lite可能支持的操作。',
'A list of SupportedOp.':'支持的名单。',
'Public API for tf.lite.experimental.nn namespace.':'tf.lite.experimental.nn命名空间的公共API。',
'Creates a recurrent neural network specified by RNNCell cell.':'创建由rnncell cell指定的递归神经网络。',
'Performs fully dynamic unrolling of inputs.':'执行输入的完全动态展开。',
'## Class TFLiteLSTMCell':'##Tflitelstmcell类',
'The peephole implementation is based on:':'窥视孔的实现基于：',
'Initialize the parameters for an LSTM cell.':'初始化lstm单元的参数。',
'Integer or TensorShape: size of outputs produced by this cell.':'整数或张量形状：此单元格生成的输出大小。',
'size(s) of state(s) used by this cell.':'此单元格使用的状态大小。',
'## Class TfLiteRNNCell':'##Tfliternncell类',
'The most basic RNN cell.':'最基本的RNN细胞。',
'Initializes the parameters for an RNN cell.':'初始化RNN单元的参数。',
'Logging and Summary Operations.':'日志和摘要操作。',
'Return how much logging output will be produced.':'返回将生成多少日志输出。',
'Log \'msg % args\' at level \'level\' once per \'n\' times.':'在“level”级别每“n”次记录一次“msg%args”。',
'Log \'msg % args\' at level \'level\' only first \'n\' times.':'仅在“level”级别记录“msg%args”前“n”次。',
'Not threadsafe.':'不是线程安全的。',
'Log \'msg % args\' at level \'level\' only if condition is fulfilled.':'仅当条件满足时，才在“level”级别记录“msg%args”。',
'Sets the threshold for what messages will be logged.':'设置将记录哪些消息的阈值。',
'Public API for tf.lookup namespace.':'tf.lookup命名空间的公共api。',
'## Class StaticHashTable':'## 类statichashtable',
'A generic hash table that is immutable once initialized.':'初始化后不可变的通用哈希表。',
'A HashTable object.':'哈希表对象。',
'The default value of the table.':'表的默认值。',
'The table key dtype.':'表键dtype。',
'The name of the table.':'表的名称。',
'Returns the resource handle associated with this Resource.':'返回与此资源关联的资源句柄。',
'The table value dtype.':'表值dtype。',
'### export':'### 出口',
'Returns tensors of all keys and values in the table.':'返回表中所有键和值的张量。',
'A pair of tensors with the first tensor containing all keys and the second tensors containing all values in the table.':'一对张量，第一张量包含所有键，第二张量包含表中所有值。',
'### lookup':'### 查找',
'Compute the number of elements in this table.':'计算此表中的元素数。',
'A scalar tensor containing the number of elements in this table.':'包含此表中元素数的标量张量。',
'## Class StaticVocabularyTable':'## 类静态词汇表',
'The Vocabulary object will performs the following mapping:':'词汇表对象将执行以下映射：',
'Construct a StaticVocabularyTable object.':'构造一个静态词汇表对象。',
'Public API for tf.lookup.experimental namespace.':'tf.lookup.experimental命名空间的公共API。',
'Loss operations for use in neural networks.':'神经网络中使用的损失操作。',
'Adds an Absolute Difference loss to the training procedure.':'将绝对差异损失添加到训练过程中。',
'Adds a externally defined loss to the collection of losses.':'将外部定义的损失添加到损失集合。',
'Computes the weighted loss.':'计算加权损失。',
'#### Note:':'#### 注：',
'a list of loss tensors.':'损失张量的列表。',
'Gets the total regularization loss.':'获取总正则化损失。',
'A scalar regularization loss.':'标量正则化损失。',
'Gets the list of regularization losses.':'获取正则化丢失的列表。',
'A list of regularization losses as Tensors.':'作为张量的正则化损失列表。',
'Returns a tensor whose value represents the total loss.':'返回一个张量，其值表示总损耗。',
'A Tensor whose value represents the total loss.':'其值代表全部损失的张量。',
'Adds a hinge loss to the training procedure.':'将铰链损失添加到训练过程中。',
'Adds a Huber Loss term to the training procedure.':'在训练过程中添加Huber损失项。',
'Adds a Log Loss term to the training procedure.':'将日志丢失项添加到培训过程中。',
'A scalar Tensor that returns the weighted loss.':'返回加权损失的标量张量。',
'## Class Reduction':'## 等级缩减',
'Types of loss reduction.':'减少损失的类型。',
'Contains the following values:':'包含以下值：',
'### all':'### 全部',
'### validate':'### 验证',
#'    key':'钥匙',
'Operators for manipulating tensors.':'操纵张量的算符。',
'Math Operations.':'数学运算。',
'TensorFlow provides a variety of math functions including:':'TensorFlow提供多种数学函数，包括：',
'## About Segmentation':'## 关于分段',
'Says whether the targets are in the top K predictions.':'表示目标是否在前k个预测中。',
'A Tensor of type bool. Computed Precision at k as a bool Tensor.':'布尔型张量。作为布尔张量计算k的精度。',
'For each batch i and class j we have':'每批I和J类',
'A Tensor. Has the same type as logits. Same shape as logits.':'张量与登录类型相同。与logits形状相同。',
'This function performs the equivalent of':'此函数执行与',
'A Tensor. Has the same type and shape as logits.':'张量具有与logits相同的类型和形状。',
'Calculates how often predictions matches labels.':'计算预测与标签匹配的频率。',
'Computes the approximate AUC via a Riemann sum.':'通过黎曼和计算近似AUC。',
'Computes average precision@k of predictions with respect to sparse labels.':'计算与稀疏标签相关的预测的平均精度@k。',
'Computes the total number of false negatives.':'计算假阴性的总数。',
'Computes false negatives at provided threshold values.':'在提供的阈值处计算假阴性。',
'Sum the weights of false positives.':'对误报的权重求和。',
'Computes false positives at provided threshold values.':'在提供的阈值处计算假阳性。',
'Computes the (weighted) mean of the given values.':'计算给定值的（加权）平均值。',
'Computes the mean absolute error between the labels and predictions.':'计算标签和预测之间的平均绝对误差。',
'Computes the cosine distance between the labels and predictions.':'计算标签和预测之间的余弦距离。',
'Computes the mean relative error by normalizing with the given values.':'通过使用给定值进行规格化来计算平均相对误差。',
'Computes the mean squared error between the labels and predictions.':'计算标签和预测之间的均方误差。',
'Computes the percentage of values less than the given threshold.':'计算小于给定阈值的值的百分比。',
'Computes the precision of the predictions with respect to the labels.':'计算相对于标签的预测精度。',
'Computes precision@k of the predictions with respect to sparse labels.':'计算相对于稀疏标签的预测精度@k。',
'Computes precision values for different thresholds on predictions.':'计算不同预测阈值的精度值。',
'Computes the recall of the predictions with respect to the labels.':'计算与标签相关的预测的调用。',
'Computes recall@k of the predictions with respect to sparse labels.':'计算与稀疏标签相关的预测调用@k。',
'Computes various recall values for different thresholds on predictions.':'计算预测的不同阈值的各种回调值。',
'Computes the root mean squared error between the labels and predictions.':'计算标签和预测之间的均方根误差。',
'Computes the specificity at a given sensitivity.':'计算给定灵敏度下的特异性。',
'Computes true negatives at provided threshold values.':'在提供的阈值处计算真负数。',
'Computes true positives at provided threshold values.':'在提供的阈值处计算真正数。',
'Public API for tf.nest namespace.':'tf.nest命名空间的公共api。',
'Wrappers for primitive Neural Net (NN) Operations.':'原始神经网络（nn）操作的包装器。',
'Performs the average pooling on the input.':'对输入执行平均池。',
'Each entry in output is the mean of the corresponding size ksize window in value.':'输出中的每个条目都是值中相应大小ksize窗口的平均值。',
'A Tensor with the same type as value. The average pooled output tensor.':'与值类型相同的张量。平均池输出张量。',
'Batch normalization.':'批量标准化。',
'Computes the gradients of convolution with respect to the filter.':'计算与滤波器相关的卷积梯度。',
'Computes the gradients of convolution with respect to the input.':'计算卷积相对于输入的梯度。',
'A Tensor. Has the same type as filter.':'张量具有与筛选器相同的类型。',
'The transpose of conv2d.':'conv2d的转置。',
'A Tensor with the same type as value.':'与值类型相同的张量。',
'The transpose of conv3d.':'conv3d的转置。',
'a rank (N+2) filter Tensor of shape':'形状的秩（n+2）滤波张量',
#'                       q]':'问]',
'A Tensor with the same type as input of shape':'与形状输入类型相同的张量',
'Computes Concatenated ReLU.':'计算连接的relu。',
'A Tensor with the same type as features.':'与特征类型相同的张量。',
'Performs beam search decoding on the logits given in input.':'对输入中给定的登录执行波束搜索解码。',
'Computes the CTC (Connectionist Temporal Classification) Loss.':'计算CTC（连接主义时间分类）损失。',
'This op implements the CTC loss as presented in the article:':'此操作实现了文章中所述的CTC损失：',
'#### Input requirements:':'#### 输入要求：',
'Here is a table of the (roughly) expected first order behavior:':'下面是（大致）预期一阶行为的表：',
'Untested. Very likely will not learn to output repeated classes.':'未经测试。很可能不会学习输出重复的类。',
#'                      c] +':'C].+',
'A Tensor of the same shape of x.':'与x形状相同的张量。',
'Looks up ids in a list of embedding tensors.':'在嵌入张量的列表中查找id。',
'A Tensor with the same type as the tensors in params.':'与params中的张量类型相同的张量。',
'Computes embeddings for the given ids and weights.':'计算给定ID和权重的嵌入。',
'then':'然后',
'First we define the following:':'首先，我们定义如下：',
'Performs the max pooling on the input.':'对输入执行最大池。',
'Performs max pooling on the input and outputs both max values and indices.':'对输入执行最大池，并输出最大值和索引。',
'Calculate the mean and variance of x.':'计算x的均值和方差。',
'Two Tensor objects: mean and variance.':'两个张量对象：均值和方差。',
'Produces the average pool of the input tensor for quantized types.':'生成量化类型的输入张量的平均池。',
'Computes a 2D convolution given quantized 4D input and filter tensors.':'计算二维卷积给定的量化4d输入和滤波器张量。',
'Produces the max pool of the input tensor for quantized types.':'生成量化类型的输入张量的最大池。',
'while not all(finished):':'并非全部（完成）：',
'Computes and returns the sampled softmax training loss.':'计算并返回采样的SoftMax训练损失。',
'This is a faster way to train a softmax classifier over a huge number of classes.':'这是在大量类上训练softmax分类器的更快方法。',
'This operation is for training only. It is generally an underestimate of the full softmax loss.':'这项手术仅供训练之用。这通常低估了SoftMax的全部损失。',
'Computes sigmoid cross entropy given logits.':'计算给定logits下的sigmoid交叉熵。',
'logits and labels must have the same type and shape.':'登录和标签必须具有相同的类型和形状。',
'A Tensor of the same shape as logits with the componentwise logistic losses.':'具有成分逻辑损失的与logits形状相同的张量。',
'Future major versions of TensorFlow will allow gradients to flow into the labels input on backprop by default.':'TensorFlow未来的主要版本默认情况下允许渐变流到backprop上输入的标签中。',
'A Tensor that contains the softmax cross entropy loss. Its type is the same as logits and its shape is the same as labels except that it does not have the last dimension of labels.':'包含软最大交叉熵损失的张量。其类型与logits相同，其形状与labels相同，只是它没有标签的最后一个维度。',
'Computes sparse softmax cross entropy between logits and labels.':'计算登录和标签之间的稀疏SoftMax交叉熵。',
'A Tensor of the same shape as labels and of the same type as logits with the softmax cross entropy loss.':'一种与标号形状相同、与logits类型相同且具有softmax交叉熵损失的张量。',
'The simplest form of RNN network generated is:':'生成的RNN网络的最简单形式是：',
'Calculate the sufficient statistics for the mean and variance of x.':'计算x的均值和方差的充分统计量。',
'Four Tensor objects of the same type as x:':'与x类型相同的四个张量对象：',
'A Tensor of the same shape as logits with the componentwise weighted logistic losses.':'具有分量加权logistic损失的与logits形状相同的张量。',
'Module for constructing RNN Cells.':'用于构建RNN单元的模块。',
'## Class BasicLSTMCell':'## 类BasiclStmCell',
'Basic LSTM recurrent network cell.':'基本的LSTM递归网络单元。',
'## Class BasicRNNCell':'## 类basicrncell',
'Operator that ensures an RNNCell runs on a particular device.':'确保RNNCell在特定设备上运行的运算符。',
'Construct a DeviceWrapper for cell with device device.':'为具有设备设备的单元构造设备包装器。',
'## Class DropoutWrapper':'## 下课说唱歌手',
'Operator adding dropout to inputs and outputs of the given cell.':'运算符向给定单元格的输入和输出添加辍学。',
'Otherwise a different dropout mask is applied at every time step.':'否则，在每个时间步应用不同的退出掩码。',
'Gated Recurrent Unit cell (cf.':'门控复发单位细胞（cf.',
'## Class LSTMStateTuple':'## 类lstmstatetuple',
#'    h':'小时',
'### c':'###C类',
'### h':'### 小时',
'## Class MultiRNNCell':'## 多核类',
'RNN cell composed sequentially of multiple simple cells.':'RNN细胞由多个简单细胞组成。',
'## Class ResidualWrapper':'## 类剩余捕获器',
'RNNCell wrapper that ensures cell inputs are added to the outputs.':'RNNCell包装器，确保单元输入添加到输出。',
'Constructs a ResidualWrapper for cell.':'为cell构造一个residualwrapper。',
'## Class RNNCell':'##RNNCELL类',
'Abstract object representing an RNN cell.':'表示RNN单元格的抽象对象。',
'Public API for tf.profiler namespace.':'tf.profiler命名空间的公共API。',
'## Class AdviceProto':'## 类adviceproto',
'### checkers':'### 跳棋',
'repeated CheckersEntry checkers':'重复的支票条目支票',
'## Class Checker':'## 类检查器',
'### reports':'### 报告',
'repeated string reports':'重复字符串报告',
'## Class CheckersEntry':'## 类检查项',
'Checker value':'棋盘格值',
'Auto profile and advise.':'自动配置文件和建议。',
'Builds profiles and automatically check anomalies of various aspects. For more details: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/README.md':'构建配置文件并自动检查各个方面的异常。有关更多详细信息，请访问：https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/readme.md',
'Returns AdviceProto proto':'返回adviceproto proto',
'## Class GraphNodeProto':'##GraphnodeProto类',
'### children':'### 儿童',
'repeated GraphNodeProto children':'重复的Graphnodeproto子代',
'### devices':'### 设备',
'repeated string devices':'重复字符串设备',
'### shapes':'### 形状',
'repeated TensorShapeProto shapes':'重复张量图形',
'## Class InputShapesEntry':'## 类inputShapeEntry',
'TensorShapeProto value':'张量shapeproto值',
'## Class OpLogProto':'## 类oplogproto',
'## Class IdToStringEntry':'## 类idToStringentry',
'string value':'字符串值',
'Profile model.':'剖面模型。',
'Tutorials and examples can be found in: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/README.md':'教程和示例见：https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/readme.md',
'## Class ProfileOptionBuilder':'## 类配置文件optionbuilder',
'Option Builder for Profiling API.':'用于分析API的选项生成器。',
'Constructor.':'构造器。',
'Whether only account the statistics of displayed profiler nodes.':'是否只统计显示的探查器节点的统计信息。',
'self':'自己',
'### build':'### 建造',
'Build a profiling option.':'生成分析选项。',
'A dict of profiling options.':'分析选项的命令。',
'Options used to profile float operations.':'用于分析浮动操作的选项。',
'Order the displayed profiler nodes based on a attribute.':'根据属性对显示的探查器节点进行排序。',
'### select':'### 选择',
'Select the attributes to display.':'选择要显示的属性。',
'See https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/g3doc/options.md for supported attributes.':'有关支持的属性，请参阅https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/g3doc/options.md。',
'Show operation time and memory consumptions.':'显示操作时间和内存消耗。',
'Options used to profile trainable variable parameters.':'用于分析可训练变量参数的选项。',
'Normally used together with \'scope\' view.':'通常与“scope”视图一起使用。',
'Selectively counting statistics based on node types.':'基于节点类型有选择地计数统计信息。',
'self.':'自我。',
'Print the result to a file.':'将结果打印到文件中。',
'Set the maximum depth of display.':'设置最大显示深度。',
'Regular expressions used to select profiler nodes to display.':'用于选择要显示的探查器节点的正则表达式。',
'Generate a pprof profile gzip file.':'生成pprof配置文件gzip文件。',
'#### To use the pprof file:':'#### 要使用pprof文件：',
'Print the result to stdout.':'将结果打印到标准输出。',
'Which profile step to use for profiling.':'要用于分析的配置文件步骤。',
'Generate a timeline json file.':'生成时间线json文件。',
'## Class Profiler':'## 类分析器',
'https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/README.md':'https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler/readme.md',
' Typical use case:':'典型用例：',
'Add statistics of a step.':'添加步骤的统计信息。',
'### advise':'### 建议',
'Automatically detect problems and generate reports.':'自动检测问题并生成报告。',
'A Advise proto that conains the reports from all checkers.':'一个通知原型，它包含所有检查者的报告。',
'a GraphNodeProto that records the results.':'记录结果的GraphnodeProto。',
'a MultiGraphNodeProto that records the results.':'记录结果的多重图形模型。',
'Profile the statistics of the Python codes.':'分析python代码的统计信息。',
'Serialize the ProfileProto to a binary string.':'将profileproto序列化为二进制字符串。',
'Users can write it to file for offline analysis by tfprof commandline or graphical interface.':'用户可以通过tfprof命令行或图形界面将其写入文件进行脱机分析。',
'ProfileProto binary string.':'profileproto二进制字符串。',
'Public API for tf.quantization namespace.':'tf.quantization命名空间的公共api。',
'Public API for tf.queue namespace.':'tf.queue命名空间的公共api。',
'Ragged Tensors.':'参差不齐的张量。',
'### Additional ops that support RaggedTensor':'### 支持RaggedSensor的附加操作',
'Arguments that accept RaggedTensors are marked in bold.':'接受raggedtensors的参数用粗体标记。',
'Constructs a RaggedTensorValue from a nested Python list.':'从嵌套的python列表构造raggedtensorvalue。',
'## Class RaggedTensorValue':'##RaggedSensorValue类',
'Represents the value of a RaggedTensor.':'表示RaggedSensor的值。',
'Creates a RaggedTensorValue.':'创建RaggedSensorValue。',
'The numpy dtype of values in this tensor.':'此张量中值的numpy类型。',
'The innermost values array for this ragged tensor value.':'此不规则张量值的最里面的值数组。',
'The number of ragged dimensions in this ragged tensor value.':'此不规则张量值中不规则维度的数目。',
'The split indices for the ragged tensor value.':'不规则张量值的分裂指数。',
'A tuple indicating the shape of this RaggedTensorValue.':'表示此RaggedSensorValue形状的元组。',
'The concatenated values for all rows in this tensor.':'此张量中所有行的连接值。',
'Returns this ragged tensor value as a nested Python list.':'将这个不规则的张量值作为嵌套的python列表返回。',
'Public API for tf.random namespace.':'tf.random命名空间的公共api。',
'Public API for tf.random.experimental namespace.':'tf.random.experimental命名空间的公共api。',
'Resource management library.':'资源管理库。',
'Get a direct path to the data files colocated with the script.':'获取与脚本同位的数据文件的直接路径。',
'Get the path to the specified file in the data dependencies.':'获取数据依赖项中指定文件的路径。',
'The path is relative to tensorflow/':'路径是相对于tensorflow的/',
'Get a root directory containing all the data attributes in the build rule.':'获取包含生成规则中所有数据属性的根目录。',
'The contents of that resource.':'资源的内容。',
'Readahead files not implemented; simply returns given path.':'未实现readahead文件；只返回给定的路径。',
'## Class Builder':'## 类生成器',
'Builds the SavedModel protocol buffer and saves variables and assets.':'构建savedModel协议缓冲区并保存变量和资产。',
'Typical usage for the SavedModelBuilder:':'savedModelBuilder的典型用法：',
'Adds the current meta graph to the SavedModel.':'将当前元图添加到savedModel。',
'Adds the current meta graph to the SavedModel and saves variables.':'将当前元图添加到savedModel并保存变量。',
'### save':'### 保存',
'Writes a SavedModel protocol buffer to disk.':'将savedModel协议缓冲区写入磁盘。',
'The function writes the SavedModel protocol buffer to the export directory in serialized format.':'函数以序列化格式将savedModel协议缓冲区写入导出目录。',
'The path to which the SavedModel protocol buffer was written.':'savedModel协议缓冲区写入的路径。',
'Utility function to build a SignatureDef protocol buffer.':'用于构建SignatureDef协议缓冲区的实用程序函数。',
'A SignatureDef protocol buffer constructed based on the supplied arguments.':'基于提供的参数构造的signaturedef协议缓冲区。',
'A TensorInfo protocol buffer constructed based on the supplied argument.':'基于提供的参数构造的tensorinfo协议缓冲区。',
'Creates classification signature from given examples and predictions.':'根据给定的示例和预测创建分类签名。',
#'    scores':'分数',
'Checks whether the provided export directory could contain a SavedModel.':'检查提供的导出目录是否可以包含savedModel。',
'Determine whether a SignatureDef can be served by TensorFlow Serving.':'确定tensorflow服务是否可以为signaturedef服务。',
'The set of ops to be run as part of the main op upon the load operation.':'在加载操作时作为主操作的一部分运行的操作集。',
'Creates prediction signature from given inputs and outputs.':'从给定的输入和输出创建预测签名。',
#'    outputs':'输出',
'Creates regression signature from given examples and predictions.':'根据给定的示例和预测创建回归签名。',
#'    predictions':'预言',
'SavedModel builder.':'保存模型生成器。',
'#### Typical usage:':'#### 典型用法：',
'SavedModel main op.':'savedModel主操作。',
'Builds a main op that defines the sequence of ops to be run as part of the SavedModel load/restore operations.':'构建一个主操作，定义要作为savedModel加载/还原操作的一部分运行的操作序列。',
'Signature constants for SavedModel save and restore operations.':'savedModel保存和还原操作的签名常量。',
'SignatureDef utility functions.':'实用函数的签名。',
'Utility functions for building and inspecting SignatureDef protos.':'用于建立和检查原型签名的实用功能。',
'Common tags used for graphs in SavedModel.':'savedModel中用于图形的公共标记。',
'SavedModel utility functions.':'savedModel实用程序函数。',
'Utility functions to assist with setup and construction of the SavedModel proto.':'帮助设置和构造savedModel proto的实用程序函数。',
'Tensorflow set operations.':'tensorflow集合运算。',
'Signal processing operations.':'信号处理操作。',
'Sparse Tensor Representation.':'稀疏张量表示。',
'Public API for tf.spectral namespace.':'tf.spectral命名空间的公共api。',
'Operations for working with string Tensors.':'使用字符串张量的操作。',
'String lengths of input.':'输入的字符串长度。',
'Computes the length of each string given in the input tensor.':'计算输入张量中给定的每个字符串的长度。',
'Split elements of input based on sep.':'基于sep分解输入元素。',
'Let N be the size of input (typically N will be the batch size). Split each element of input based on sep and return a SparseTensor or RaggedTensor containing the split tokens. Empty tokens are ignored.':'设n为输入的大小（通常n为批处理大小）。基于sep拆分每个输入元素，并返回包含拆分标记的sparsetensor或raggedtensor。忽略空标记。',
'result will contain no empty strings at the start or end if the string has':'如果字符串有',
'leading or trailing whitespace.':'前导或尾随空白。',
'Note that the above mentioned behavior matches python\'s str.split.':'注意，上面提到的行为与python的str.split匹配。',
'according to the delimiter.':'根据分隔符。',
'Outputs a Summary protocol buffer with audio.':'输出带音频的摘要协议缓冲区。',
'A scalar Tensor of type string. The serialized Summary protocol buffer.':'字符串类型的标量张量。序列化的摘要协议缓冲区。',
'## Class FileWriter':'## 类文件编写器',
'Writes Summary protocol buffers to event files.':'将摘要协议缓冲区写入事件文件。',
'TensorBoard will pick the graph from the file and display it graphically so you can interactively explore the graph you built. You will usually pass the graph from the session in which you launched it:':'TensorBoard将从文件中选择图形并以图形方式显示它，这样您就可以交互地浏览所构建的图形。通常，您将从启动图形的会话中传递该图形：',
'Adds an event to the event file.':'将事件添加到事件文件。',
'Adds a Graph to the event file.':'将图形添加到事件文件。',
'The graph described by the protocol buffer will be displayed by TensorBoard. Most users pass a graph in the constructor instead.':'协议缓冲区描述的图形将由tensorboard显示。大多数用户在构造函数中传递一个图。',
'Adds a MetaGraphDef to the event file.':'将metagraphdef添加到事件文件。',
'Adds a metadata information for a single session.run() call.':'为单个session.run（）调用添加元数据信息。',
'Adds a SessionLog protocol buffer to the event file.':'将SessionLog协议缓冲区添加到事件文件。',
'This method wraps the provided session in an Event protocol buffer and adds it to the event file.':'此方法将提供的会话包装在事件协议缓冲区中，并将其添加到事件文件中。',
'Adds a Summary protocol buffer to the event file.':'将摘要协议缓冲区添加到事件文件。',
'This method wraps the provided summary in an Event protocol buffer and adds it to the event file.':'此方法将提供的摘要包装在事件协议缓冲区中，并将其添加到事件文件中。',
'Flushes the event file to disk and close the file.':'将事件文件刷新到磁盘并关闭该文件。',
'Call this method when you do not need the summary writer anymore.':'当不再需要摘要编写器时调用此方法。',
'Flushes the event file to disk.':'将事件文件刷新到磁盘。',
'Call this method to make sure that all pending events have been written to disk.':'调用此方法以确保所有挂起的事件都已写入磁盘。',
'Returns the directory where event file will be written.':'返回将写入事件文件的目录。',
'### reopen':'### 重新打开',
'Reopens the EventFileWriter.':'重新打开EventFileWriter。',
'Can be called after close() to add more events in the same directory. The events will go into a new events file.':'可以在close（）之后调用以在同一目录中添加更多事件。事件将进入新的事件文件。',
'Does nothing if the EventFileWriter was not closed.':'如果EventFileWriter未关闭，则不执行任何操作。',
'## Class FileWriterCache':'## 类FileWriterCache',
'Cache for file writers.':'文件写入程序的缓存。',
'### clear':'### 清除',
'Clear cached summary writers. Currently only used for unit tests.':'清除缓存的摘要编写器。目前只用于单元测试。',
'### get':'### 得到',
'Returns the FileWriter for the specified directory.':'返回指定目录的文件写入程序。',
'A FileWriter.':'文件编写者。',
'Outputs a Summary protocol buffer with a histogram.':'输出带有直方图的摘要协议缓冲区。',
'This op reports an InvalidArgument error if any value is not finite.':'如果任何值不是有限的，此操作将报告InvalidArgument错误。',
'Outputs a Summary protocol buffer with images.':'输出带有图像的摘要协议缓冲区。',
'Initializes summary writing for graph execution mode.':'初始化图表执行模式的摘要写入。',
'Merges summaries.':'合并摘要。',
'A scalar Tensor of type string. The serialized Summary protocol buffer resulting from the merging.':'字符串类型的标量张量。合并产生的序列化摘要协议缓冲区。',
'Merges all summaries collected in the default graph.':'合并默认图表中收集的所有摘要。',
'Outputs a Summary protocol buffer containing a single scalar value.':'输出包含单个标量值的摘要协议缓冲区。',
'The generated Summary has a Tensor.proto containing the input Tensor.':'生成的摘要具有包含输入张量的tensor.proto。',
'A scalar Tensor of type string. Which contains a Summary protobuf.':'字符串类型的标量张量。其中包含一个摘要协议。',
'## Class SummaryDescription':'## 类摘要描述',
'## Class TaggedRunMetadata':'## 类标记',
'Outputs a Summary protocol buffer with a serialized tensor.proto.':'输出带有序列化tensor.proto的摘要协议缓冲区。',
'Summarizes textual data.':'总结文本数据。',
'A TensorSummary op that is configured so that TensorBoard will recognize that it contains textual data. The TensorSummary is a scalar Tensor of type string which contains Summary protobufs.':'一种tensorSummary操作，其配置使tensorBoard能够识别它包含文本数据。tensorSummary是一个字符串类型的标量张量，它包含摘要protobuf。',
'System configuration library.':'系统配置库。',
'Testing.':'测试。',
'Asserts that two GraphDefs are (mostly) the same.':'断言两个图形（基本上）是相同的。',
'Computes the maximum error for dy/dx between the computed Jacobian and the numerically estimated Jacobian.':'计算计算出的雅可比矩阵和数值估计的雅可比矩阵之间dy/dx的最大误差。',
'This function will modify the tensors passed in as it adds more operations and hence changing the consumers of the operations of the input tensors.':'此函数将修改传入的张量，因为它添加了更多操作，因此更改了输入张量操作的使用者。',
'The maximum error in between the two Jacobians.':'两个雅可比之间的最大误差。',
'Returns a temporary directory for use during tests.':'返回测试期间使用的临时目录。',
'There is no need to delete the directory after the test.':'测试后不需要删除目录。',
'The temporary directory.':'临时目录。',
'## Class StubOutForTesting':'## 类存根外移',
'Support class for stubbing methods out for unit testing.':'用于单元测试的stubbing方法的支持类。',
'#### Sample Usage:':'#### 示例用法：',
'You want os.path.exists() to always return true during testing.':'您希望os.path.exists（）在测试期间始终返回true。',
'### CleanUp':'### 清理',
'### Set':'### 套',
'### SmartSet':'### 智能集',
'### SmartUnsetAll':'### 智能重置',
'This method is automatically called when the StubOutForTesting() object is deleted; there is no need to call it explicitly.':'删除stubOutorting（）对象时自动调用此方法；无需显式调用它。',
'### UnsetAll':'### 不稳定',
'Creates an absolute test srcdir path given a relative path.':'创建给定相对路径的绝对测试srcdir路径。',
'An absolute path to the linked in runfiles.':'指向运行文件中链接的绝对路径。',
'Ops related to Tensor Processing Units.':'与张量处理单元有关的操作。',
'Shards computation along the batch dimension for parallel execution.':'沿批处理维度进行碎片计算，以便并行执行。',
'Convenience wrapper around shard().':'shard（）周围的便利包装。',
'A list of output tensors.':'输出张量的列表。',
'Scope class for bfloat16 variables so that the model uses custom getter.':'bfloat16变量的作用域类，以便模型使用自定义getter。',
'Returns the device name for a core in a replicated TPU computation.':'返回复制的TPU计算中核心的设备名。',
'## Class CrossShardOptimizer':'## 类crossshardoptimizer',
'An optimizer that averages gradients across TPU shards.':'一个优化程序，它平均跨tpu碎片的梯度。',
'Apply gradients to variables.':'对变量应用渐变。',
'Return a slot named "name" created for "var" by the Optimizer.':'返回优化器为“var”创建的名为“name”的槽。',
'Return a list of the names of slots created by the Optimizer.':'返回优化器创建的插槽的名称列表。',
'A list of strings.':'字符串列表。',
'### minimize':'### 最小化',
'Forwarding the variables from the underlying optimizer.':'从底层优化器转发变量。',
'A Tensor which is summed across replicas.':'在复制品上求和的张量。',
'Initializes a distributed TPU system for use with TensorFlow.':'初始化用于TensorFlow的分布式TPU系统。',
'A serialized TopologyProto that describes the TPU system. Note: the topology must be evaluated using Session.run before it can be used.':'描述TPU系统的序列化拓扑协议。注意：必须使用session.run计算拓扑，然后才能使用它。',
'Builds part of a computation outside any current TPU replicate scope.':'在任何当前tpu复制作用域之外生成计算的一部分。',
'The Tensors returned by computation.':'计算得到的张量。',
'Builds a graph operator that runs a replicated TPU computation.':'构建运行复制的TPU计算的图形运算符。',
'Rewrites computation for execution on a TPU system.':'重写计算以在TPU系统上执行。',
'Shards computation for parallel execution.':'并行执行的碎片计算。',
'TODO(phawkins): consider adding support for broadcasting Tensors passed as inputs.':'todo（phawkins）：考虑添加对作为输入传递的广播张量的支持。',
'Shuts down a running a distributed TPU system.':'关闭正在运行的分布式TPU系统。',
'Public API for tf.tpu.experimental namespace.':'tf.tpu.实验命名空间的公共api。',
'## Class AdagradParameters':'##AdagradParameters类',
'Optimization parameters for Adagrad with TPU embeddings.':'带tpu嵌入的adagrad优化参数。',
'Optimization parameters for Adagrad.':'adagrad的优化参数。',
'## Class AdamParameters':'##ADAMparameters类',
'Optimization parameters for Adam with TPU embeddings.':'带tpu嵌入的adam优化参数。',
'Optimization parameters for Adam.':'ADAM的优化参数。',
'## Class StochasticGradientDescentParameters':'## 类StochasticGradientDescentParameters',
'Optimization parameters for stochastic gradient descent for TPU embeddings.':'tpu嵌入随机梯度下降的优化参数。',
'Optimization parameters for stochastic gradient descent.':'随机梯度下降的优化参数。',
'Support for training models.':'支持培训模式。',
'## Class AdadeltaOptimizer':'##AdadeltaOptimizer类',
'Optimizer that implements the Adadelta algorithm.':'实现adadelta算法的优化器。',
'Construct a new Adadelta optimizer.':'构造一个新的adadelta优化器。',
'This is the second part of minimize(). It returns an Operation that applies gradients.':'这是minimize（）的第二部分。它返回应用渐变的操作。',
#'    name':'名称',
'Return a slot named name created for var by the Optimizer.':'返回优化器为var创建的名为name的槽。',
'Some Optimizer subclasses use additional variables. For example Momentum and Adagrad use variables to accumulate updates. This method gives access to these Variable objects if for some reason you need them.':'一些优化器子类使用附加变量。例如，momentum和adagrad使用变量来累积更新。如果出于某种原因您需要这些变量对象，则此方法允许您访问它们。',
'A list of variables which encode the current state of Optimizer.':'编码优化器当前状态的变量列表。',
'Includes slot variables and additional global variables created by the optimizer in the current default graph.':'包括当前默认图中由优化器创建的槽变量和其他全局变量。',
'A list of variables.':'变量列表。',
'## Class AdagradDAOptimizer':'##AdagraddaoOptimizer类',
'Adagrad Dual Averaging algorithm for sparse linear models.':'稀疏线性模型的adagrad对偶平均算法。',
'AdagradDA is typically used when there is a need for large sparsity in the trained model. This optimizer only guarantees sparsity for linear models. Be careful when using AdagradDA for deep networks as it will require careful initialization of the gradient accumulators for it to train.':'adagradda通常在训练模型需要大量稀疏性时使用。这个优化器只保证线性模型的稀疏性。在深层网络中使用adagradda时要小心，因为它需要对梯度累加器进行仔细的初始化才能进行训练。',
'Construct a new AdagradDA optimizer.':'构造一个新的adagradda优化器。',
'## Class AdagradOptimizer':'## 类AdagradOptimizer',
'Optimizer that implements the Adagrad algorithm.':'实现adagrad算法的优化器。',
'Construct a new Adagrad optimizer.':'构造一个新的adagrad优化器。',
'## Class AdamOptimizer':'## 类AdamopTimizer',
'Optimizer that implements the Adam algorithm.':'实现ADAM算法的优化器。',
'Construct a new Adam optimizer.':'构造一个新的adam优化器。',
'#### Initialization:':'#### 初始化：',
'The update rule for variable with gradient g uses an optimization described at the end of section 2 of the paper:':'带梯度g的变量的更新规则使用本文第2节末尾描述的优化：',
'When building a complex model that uses many queues it is often difficult to gather all the queue runners that need to be run. This convenience function allows you to add a queue runner to a well known collection in the graph.':'在构建使用多个队列的复杂模型时，通常很难收集所有需要运行的队列运行器。此便利功能允许您将队列运行器添加到图中的已知集合。',
'Basic loop to train a model.':'训练模型的基本回路。',
'The argument tensors can be a list or a dictionary of tensors. The value returned by the function will be of the same type as tensors.':'参数张量可以是张量的列表或字典。函数返回的值将与张量类型相同。',
'The capacity argument controls the how long the prefetching is allowed to grow the queues.':'capacity参数控制允许预取增长队列的时间。',
'## Class Checkpoint':'## 类检查点',
'Example usage when graph building:':'图形生成时的示例用法：',
'Example usage with eager execution enabled:':'启用紧急执行的示例用法：',
'Group objects into a training checkpoint.':'将对象分组到训练检查点。',
'An integer variable which starts at zero and is incremented on save.':'从零开始并在保存时递增的整数变量。',
'Used to number checkpoints.':'用于对检查点进行编号。',
'The save counter variable.':'保存计数器变量。',
'### restore':'### 恢复',
'Restore a training checkpoint.':'恢复训练检查点。',
'Restores this Checkpoint and any objects it depends on.':'还原此检查点及其依赖的任何对象。',
'The returned status object has the following methods:':'返回的status对象具有以下方法：',
'Saves a training checkpoint and provides basic checkpoint management.':'保存培训检查点并提供基本检查点管理。',
'The saved checkpoint includes variables created by this object and any trackable objects it depends on at the time Checkpoint.save() is called.':'保存的检查点包括此对象创建的变量以及调用checkpoint.save（）时它所依赖的任何可跟踪对象。',
'The full path to the checkpoint.':'检查点的完整路径。',
'Writes a training checkpoint.':'编写训练检查点。',
'The checkpoint includes variables created by this object and any trackable objects it depends on at the time Checkpoint.write() is called.':'检查点包括此对象创建的变量以及调用checkpoint.write（）时它所依赖的任何可跟踪对象。',
'## Class ChiefSessionCreator':'## 班主席',
'Creates a tf.compat.v1.Session for a chief.':'为主管创建tf.compat.v1.session。',
'Initializes a chief session creator.':'初始化主会话创建者。',
'Applies cosine decay to the learning rate.':'对学习率应用余弦衰减。',
'The function returns the decayed learning rate. It is computed as:':'函数返回衰减的学习速率。计算如下：',
'Applies cosine decay with restarts to the learning rate.':'将余弦衰减和重新启动应用于学习速率。',
'Create global step tensor in graph.':'在图中创建全局阶跃张量。',
'Global step tensor.':'全局阶跃张量。',
'Applies exponential decay to the learning rate.':'对学习率应用指数衰减。',
'Returns MetaGraphDef proto.':'返回metagraphdef proto。',
'Optionally writes it to filename.':'可以选择将其写入文件名。',
'A MetaGraphDef proto.':'一个元图形原型。',
'## Class FtrlOptimizer':'## 类ftrloptimizer',
'Optimizer that implements the FTRL algorithm.':'实现ftrl算法的优化器。',
'Construct a new FTRL optimizer.':'构造一个新的ftrl优化器。',
'Generates a checkpoint state proto.':'生成检查点状态原型。',
'A list of mtimes (in microseconds) of the found checkpoints.':'找到的检查点的mtimes（微秒）列表。',
'Get the global step tensor.':'得到全局阶跃张量。',
'Returns and create (if necessary) the global step tensor.':'返回并创建（如果需要）全局阶跃张量。',
'The global step tensor.':'全局阶跃张量。',
'Small helper to get the global step.':'获取全局步骤的小助手。',
'The global step value.':'全局步长值。',
'## Class GradientDescentOptimizer':'## 类GradientDescentOptimizer',
'Optimizer that implements the gradient descent algorithm.':'实现梯度下降算法的优化器。',
'Construct a new gradient descent optimizer.':'构造一个新的梯度下降优化器。',
'Recreates a Graph saved in a MetaGraphDef proto.':'重新创建保存在metagraphdef proto中的图形。',
'Later this model can be restored and contents loaded.':'稍后可以恢复此模型并加载内容。',
'Exporting/importing meta graphs is not supported. No graph exists when eager execution is enabled.':'不支持导出/导入元图。启用紧急执行时不存在图。',
'Assignment map supports following syntax:':'赋值映射支持以下语法：',
'Applies inverse time decay to the initial learning rate.':'对初始学习率应用逆时间衰减。',
'tensor or OutOfRange.':'张量或超出范围。',
'Applies linear cosine decay to the learning rate.':'将线性余弦衰减应用于学习速率。',
'Note that linear cosine decay is more aggressive than cosine decay and larger initial learning rates can typically be used.':'注意，线性余弦衰减比余弦衰减更具攻击性，通常可以使用更大的初始学习速率。',
'## Class LooperThread':'## 类循环线程',
'Before each run the thread checks if the coordinator has requested stop. In that case the looper thread terminates immediately.':'每次运行之前，线程检查协调器是否已请求停止。在这种情况下，循环线程立即终止。',
'You typically pass looper threads to the supervisor Join() method.':'您通常将循环线程传递给supervisor join（）方法。',
'Create a LooperThread.':'创建looperthread。',
'### daemon':'### 守护进程',
'A boolean value indicating whether this thread is a daemon thread.':'一个布尔值，指示此线程是否为守护进程线程。',
'### ident':'### 识别',
'Thread identifier of this thread or None if it has not been started.':'此线程的线程标识符，如果尚未启动，则为无。',
'A string used for identification purposes only.':'仅用于标识目的的字符串。',
'It has no semantics. Multiple threads may be given the same name. The initial name is set by the constructor.':'它没有语义。多个线程可以被赋予相同的名称。初始名称由构造函数设置。',
'### getName':'### 获取名称',
'### isAlive':'### 伊莎莉',
'Return whether the thread is alive.':'返回线程是否处于活动状态。',
'This method returns True just before the run() method starts until just after the run() method terminates. The module function enumerate() returns a list of all alive threads.':'此方法在run（）方法开始之前返回true，直到run（）方法终止之后返回true。模块函数enumerate（）返回所有活动线程的列表。',
'### isDaemon':'### 伊斯戴蒙',
'### join':'### 加入',
'Wait until the thread terminates.':'等到线程终止。',
'A thread can be join()ed many times.':'一个线程可以被join（）多次。',
'join() raises a RuntimeError if an attempt is made to join the current thread as that would cause a deadlock. It is also an error to join() a thread before it has been started and attempts to do so raises the same exception.':'如果试图连接当前线程，join（）将引发运行时错误，因为这将导致死锁。在线程启动之前加入它也是一个错误，尝试这样做会引发相同的异常。',
'### loop':'### 循环',
'Start a LooperThread that calls a function periodically.':'启动周期性调用函数的looperthread。',
'The started thread.':'开始的线程。',
'Method representing the thread\'s activity.':'表示线程活动的方法。',
'### setDaemon':'###setdaemon程序',
'### setName':'### 集合名',
'### start':'### 开始',
'Start the thread\'s activity.':'启动线程的活动。',
'It must be called at most once per thread object. It arranges for the object\'s run() method to be invoked in a separate thread of control.':'每个线程对象最多只能调用一次。它安排在单独的控制线程中调用对象的run（）方法。',
'This method will raise a RuntimeError if called more than once on the same thread object.':'如果在同一线程对象上多次调用此方法，则会引发运行时错误。',
'Called when the thread starts.':'线程启动时调用。',
'Called when the thread stops.':'当线程停止时调用。',
'See docstring in batch for more details.':'有关详细信息，请参阅批处理中的docstring。',
'A list or dictionary of tensors with the same types as tensors.':'与张量具有相同类型的张量的列表或字典。',
'A list or dictionary of tensors with the types as tensors.':'类型为张量的张量列表或词典。',
'## Class MomentumOptimizer':'## 类动量优化器',
'Optimizer that implements the Momentum algorithm.':'实现动量算法的优化器。',
'Construct a new Momentum optimizer.':'构造一个新的动量优化器。',
'## Class MonitoredSession':'## 类监视会话',
'Initialization: At creation time the monitored session does following things in given order:':'初始化：在创建时，被监视的会话按给定顺序执行以下操作：',
'See MonitoredTrainingSession for an example usage based on chief or worker.':'请参见MonitoredTrainingSession，以获取基于主管或工人的示例用法。',
'A MonitoredSession object.':'监视会话对象。',
'Sets up a Monitored or Hooked Session.':'设置监视或连接的会话。',
'Run ops in the monitored session.':'在监视的会话中运行操作。',
'This method is completely compatible with the tf.Session.run() method.':'此方法与tf.session.run（）方法完全兼容。',
'Same as tf.Session.run().':'与tf.session.run（）相同。',
'Run ops using a step function.':'使用step函数运行ops。',
'## Class StepContext':'## 类StepContext',
'### session':'### 会议',
'StopIteration':'停止迭代',
'Same as MonitoredSession.run. Accepts the same arguments.':'与monitoredSession.run相同。接受相同的参数。',
'Creates a MonitoredSession for training.':'创建用于培训的监视会话。',
'Applies natural exponential decay to the initial learning rate.':'对初始学习率应用自然指数衰减。',
'Applies noisy linear cosine decay to the learning rate.':'将噪声线性余弦衰减应用于学习速率。',
'## Class Optimizer':'## 类优化器',
'Base class for optimizers.':'优化器的基类。',
'### Usage':'### 用法',
'In the training program you will just have to run the returned Op.':'在训练计划中，你只需要运行返回的操作。',
'### Processing gradients before applying them.':'### 在应用渐变之前处理渐变。',
'Calling minimize() takes care of both computing the gradients and applying them to the variables. If you want to process the gradients before applying them you can instead use the optimizer in three steps:':'调用minimize（）同时计算渐变并将其应用于变量。如果要在应用渐变之前处理渐变，可以通过三个步骤使用优化器：',
'### Gating Gradients':'### 选通梯度',
'### Slots':'### 插槽',
'Create a new Optimizer.':'创建新的优化器。',
'This must be called by the constructors of subclasses.':'这必须由子类的构造函数调用。',
'Piecewise constant from boundaries and interval values.':'从边界值和区间值中分段常数。',
'Applies a polynomial decay to the learning rate.':'对学习率应用多项式衰减。',
'## Class ProximalAdagradOptimizer':'## 类proximaladagradumizer',
'Optimizer that implements the Proximal Adagrad algorithm.':'实现近端adagrad算法的优化器。',
'Construct a new ProximalAdagrad optimizer.':'构造一个新的proximaladagrad优化器。',
'## Class ProximalGradientDescentOptimizer':'## 类ProximalGradientDescentOptimizer',
'Optimizer that implements the proximal gradient descent algorithm.':'实现近端梯度下降算法的优化器。',
'Construct a new proximal gradient descent optimizer.':'构造一个新的近端梯度下降优化器。',
'## Class QueueRunner':'## 类队列管理器',
'On construction the QueueRunner adds an op to close the queue. That op will be run if the enqueue ops raise exceptions.':'在构造时，queuerunner会添加一个op来关闭队列。如果队列操作引发异常，则将运行该操作。',
'Exceptions raised but not handled by the QueueRunner threads.':'队列运行器线程引发但未处理的异常。',
'The string name of the underlying Queue.':'基础队列的字符串名称。',
'### queue':'### 排队',
'Create threads to run the enqueue ops for the given session.':'创建线程以运行给定会话的排队操作。',
'A list of threads.':'线程列表。',
'Converts this QueueRunner to a QueueRunnerDef protocol buffer.':'将此QueueRunner转换为QueueRunnerDef协议缓冲区。',
'Return a device function to use when building a Graph for replicas.':'返回在为副本生成图形时要使用的设备函数。',
'## Class RMSPropOptimizer':'##rmspropoptimizer类',
'Optimizer that implements the RMSProp algorithm.':'实现rmsprop算法的优化器。',
'Construct a new RMSProp optimizer.':'构造一个新的rmsprop优化器。',
'## Class Saver':'## 类保护程序',
'Saves and restores variables.':'保存和还原变量。',
'The Saver class adds ops to save and restore variables to and from checkpoints. It also provides convenience methods to run these ops.':'saver类添加ops以在检查点之间保存和还原变量。它还提供了运行这些操作的方便方法。',
'Checkpoints are binary files in a proprietary format which map variable names to tensor values. The best way to examine the contents of a checkpoint is to load it using a Saver.':'检查点是以专有格式将变量名映射到张量值的二进制文件。检查检查点内容的最佳方法是使用保存程序加载它。',
'Note that you still have to call the save() method to save the model. Passing these arguments to the constructor will not save variables automatically for you.':'注意，仍然需要调用save（）方法来保存模型。将这些参数传递给构造函数不会自动为您保存变量。',
'A training program that saves regularly looks like:':'定期保存的培训计划如下：',
'Creates a Saver.':'创建一个保存程序。',
'The constructor adds ops to save and restore variables.':'构造函数添加操作以保存和还原变量。',
'You can pass any of the returned values to restore().':'可以将任何返回值传递给restore（）。',
'Generates a SaverDef representation of this saver.':'生成此保存程序的saverdef表示形式。',
'A SaverDef proto.':'一个saverdef原型。',
'Recovers the internal saver state after a crash.':'恢复崩溃后的内部保护程序状态。',
'Restores previously saved variables.':'恢复以前保存的变量。',
'Saves variables.':'保存变量。',
'This method runs the ops added by the constructor for saving variables. It requires a session in which the graph was launched. The variables to save must also have been initialized.':'此方法运行构造函数添加的用于保存变量的操作。它需要启动图形的会话。要保存的变量也必须已初始化。',
'The method returns the path prefix of the newly created checkpoint files. This string can be passed directly to a call to restore().':'该方法返回新创建的检查点文件的路径前缀。此字符串可以直接传递给restore（）调用。',
'Sets the list of old checkpoint filenames.':'设置旧检查点文件名的列表。',
'Sets the list of old checkpoint filenames and timestamps.':'设置旧检查点文件名和时间戳的列表。',
'Converts this Saver to a SaverDef protocol buffer.':'将此保存程序转换为saverdef协议缓冲区。',
'A SaverDef protocol buffer.':'saverdef协议缓冲区。',
'## Class SaverDef':'## 类saverdef',
'### sharded':'### 切碎的',
'CheckpointFormatVersion version':'检查点格式版本',
'## Class Scaffold':'## 等级脚手架',
'Structure to create or gather pieces commonly needed to train a model.':'用于创建或收集训练模型通常需要的片段的结构。',
'The following pieces are directly accessible as attributes of the Scaffold object:':'以下部分可以作为scaffold对象的属性直接访问：',
'You can also pass the following additional pieces to the constructor:':'您还可以将以下附加部分传递给构造函数：',
'Create a scaffold.':'创建脚手架。',
'### saver':'### 储蓄者',
'Returns an op that groups the default local init ops.':'返回对默认本地初始化操作进行分组的操作。',
'The default Scaffold local init op.':'默认的scaffold局部初始化操作。',
'Creates operations if needed and finalizes the graph.':'根据需要创建操作并完成图形。',
'Get from cache or create a default operation.':'从缓存获取或创建默认操作。',
'Computes fingerprints of the input strings.':'计算输入字符串的指纹。',
'Distributed version of Stochastic Dual Coordinate Ascent (SDCA) optimizer for':'分布式随机双坐标上升优化器',
'Applies L1 regularization shrink step on the parameters.':'对参数应用l1正则化收缩步骤。',
'## Class SessionCreator':'## 类SessionCreator',
'A factory for tf.Session.':'一个训练营的工厂。',
'## Class SessionManager':'## 类会话管理器',
'Training helper that restores from checkpoint and creates session.':'从检查点恢复并创建会话的训练助手。',
'This class is a small wrapper that takes care of session creation and checkpoint recovery. It also provides functions that to facilitate coordination among multiple training threads or processes.':'这个类是一个小包装器，负责会话创建和检查点恢复。它还提供有助于多个训练线程或进程之间协调的功能。',
'### Usage:':'### 用法：',
'A second process could wait for the model to be ready by doing the following:':'第二个进程可以通过执行以下操作等待模型就绪：',
'Creates a SessionManager.':'创建SessionManager。',
'Creates a Session. Makes sure the model is ready to be used.':'创建会话。确保模型可以使用。',
'A Session object that can be used to drive the model.':'可用于驱动模型的会话对象。',
'Creates a new Session and waits for model to be ready.':'创建新会话并等待模型准备就绪。',
'This function adds the following to the current Graph:':'此函数将以下内容添加到当前图表中：',
'This version enqueues a different list of tensors in different threads. It adds the following to the current Graph:':'这个版本在不同的线程中排列一个不同的张量列表。它将以下内容添加到当前图表中：',
'## Class SingularMonitoredSession':'## 类奇点监视会话',
'To `run` without hooks.':'不用钩子就跑。',
'To save and restore.':'保存和恢复。',
'Initialization: At creation time the hooked session does following things in given order:':'初始化：在创建时，挂接会话按给定顺序执行以下操作：',
'Creates a SingularMonitoredSession.':'创建奇点监视会话。',
'Returns underlying TensorFlow.Session object.':'返回基础TensorFlow.Session对象。',
'An iterator for reading Event protocol buffers from an event file.':'从事件文件中读取事件协议缓冲区的迭代器。',
'You can use this function to read events written to an event file. It returns a Python iterator that yields Event protocol buffers.':'可以使用此函数读取写入事件文件的事件。它返回生成事件协议缓冲区的python迭代器。',
'Example: Print the contents of an events file.':'示例：打印事件文件的内容。',
'Example: Print selected summary values.':'示例：打印选定的摘要值。',
'Event protocol buffers.':'事件协议缓冲区。',
'## Class Supervisor':'## 班主任',
'A training helper that checkpoints models and computes summaries.':'用于检查点建模和计算摘要的训练助手。',
'#### Use for a single program':'#### 用于单个程序',
'#### Use for multiple replicas':'#### 用于多个副本',
'The only change you have to do to the single program code is to indicate if the program is running as the chief.':'对单个程序代码所做的唯一更改是指示该程序是否作为主程序运行。',
'NOTE: This modified program still works fine as a single program. The single program marks itself as the chief.':'注意：这个修改过的程序仍然可以作为一个单独的程序运行。单个程序将自己标记为主任。',
'#### What master string to use':'#### 使用什么主字符串',
'#### Advanced use':'#### 高级使用',
'##### Launching additional services':'##### 启动附加服务',
'##### Launching fewer services':'##### 推出更少的服务',
'##### Custom model initialization':'##### 自定义模型初始化',
'A Supervisor.':'一个主管。',
'Supervisors are not supported when eager execution is enabled.':'启用紧急执行时不支持监视程序。',
'### coord':'### 坐标',
'Return the Coordinator used by the Supervisor.':'归还主管使用的协调员。',
'The Coordinator can be useful if you want to run multiple threads during your training.':'如果您希望在培训期间运行多个线程，则协调器可能很有用。',
'A Coordinator object.':'协调对象。',
'A feed dictionary or None.':'一个feed字典或没有。',
'Return the Init Op used by the supervisor.':'返回主管使用的init op。',
'An Op or None.':'手术或不手术。',
'Return True if this is a chief supervisor.':'如果这是主管，则返回true。',
'A bool.':'一个布尔。',
'Return the Ready Op used by the supervisor.':'返回主管使用的就绪操作。',
'Return the delay between checkpoints.':'返回检查点之间的延迟。',
'A timestamp.':'时间戳。',
'Return the save path used by the supervisor.':'返回主管使用的保存路径。',
'A string.':'一根绳子。',
'Return the delay between summary computations.':'返回摘要计算之间的延迟。',
'Return the Saver used by the supervisor.':'返回主管使用的保存程序。',
'A Saver object.':'一个保存程序对象。',
'Return the SessionManager used by the Supervisor.':'返回主管使用的sessionmanager。',
'A SessionManager object.':'SessionManager对象。',
'Return the Summary Tensor used by the chief supervisor.':'返回主管使用的汇总张量。',
'A string Tensor for the summary or None.':'用于摘要或无摘要的字符串张量。',
'Return the SummaryWriter used by the chief supervisor.':'返回主管使用的摘要编写器。',
'A SummaryWriter.':'总结作家',
'### Loop':'### 循环',
'The started thread is added to the list of threads managed by the supervisor so it does not need to be passed to the stop() method.':'启动的线程被添加到由主管管理的线程列表中，因此不需要将其传递给stop（）方法。',
'### PrepareSession':'### 预备会议',
'Make sure the model is ready to be used.':'确保模型已准备好使用。',
'### RequestStop':'### 请求停止',
'Request that the coordinator stop the threads.':'请求协调器停止线程。',
'### ShouldStop':'### 应该停止',
'Check if the coordinator was told to stop.':'检查协调员是否被告知停止工作。',
'### StartQueueRunners':'###StartQueueRunners公司',
'Start threads for QueueRunners.':'为队列运行程序启动线程。',
'The list of threads started for the QueueRunners.':'为队列运行程序启动的线程列表。',
'### StartStandardServices':'### 标准服务',
'Start the standard services for \'sess\'.':'启动“sess”的标准服务。',
'This starts services in the background. The services started depend on the parameters to the constructor and may include:':'这将在后台启动服务。启动的服务取决于构造函数的参数，可能包括：',
'### Stop':'### 停止',
'Stop the services and the coordinator.':'停止服务和协调员。',
'This does not close the session.':'这不会关闭会话。',
'### StopOnException':'### 停止例外',
'Context handler to stop the supervisor when an exception is raised.':'在引发异常时停止管理器的上下文处理程序。',
'A context handler.':'上下文处理程序。',
'### SummaryComputed':'### 汇总计算',
'Indicate that a summary was computed.':'表示已计算摘要。',
'### WaitForStop':'### 等待停止',
'Block waiting for the coordinator to stop.':'阻止等待协调员停止。',
'Returns a context manager for a managed session.':'返回托管会话的上下文管理器。',
'This context manager creates and automatically recovers a session. It optionally starts the standard services that handle checkpoints and summaries. It monitors exceptions raised from the with block or from the services and stops the supervisor as needed.':'此上下文管理器创建并自动恢复会话。它可以选择启动处理检查点和摘要的标准服务。它监视从WITH块或服务引发的异常，并根据需要停止监视程序。',
'The context manager is typically used as follows:':'上下文管理器通常使用如下：',
#'        break':'打破',
'If you want to retry the training loop in case of preemption you can do it as follows:':'如果您想在抢占的情况下重试训练循环，可以执行以下操作：',
#'  while True':'虽然是真的',
#'    except tf.errors.Aborted:':'除了tf.errors.aborted：',
#'      pass':'通过',
'A context manager that yields a Session restored from the latest checkpoint or initialized from scratch if not checkpoint exists. The session is closed when the with block exits.':'一种上下文管理器，它产生一个从最新的检查点还原的会话，如果不存在检查点，则从头开始初始化。WITH块退出时会话将关闭。',
'### stop':'### 停止',
'## Class SyncReplicasOptimizer':'## 类syncreplicasoptimizer',
'The following accumulators/queue are created:':'将创建以下累加器/队列：',
'The optimizer adds nodes to the graph to collect gradients and pause the trainers until variables are updated. For the Parameter Server job:':'优化器将节点添加到图中以收集渐变，并暂停训练器，直到变量更新。对于参数服务器作业：',
'#### For the replicas:':'#### 对于副本：',
'Returns the QueueRunner for the chief to execute.':'返回首席执行官要执行的QueueRunner。',
'A QueueRunner for chief to execute.':'队长执行任务的排队者。',
'An op for the chief/sync replica to fill the token queue.':'主/同步复制副本填充令牌队列的操作。',
'Creates a hook to handle SyncReplicasHook ops such as initialization.':'创建一个钩子来处理syncreplicasharked操作，如初始化。',
'Fetches a list of optimizer variables in the default graph.':'获取默认图中优化器变量的列表。',
'This wraps variables() from the actual optimizer. It does not include the SyncReplicasOptimizer\'s local step.':'这将包装实际优化器中的变量（）。它不包括syncreplicasoptimizer的本地步骤。',
'This updates the checkpoint file containing a CheckpointState proto.':'这将更新包含检查点状态协议的检查点文件。',
'## Class WorkerSessionCreator':'## 类WorkerSessionCreator',
'Creates a tf.compat.v1.Session for a worker.':'为工作进程创建tf.compat.v1.session。',
'Initializes a worker session creator.':'初始化工作会话创建者。',
'Public API for tf.train.experimental namespace.':'tf.train.experimental命名空间的公共api。',
'Disables the mixed precision graph rewrite.':'禁用混合精度图形重写。',
'Enable mixed precision via a graph rewrite.':'通过图形重写启用混合精度。',
'A version of opt that will use loss scaling to prevent underflow.':'opt的一个版本，它将使用损失比例来防止下溢。',
'## Class MixedPrecisionLossScaleOptimizer':'## 类MixedPrecisionLossCalleOptimizer',
'An optimizer that applies loss scaling.':'应用损失缩放的优化器。',
'This adjusts the dynamic range of the gradient evaluation by scaling up the loss value. The gradient values are then scaled back down by the recipricol of the loss scale. This is useful in reduced precision training where small gradient values would otherwise underflow the representable range.':'这将通过放大损失值来调整渐变求值的动态范围。然后，梯度值被损耗标度的倒数缩小。这在精度降低的训练中是有用的，否则小的梯度值会在可表示的范围内下溢。',
'Example of overriding the generated code for an Op.':'重写操作生成代码的示例。',
'Public API for tf.version namespace.':'tf.version命名空间的公共API。',
'Public API for tf.xla namespace.':'tf.xla命名空间的公共api。',
'Public API for tf.xla.experimental namespace.':'tf.xla.实验命名空间的公共API。',
'Public API for tf.config.threading namespace.':'tf.config.threading命名空间的公共API。',
'## Glossary':'## 词汇表',
'##Modules':'## 模块',
'Library imports for ClusterResolvers.':'用于ClusterResolver的库导入。',
'Experimental Distribution Strategy library.':'实验分发策略库。',
'ResNet models for Keras.':'路缘石的resnet模型。',
'ResNet v2 models for Keras.':'用于Keras的Resnet v2模型。',
'VGG16 model for Keras.':'用于路缘石的VGG16车型。',
'VGG19 model for Keras.':'VGG19路缘石模型。',
'Mixed precision API.':'混合精度API。',
'Connects to the given cluster.':'连接到给定的群集。',
'Connects to a single machine to enable remote execution on it.':'连接到单个计算机以在其上启用远程执行。',
'List the names of the available devices.':'列出可用设备的名称。',
'This can be useful for debugging or profiling.':'这对于调试或分析非常有用。',
'Get if soft device placement is enabled.':'如果启用软设备放置，则获取。',
'If soft placement is enabled.':'如果启用软放置。',
'Set if soft device placement is enabled.':'设置是否启用软设备放置。',
'Gets the current device policy.':'获取当前设备策略。',
'This function only gets the device policy for the current thread. Any subsequently started thread will again use the default policy.':'此函数仅获取当前线程的设备策略。任何随后启动的线程将再次使用默认策略。',
'Current thread device policy':'当前线程设备策略',
'Get if memory growth is enabled for a PhysicalDevice.':'如果物理设备启用了内存增长，则获取。',
'A PhysicalDevice with memory growth set will not allocate all memory on the device upfront.':'已设置内存增长的physicaldevice不会预先分配设备上的所有内存。',
'Current memory growth setting.':'当前内存增长设置。',
'Gets whether operations are executed synchronously or asynchronously.':'获取操作是同步执行还是异步执行。',
'Current thread execution mode':'当前线程执行模式',
'Get the virtual device configuration for a PhysicalDevice.':'获取物理设备的虚拟设备配置。',
'Get the list of visible physical devices.':'获取可见物理设备的列表。',
'Returns a list of PhysicalDevice objects that are current marked as visible to the runtime. Any visible devices will have LogicalDevices assigned to them once the runtime is initialized.':'返回当前标记为对运行时可见的PhysicalDevice对象的列表。一旦运行时初始化，任何可见设备都将被分配逻辑设备。',
'The following example verifies all visible GPUs have been disabled:':'以下示例验证是否已禁用所有可见的GPU：',
'List of PhysicalDevice objects':'物理设备对象列表',
'Return a list of logical devices created by runtime.':'返回运行时创建的逻辑设备列表。',
'Logical devices may correspond to physical devices or remote devices in the cluster. Operations and tensors may be placed on these devices by using the name of the LogicalDevice.':'逻辑设备可以对应于群集中的物理设备或远程设备。操作和张量可以通过使用逻辑设备的名称放置在这些设备上。',
'List of LogicalDevice objects':'逻辑设备对象列表',
'Return a list of physical devices visible to the runtime.':'返回运行时可见的物理设备列表。',
'The following example ensures the machine can see at least 1 GPU.':'下面的示例确保机器至少可以看到1个GPU。',
'Sets the current thread device policy.':'设置当前线程设备策略。',
'This function only sets the device policy for the current thread. Any subsequently started thread will again use the default policy.':'此函数仅设置当前线程的设备策略。任何随后启动的线程将再次使用默认策略。',
'Set if memory growth should be enabled for a PhysicalDevice.':'设置是否应为物理设备启用内存增长。',
#'    enable':'使可能',
'A PhysicalDevice with memory growth set will not allocate all memory on the device upfront. Memory growth cannot be configured on a PhysicalDevice with virtual devices configured.':'已设置内存增长的physicaldevice不会预先分配设备上的所有内存。无法在配置了虚拟设备的物理设备上配置内存增长。',
'Specifies whether operations are executed synchronously or asynchronously.':'指定操作是同步执行还是异步执行。',
'True: executes each operation synchronously.':'true：同步执行每个操作。',
'False: executes each operation asynchronously.':'false:异步执行每个操作。',
'Set the virtual device configuration for a PhysicalDevice.':'为物理设备设置虚拟设备配置。',
'A PhysicalDevice marked as visible will by default have a single LogicalDevice allocated to it once the runtime is configured. Specifying a list of tf.config.experimental.VirtualDeviceConfiguration objects allows multiple devices to be configured that utilize the same PhysicalDevice.':'配置运行时后，默认情况下，标记为可见的物理设备将分配一个逻辑设备。通过指定tf.config.experimental.virtualDevice配置对象的列表，可以配置使用同一物理设备的多个设备。',
'The following example splits the CPU into 2 virtual devices:':'以下示例将CPU拆分为两个虚拟设备：',
'except:':'除外：',
'Set the list of visible devices.':'设置可见设备的列表。',
'Sets the list of PhysicalDevices to be marked as visible to the runtime. Any devices that are not marked as visible means TensorFlow will not allocate memory on it and will not be able to place any operations on it as no LogicalDevice will be created on it. By default all discovered devices are marked as visible.':'设置要标记为对运行时可见的物理设备列表。任何未标记为可见的设备意味着TensorFlow不会在其上分配内存，也不会在其上放置任何操作，因为不会在其上创建任何逻辑设备。默认情况下，所有发现的设备都标记为可见。',
'The following example demonstrates disabling the first GPU on the machine.':'下面的示例演示如何禁用计算机上的第一个GPU。',
'## Class VirtualDeviceConfiguration':'## 类虚拟设备配置',
'Configuration class for virtual devices for a PhysicalDevice.':'物理设备的虚拟设备的配置类。',
'#### Fields:':'#### 字段：',
'Get experimental optimizer options.':'获取实验优化器选项。',
'Dictionary of configured experimental optimizer options':'已配置的实验优化器选项字典',
'Get if JIT compilation is enabled.':'如果启用了jit编译，则获取。',
'If JIT compilation is enabled.':'如果启用了jit编译。',
'Set experimental optimizer options.':'设置实验优化器选项。',
'remapping: Remap subgraphs onto more efficient implementations.':'重新映射：将子图重新映射到更有效的实现上。',
'Set if JIT compilation is enabled.':'设置是否启用JIT编译。',
'Get number of threads used for parallelism between independent operations.':'获取用于独立操作之间并行的线程数。',
'Number of parallel threads':'并行线程数',
'Get number of threads used within an individual op for parallelism.':'获取单个操作中用于并行性的线程数。',
'Set number of threads used for parallelism between independent operations.':'设置用于独立操作之间并行的线程数。',
'Set number of threads used within an individual op for parallelism.':'为并行性设置单个操作中使用的线程数。',
'#### Example elements:':'#### 示例元素：',
'## Class DatasetSpec':'## 类数据集规范',
'## Class Options':'## 类选项',
'Represents options for tf.data.Dataset.':'表示tf.data.dataset的选项。',
'### merge':'### 合并',
'A transformation that buckets elements in a Dataset by length.':'按长度存储数据集中元素的转换。',
'Elements of the Dataset are grouped together by length and then are padded and batched.':'数据集的元素按长度分组，然后填充和批处理。',
'This is useful for sequence tasks in which the elements have variable length. Grouping together elements that have similar lengths reduces the total fraction of padding in a batch which increases training step efficiency.':'这对于元素长度可变的序列任务非常有用。将具有相似长度的元素组合在一起可以减少批处理中填充的总分数，从而提高训练步骤的效率。',
'Records the number of bytes produced by each element of the input dataset.':'记录输入数据集的每个元素生成的字节数。',
'## Class CheckpointInputPipelineHook':'## 类检查点输入管道挂钩',
'Checkpoints input pipeline state every N steps or seconds.':'检查点每隔N步或秒输入管道状态。',
'Differences from CheckpointSaverHook: 1. Saves only the input pipelines in the "iterators" collection and not the global variables or other saveable objects. 2. Does not write the GraphDef and MetaGraphDef to the summary.':'与checkpointsaverhook的区别：1。只保存“迭代器”集合中的输入管道，而不保存全局变量或其他可保存对象。2.不将graphdef和metagraphdef写入摘要。',
'Example of checkpointing the training pipeline:':'检查培训管道的示例：',
'while True:':'如果是真的：',
#'    break':'打破',
'Initializes a CheckpointInputPipelineHook.':'初始化检查点输入管道挂钩。',
#'    coord':'坐标',
'Called when new TensorFlow session is created.':'在创建新的tensorflow会话时调用。',
'This is called to signal the hooks that a new session has been created. This has two essential differences with the situation in which begin is called:':'调用此函数是为了向钩子发送已创建新会话的信号。这与begin的情况有两个本质区别：',
'Called after each call to run().':'每次调用run（）后调用。',
'Called before each call to run().':'在每次调用run（）之前调用。',
'You can return from this call a SessionRunArgs object indicating ops or tensors to add to the upcoming run() call. These ops/tensors will be run together with the ops/tensors originally passed to the original run() call. The run args you return can also contain feeds to be added to the run() call.':'您可以从此调用返回一个sessionrunargs对象，该对象指示要添加到即将进行的run（）调用中的操作或张量。这些ops/tensor将与最初传递给原始run（）调用的ops/tensor一起运行。返回的run参数还可以包含要添加到run（）调用中的提要。',
'At this point graph is finalized and you can not add ops.':'此时图表已完成，无法添加操作。',
'### begin':'### 开始',
'Called once before using the session.':'在使用会话之前调用一次。',
'### end':'### 结束',
'Called at the end of session.':'在会话结束时调用。',
'Creates a dataset that deterministically chooses elements from datasets.':'创建确定地从数据集中选择元素的数据集。',
'The elements of result will be:':'结果要素如下：',
'Creates a Dataset that counts from start in steps of size step.':'创建一个数据集，该数据集从一开始就按大小步进行计数。',
'A Dataset of scalar dtype elements.':'标量数据类型元素的数据集。',
'## Class CsvDataset':'## 类CSVDataset',
'A Dataset comprising lines from one or more CSV files.':'由一个或多个csv文件的行组成的数据集。',
'Creates a CsvDataset by reading and decoding CSV files.':'通过读取和解码csv文件创建csvdataset。',
'We can construct a CsvDataset from it as follows:':'我们可以用它构造一个csvdataset，如下所示：',
'The expected output of its iterations is:':'迭代的预期输出是：',
'## Class DistributeOptions':'## 阶级分布',
'Represents options for distributed data processing.':'表示分布式数据处理的选项。',
'The number of devices attached to this input pipeline. This will be automatically set by MultiDeviceIterator.':'连接到此输入管道的设备数。这将由multideviceiterator自动设置。',
'It is similar to python\'s enumerate. For example:':'它类似于python的枚举。例如：',
'Constructs a dataset from the given variant and structure.':'从给定的变量和结构构造数据集。',
#'    structure':'结构',
'Returns an Optional that contains the next value from the iterator.':'返回包含迭代器的下一个值的可选值。',
'An Optional object representing the next value from the iterator (if it has one) or no value.':'表示迭代器的下一个值（如果它有）或没有值的可选对象。',
'Returns the single element in dataset as a nested structure of tensors.':'将数据集中的单个元素作为张量的嵌套结构返回。',
'Returns the type specification of an element of a Dataset or Iterator.':'返回数据集或迭代器的元素的类型规范。',
'A transformation that groups elements and performs a reduction.':'对元素进行分组并执行缩减的转换。',
#'    reducer':'减速器',
'A transformation that groups windows of elements by key and reduces them.':'按键对元素窗口进行分组并缩小它们的转换。',
'Creates a Dataset from another Dataset and silently ignores any errors.':'从另一个数据集创建数据集，并自动忽略任何错误。',
'InvalidArgumentError.':'无效argumenterror。',
'Records the latency of producing each element of the input dataset.':'记录生成输入数据集的每个元素的延迟。',
'Reads CSV files into a dataset.':'将csv文件读入数据集。',
'Returns a SaveableObject for saving/restoring iterator state using Saver.':'返回用于使用saver保存/还原迭代器状态的saveableobject。',
'A SaveableObject for saving/restoring iterator state using Saver.':'用于使用saver保存/还原迭代器状态的saveableobject。',
'## Class MapVectorizationOptions':'## 类映射矢量化选项',
'Represents options for the MapVectorization optimization.':'表示地图矢量化优化的选项。',
'### enabled':'### 启用',
'## Class OptimizationOptions':'## 类优化选项',
'Represents options for dataset optimizations.':'表示数据集优化的选项。',
'### autotune':'### 自动调谐',
'Wraps a value that may/may not be present at runtime.':'包装运行时可能/可能不存在的值。',
'Optional can only be used by values that are convertible to Tensor or CompositeTensor.':'可选只能由可转换为张量或合成器的值使用。',
'The structure of the components of this optional.':'此可选组件的结构。',
'A Structure object representing the structure of the components of this optional.':'表示此可选组件的结构的结构对象。',
'Returns an Optional that wraps the given value.':'返回包装给定值的可选值。',
'An Optional that wraps value.':'包装值的可选项。',
'Returns the value wrapped by this optional.':'返回此可选值包装的值。',
'The wrapped value.':'包装的价值。',
'Returns a tensor that evaluates to True if this optional has a value.':'如果可选的张量有值，则返回计算为true的张量。',
'Returns an Optional that has no value.':'返回一个没有值的可选值。',
'NOTE: This method takes an argument that defines the structure of the value that would be contained in the returned Optional if it had a value.':'注意：此方法接受一个参数，该参数定义了值的结构，如果该值有值，则该值将包含在返回的可选值中。',
'An Optional that has no value.':'一个没有价值的选项。',
'A transformation that parses Example protos into a dict of tensors.':'将示例原型解析为一组张量的转换。',
'A transformation that prefetches dataset values to the given device.':'将数据集值预取到给定设备的转换。',
'## Class RandomDataset':'## 类随机数据集',
'A Dataset of pseudorandom values.':'伪随机值的数据集。',
'## Class Reducer':'## 级减速器',
'A reducer is used for reducing a set of elements.':'减速机用于减少一组元素。',
'A transformation that resamples a dataset to achieve a target distribution.':'对数据集重新采样以实现目标分布的转换。',
'NOTE Resampling is performed via rejection sampling; some fraction of the input values will be dropped.':'注：重采样通过拒绝采样执行；输入值的一部分将被删除。',
'Samples elements at random from the datasets in datasets.':'从数据集中的数据集中随机采样元素。',
'A transformation that scans a function across an input dataset.':'在输入数据集中扫描函数的转换。',
'## Class SqlDataset':'## 类SqlDataSet',
'A Dataset consisting of the results from a SQL query.':'由SQL查询结果组成的数据集。',
'Creates a SqlDataset.':'创建SqlDataSet。',
'SqlDataset allows a user to read data from the result set of a SQL query. For example:':'sql data set允许用户从sql查询的结果集中读取数据。例如：',
'## Class StatsAggregator':'## 类statsaggregator',
'A stateful resource that aggregates statistics from one or more iterators.':'从一个或多个迭代器聚合统计信息的有状态资源。',
'## Class StatsOptions':'## 类状态选项',
'Represents options for collecting dataset stats using StatsAggregator.':'表示使用StatsAggregator收集数据集统计信息的选项。',
'### aggregator':'### 聚合器',
'Associates the given statistics aggregator with the dataset pipeline.':'将给定的统计聚合器与数据集管道关联。',
'Prefix for the statistics recorded as counter.':'记录为计数器的统计信息的前缀。',
'Whether to add latency measurements on all edges. Defaults to False.':'是否在所有边上添加延迟度量。默认为false。',
'### prefix':'### 前缀',
'Prefix to prepend all statistics recorded for the input dataset with.':'前缀，用以前置为输入数据集记录的所有统计信息。',
'A transformation that stops dataset iteration based on a predicate.':'基于谓词停止数据集迭代的转换。',
'## Class TFRecordWriter':'## 类tfrecordwriter',
'Writes data to a TFRecord file.':'将数据写入tfrecord文件。',
'To write a dataset to a single TFRecord file:':'要将数据集写入单个tfrecord文件，请执行以下操作：',
'To shard a dataset across multiple TFRecord files:':'要跨多个tfrecord文件切分数据集，请执行以下操作：',
'## Class ThreadingOptions':'## 类线程选项',
'Represents options for dataset threading.':'表示数据集线程的选项。',
'Returns a variant representing the given dataset.':'返回表示给定数据集的变量。',
'Use this transformation to produce a dataset that contains one instance of each unique element in the input. For example:':'使用此转换生成包含输入中每个唯一元素的一个实例的数据集。例如：',
'Asserts that the given condition is true.':'断言给定条件为真。',
'Same tensor as x.':'张量与x相同。',
'Static assert that values is a "proper" iterable.':'静态断言值是“适当的”iterable。',
'Assert that x has rank equal to rank.':'断言x的秩等于秩。',
'This Op checks that the rank of x is equal to rank.':'这个操作检查x的秩是否等于秩。',
'Assert that x has rank of at least rank.':'断言x的秩至少为秩。',
'This Op checks that the rank of x is greater or equal to rank.':'此操作检查x的秩是否大于或等于秩。',
'Assert that x has a rank in ranks.':'断言x在列中有一个列。',
'This Op checks that the rank of x is in ranks.':'这个操作检查x的秩是否在秩中。',
'Validate and return float type based on tensors and dtype.':'基于张量和dtype验证并返回float类型。',
'Validated type.':'已验证类型。',
'Asserts that the given tensor is a scalar.':'断言给定的张量是标量。',
'Asserts that the given Tensor is of the specified type.':'断言给定的张量属于指定类型。',
'Checks a tensor for NaN and Inf values.':'检查张量的NaN和INF值。',
'Get if device placements are logged.':'获取是否记录了设备放置。',
'If device placements are logged.':'如果记录了设备放置。',
'Returns True if the elements of tensor are numbers.':'如果张量的元素是数字，则返回true。',
'Set if device placements should be logged.':'设置是否应记录设备放置。',
'## Class CrossDeviceOps':'## 类CrossDeviceOps',
'Reduce PerReplica objects in a batch.':'成批减少perreplica对象。',
'a list of Mirrored objects.':'镜像对象的列表。',
'Implementation of reduce PerReplica objects in a batch.':'成批实现reduce-perreplica对象。',
'### broadcast':'### 广播',
'Broadcast the tensor to destinations.':'把张量广播到目的地。',
'a Mirrored object.':'镜像对象。',
'Implementation of broadcast the tensor to destinations.':'将张量广播到目的地的实现。',
'#### Note that execution:':'#### 注意执行：',
'True if inside a with strategy.scope():.':'如果在具有strategy.scope（）的内部，则为true。',
'## Class HierarchicalCopyAllReduce':'## 类层次结构CopyAllReduce',
'Initializes the object.':'初始化对象。',
'## Class InputContext':'## 类inputcontext',
'A class wrapping information needed by an input function.':'输入函数所需的类包装信息。',
'Initializes an InputContext object.':'初始化inputcontext对象。',
'Returns the input pipeline ID.':'返回输入管道ID。',
'Returns the number of compute replicas in sync.':'返回同步的计算副本数。',
'## Class InputReplicationMode':'## 类inputrepplicationmode',
'Replication mode for input function.':'输入功能的复制模式。',
#'    axis':'轴',
'## Class NcclAllReduce':'##ncclallreduce类',
'A "distributed Dataset" that the caller can iterate over.':'调用方可以遍历的“分布式数据集”。',
'Return value from running fn.':'运行fn返回值。',
'A context manager to use for creating variables with this strategy.':'用于使用此策略创建变量的上下文管理器。',
'## Class ReduceOp':'## 类reduceop',
'Indicates how a set of values should be reduced.':'指示应如何减少一组值。',
'## Class ReductionToOneDevice':'## 类还原到设备',
'Always do reduction to one device first and then do broadcasting.':'总是先还原到一个设备，然后再进行广播。',
'Batch reduction is done by reduction on each element one by one.':'批量还原是通过逐个还原每个元素来完成的。',
'## Class ReplicaContext':'## 类复制上下文',
'Returns the id of the replica being defined.':'返回正在定义的副本的ID。',
'### strategy':'### 策略',
'IMPORTANT: The ordering of communications must be identical in all replicas.':'重要提示：所有副本中的通信顺序必须相同。',
'## Class Server':'## 类服务器',
'Creates a new server with the given definition.':'创建具有给定定义的新服务器。',
'### target':'### 目标',
'A string containing a session target for this server.':'包含此服务器的会话目标的字符串。',
'Blocks until the server has shut down.':'直到服务器关闭。',
'This method currently blocks forever.':'此方法当前将永远阻止。',
'Starts this server.':'启动此服务器。',
'A state & compute distribution policy on a list of devices.':'设备列表上的状态和计算分发策略。',
'#### In short:':'#### 简而言之：',
'A custom training loop can be as simple as:':'自定义训练循环可以简单到：',
'## Class ClusterResolver':'## 类ClusterResolver',
'Abstract class for all implementations of ClusterResolvers.':'所有ClusterResolver实现的抽象类。',
'### environment':'### 环境',
'Returns the current environment which TensorFlow is running in.':'返回TensorFlow正在运行的当前环境。',
'Retrieve the current state of the cluster and return a ClusterSpec.':'检索集群的当前状态并返回集群规范。',
'A ClusterSpec representing the state of the cluster at the moment this function is called.':'一个ClusterSpec，表示调用此函数时群集的状态。',
'Retrieves the name or URL of the session master.':'检索会话主机的名称或url。',
'The name or URL of the session master.':'会话主机的名称或url。',
'Returns the number of accelerator cores per worker.':'返回每个工作进程的加速器核心数。',
'This returns the number of accelerator cores (such as GPUs and TPUs) available per worker.':'这将返回每个工作进程可用的加速器核心数（如GPU和TPU）。',
'A map of accelerator types to number of cores.':'加速器类型与核心数的映射。',
'## Class GCEClusterResolver':'##GCeclusterResolver类',
'ClusterResolver for Google Compute Engine.':'用于Google计算引擎的ClusterResolver。',
'Creates a new GCEClusterResolver object.':'创建新的gceClusterResolver对象。',
'This takes in a few parameters and creates a GCEClusterResolver project. It will then use these parameters to query the GCE API for the IP addresses of each instance in the instance group.':'这需要几个参数并创建一个gceclusterresolver项目。然后，它将使用这些参数查询实例组中每个实例的IP地址。',
'Returns a ClusterSpec object based on the latest instance group info.':'根据最新的实例组信息返回ClusterSpec对象。',
'This returns a ClusterSpec object for use based on information from the specified instance group. We will retrieve the information from the GCE APIs every time this method is called.':'这将根据来自指定实例组的信息返回一个clusterspec对象以供使用。每次调用此方法时，我们都将从gce api检索信息。',
'A ClusterSpec containing host information retrieved from GCE.':'包含从GCE检索到的主机信息的ClusterSpec。',
'## Class KubernetesClusterResolver':'##KubernetesClusterResolver类',
'Initializes a new KubernetesClusterResolver.':'初始化新的KubernetesClusterResolver。',
'This initializes a new Kubernetes ClusterResolver. The ClusterResolver will attempt to talk to the Kubernetes master to retrieve all the instances of pods matching a label selector.':'这将初始化新的kubernetes clusterresolver。clusterresolver将尝试与kubernetes主机对话，以检索与标签选择器匹配的pods的所有实例。',
'Returns a ClusterSpec object based on the latest info from Kubernetes.':'根据来自kubernetes的最新信息返回clusterspec对象。',
'We retrieve the information from the Kubernetes master every time this method is called.':'每次调用此方法时，我们都从kubernetes主机检索信息。',
'A ClusterSpec containing host information returned from Kubernetes.':'包含从kubernetes返回的主机信息的clusterspec。',
'Returns the master address to use when creating a session.':'返回创建会话时要使用的主地址。',
'## Class SimpleClusterResolver':'## 类SimpleClusterResolver',
'Simple implementation of ClusterResolver that accepts a ClusterSpec.':'接受ClusterSpec的ClusterResolver的简单实现。',
'Creates a SimpleClusterResolver from a ClusterSpec.':'从ClusterSpec创建SimpleClusterResolver。',
'Returns the ClusterSpec passed into the constructor.':'返回传入构造函数的ClusterSpec。',
'## Class SlurmClusterResolver':'## 类slurmClusterResolver',
'ClusterResolver for system with Slurm workload manager.':'具有slurm工作负载管理器的系统的ClusterResolver。',
'Creates a new SlurmClusterResolver object.':'创建新的slurmClusterResolver对象。',
'This takes in parameters and creates a SlurmClusterResolver object. It uses those parameters to check which nodes will processes reside on and resolves their hostnames. With the number of the GPUs on each node and number of GPUs for each task it offsets the port number for each process and allocates GPUs to tasks by setting environment variables. The resolver currently supports homogeneous tasks and default Slurm process allocation.':'这将接受参数并创建slurmClusterResolver对象。它使用这些参数来检查哪些节点将驻留进程并解析其主机名。使用每个节点上的GPU数和每个任务的GPU数，它将偏移每个进程的端口号，并通过设置环境变量将GPU分配给任务。解析器当前支持同构任务和默认的slurm进程分配。',
'A ClusterResolver object which can be used with distributed TensorFlow.':'可用于分布式TensorFlow的ClusterResolver对象。',
'A ClusterSpec containing host information retrieved from Slurm\'s environment variables.':'包含从slurm的环境变量检索到的主机信息的clusterspec。',
'A string specifying job name the process belongs to and an integner specifying the task index the process belongs to in that job.':'指定进程所属作业名称的字符串，以及指定该进程在该作业中所属任务索引的整数。',
'Returns the master string for connecting to a TensorFlow master.':'返回用于连接TensorFlow主控形状的主字符串。',
'A connection string for connecting to a TensorFlow master.':'用于连接tensorflow主机的连接字符串。',
'## Class TFConfigClusterResolver':'## 类tfconfigclusterresolver',
'Creates a new TFConfigClusterResolver.':'创建新的tfconfigclusterresolver。',
'Returns the master address to use when creating a TensorFlow session.':'返回创建tensorflow会话时要使用的主地址。',
'The address of the master.':'主人的地址。',
'## Class TPUClusterResolver':'##TPUClusterResolver类',
'Cluster Resolver for Google Cloud TPUs.':'google云tpu的集群解析器。',
'TPUClusterResolver supports the following distinct environments: Google Compute Engine Google Kubernetes Engine Google internal':'tpuclusterresolver支持以下不同的环境：google计算引擎google kubernetes引擎google内部',
'Creates a new TPUClusterResolver object.':'创建新的tpuclusterresolver对象。',
'The ClusterResolver will then use the parameters to query the Cloud TPU APIs for the IP addresses and ports of each Cloud TPU listed.':'然后，clusterresolver将使用这些参数查询列出的每个云tpu的ip地址和端口的云tpu api。',
'Returns a ClusterSpec object based on the latest TPU information.':'基于最新的TPU信息返回ClusterSpec对象。',
'We retrieve the information from the GCE APIs every time this method is called.':'每次调用此方法时，我们都从gceapi中检索信息。',
'Get the Master string to be used for the session.':'获取用于会话的主字符串。',
'Returns the number of TPU cores per worker.':'返回每个工作进程的TPU核心数。',
'## Class UnionResolver':'## 类UnionResolver',
'Performs a union on underlying ClusterResolvers.':'在底层的ClusterResolver上执行联合。',
'Initializes a UnionClusterResolver with other ClusterResolvers.':'使用其他ClusterResolver初始化UnionClusterResolver。',
'Returns a union of all the ClusterSpecs from the ClusterResolvers.':'从ClusterResolver返回所有ClusterSpec的并集。',
'A ClusterSpec containing host information merged from all the underlying ClusterResolvers.':'包含从所有底层ClusterResolver合并的主机信息的ClusterSpec。',
'## Class CentralStorageStrategy':'## 类中心存储策略',
'#### For Example:':'#### 例如：',
'The returned dataset is a wrapped strategy dataset which creates a multidevice iterator under the hood. It prefetches the input data to the specified devices on the worker. The returned distributed dataset can be iterated over similar to how regular datasets can.':'返回的数据集是一个包装策略数据集，它在引擎盖下创建一个多设备迭代器。它将输入数据预取到工作机上的指定设备。返回的分布式数据集可以像常规数据集那样进行迭代。',
'In CentralStorageStrategy there is a single worker so the value returned will be all the values on that worker.':'在CentralStorageStrategy中只有一个worker，因此返回的值将是该worker上的所有值。',
'## Class CollectiveCommunication':'## 集体通讯',
'Communication choices for CollectiveOps.':'集体行动的通讯选择。',
'## Class MultiWorkerMirroredStrategy':'## 类MultiWorkerMirroredStrategy',
'A distribution strategy for synchronous training on multiple workers.':'多人同步培训的分配策略。',
'Creates the strategy.':'创建策略。',
'## Class ParameterServerStrategy':'## 类参数服务器策略',
'This strategy requires two jobs: workers and parameter servers. Variables and updates to those variables will be assigned to parameter servers and other operations are assigned to workers.':'此策略需要两个作业：工人和参数服务器。变量和对这些变量的更新将分配给参数服务器，其他操作将分配给工人。',
'## Class TPUStrategy':'## 类别TPustrategy',
'TPU distribution strategy implementation.':'tpu分销策略的实施。',
'Initializes the TPUStrategy object.':'初始化tpustrategy对象。',
'Casts a tensor to a new type.':'把张量转换成一种新的类型。',
'The operation casts x (in case of Tensor) or x.values (in case of SparseTensor or IndexedSlices) to dtype.':'该操作将x（对于张量）或x.values（对于sparsetensor或indexedlices）转换为dtype。',
'A Tensor or SparseTensor or IndexedSlices with same shape as x and same type as dtype.':'与x形状相同、与dtype类型相同的张量或sparsetensor或indexedlices。',
'Converts two real numbers to a complex number.':'将两个实数转换为复数。',
'The input tensors real and imag must have the same shape.':'输入张量real和imag必须具有相同的形状。',
'A Tensor of type complex64 or complex128.':'复数64或复数128型张量。',
'## Class DType':'## 类数据类型',
'Represents the type of the elements in a Tensor.':'表示张量中元素的类型。',
'The following DType objects are defined:':'定义了以下dtype对象：',
'Creates a new DataType.':'创建新数据类型。',
'Returns a numpy.dtype based on this DType.':'基于此数据类型返回numpy.dtype。',
'Returns whether this is a boolean data type':'返回是否为布尔数据类型',
'Returns whether this is a complex floating point type.':'返回这是否为复杂浮点类型。',
'Returns whether this is a quantized data type.':'返回这是否是量化数据类型。',
'Returns whether this type is unsigned.':'返回此类型是否无符号。',
'Whether a DType is unsigned.':'数据类型是否未签名。',
'### limits':'### 限制',
'Returns the maximum representable value in this data type.':'返回此数据类型中可表示的最大值。',
'Returns the minimum representable value in this data type.':'返回此数据类型中可表示的最小值。',
'Returns the string name for this DType.':'返回此数据类型的字符串名称。',
'Returns the dtype correspond to this dtype\'s real part.':'返回与此数据类型的实际部分相对应的数据类型。',
'Returns True iff this DType refers to the same type as other.':'如果此数据类型引用与其他类型相同的类型，则返回true。',
'Returns True if the other DType will be converted to this DType.':'如果其他数据类型将转换为此数据类型，则返回true。',
'The conversion rules are as follows:':'转换规则如下：',
'True if a Tensor of the other DType will be implicitly converted to this DType.':'如果另一个dtype的张量将隐式转换为此dtype，则为true。',
'Performs a safe saturating cast of value to dtype.':'执行值到dtype的安全饱和转换。',
'value safely cast to dtype.':'值安全地转换为dtype。',
'## Class AbortedError':'## 类中止错误',
#'    message':'消息',
'Creates an AbortedError.':'创建中止错误。',
'The integer error code that describes the error.':'描述错误的整数错误代码。',
'The error message that describes the error.':'描述错误的错误消息。',
'The NodeDef proto representing the op that failed.':'nodedef proto表示失败的操作。',
'## Class AlreadyExistsError':'## 类alreadyexistserror',
'Raised when an entity that we attempted to create already exists.':'当我们试图创建的实体已存在时引发。',
'Creates an AlreadyExistsError.':'创建alreadyExistsRor。',
'## Class CancelledError':'## 类取消错误',
'Raised when an operation or step is cancelled.':'取消操作或步骤时引发。',
'Creates a CancelledError.':'创建CancelleDerror。',
'## Class DataLossError':'## 类datalosserror',
'Raised when unrecoverable data loss or corruption is encountered.':'遇到无法恢复的数据丢失或损坏时引发。',
'Creates a DataLossError.':'创建datalosserror。',
'## Class DeadlineExceededError':'## 类死线异常错误',
'Raised when a deadline expires before an operation could complete.':'在操作完成之前的截止日期过期时引发。',
'This exception is not currently used.':'当前未使用此异常。',
'Creates a DeadlineExceededError.':'创建死线异常错误。',
'## Class FailedPreconditionError':'## 类失败预处理错误',
'Operation was rejected because the system is not in a state to execute it.':'操作被拒绝，因为系统未处于执行该操作的状态。',
'Creates a FailedPreconditionError.':'创建失败的预处理错误。',
'## Class InternalError':'## 类内部错误',
'Raised when the system experiences an internal error.':'当系统遇到内部错误时引发。',
'This exception is raised when some invariant expected by the runtime has been broken. Catching this exception is not recommended.':'当运行时预期的某个不变量被破坏时，会引发此异常。不建议捕获此异常。',
'Creates an InternalError.':'创建内部错误。',
'## Class InvalidArgumentError':'## 类InvalidArgumenterRor',
'Raised when an operation receives an invalid argument.':'当操作收到无效参数时引发。',
'Creates an InvalidArgumentError.':'创建InvalidArgumenterRor。',
'## Class NotFoundError':'## 类notfounderror',
'Creates a NotFoundError.':'创建notfounderror。',
'## Class OpError':'## 职业操作工',
'A generic error that is raised when TensorFlow execution fails.':'当TensorFlow执行失败时引发的一般性错误。',
'Creates a new OpError indicating that a particular op failed.':'创建指示特定操作失败的新操作错误。',
'## Class OutOfRangeError':'## 类超出范围错误',
'Raised when an operation iterates past the valid input range.':'当操作迭代超过有效输入范围时引发。',
'Creates an OutOfRangeError.':'创建outofrangeerror。',
'## Class PermissionDeniedError':'## 类许可错误',
'Raised when the caller does not have permission to run an operation.':'调用方没有运行操作的权限时引发。',
'Creates a PermissionDeniedError.':'创建PermissionDeniederror。',
'## Class ResourceExhaustedError':'## 类ResourceExhausterRor',
'Some resource has been exhausted.':'一些资源已经耗尽。',
'Creates a ResourceExhaustedError.':'创建ResourceExhausterRor。',
'## Class UnauthenticatedError':'## 类未经身份验证的错误',
'The request does not have valid authentication credentials.':'请求没有有效的身份验证凭据。',
'Creates an UnauthenticatedError.':'创建未经身份验证的错误。',
'## Class UnavailableError':'## 类不可用错误',
'Raised when the runtime is currently unavailable.':'当运行时当前不可用时引发。',
'Creates an UnavailableError.':'创建不可用的错误。',
'## Class UnimplementedError':'## 类不重要错误',
'Raised when an operation has not been implemented.':'未实现操作时引发。',
'Creates an UnimplementedError.':'创建一个不重要的错误。',
'## Class UnknownError':'## 类未知错误',
'Unknown error.':'未知错误。',
'Creates an UnknownError.':'造成未知错误。',
'Example usage of custom metric which uses features:':'使用特性的自定义度量的示例用法：',
'Args: can only have following four arguments in any order:':'args:任何顺序只能有以下四个参数：',
'pre`dict`ions: Pre`dict`ions `Tensor` or `dict` of `Tensor` created by given `estimator`.':'pre`dict`ions：由给定的“估计器”创建的“tensor”的pre`dict`tensor`或“dict”。',
'config: config attribute of the `estimator`.':'config:estimator的config属性。',
'Initializes a BaselineClassifier instance.':'初始化基线分类器实例。',
'A BaselineClassifier estimator.':'基线分类器估计器。',
'Initializes a BaselineEstimator instance.':'初始化基线估计器实例。',
'Initializes a BaselineRegressor instance.':'初始化BaselineRegressor实例。',
'A BaselineRegressor estimator.':'基线回归估计。',
'## Class BestExporter':'## 一流的出口商',
'This class exports the serving graph and checkpoints of the best models.':'这个类导出最佳模型的服务图和检查点。',
'This class performs a model export everytime the new model is better than any existing model.':'每当新模型优于任何现有模型时，此类都会执行模型导出。',
'Example of creating a BestExporter for training and evaluation:':'为培训和评估创建最佳导出程序的示例：',
'Directory name.':'目录名。',
'A directory name under the export base directory where exports of this type are written. Should not be None nor empty.':'导出基目录下写入此类型导出的目录名。不应为无或空。',
'Exports the given Estimator to a specific format.':'将给定的估计量导出为特定格式。',
'The string path to the exported directory or None if export is skipped.':'导出目录的字符串路径，如果跳过导出，则为无。',
'## Class BinaryClassHead':'## 类BinaryClassHead',
'Creates a Head for single label binary classification.':'创建单标签二进制分类的标题。',
'It is recommended to pass all args via name.':'建议通过名称传递所有参数。',
'EstimatorSpec.':'估计器规范。',
'### metrics':'### 指标',
'A dict of predictions.':'预言的名言',
'## Class BoostedTreesClassifier':'## 类boostedTreesClassifier',
'A Classifier for Tensorflow Boosted Trees models.':'Tensorflow 增强树模型的分类器。',
'Initializes a BoostedTreesClassifier instance.':'初始化BoostedTreesClassifier实例。',
'Computes model explainability outputs per example along with predictions.':'计算每个示例的模型可解释性输出以及预测。',
'## Class BoostedTreesEstimator':'## 类BoostedTreesEstimator',
'An Estimator for Tensorflow Boosted Trees models.':'Tensorflow 增强树模型的估计量。',
'Initializes a BoostedTreesEstimator instance.':'初始化BoostedTreesEstimator实例。',
'## Class BoostedTreesRegressor':'## 类boostedtreesregressor',
'A Regressor for Tensorflow Boosted Trees models.':'Tensorflow 增强树模型的回归器。',
'Initializes a BoostedTreesRegressor instance.':'初始化boostedtreesregressor实例。',
'## Class CheckpointSaverHook':'## 类检查点saverhook',
'Saves checkpoints every N steps or seconds.':'每隔N步或秒保存检查点。',
'Initializes a CheckpointSaverHook.':'初始化检查点saverhook。',
'## Class CheckpointSaverListener':'## 类检查点SaverListener',
'Interface for listeners that take action before or after checkpoint save.':'在检查点保存之前或之后执行操作的侦听器的接口。',
'Initializes a DNNClassifier instance.':'初始化dnnclassifier实例。',
'Initializes a DNNEstimator instance.':'初始化dnnestimator实例。',
'Initializes a DNNLinearCombinedClassifier instance.':'初始化dnnlinearcombinedClassifier实例。',
'Initializes a DNNLinearCombinedEstimator instance.':'初始化dnnlinearcombinedestimator实例。',
'Initializes a DNNLinearCombinedRegressor instance.':'初始化dnnlinearcombinedregressor实例。',
'Initializes a DNNRegressor instance.':'初始化dnnRegressor实例。',
'## Class EstimatorSpec':'## 类估计量规范',
'EstimatorSpec fully defines the model to be run by an Estimator.':'EstimatorSpec完全定义了要由估计器运行的模型。',
'Creates a validated EstimatorSpec instance.':'创建已验证的EstimatorSpec实例。',
'name: An arbitrary name for this output.':'名称：此输出的任意名称。',
'A validated EstimatorSpec object.':'已验证的EstimatorSpec对象。',
'### scaffold':'### 脚手架',
'## Class EvalSpec':'## 等级评估规范',
'EvalSpec combines details of evaluation of the trained model as well as its export. Evaluation consists of computing metrics to judge the performance of the trained model. Export writes out the trained model on to external storage.':'evalspec结合了训练模型的评估细节及其导出。评估包括计算度量来判断训练模型的性能。导出将经过训练的模型写入外部存储。',
'Creates a validated EvalSpec instance.':'创建已验证的evalspec实例。',
'A validated EvalSpec object.':'已验证的evalspec对象。',
'### steps':'### 台阶',
'### hooks':'### 钩子',
'### exporters':'### 出口商',
'## Class Exporter':'## 类别导出器',
'A class representing a type of model export.':'表示模型导出类型的类。',
'## Class FeedFnHook':'## 类feedfnhook',
'Initializes a FeedFnHook.':'初始化feedfnhook。',
'## Class FinalExporter':'## 班财务报告员',
'This class exports the serving graph and checkpoints at the end.':'这个类在最后导出服务图和检查点。',
'This class performs a single export at the end of training.':'这个班在训练结束时进行一次输出。',
'## Class FinalOpsHook':'## 最后一课',
'A hook which evaluates Tensors at the end of a session.':'在会话结束时计算张量的钩子。',
'Initializes FinalOpHook with ops to run at the end of the session.':'使用要在会话结束时运行的操作初始化finalLopHook。',
'## Class GlobalStepWaiterHook':'## 类GlobalStepWaiterHook',
'Initializes a GlobalStepWaiterHook.':'初始化GlobalStepWaiterBook。',
'## Class Head':'## 班长',
'Interface for the head/top of a model.':'模型头部/顶部的接口。',
'#### Common usage:':'#### 常用用法：',
'Size of the last dimension of the logits Tensor.':'logits张量的最后维度的大小。',
'The expected size of the logits tensor.':'logits张量的预期大小。',
'The type of loss reduction used in the head.':'头部使用的减少损失的类型。',
'The name of this head.':'这个头的名字。',
'Returns a loss Tensor from provided arguments.':'从提供的参数返回损失张量。',
'A scalar Tensor representing regularized training loss used in train and eval.':'表示训练和评估中使用的正则化训练损失的标量张量。',
'Returns a dict of metric objects.':'返回度量对象的dict。',
'A dict of metrics keyed by string name. The value is an instance of Metric class.':'由字符串名键控的一种度量。该值是Metric类的实例。',
'Returns a dict of predictions from provided logits.':'从提供的登录返回预测的dict。',
'A dict of predicted Tensor keyed by prediction name.':'由预测名称键入的预测张量的一种指令。',
'Updates metric objects and returns a dict of the updated metrics.':'更新度量对象并返回更新度量的dict。',
'A dict of updated metrics keyed by name. The value is an instance of Metric class.':'按名称键控的更新度量的指令。该值是Metric类的实例。',
'## Class LatestExporter':'## 类LatesExporter',
'This class regularly exports the serving graph and checkpoints.':'此类定期导出服务图和检查点。',
'Construct a LinearClassifier estimator object.':'构造一个线性辅助估计对象。',
'A LinearClassifier estimator.':'线性辅助估计。',
'Initializes a LinearRegressor instance.':'初始化LinearGressor实例。',
'## Class LoggingTensorHook':'## Class 日志tensorhook',
'Initializes a LoggingTensorHook.':'初始化LoggingTensorHook。',
'## Class LogisticRegressionHead':'## 类logisticRegressionHead',
'Creates a Head for logistic regression.':'创建逻辑回归的头部。',
'The head can be used with a canned estimator. Example:':'头部可以与罐头估计器一起使用。例子：',
'## Class MultiClassHead':'## 类多类头',
'Creates a Head for multi class classification.':'创建多类别分类的标题。',
'## Class MultiHead':'## 类多头',
'This class merges the output of multiple Head objects. Specifically:':'这个类合并多个head对象的输出。明确地：',
'Usage:':'用法：',
'## Class MultiLabelHead':'## 类多标签头',
'#### Labels can be:':'#### 标签可以是：',
'## Class NanLossDuringTrainingError':'## 类NanlossDuringTrainingError',
'## Class NanTensorHook':'## 南滕索克类',
'Monitors the loss tensor and stops training if loss is NaN.':'监测损失张量，如果损失为NaN，则停止训练。',
'Can either fail with exception or just stop training.':'可能会异常失败，也可能只是停止训练。',
'Initializes a NanTensorHook.':'初始化nantensorhook。',
'## Class PoissonRegressionHead':'## 类泊松回归头',
'## Class ProfilerHook':'## 类配置文件',
'Captures CPU/GPU profiling information every N steps or seconds.':'每隔N步或秒捕获CPU/GPU分析信息。',
'Initializes a hook that takes periodic profiling snapshots.':'初始化获取定期分析快照的挂钩。',
'## Class RegressionHead':'## 类回归头',
'This class specifies the configurations for an Estimator run.':'此类指定估计器运行的配置。',
'#### Example of chief node:':'#### 主节点示例：',
'Example of evaluator node (evaluator is not part of training cluster):':'Evaluator节点示例（Evaluator不属于训练群集）：',
'## Class SecondOrStepTimer':'## 类辅助计时器',
'Timer that triggers at most once every N seconds or once every N steps.':'每N秒或每N步最多触发一次的计时器。',
'Returns the last triggered time step or None if never triggered.':'返回上次触发的时间步，如果从未触发，则返回“无”。',
'Resets the timer.':'重置计时器。',
'Return true if the timer should trigger for the specified step.':'如果计时器应为指定步骤触发，则返回true。',
'Update the last triggered time and step number.':'更新上次触发的时间和步骤号。',
'## Class SessionRunArgs':'## 类sessionrunargs',
'Represents arguments to be added to a Session.run() call.':'表示要添加到session.run（）调用的参数。',
'### fetches':'### 获取',
'## Class SessionRunContext':'## 类SessionRunContext',
'Provides information about the session.run() call being made.':'提供有关正在进行的session.run（）调用的信息。',
#'    session':'阶段',
'Initializes SessionRunContext.':'初始化SessionRunContext。',
'A SessionRunArgs object holding the original arguments of run().':'一个sessionrunargs对象，包含run（）的原始参数。',
'A SessionRunArgs object':'SessionRunArgs对象',
'A TensorFlow session object which will execute the run.':'将执行运行的TensorFlow会话对象。',
'Returns whether a stop is requested or not.':'返回是否请求停止。',
'Sets stop requested field.':'设置停止请求字段。',
'Hooks can use this function to request stop of iterations. MonitoredSession checks whether this is called or not.':'hooks可以使用这个函数来请求停止迭代。monitoredSession检查是否调用了此会话。',
'## Class SessionRunHook':'## 类会话runhook',
'Hook to extend calls to MonitoredSession.run().':'钩子以扩展对monitoredSession.run（）的调用。',
'## Class SessionRunValues':'## 类SessionRunValues',
'Contains the results of Session.run().':'包含session.run（）的结果。',
'In the future we may use this object to add more information about result of run without changing the Hook API.':'将来，我们可以使用此对象添加有关运行结果的更多信息，而无需更改hook api。',
'### results':'### 结果',
'## Class StepCounterHook':'## 级步进钩',
'Hook that counts steps per second.':'每秒计算步数的钩子。',
'## Class StopAtStepHook':'##StopatStephook班',
'Hook that requests stop at a specified step.':'请求在指定步骤停止的挂钩。',
'Initializes a StopAtStepHook.':'初始化stopatstephook。',
'This hook requests stop after either a number of steps have been executed or a last step has been reached. Only one of the two options can be specified.':'此钩子请求在执行多个步骤或到达最后一个步骤后停止。只能指定两个选项中的一个。',
'## Class SummarySaverHook':'## 类摘要saverhook',
'Saves summaries every N steps.':'每n步保存摘要。',
'Initializes a SummarySaverHook.':'初始化SummarySaverHook。',
'## Class TrainSpec':'## 列车等级规范',
'Creates a validated TrainSpec instance.':'创建已验证的trainspec实例。',
'A validated TrainSpec object.':'已验证的trainspec对象。',
'Train and evaluate the estimator.':'训练和评估估计器。',
'Example of distributed training:':'分布式培训示例：',
#'    "cluster": {':'“群集”：{',
'## Class VocabInfo':'## Class 声乐',
#'   Example Usage:':'示例用法：',
'### axis':'### 轴线',
'## Class WarmStartSettings':'## 类warmstartsettings',
'THIS FUNCTION IS EXPERIMENTAL. Keras layers/models are the recommended APIs for logit and model composition.':'这个函数是实验性的。keras层/模型是logit和模型组合的推荐api。',
'## Class InMemoryEvaluatorHook':'## 类inMemoryEvaluatorHook',
'Hook to run evaluation in training without a checkpoint.':'在没有检查点的训练中进行挂钩运行评估。',
'Current limitations of this approach are:':'这种方法目前的局限性是：',
'Initializes a InMemoryEvaluatorHook.':'初始化InMemoryEvaluatorHook。',
'Does first run which shows the eval metrics before training.':'进行第一次跑步，显示训练前的评估指标。',
'Runs evaluator.':'运行Evaluator。',
'Build eval graph and restoring op.':'建立评估图并恢复操作。',
'Runs evaluator for final model.':'运行最终模型的计算器。',
'## Class LinearSDCA':'## 类linearsdca',
'Stochastic Dual Coordinate Ascent helper for linear estimators.':'线性估计器的随机对偶坐标上升辅助。',
'SDCA can only be used with LinearClassifier and LinearRegressor under the following conditions:':'在下列情况下，SDCA只能与LinearClassifier和LinearGressor一起使用：',
'Construct a new SDCA optimizer for linear estimators.':'构造一个新的线性估计sdca优化器。',
'Returns the training operation of an SdcaModel optimizer.':'返回SDCAModel优化器的训练操作。',
'#### Usage example:':'#### 用法示例：',
'Creates a proper StopAtCheckpointStepHook based on chief status.':'根据主要状态创建正确的StopAtcheckPointStephook。',
'## Class RNNClassifier':'## 类rnnclassifier',
'A classifier for TensorFlow RNN models.':'Tensorflow rnn模型的分类器。',
'Trains a recurrent neural network model to classify instances into one of multiple classes.':'训练递归神经网络模型，将实例分类为多个类中的一个。',
'Estimators are not compatible with eager execution.':'估计器与紧急执行不兼容。',
'Initializes a RNNClassifier instance.':'初始化rnnclassifier实例。',
'## Class RNNEstimator':'##RNnestImator类',
'Initializes a RNNEstimator instance.':'初始化rnnestimator实例。',
'Creates hook to stop if the given metric is higher than the threshold.':'如果给定的度量值高于阈值，则创建要停止的挂钩。',
'Creates hook to stop if metric does not decrease within given max steps.':'如果度量在给定的最大步数内没有减少，则创建要停止的挂钩。',
'Creates hook to stop if metric does not increase within given max steps.':'如果度量在给定的最大步数内没有增加，则创建要停止的挂钩。',
'Represents the output of a classification head.':'表示分类标题的输出。',
'Either classes or scores or both must be set.':'必须设置Class 或分数或两者。',
'Constructor for ClassificationOutput.':'用于分类输出的构造函数。',
'### classes':'### Class ',
'### scores':'### 分数',
'Generate a SignatureDef proto for inclusion in a MetaGraphDef.':'生成signaturedef proto以包含在metagraphdef中。',
'## Class ExportOutput':'## 类导出输出',
'Represents an output of a model that can be served.':'表示可以提供服务的模型的输出。',
'These typically correspond to model heads.':'这些通常对应于模型头。',
'## Class PredictOutput':'## 类预测输出',
'Represents the output of a generic prediction head.':'表示泛型预测头的输出。',
'A generic prediction need not be either a classification or a regression.':'一般预测不必是分类或回归。',
'Constructor for PredictOutput.':'PredictOutput的构造函数。',
'## Class RegressionOutput':'## 类回归输出',
'Represents the output of a regression head.':'表示回归头的输出。',
'Constructor for RegressionOutput.':'用于回归输出的构造函数。',
'## Class ServingInputReceiver':'## 服务类别',
'### features':'### 特点',
'## Class TensorServingInputReceiver':'## 类TensorServingImputreceiver',
'Context manager for setting the executor of eager defined functions.':'用于设置紧急定义函数的执行器的上下文管理器。',
'Eager defined functions are functions decorated by tf.contrib.eager.defun.':'急切定义的函数是由tf.contrib.eager.defun修饰的函数。',
'Represents discretized dense input.':'表示离散化的密集输入。',
#'    boundaries':'边界',
'A BucketizedColumn.':'一个bucketizedColumn。',
'Represents sparse feature where ids are set by hashing.':'表示通过哈希设置ID的稀疏特性。',
'A HashedCategoricalColumn.':'哈希分类列。',
'A CategoricalColumn that returns identity values.':'返回标识值的categoricalcolumn。',
'#### Linear model:':'#### 线性模型：',
'Embedding for a DNN model:':'DNN模型的嵌入：',
'Returns a column for performing crosses of categorical features.':'返回一列，用于执行分类功能的交叉。',
'then crossed feature will look like:':'然后交叉特征看起来像：',
'Here is an example to create a linear model with crosses of string features:':'下面是创建具有字符串交叉特征的线性模型的示例：',
'You could also use vocabulary lookup before crossing:':'也可以在交叉之前使用词汇表查找：',
'string: Will use the corresponding feature which must be of string type.':'string：将使用相应的特性，该特性必须是string类型。',
'A CrossedColumn.':'横列',
'DenseColumn that converts from sparse input.':'从稀疏输入转换的DenseColumn。',
'An IndicatorColumn.':'指示柱',
'Represents real valued or numerical features.':'表示实值或数值特征。',
'A NumericColumn.':'数字栏',
'A sequence of categorical terms where ids are set by hashing.':'通过哈希设置id的一系列分类术语。',
'A SequenceCategoricalColumn.':'SequenceCategoricalColumn。',
'Returns a feature column that represents sequences of integers.':'返回表示整数序列的特征列。',
'A sequence of categorical terms where ids use a vocabulary file.':'ids使用词汇表文件的一系列分类术语。',
'Returns a feature column that represents sequences of numeric data.':'返回表示数字数据序列的特征列。',
'A SequenceNumericColumn.':'序列数字列。',
'Applies weight values to a CategoricalColumn.':'将权重值应用于CategoricalColumn。',
'Input tf.Example objects:':'输入tf。示例对象：',
#'    feature {':'特征{',
#'      key: "terms"':'关键：“条款”',
#'      key: "frequencies"':'关键：“频率”',
'Adjust the brightness of RGB or Grayscale images.':'调整RGB或灰度图像的亮度。',
#'    delta':'三角洲',
'Adjust contrast of RGB or grayscale images.':'调整RGB或灰度图像的对比度。',
'Contrast is adjusted independently for each channel of each image.':'为每个图像的每个通道独立地调整对比度。',
'Performs Gamma Correction on the input image.':'对输入图像执行伽马校正。',
'Adjust hue of RGB images.':'调整rgb图像的色调。',
'image is an RGB image. The image hue is adjusted by converting the image(s) to HSV and rotating the hue channel (H) by delta. The image is then converted back to RGB.':'图像是RGB图像。通过将图像转换为hsv并将色调通道（h）旋转delta来调整图像色调。然后将图像转换回rgb。',
'Adjust jpeg encoding quality of an RGB image.':'调整RGB图像的JPEG编码质量。',
'This is a convenience method that adjusts jpeg encoding quality of an RGB image.':'这是一种调整rgb图像jpeg编码质量的方便方法。',
'Adjust saturation of RGB images.':'调整RGB图像的饱和度。',
'Crop the central region of the image(s).':'裁剪图像的中心区域。',
#'|        |':'||',
#'|  XXXX  |':'| XXXX|',
'Greedily selects a subset of bounding boxes in descending order of score.':'贪婪地按分数降序选择边界框的子集。',
'Crops an image to a specified bounding box.':'将图像裁剪到指定的边界框。',
'Extract patches from images.':'从图像中提取面片。',
#'   + 52  + 54  +  o 57  o 59  o':'+52+54+O 57-O 59度',
#'   + 72  + 74  +  o 77  o 79  o':'+72+74+O 77至79度',
#'   + 92  + 94  +  o 97  o 99  o':'+92+94+O 97-O 99度',
'Flip an image horizontally (left to right).':'水平翻转图像（从左到右）。',
'Outputs the contents of image flipped along the width dimension.':'输出沿宽度维度翻转的图像内容。',
'See also reverse().':'另请参见reverse（）。',
'A tensor of the same type and shape as image.':'张量与象具有相同类型和形状的张量',
'Flip an image vertically (upside down).':'垂直翻转图像（上下颠倒）。',
'Outputs the contents of image flipped along the height dimension.':'输出沿高度维度翻转的图像内容。',
'A Tensor of the same type and shape as image.':'张量与象具有相同类型和形状的张量',
'Converts one or more images from Grayscale to RGB.':'将一个或多个图像从灰度转换为RGB。',
'The converted grayscale image(s).':'转换的灰度图像。',
'Convert one or more images from HSV to RGB.':'将一个或多个图像从HSV转换为RGB。',
'Pad image with zeros to the specified height and width.':'将带有零的图像填充到指定的高度和宽度。',
'A Tensor with same shape and dtype as image.':'与图象形状和数据类型相同的张量。',
'This is intended to be used on signals (or images). Produces a PSNR value for each image in batch.':'这是用于信号（或图像）。为批处理中的每个图像生成psnr值。',
'Adjust the brightness of images by a random factor.':'通过随机因素调整图像的亮度。',
'Adjust the contrast of an image or images by a random factor.':'通过随机因素调整图像的对比度。',
'Randomly crops a tensor to a given size.':'随机将张量裁剪为给定大小。',
'A cropped tensor of the same rank as value and shape size.':'与值和形状大小等级相同的裁剪张量。',
'Randomly flip an image horizontally (left to right).':'水平（从左到右）随机翻转图像。',
'Randomly flips an image vertically (upside down).':'随机垂直翻转图像（上下颠倒）。',
'Adjust the hue of RGB images by a random factor.':'通过随机因素调整rgb图像的色调。',
'Randomly changes jpeg encoding quality for inducing jpeg noise.':'随机改变jpeg编码质量以产生jpeg噪声。',
'Adjust the saturation of RGB images by a random factor.':'通过随机因素调整rgb图像的饱和度。',
'Crops and/or pads an image to a target width and height.':'裁剪和/或将图像填充到目标宽度和高度。',
'Resizes an image to a target width and height by either centrally cropping the image or padding it evenly with zeros.':'通过集中裁剪图像或使用零均匀填充图像，将图像大小调整为目标宽度和高度。',
'Converts one or more images from RGB to Grayscale.':'将一个或多个图像从RGB转换为灰度。',
'Converts one or more images from RGB to HSV.':'将一个或多个图像从RGB转换为HSV。',
'Converts one or more images from RGB to YIQ.':'将一个或多个图像从rgb转换为yiq。',
'Converts one or more images from RGB to YUV.':'将一个或多个图像从rgb转换为yuv。',
'A rotated tensor of the same type and shape as image.':'一种旋转的张量，其类型和形状与图像相同。',
'Generate a single randomly distorted bounding box for an image.':'为图像生成一个随机扭曲的边界框。',
'Returns a tensor holding Sobel edge maps.':'返回包含sobel边映射的张量。',
'Computes SSIM index between img1 and img2.':'计算img1和img2之间的ssim索引。',
'#### Details:':'#### 详细信息：',
'The image sizes must be at least 11x11 because of the filter size.':'由于筛选器的大小，图像大小必须至少为11x11。',
'Calculate and return the total variation for one or more images.':'计算并返回一个或多个图像的总变化。',
'The total variation of images.':'图像的总变化。',
'Transpose image(s) by swapping the height and width dimension.':'通过交换高度和宽度维度来转置图像。',
'Converts one or more images from YIQ to RGB.':'将一个或多个图像从YIQ转换为RGB。',
'Converts one or more images from YUV to RGB.':'将一个或多个图像从YUV转换为RGB。',
'The attr channels indicates the desired number of color channels for the decoded image.':'attr channels指示解码图像所需的颜色通道数。',
'#### Accepted values are:':'#### 接受值为：',
'A Tensor of type uint8.':'uint8型张量。',
'Decompress strings.':'解压缩字符串。',
'A Tensor of type dtype.':'dtype类型的张量。',
'The op extracts fields from a serialized protocol buffers message into tensors.':'op将序列化协议缓冲区消息中的字段提取为张量。',
'Convert raw byte strings into tensors.':'将原始字节字符串转换为张量。',
'Deserialize and concatenate SparseTensors from a serialized minibatch.':'从序列化的小批量反序列化和连接SparSetensors。',
'then the final deserialized SparseTensor will be:':'那么最终的反序列化sparsetensor将是：',
'All of the serialized SparseTensors must have had the same rank and type.':'所有序列化的sparsetensors必须具有相同的秩和类型。',
'The attr format can be used to override the color format of the encoded output. Values can be:':'attr格式可用于覆盖编码输出的颜色格式。值可以是：',
'The op serializes protobuf messages provided in the input tensors.':'op序列化输入张量中提供的protobuf消息。',
'The sizes tensor specifies repeat counts for each field. The repeat count (last dimension) of a each tensor in values must be greater than or equal to corresponding repeat count in sizes.':'size张量指定每个字段的重复计数。值中每个张量的重复计数（最后一个维度）必须大于或等于相应的大小重复计数。',
'## Class FixedLenFeature':'## 类FixedLenFeature',
'## Class FixedLenSequenceFeature':'## 类FixedLenSequenceFeature',
'Convenience function to check if the \'contents\' encodes a JPEG image.':'检查“内容”是否编码JPEG图像的便利功能。',
'Returns the set of files matching one or more glob patterns.':'返回与一个或多个全局模式匹配的文件集。',
'NOTE: The order of the files returned is deterministic.':'注意：返回文件的顺序是确定的。',
'A variable that is initialized to the list of files matching the pattern(s).':'初始化为与模式匹配的文件列表的变量。',
'Parses a batch of SequenceExample protos.':'解析一批SequenceExample原型。',
'Parses a single SequenceExample proto.':'解析一个SequenceExample原型。',
'Transforms a serialized tensorflow.TensorProto proto into a Tensor.':'将序列化的tensorflow.tensor proto proto转换为张量。',
'Reads and outputs the entire contents of the input filename.':'读取并输出输入文件名的全部内容。',
'Transforms a Tensor into a serialized TensorProto proto.':'将张量转换为序列化的张量proto。',
'## Class SparseFeature':'## 类稀疏特征',
'Configuration for parsing a sparse input feature from an Example.':'用于从示例分析稀疏输入功能的配置。',
' features {':'功能{',
'## Class TFRecordOptions':'## 类tfrecordoptions',
'Options used for manipulating TFRecord files.':'用于操作tfrecord文件的选项。',
'Creates a TFRecordOptions instance.':'创建tfrecordoptions实例。',
'A TFRecordOptions object.':'一个tfrecordoptions对象。',
#'    options':'选项',
'Convert various option types to a unified string.':'将各种选项类型转换为统一字符串。',
'A class to write records to a TFRecords file.':'将记录写入tfrecords文件的类。',
'Opens file path and creates a TFRecordWriter writing to it.':'打开文件路径并创建对其进行写入的tfrecordwriter。',
'Enter a with block.':'输入带块的。',
'Close the file.':'关闭文件。',
'Flush the file.':'刷新文件。',
'Write a string record to the file.':'将字符串记录写入文件。',
'## Class VarLenFeature':'## 类varlenfeature',
'Writes contents to the file at input filename. Creates file and recursively':'在输入文件名处将内容写入文件。创建文件并递归',
'creates directory if not existing.':'创建目录（如果不存在）。',
'Copies data from src to dst.':'将数据从src复制到dst。',
'## Class GFile':'##G类文件',
'It succeeds if path already exists and is writable.':'如果路径已存在且可写，则会成功。',
'Creates a directory with the name given by \'path\'.':'使用“path”给定的名称创建目录。',
'Deletes the path located at \'path\'.':'删除位于“path”的路径。',
'Deletes everything under path recursively.':'递归删除路径下的所有内容。',
'Input() is used to instantiate a Keras tensor.':'input（）用于实例化keras张量。',
'A tensor.':'张量',
'## Class Model':'## 类模型',
'Model groups layers into an object with training and inference features.':'模型将层分组到具有训练和推理功能的对象中。',
'There are two ways to instantiate a Model:':'有两种方法可以实例化模型：',
'### layers':'### 层数',
'Returns the model\'s display labels for all outputs.':'返回所有输出的模型显示标签。',
'Settable attribute indicating whether the model should run eagerly.':'可设置属性，指示模型是否应立即运行。',
'Returns the updates from all layers that are stateful.':'返回所有有状态层的更新。',
'A list of update ops.':'更新操作列表。',
'### stateful':'### 有状态的',
'### compile':'### 编译',
'Configures the model for training.':'配置用于培训的模型。',
'Returns the loss value & metrics values for the model in test mode.':'返回测试模式下模型的损失值和度量值。',
'Computation is done in batches.':'计算是分批进行的。',
'A `tf.data` dataset.':'一个“tf.data”数据集。',
'A generator or `keras.utils.Sequence` instance.':'生成器或“keras.utils.sequence”实例。',
'Evaluates the model on a data generator.':'在数据生成器上计算模型。',
'### fit':'### 适合',
'Trains the model for a fixed number of epochs (iterations on a dataset).':'为固定数量的阶段（数据集上的迭代）训练模型。',
'a `generator` for the validation data':'验证数据的“生成器”',
'A History object.':'历史对象。',
#'        while 1:':'当1：',
'Raises: ValueError: In case the generator yields data in an invalid format.':'引发：valueerror：以防生成器生成无效格式的数据。',
'Retrieves a layer based on either its name (unique) or index.':'根据层的名称（唯一）或索引检索层。',
'A layer instance.':'层实例。',
'Generates output predictions for the input samples.':'为输入样本生成输出预测。',
'Numpy array(s) of predictions.':'预测的numpy数组。',
'Generates predictions for the input samples from a data generator.':'从数据生成器生成输入样本的预测。',
'Returns predictions for a single batch of samples.':'返回一批样本的预测。',
'Resets the state of metrics.':'重置度量的状态。',
'Saves the model to Tensorflow SavedModel or a single HDF5 file.':'将模型保存到tensorflow savedmodel或单个hdf5文件。',
'#### The savefile includes:':'#### 保存文件包括：',
'This allows you to save the entirety of the state of a model in a single file.':'这允许您将模型的整个状态保存在单个文件中。',
'del model  # deletes the existing model':'del model删除现有模型',
'Saves all layer weights.':'保存所有层权重。',
'Prints a string summary of the network.':'打印网络的字符串摘要。',
'Test the model on a single batch of samples.':'在一批样品上测试模型。',
'Returns a JSON string containing the network configuration.':'返回包含网络配置的json字符串。',
'A JSON string.':'一个json字符串。',
'Returns a yaml string containing the network configuration.':'返回包含网络配置的yaml字符串。',
'A YAML string.':'一根山药线。',
'Runs a single gradient update on a single batch of data.':'对一批数据运行单一渐变更新。',
'## Class Sequential':'## 类序列',
'Linear stack of layers.':'线性层叠。',
'model.weights  # returns []':'model.weights返回[]',
'model.weights  # returns list of length 4':'model.weights返回长度为4的列表',
'Adds a layer instance on top of the layer stack.':'在层堆栈的顶部添加层实例。',
'### pop':'### 流行音乐',
'Removes the last layer in the model.':'删除模型中的最后一层。',
'Generate class predictions for the input samples.':'为输入样本生成类预测。',
'The input samples are processed batch by batch.':'输入的样本逐批处理。',
'A numpy array of class predictions.':'类预测的numpy数组。',
'Generates class probability predictions for the input samples.':'为输入样本生成类概率预测。',
'A Numpy array of probability predictions.':'一系列的概率预测。',
'Exponential linear unit.':'指数线性单位。',
'#### Reference:':'#### 参考：',
'Exponential activation function.':'指数激活函数。',
'The exponential activation: exp(x).':'指数激活：exp（x）。',
'Hard sigmoid activation function.':'硬乙状结肠激活功能。',
'Faster to compute than sigmoid activation.':'计算速度比乙状结肠激活快。',
'Linear activation function.':'线性激活函数。',
'The linear activation: x.':'线性激活：x。',
'Rectified Linear Unit.':'整流线性单元。',
'Scaled Exponential Linear Unit (SELU).':'标度指数线性单位（selu）。',
'#### Example Usage:':'#### 示例用法：',
'Sigmoid.':'乙状结肠。',
'Sigmoid activation function.':'乙状结肠激活功能。',
'The softmax activation function transforms the outputs so that all values are in':'SoftMax激活函数转换输出，以便所有值都在',
'Softplus activation function.':'SoftPlus激活功能。',
'The softplus activation: log(exp(x) + 1).':'softplus激活：log（exp（x）+1）。',
'Softsign activation function.':'软标志激活功能。',
'The softplus activation: x / (abs(x) + 1).':'SoftPlus激活：x/（abs（x）+1）。',
'Hyperbolic Tangent (tanh) activation function.':'双曲正切（tanh）激活函数。',
'Arguments: x: Input tensor.':'参数：x：输入张量。',
'Bitwise reduction (logical AND).':'按位缩减（逻辑和）。',
'Bitwise reduction (logical OR).':'按位缩减（逻辑或）。',
'Creates a 1D tensor containing a sequence of integers.':'创建包含整数序列的一维张量。',
'The default type of the returned tensor is \'int32\' to match TensorFlow\'s default.':'返回的张量的默认类型为“int32”，以匹配Tensorflow 的默认类型。',
'An integer tensor.':'整数张量。',
'Returns the index of the maximum value along an axis.':'返回沿轴的最大值的索引。',
'Returns the index of the minimum value along an axis.':'返回沿轴的最小值的索引。',
'Publicly accessible method for determining the current backend.':'用于确定当前后端的公共访问方法。',
'The string "tensorflow".':'字符串“tensorflow”。',
'Batchwise dot product.':'批量点产品。',
'Flattening a 3D tensor to 2D by collapsing the last dimension.':'通过折叠最后一个维度将三维张量展平到二维。',
'Returns the value of more than one tensor variable.':'返回多个张量变量的值。',
'A list of Numpy arrays.':'numpy数组的列表。',
'Sets the values of many tensor variables at once.':'同时设置多个张量变量的值。',
'Adds a bias vector to a tensor.':'将偏移向量添加到张量。',
'Binary crossentropy between an output tensor and a target tensor.':'输出张量和目标张量之间的二元交叉熵。',
'Casts a tensor to a different dtype and returns it.':'将张量转换为不同的数据类型并返回它。',
'You can cast a Keras variable but it still returns a Keras tensor.':'可以强制转换keras变量，但它仍然返回keras张量。',
'Keras tensor with dtype dtype.':'具有dtype-dtype的keras张量。',
'Cast a float32 variable to a float64 tensor':'将float32变量转换为float64张量',
'Cast a Numpy array to the default Keras float type.':'将numpy数组强制转换为默认的keras float类型。',
'Categorical crossentropy between an output tensor and a target tensor.':'输出张量和目标张量之间的范畴交叉熵。',
#'    from tensorflow.keras import backend as K':'从tensorflow.keras导入后端作为k',
'Destroys the current TF graph and creates a new one.':'破坏当前的tf图并创建一个新的tf图。',
'Useful to avoid clutter from old models / layers.':'有助于避免旧模型/层的混乱。',
'Concatenates a list of tensors alongside the specified axis.':'沿着指定轴连接一个张量列表。',
'transposed convolution).':'转置卷积）。',
'Returns the static number of elements in a variable or tensor.':'返回变量或张量中元素的静态数目。',
'Runs CTC loss algorithm on each batch element.':'对每个批处理元素运行CTC丢失算法。',
'Tensor with shape (samples,1) containing the CTC loss of each element.':'形状张量（样本，1），包含每个元素的CTC损失。',
'Decodes the output of a softmax.':'解码SoftMax的输出。',
'Can use either greedy search (also known as best path) or a constrained dictionary search.':'可以使用贪婪搜索（也称为最佳路径）或约束字典搜索。',
'Converts CTC labels from dense to sparse.':'将CTC标签从密集转换为稀疏。',
'A sparse tensor representation of the labels.':'标签的稀疏张量表示。',
'A tensor of the cumulative product of values of x along axis.':'x值沿轴的累积乘积的张量。',
'A tensor of the cumulative sum of values of x along axis.':'x沿轴的累积和的张量。',
'Multiplies 2 tensors (and/or variables) and returns a tensor.':'乘以2个张量（和/或变量）并返回一个张量。',
'Returns the value of the fuzz factor used in numeric expressions.':'返回数值表达式中使用的模糊因子的值。',
'A float.':'漂浮物',
'A bool tensor.':'布尔张量',
'Evaluates the value of a variable.':'计算变量的值。',
'A Numpy array.':'一个核阵列。',
'A tensor with expanded dimensions.':'具有扩展维度的张量。',
'Instantiate an identity matrix and returns it.':'实例化一个标识矩阵并返回它。',
'Flatten a tensor.':'使张量变平。',
#'    &gt;&gt;&gt; b':'&gt；gt；gt；b',
' keras.backend.floatx() >>> \'float32\'':'keras.backend.floatx（）>>>“浮动32”',
'Reduce elems using fn to combine them from left to right.':'使用fn从左到右合并元素来减少元素。',
'Tensor with same type and shape as initializer.':'与初始值设定项具有相同类型和形状的张量。',
'Reduce elems using fn to combine them from right to left.':'使用fn从右到左合并元素来减少元素。',
'Same type and shape as initializer':'与初始值设定项相同的类型和形状',
'Instantiates a Keras function.':'实例化一个keras函数。',
'Output values as Numpy arrays.':'将值输出为numpy数组。',
'Retrieves the elements of indices indices in the tensor reference.':'检索张量引用中索引索引的元素。',
#'    indices':'指数',
'A tensor of same type as reference.':'与参照物类型相同的张量。',
'Associates a string prefix with an integer counter in a TensorFlow graph.':'将字符串前缀与TensorFlow图中的整数计数器相关联。',
'Unique integer ID.':'唯一整数ID。',
'Returns the value of a variable.':'返回变量的值。',
'Returns the gradients of loss w.r.t. variables.':'返回损失w.r.t.变量的梯度。',
#'    variables':'变量',
'A gradients tensor.':'梯度张量。',
'Returns the default image data format convention.':'返回默认图像数据格式约定。',
'Returns the shape of tensor or variable as a tuple of int or None entries.':'将张量或变量的形状作为int或none项的元组返回。',
'A tuple of integers (or None entries).':'整数的元组（或无项）。',
'Note that alt should have the same shape as x.':'注意alt应该具有与x相同的形状。',
'Returns whether the targets are in the top k predictions.':'返回目标是否在前k个预测中。',
#'    k':'千',
'Returns whether x is a Keras tensor.':'返回x是否为keras张量。',
'A boolean: Whether the argument is a Keras tensor.':'布尔值：参数是否为keras张量。',
#'    ValueError':'值错误',
#'    keras is not a Keras tensor.':'keras不是keras张量。',
#'    False':'假',
#'    backend is not a Keras tensor.':'后端不是keras张量。',
#'    tensor.':'张量。',
#'    True':'真的',
#'    Keras tensor.':'凯拉斯张量。',
'Returns whether a tensor is a sparse tensor.':'返回张量是否为稀疏张量。',
'A boolean.':'布尔值。',
'Normalizes a tensor wrt the L2 norm alongside the specified axis.':'规范化与指定轴的l2范数相关的张量。',
'Returns the learning phase flag.':'返回学习阶段标志。',
'Learning phase (scalar integer tensor or Python integer).':'学习阶段（标量整数张量或python整数）。',
'Provides a scope within which the learning phase is equal to value.':'提供学习阶段等于价值的范围。',
'The learning phase gets restored to its original value upon exiting the scope.':'在退出作用域时，学习阶段将恢复到其原始值。',
'Sets the manual variable initialization flag.':'设置手动变量初始化标志。',
'Map the function fn over the elements elems and return the outputs.':'将函数fn映射到元素元素上并返回输出。',
'Tensor with dtype dtype.':'具有dtype-dtype的张量。',
'Maximum value in a tensor.':'张量的最大值。',
'A tensor with maximum values of x.':'最大值为x的张量。',
'A tensor with the element wise maximum value(s) of x and y.':'元素最大值为x和y的张量。',
'A tensor with the mean of elements of x.':'具有x元素平均值的张量。',
'Minimum value in a tensor.':'张量的最小值。',
'A tensor with minimum values of x.':'最小值为x的张量。',
'Compute the moving average of a variable.':'计算变量的移动平均值。',
#'    momentum':'动量',
'An Operation to update the variable.':'更新变量的操作。',
'Name scope context manager.':'命名作用域上下文管理器。',
'A Keras variable with the shape of x filled with ones.':'一个x形状的keras变量，其中填充了一个。',
'Permutes axes in a tensor.':'在张量中排列轴。',
#'    pattern':'图案',
#'    &gt;&gt;&gt; a':'&gt；gt；gt；a',
'Instantiates a placeholder tensor and returns it.':'实例化占位符张量并返回它。',
'Tensor instance (with Keras metadata included).':'Tensor实例（包括Keras元数据）。',
#'    a':'一',
'Prints message and the tensor value when evaluated.':'计算时打印消息和张量值。',
#'   ':'',
'A tensor with the product of elements of x.':'具有x元素乘积的张量。',
'Returns a tensor with random binomial distribution of values.':'返回值随机二项分布的张量。',
'Returns a tensor with normal distribution of values.':'返回值正态分布的张量。',
'Instantiates a variable with values drawn from a normal distribution.':'用从正态分布中提取的值实例化变量。',
'Returns a tensor with uniform distribution of values.':'返回值均匀分布的张量。',
'Instantiates a variable with values drawn from a uniform distribution.':'使用从统一分布中提取的值实例化变量。',
'Rectified linear unit.':'整流线性单元。',
'Repeats a 2D tensor.':'重复二维张量。',
#'    n':'n个',
'Resets graph identifiers.':'重置图形标识符。',
'Reshapes a tensor to the specified shape.':'将张量重塑为指定形状。',
#'    shape':'形状',
'Resizes the images contained in a 4D tensor.':'调整包含在4D张量中的图像的大小。',
'Resizes the volume contained in a 5D tensor.':'调整包含在5d张量中的体积的大小。',
'Reverse a tensor along the specified axes.':'沿指定轴反转张量。',
#'    axes':'轴',
'Iterates over the time dimension of a tensor.':'在张量的时间维上迭代。',
'Sets the value of the fuzz factor used in numeric expressions.':'设置数值表达式中使用的模糊因子的值。',
'Sets the default float type.':'设置默认浮点类型。',
'Sets the value of the image data format convention.':'设置图像数据格式约定的值。',
'Sets the learning phase to a fixed value.':'将学习阶段设置为固定值。',
'Returns the symbolic shape of a tensor or variable.':'返回张量或变量的符号形状。',
'A symbolic shape (which is itself a tensor).':'一种符号形状（它本身就是张量）。',
'Softmax of a tensor.':'张量的softmax。',
'Softplus of a tensor.':'张量的软加。',
'Softsign of a tensor.':'张量的软符号。',
'Categorical crossentropy with integer targets.':'带整数目标的分类交叉熵。',
'Pads the 2nd and 3rd dimensions of a 4D tensor.':'垫4D张量的第2和第3维度。',
'A padded 4D tensor.':'加垫的4D张量。',
'A padded 5D tensor.':'加垫的5维张量。',
'A tensor with the same data as x but reduced dimensions.':'具有与x相同数据但维数减少的张量。',
'Stacks a list of rank R tensors into a rank R+1 tensor.':'将秩r张量的列表堆叠成秩r+1张量。',
'A tensor with the standard deviation of elements of x.':'具有x元素标准差的张量。',
'Returns variables but with zero gradient w.r.t. every other variable.':'返回变量，但梯度为零，w.r.t.每隔一个变量。',
'A single tensor or a list of tensors (depending on the passed argument) that has no gradient with respect to any other variable.':'单个张量或张量列表（取决于传递的参数），与任何其他变量都没有梯度。',
'A tensor with sum of x.':'和为x的张量。',
'Switches between two operations depending on a scalar value.':'根据标量值在两个操作之间切换。',
'The selected tensor.':'选定的张量。',
'Pads the middle dimension of a 3D tensor.':'填充三维张量的中间尺寸。',
'A padded 3D tensor.':'填充的三维张量。',
'Creates a tensor by tiling x by n.':'通过将x平铺为n来创建张量。',
'A tiled tensor.':'平铺张量',
'Converts a sparse tensor into a dense tensor and returns it.':'将稀疏张量转换为密集张量并返回它。',
'A dense tensor.':'密集的张量。',
'Transposes a tensor and returns it.':'转换张量并返回它。',
'Returns a tensor with truncated random normal distribution of values.':'返回值的截断随机正态分布的张量。',
'Update the value of x by adding increment.':'通过添加增量来更新x的值。',
#'    increment':'增量',
'The variable x updated.':'变量x已更新。',
'Update the value of x by subtracting decrement.':'通过减去减量来更新x的值。',
#'    decrement':'减量',
'A tensor with the variance of elements of x.':'具有x元素方差的张量。',
'Instantiates a variable and returns it.':'实例化变量并返回它。',
'A variable instance (with Keras metadata included).':'变量实例（包括keras元数据）。',
' from tensorflow.keras import backend as K':'从tensorflow.keras导入后端作为k',
'A Keras variable with the shape of x filled with zeros.':'x形状为零的keras变量。',
'## Class BaseLogger':'## 基于类的记录器',
'Callback that accumulates epoch averages of metrics.':'累积度量的纪元平均值的回调。',
'This callback is automatically applied to every Keras model.':'此回调将自动应用于每个keras模型。',
'Called at the start of an epoch.':'在一个新纪元开始时被召唤。',
'Subclasses should override for any actions to run. This function should only be called during TRAIN mode.':'子类应该重写以运行任何操作。此功能只能在列车模式下调用。',
'Called at the end of an epoch.':'在一个时代结束时被召唤。',
'## Class Callback':'## 类回调',
'Abstract base class used to build new callbacks.':'用于生成新回调的抽象基类。',
'The logs dictionary that callback methods take as argument will contain keys for quantities relevant to the current batch or epoch.':'回调方法用作参数的日志字典将包含与当前批处理或epoch相关的数量的键。',
#'    (if validation and accuracy monitoring are enabled).':'（如果启用验证和精度监控）。',
#'    the number of samples in the current batch.':'当前批次中的样本数。',
#'    (if accuracy monitoring is enabled).':'（如果启用精度监控）。',
'## Class CSVLogger':'##CSV级记录器',
'Callback that streams epoch results to a csv file.':'将epoch结果流式处理到csv文件的回调。',
'## Class EarlyStopping':'## Class 早起',
'Stop training when a monitored quantity has stopped improving.':'当监控量停止改善时，停止训练。',
'## Class History':'## Class 历史',
'Callback that records events into a History object.':'将事件记录到历史对象中的回调。',
'This callback is automatically applied to every Keras model. The History object gets returned by the fit method of models.':'此回调将自动应用于每个keras模型。历史对象由模型的fit方法返回。',
'## Class LambdaCallback':'## 类lambdacallback',
'## Class LearningRateScheduler':'## 类LearningRateScheduler',
'Learning rate scheduler.':'学习速率调度程序。',
'## Class ModelCheckpoint':'## 类模型检查点',
'Save the model after every epoch.':'在每个纪元之后保存模型。',
'## Class ProgbarLogger':'## 类progbarlogger',
'Callback that prints metrics to stdout.':'将指标打印到stdout的回调。',
'## Class ReduceLROnPlateau':'## 类还原隆平台',
'Reduce learning rate when a metric has stopped improving.':'当指标停止改善时，降低学习率。',
'## Class RemoteMonitor':'## 类远程监视器',
'Callback used to stream events to a server.':'用于将事件流式处理到服务器的回调。',
'Runs metrics and histogram summaries at epoch end.':'在历元结束时运行度量和直方图摘要。',
'Sets Keras model and writes graph if specified.':'设置keras模型并在指定时写入图形。',
'## Class TerminateOnNaN':'## 班底南',
'Callback that terminates training when a NaN loss is encountered.':'在遇到NaN丢失时终止训练的回调。',
'## Class Constraint':'## 类约束',
'## Class MaxNorm':'## 类maxnorm',
'MaxNorm weight constraint.':'最大范数权重约束。',
'Constrains the weights incident to each hidden unit to have a norm less than or equal to a desired value.':'约束每个隐藏单元的权重，使其范数小于或等于所需值。',
'## Class MinMaxNorm':'##minmaxnorm类',
'MinMaxNorm weight constraint.':'minmaxnorm权重约束。',
'Constrains the weights incident to each hidden unit to have the norm between a lower bound and an upper bound.':'约束每个隐藏单元的权重在下限和上限之间具有范数。',
'## Class NonNeg':'## 非负类',
'## Class RadialConstraint':'## 类半径约束',
'Constrains Conv2D kernel weights to be the same for each radius.':'约束每个半径的conv2d核权重相同。',
'is this::':'这是：',
'## Class UnitNorm':'## 类单位规范',
'Constrains the weights incident to each hidden unit to have unit norm.':'将关联到每个隐藏单元的权重约束为具有单元范数。',
'Loads the Boston Housing dataset.':'加载波士顿住房数据集。',
'#### License:':'#### 许可证：',
'Loads the IMDB dataset.':'加载imdb数据集。',
'Loads the MNIST dataset.':'加载mnist数据集。',
'Retrieves the dictionary mapping word indices back to words.':'检索将单词索引映射回单词的词典。',
'The word index dictionary.':'单词索引字典。',
'Loads the Reuters newswire classification dataset.':'加载路透社新闻专线分类数据集。',
'Functions':'功能',
'Return an Initializer object from its config.':'从其配置返回初始值设定项对象。',
'## Class GlorotNormal':'## 类glorotnormal',
'## Class GlorotUniform':'##glorotuniform类',
'## Class AbstractRNNCell':'## 抽象类',
'This is the base class for implementing RNN cells with custom behavior.':'这是用自定义行为实现RNN单元的基类。',
'## Class Activation':'## 类激活',
'Applies an activation function to an output.':'对输出应用激活函数。',
'## Class ActivityRegularization':'## Class 活动规范化',
'Layer that applies an update to the cost function based input activity.':'对基于成本函数的输入活动应用更新的层。',
'## Class Add':'## 类添加',
'Layer that adds a list of inputs.':'添加输入列表的层。',
'## Class AdditiveAttention':'## 类相加',
'#### Call Arguments:':'#### 调用参数：',
'Here is a code example for using AdditiveAttention in a CNN+Attention network:':'下面是在CNN+注意力网中使用加法运算的代码示例：',
'## Class AlphaDropout':'## 字母辍学',
'Applies Alpha Dropout to the input.':'对输入应用Alpha Dropout。',
'## Class Attention':'## 全班注意',
'Here is a code example for using Attention in a CNN+Attention network:':'以下是在CNN+注意力网中使用注意力的代码示例：',
'## Class Average':'## 平均水平',
'Layer that averages a list of inputs.':'平均输入列表的层。',
'Average pooling for temporal data.':'时态数据的平均池。',
'## Class AveragePooling2D':'## 类平均池2d',
'Average pooling operation for spatial data.':'空间数据的平均池操作。',
'## Class Bidirectional':'## 类双向',
'Bidirectional wrapper for RNNs.':'RNN的双向包装。',
'The call arguments for this layer are the same as those of the wrapped RNN layer.':'此层的调用参数与包装的rnn层的调用参数相同。',
'### constraints':'### 约束条件',
'## Class Concatenate':'## 类连接',
'Layer that concatenates a list of inputs.':'连接输入列表的层。',
'Transposed convolution layer (sometimes called Deconvolution).':'转置卷积层（有时称为反卷积）。',
'## Class ConvLSTM2D':'##ConvlstM2D级',
'Convolutional LSTM.':'卷积LSTM。',
'### filters':'### 过滤器',
'### padding':'### 衬垫',
'### strides':'### 跨步',
'## Class Cropping1D':'## 等级裁剪1d',
'Cropping layer for 1D input (e.g. temporal sequence).':'用于1D输入的裁剪层（例如时间序列）。',
'It crops along the time dimension (axis 1).':'它沿着时间维度（轴1）生长。',
'## Class Cropping2D':'## Class 裁剪2d',
'Cropping layer for 2D input (e.g. picture).':'用于二维输入的裁剪层（如图片）。',
'If int: the same symmetric `cropping` is applied to height and width.':'if int：对高度和宽度应用相同的对称“裁剪”。',
'## Class Cropping3D':'## 类裁剪3d',
'Creates a DenseFeatures object.':'创建DenseFeatures对象。',
'## Class DepthwiseConv2D':'## 等级DepthwiseConv2',
'Instantiates a layer from a config dictionary.':'从配置字典实例化层。',
'## Class Dot':'## 类点',
'Layer that computes a dot product between samples in two tensors.':'计算两个张量中样本之间的点积的层。',
'## Class ELU':'##ELU类',
'Exponential Linear Unit.':'指数线性单位。',
'#### It follows:':'#### 它如下：',
'Same shape as the input.':'与输入形状相同。',
'## Class Embedding':'## 类嵌入',
'Turns positive integers (indexes) into dense vectors of fixed size.':'将正整数（索引）转换为固定大小的密集向量。',
'This layer can only be used as the first layer in a model.':'此层只能用作模型中的第一层。',
'Flattens the input. Does not affect the batch size.':'使输入变平。不影响批处理大小。',
'## Class GaussianDropout':'##Gaussiandropout类',
'## Class GaussianNoise':'## 高斯噪声类',
'This is useful to mitigate overfitting (you could see it as a form of random data augmentation). Gaussian Noise (GS) is a natural choice as corruption process for real valued inputs.':'这有助于缓解过度拟合（您可以将其视为随机数据增加的一种形式）。高斯噪声（GS）是一种自然选择，作为实际值输入的腐败过程。',
'## Class GlobalAveragePooling1D':'## 类globalaveragepooling1d',
'Global average pooling operation for temporal data.':'时态数据的全局平均池操作。',
'## Class GlobalAveragePooling2D':'## 类全局平均池2d',
'Global average pooling operation for spatial data.':'空间数据的全局平均池操作。',
'## Class GlobalAveragePooling3D':'## 类全局平均池3d',
'Global Average pooling operation for 3D data.':'三维数据的全局平均池操作。',
'## Class GlobalMaxPool1D':'## 类globalmaxpool1d',
'Global max pooling operation for temporal data.':'时态数据的全局最大池操作。',
'## Class GlobalMaxPool2D':'## 类globalmaxpool2d',
'Global max pooling operation for spatial data.':'空间数据的全局最大池操作。',
'## Class GlobalMaxPool3D':'## 类globalMaxPool3D',
'Global Max pooling operation for 3D data.':'三维数据的全局最大池操作。',
'## Class GRU':'##GRU类',
'The requirements to use the cuDNN implementation are:':'使用CUDNN实现的要求如下：',
'## Class InputLayer':'## 类输入层',
'Layer to be used as an entry point into a Network (a graph of layers).':'用作网络入口点的层（层的图形）。',
'## Class InputSpec':'## 类输入规范',
'## Class Lambda':'##lambda类',
'Wraps arbitrary expressions as a Layer object.':'将任意表达式包装为层对象。',
'Example of variable creation:':'变量创建示例：',
'Note that creating two instances of Lambda using the same function will not share Variables between the two instances. Each instance of Lambda will create and manage its own weights.':'请注意，使用同一函数创建lambda的两个实例不会在两个实例之间共享变量。lambda的每个实例都将创建和管理自己的权重。',
'This is the class from which all layers inherit.':'这是所有层都从中继承的类。',
'Users will just instantiate a layer and then treat it as a callable.':'用户只需实例化一个层，然后将其视为可调用的。',
'We recommend that descendants of Layer implement the following methods:':'我们建议层的后代实现以下方法：',
'### Dtypes and casting':'###D类型和铸造',
'#### Running models in float64 in TensorFlow 2':'####Tensorflow 2中float64中的运行模型',
'Optional regularizer function for the output of this layer.':'此层输出的可选正则化函数。',
'### dynamic':'### 动态的',
'Retrieves the input tensor(s) of a layer.':'检索层的输入张量。',
'Input tensor or list of input tensors.':'输入张量或输入张量列表。',
'Retrieves the input mask tensor(s) of a layer.':'检索层的输入掩码张量。',
'Input mask tensor (potentially None) or list of input mask tensors.':'输入掩码张量（可能为无）或输入掩码张量列表。',
'Retrieves the input shape(s) of a layer.':'检索层的输入形状。',
'### losses':'### 损失',
'Losses which are associated with this Layer.':'与该层相关的损失。',
'A list of tensors.':'张量表。',
'### output':'### 输出',
'Retrieves the output tensor(s) of a layer.':'检索层的输出张量。',
'Output tensor or list of output tensors.':'输出张量或输出张量列表。',
'Retrieves the output mask tensor(s) of a layer.':'检索层的输出掩码张量。',
'Output mask tensor (potentially None) or list of output mask tensors.':'输出掩码张量（可能为无）或输出掩码张量列表。',
'Retrieves the output shape(s) of a layer.':'检索层的输出形状。',
'### updates':'### 更新',
'Returns the list of all layer variables/weights.':'返回所有图层变量/权重的列表。',
'Alias of self.weights.':'self.weights的别名。',
'### weights':'### 重量',
'Output tensor(s).':'输出张量。',
'Adds metric tensor to the layer.':'向层添加度量张量。',
'Adds a new variable to the layer.':'向图层添加新变量。',
'This is typically used to create the weights of Layer subclasses.':'这通常用于创建层子类的权重。',
'### call':'### 呼叫',
'This is where the layer\'s logic lives.':'这就是层的逻辑所在。',
'A tensor or list/tuple of tensors.':'张量或张量的列表/元组。',
'Computes an output mask tensor.':'计算输出遮罩张量。',
'Computes the output shape of the layer.':'计算层的输出形状。',
'An input shape tuple.':'输入形状元组。',
'Compute the output tensor signature of the layer based on the inputs.':'根据输入计算层的输出张量特征。',
'Count the total number of scalars composing the weights.':'计算组成权重的标量总数。',
'An integer count.':'整数计数。',
'Creates a layer from its config.':'从其配置创建层。',
'Returns the config of the layer.':'返回层的配置。',
'A layer config is a Python dictionary (serializable) containing the configuration of a layer. The same layer can be reinstantiated later (without its trained weights) from this configuration.':'层配置是包含层配置的python字典（可序列化）。同一层可以稍后从该配置重新实例化（无需经过训练的权重）。',
'Python dictionary.':'python字典。',
'Retrieves the input tensor(s) of a layer at a given node.':'检索给定节点处的层的输入张量。',
'A tensor (or list of tensors if the layer has multiple inputs).':'张量（或张量列表，如果层有多个输入）。',
'Retrieves the input mask tensor(s) of a layer at a given node.':'检索给定节点处的层的输入掩码张量。',
'A mask tensor (or list of tensors if the layer has multiple inputs).':'遮罩张量（或张量列表，如果层有多个输入）。',
'Retrieves the input shape(s) of a layer at a given node.':'检索给定节点处的层的输入形状。',
'A shape tuple (or list of shape tuples if the layer has multiple inputs).':'形状元组（如果层有多个输入，则为形状元组列表）。',
'Retrieves losses relevant to a specific set of inputs.':'检索与特定输入集相关的丢失。',
'List of loss tensors of the layer that depend on inputs.':'依赖于输入的层的损耗张量列表。',
'Retrieves the output tensor(s) of a layer at a given node.':'检索给定节点处层的输出张量。',
'A tensor (or list of tensors if the layer has multiple outputs).':'张量（或张量列表，如果层有多个输出）。',
'Retrieves the output mask tensor(s) of a layer at a given node.':'检索给定节点处的层的输出掩码张量。',
'A mask tensor (or list of tensors if the layer has multiple outputs).':'遮罩张量（或张量列表，如果层有多个输出）。',
'Retrieves the output shape(s) of a layer at a given node.':'检索给定节点处的层的输出形状。',
'A shape tuple (or list of shape tuples if the layer has multiple outputs).':'形状元组（如果层有多个输出，则为形状元组列表）。',
'Retrieves updates relevant to a specific set of inputs.':'检索与特定输入集相关的更新。',
'List of update ops of the layer that depend on inputs.':'依赖于输入的层的更新操作列表。',
'Returns the current weights of the layer.':'返回层的当前权重。',
'Weights values as a list of numpy arrays.':'将值作为numpy数组的列表进行加权。',
'## Class LayerNormalization':'## 类层规范化',
'## Class LeakyReLU':'## 类leakyrelu',
'Leaky version of a Rectified Linear Unit.':'校正线性单元的泄漏版本。',
'## Class LocallyConnected1D':'## 类locallyconnected1d',
'How to choose:':'如何选择：',
'## Class LocallyConnected2D':'## 类locallyconnected2d',
#'    parameters':'参数',
'## Class Masking':'## 类屏蔽',
'Masks a sequence by using a mask value to skip timesteps.':'通过使用掩码值跳过时间步来屏蔽序列。',
'## Class Maximum':'## 类最大值',
'## Class MaxPool1D':'##MaxPool1D类',
'Max pooling operation for temporal data.':'时态数据的最大池操作。',
'## Class MaxPool2D':'##MaxPool2D类',
'Max pooling operation for spatial data.':'空间数据的最大池操作。',
'## Class MaxPool3D':'##MaxPool3D类',
'## Class Minimum':'## 最低等级',
'## Class Multiply':'## 类乘法',
'## Class Permute':'## 类置换',
'Permutes the dimensions of the input according to a given pattern.':'根据给定的模式排列输入的维度。',
'Useful for e.g. connecting RNNs and convnets together.':'用于将RNN和ConvNets连接在一起。',
'## Class PReLU':'## 班前预科',
'Parametric Rectified Linear Unit.':'参数校正线性单元。',
'## Class ReLU':'## 类relu',
'Rectified Linear Unit activation function.':'校正线性单元激活函数。',
'## Class RepeatVector':'## 类重复向量',
'Repeats the input n times.':'重复输入n次。',
'## Class Reshape':'## 类重塑',
'Reshapes an output to a certain shape.':'将输出重塑为特定形状。',
'## Class RNN':'##RNN类',
'Base class for recurrent layers.':'递归层的基类。',
'#### Masking:':'#### 掩蔽：',
'## Class SimpleRNN':'## 类simplernn',
'## Class SimpleRNNCell':'## 类simplerncell',
'Cell class for SimpleRNN.':'SimpleRN的单元格类。',
'## Class Softmax':'##SoftMax类',
'Softmax activation function.':'SoftMax激活功能。',
'## Class SpatialDropout1D':'## 类空间丢弃1d',
'Spatial 1D version of Dropout.':'辍学的空间1D版本。',
'Same as input.':'与输入相同。',
'## Class SpatialDropout2D':'## 类空间丢弃2d',
'Spatial 2D version of Dropout.':'辍学的空间二维版本。',
'## Class SpatialDropout3D':'## 类SpatialDropout3D',
'Spatial 3D version of Dropout.':'空间三维版本的辍学。',
'## Class StackedRNNCells':'## 类StackedRunCells',
'Wrapper allowing a stack of RNN cells to behave as a single cell.':'包装器，允许一堆RNN单元作为单个单元运行。',
'Used to implement efficient stacked RNNs.':'用于实现高效的堆叠RNN。',
'## Class Subtract':'## 类减法',
'Layer that subtracts two inputs.':'减去两个输入的层。',
'## Class ThresholdedReLU':'## 类阈值Delu',
'Thresholded Rectified Linear Unit.':'阈值校正线性单元。',
'## Class TimeDistributed':'## Class 时间分布',
'This wrapper allows to apply a layer to every temporal slice of an input.':'这个包装器允许对输入的每个时态片应用一个层。',
'## Class UpSampling1D':'## 类上采样1d',
'Upsampling layer for 1D inputs.':'1D输入的上采样层。',
'Repeats each temporal step size times along the time axis.':'沿时间轴重复每个时间步长次。',
'## Class UpSampling2D':'## 类上采样2d',
'Upsampling layer for 2D inputs.':'二维输入的上采样层。',
'## Class UpSampling3D':'## 类Upsampling3D',
'Upsampling layer for 3D inputs.':'三维输入的上采样层。',
'## Class Wrapper':'## 类包装器',
'Abstract wrapper base class.':'抽象包装基类。',
'## Class ZeroPadding1D':'## 零填充1D类',
'If int: How many zeros to add at the beginning and end of the `padding` dimension (axis 1).':'if int：要在“padding”维度（轴1）的开头和结尾添加多少个零。',
'## Class ZeroPadding2D':'## 类零填充2d',
'If int: the same symmetric `padding` is applied to height and width.':'if int：对高度和宽度应用相同的对称“padding”。',
'## Class ZeroPadding3D':'## 类零填充3D',
'## Class BinaryCrossentropy':'## 类二元交叉熵',
'Invokes the Loss instance.':'调用损失实例。',
'A Loss instance.':'一个失败的例子。',
'## Class CategoricalCrossentropy':'## 类类别交叉熵',
'Computes the crossentropy loss between the labels and predictions.':'计算标签和预测之间的交叉熵损失。',
'Usage with the compile API:':'与编译API一起使用：',
'## Class CategoricalHinge':'## 类分类铰链',
'Computes the categorical crossentropy loss.':'计算类别交叉熵损失。',
'Categorical crossentropy loss value.':'分类交叉熵损失值。',
'## Class CosineSimilarity':'## 类余弦相似性',
'Computes the cosine similarity between labels and predictions.':'计算标签和预测之间的余弦相似性。',
'Cosine similarity tensor.':'余弦相似张量。',
'## Class Hinge':'## 类铰链',
'## Class Huber':'## 休伯类',
'A Tensor with loss.':'有损失的张量。',
'## Class KLDivergence':'##K级发散',
'## Class LogCosh':'## 类logcosh',
'Computes the logarithm of the hyperbolic cosine of the prediction error.':'计算预测误差的双曲余弦的对数。',
'## Class Loss':'## 阶级损失',
'Loss base class.':'损失基类。',
'Example subclass implementation:':'子类实现示例：',
'## Class MeanAbsoluteError':'## 类平均绝对误差',
'Computes the mean of absolute difference between labels and predictions.':'计算标签和预测之间绝对差的平均值。',
'## Class MeanAbsolutePercentageError':'## 类平均绝对百分比误差',
'## Class MeanSquaredError':'## 类meansquarederror',
'Computes the mean of squares of errors between labels and predictions.':'计算标签和预测之间误差平方的平均值。',
'## Class MeanSquaredLogarithmicError':'## 类平均平方对数误差',
'## Class Poisson':'## 泊松类',
'## Class SparseCategoricalCrossentropy':'## 类Sparsecategoricrossindormy',
'## Class SquaredHinge':'## 类方格',
'Tensor with one scalar loss entry per sample.':'每个样本有一个标量损失项的张量。',
'## Class Accuracy':'## 类精度',
'Usage with tf.keras API:':'与tf.keras api一起使用：',
'Creates a MeanMetricWrapper instance.':'创建MeanMetricWrapper实例。',
'Create and return a new object. See help(type) for accurate signature.':'创建并返回一个新对象。请参阅帮助（键入）以获取准确签名。',
'Resets all of the metric state variables.':'重置所有度量状态变量。',
'### result':'### 结果',
'Computes and returns the metric value tensor.':'计算并返回度量值张量。',
'Result computation is an idempotent operation that simply calculates the metric value using the state variables.':'结果计算是一个等幂运算，它使用状态变量简单地计算度量值。',
'Accumulates metric statistics.':'累积度量统计。',
'Update op.':'更新操作。',
'## Class AUC':'## 类AUC',
'Computes the approximate AUC (Area under the curve) via a Riemann sum.':'通过黎曼和计算近似AUC（曲线下面积）。',
'Creates an AUC instance.':'创建AUC实例。',
#'https://www.biostat.wisc.edu/~page/rocpr.pdf':'https://www.biostat.wisc.edu/~page/rocpr.pdf',
'Note here we derive & use a closed formula not present in the paper as follows:':'注：这里我们导出并使用了本文中没有的闭式公式，如下所示：',
'Accumulates confusion matrix statistics.':'累积混淆矩阵统计。',
'## Class BinaryAccuracy':'## 类二进制精度',
'Creates a BinaryAccuracy instance.':'创建BinaryAccurance实例。',
'Computes the crossentropy metric between the labels and predictions.':'计算标签和预测之间的交叉熵度量。',
'Creates a BinaryCrossentropy instance.':'创建BinaryCross熵实例。',
'## Class CategoricalAccuracy':'## 类分类精度',
'Creates a CategoricalAccuracy instance.':'创建分类精度实例。',
'Computes the cosine similarity between the labels and predictions.':'计算标签和预测之间的余弦相似性。',
'This metric keeps the average cosine similarity between predictions and labels over a stream of data.':'此度量保留数据流上预测和标签之间的平均余弦相似性。',
'Creates a CosineSimilarity instance.':'创建余弦相似性实例。',
'## Class FalseNegatives':'## 类假否定',
'Calculates the number of false negatives.':'计算假阴性的数目。',
'Creates a FalseNegatives instance.':'创建FalseNegatives实例。',
'Accumulates the given confusion matrix condition statistics.':'累积给定的混淆矩阵条件统计量。',
'Calculates the number of false positives.':'计算误报次数。',
'Creates a FalsePositives instance.':'创建误报实例。',
'## Class LogCoshError':'## 类logcosherror',
'## Class Mean':'## 阶级平均数',
'Creates a Mean instance.':'创建平均实例。',
'Accumulates statistics for computing the reduction metric.':'累积用于计算缩减度量的统计信息。',
'## Class MeanIoU':'## 阶级意义',
'Creates a MeanIoU instance.':'创建Meaniou实例。',
'Accumulates the confusion matrix statistics.':'累积混淆矩阵统计。',
'## Class MeanRelativeError':'## 阶级相对论者',
'Creates a MeanRelativeError instance.':'创建MeanRelativeRor实例。',
'## Class MeanTensor':'## 类平均张量',
'Creates a MeanTensor instance.':'创建MeanTensor实例。',
'### count':'### 计数',
'### total':'### 总计',
'## Class Metric':'## 等级度量',
'Encapsulates metric logic and state.':'封装度量逻辑和状态。',
'Adds state variable. Only for use by subclasses.':'添加状态变量。只供子类使用。',
'Accumulates statistics for the metric.':'累积度量的统计信息。',
'## Class Precision':'## 类精度',
'Creates a Precision instance.':'创建精度实例。',
'Accumulates true positive and false positive statistics.':'累积真阳性和假阳性统计数据。',
'## Class Recall':'## Class 召回',
'Creates a Recall instance.':'创建调用实例。',
'Accumulates true positive and false negative statistics.':'累积真阳性和假阴性统计数据。',
'## Class RootMeanSquaredError':'## 类rootmeansquarederror',
'Accumulates root mean squared error statistics.':'累积均方根误差统计。',
'## Class SensitivityAtSpecificity':'## 类敏感性特异性',
'Computes the sensitivity at a given specificity.':'计算给定特异度下的灵敏度。',
'Sensitivity measures the proportion of actual positives that are correctly identified as such (tp / (tp + fn)). Specificity measures the proportion of actual negatives that are correctly identified as such (tn / (tn + fp)).':'敏感度测量正确识别的实际阳性的比例（tp/（tp+fn））。特异性测量正确识别的实际阴性的比例（tn/（tn+fp））。',
'Creates a SensitivityAtSpecificity instance.':'创建SensitivitySpecification实例。',
'## Class SparseCategoricalAccuracy':'##Sparsecategoriaccuracy类',
'Calculates how often predictions matches integer labels.':'计算预测与整数标签匹配的频率。',
'## Class SparseTopKCategoricalAccuracy':'##SparsetOpkCategoricalaccuracity类',
'Computes how often integer targets are in the top K predictions.':'计算整数目标在前k个预测中的频率。',
'Creates a SparseTopKCategoricalAccuracy instance.':'创建SparSetOpkCategoricalCuracity实例。',
'## Class SpecificityAtSensitivity':'## 类特定灵敏度',
'Creates a SpecificityAtSensitivity instance.':'创建特定的敏感度实例。',
'## Class Sum':'## 类和',
'Computes the (weighted) sum of the given values.':'计算给定值的（加权）和。',
'Creates a Sum instance.':'创建sum实例。',
'## Class TopKCategoricalAccuracy':'##TopkCategoricalaccuracity类',
'Computes how often targets are in the top K predictions.':'计算目标在前k个预测中的频率。',
'Creates a TopKCategoricalAccuracy instance.':'创建topkcategoricalaccuracity实例。',
'## Class TrueNegatives':'## 类真负片',
'Calculates the number of true negatives.':'计算真负片的数目。',
'Creates a TrueNegatives instance.':'创建TrueNegatives实例。',
'## Class TruePositives':'## 类真正数',
'Calculates the number of true positives.':'计算真正数。',
'Creates a TruePositives instance.':'创建TruePositives实例。',
'Returns the global Policy.':'返回全局策略。',
'The global Policy.':'全球政策。',
'## Class LossScaleOptimizer':'## 类损失标量优化器',
'Initializes this loss scale optimizer.':'初始化此损失比例优化器。',
'### iterations':'### 迭代',
'Variable. The number of training steps this Optimizer has run.':'变量。此优化器已运行的训练步骤数。',
'The LossScale instance associated with this optimizer.':'与此优化器关联的LossCalle实例。',
#'### lr':'### 轻轨',
'Returns variables of this Optimizer based on the order created.':'根据创建的顺序返回此优化器的变量。',
'Add a new slot variable for var.':'为var添加一个新的slot变量。',
'Creates an optimizer from its config.':'从其配置创建优化器。',
'An optimizer instance.':'优化器实例。',
'Returns the config of the optimimizer.':'返回优化程序的配置。',
'An optimizer config is a Python dictionary (serializable) containing the configuration of an optimizer. The same optimizer can be reinstantiated later (without any saved state) from this configuration.':'优化器配置是包含优化器配置的python字典（可序列化）。以后可以从此配置中重新实例化同一优化器（不保存任何状态）。',
#'    params':'参数',
'Returns gradients of loss with respect to params.':'返回相对于参数的损失梯度。',
'List of gradient tensors.':'梯度张量列表。',
'Scales the loss by the loss scale.':'用损失量表来衡量损失。',
'A list of names for this optimizer\'s slots.':'此优化器插槽的名称列表。',
'Unscales the gradients by the loss scale.':'用损失量表来解释梯度。',
'## Class Policy':'## 阶级政策',
'A dtype policy for a Keras layer.':'keras层的数据类型策略。',
'### How to use mixed precision in layers with Policies':'### 如何在具有策略的层中使用混合精度',
'### The deprecated "infer" policy':'### 不赞成的“推断”策略',
'Constructs the policy.':'构建策略。',
'The compute dtype of this policy.':'此策略的计算数据类型。',
'This is the dtype layers will do their computations in.':'这是将在中进行计算的dtype层。',
'Returns the loss scale of this Policy.':'返回此保险单的损失等级。',
'Returns the name of this policy.':'返回此策略的名称。',
'Returns True if variables should be casted.':'如果变量应强制类型化，则返回true。',
'This is true if the variable dtype is not the same as the compute dtype.':'如果变量dtype与计算dtype不同，则为true。',
'The variable dtype of this policy.':'此策略的可变数据类型。',
'Sets the global Policy.':'设置全局策略。',
'Clone any Model instance.':'克隆任何模型实例。',
'Instantiates a Keras model from its config.':'从配置中实例化keras模型。',
'A Keras model instance (uncompiled).':'Keras模型实例（未编译）。',
'Parses a JSON model configuration file and returns a model instance.':'解析json模型配置文件并返回模型实例。',
'Parses a yaml model configuration file and returns a model instance.':'解析一个yaml模型配置文件并返回一个模型实例。',
'Saves a model as a TensorFlow SavedModel or HDF5 file.':'将模型保存为TensorFlow SavedModel或HDF5文件。',
'## Class Adadelta':'##Adadelta类',
'Adadelta optimization is a stochastic gradient descent method that is based on adaptive learning rate per dimension to address two drawbacks: 1) the continual decay of learning rates throughout training 2) the need for a manually selected global learning rate':'adadelta优化是一种随机梯度下降方法，它基于每个维度的自适应学习率来解决两个缺点：1）整个训练过程中学习率的持续衰减2）需要手动选择全局学习率',
'## Class Adagrad':'##Adagrad类',
'#### Update step:':'#### 更新步骤：',
'## Class Adam':'## 亚当阶级',
'## Class Adamax':'##Adamax类',
'Optimizer that implements the Adamax algorithm.':'实现adamax算法的优化器。',
'Construct a new Adamax optimizer.':'构造一个新的adamax优化器。',
'The update rule for variable with gradient g uses an optimization described at the end of section 7.1 of the paper:':'带梯度g的变量的更新规则使用本文第7.1节末尾描述的优化：',
'Inverse of the serialize function.':'序列化函数的逆函数。',
'A Keras Optimizer instance.':'Keras优化器实例。',
'## Class Ftrl':'##FTRL级',
'Retrieves a Keras Optimizer instance.':'检索Keras优化器实例。',
'String: name of an optimizer':'string：优化器的名称',
'## Class Nadam':'##NADAM类',
'Optimizer that implements the NAdam algorithm.':'实现NADAM算法的优化器。',
'#### Computes:':'#### 计算：',
'Construct a new Nadam optimizer.':'构造一个新的NADAM优化器。',
'Updated base class for optimizers.':'为优化器更新了基类。',
'### Custom training loop with Keras models':'### 带Keras模型的定制训练循环',
'### Use with tf.distribute.Strategy.':'### 与tf.distribute.strategy一起使用。',
'### Variable Constraint':'### 可变约束',
'### Thread Compatibility':'### 线程兼容性',
'### Hyper parameters':'### 超参数',
'Hyper parameters can be overwritten through user code:':'可以通过用户代码覆盖超参数：',
'### Write a customized optimizer.':'### 编写一个定制的优化器。',
'## Class RMSprop':'##RMSProp类',
'Optimizer that implements the RMSprop algorithm.':'实现rmsprop算法的优化器。',
'A detailed description of rmsprop.':'rmsprop的详细描述。',
'Construct a new RMSprop optimizer.':'构造一个新的rmsprop优化器。',
'## Class SGD':'##SGD级',
'Stochastic gradient descent and momentum optimizer.':'随机梯度下降和动量优化。',
'gradient is evaluated at theta(t).':'梯度在θ（t）处计算。',
#'  http://jmlr.org/proceedings/papers/v28/sutskever13.pdf).':'http://jmlr.org/proceedings/papers/v28/sutskever13.pdf）。',
'Construct a new Stochastic Gradient Descent or Momentum optimizer.':'构造一个新的随机梯度下降或动量优化器。',
'## Class ExponentialDecay':'## 类指数衰减',
'A LearningRateSchedule that uses an exponential decay schedule.':'使用指数衰减计划的LearningRateSchedule。',
'Instantiates a LearningRateSchedule from its config.':'从其配置中实例化LearningRateSchedule。',
'A LearningRateSchedule instance.':'LearningRateSchedule实例。',
'## Class InverseTimeDecay':'## Class 倒转',
'A LearningRateSchedule that uses an inverse time decay schedule.':'使用反时间衰减计划的LearningRateSchedule。',
'## Class LearningRateSchedule':'## 课程学习率表',
'A serializable learning rate decay schedule.':'可串行化的学习速率衰减表。',
'## Class PiecewiseConstantDecay':'## 类分段不变',
'A LearningRateSchedule that uses a piecewise constant decay schedule.':'使用分段常数衰减时间表的LearningRateSchedule。',
'## Class PolynomialDecay':'## 类多项式',
'A LearningRateSchedule that uses a polynomial decay schedule.':'使用多项式衰减时间表的LearningRateSchedule。',
'It requires a step value to compute the decayed learning rate. You can just pass a TensorFlow variable that you increment at each training step.':'它需要一个步长值来计算衰减的学习率。您只需传递在每个训练步骤中递增的tensorflow变量。',
'Applies an affine transformation specified by the parameters given.':'应用由给定参数指定的仿射变换。',
'theta: Rotation angle in degrees.':'θ：旋转角度，单位为度。',
'tx: Width shift.':'TX：宽度偏移。',
'ty: Heigh shift.':'泰：嗨，换班。',
'shear: Shear angle in degrees.':'剪切：以度为单位的剪切角。',
'zx: Zoom in x direction.':'ZX：放大X方向。',
'zy: Zoom in y direction':'ZY:沿Y方向缩放',
#'    are filled according to the given mode':'根据给定的模式填充',
'cval: Value used for points outside the boundaries':'cval：用于边界外点的值',
' The transformed version of the input.':'输入的转换版本。',
'Performs a brightness shift.':'执行亮度偏移。',
#'    brightness':'亮度',
' x: Input tensor. Must be 3D.':'x：输入张量。必须是三维的。',
'brightness: Float. The new brightness value.':'亮度：浮动。新的亮度值。',
' Numpy image tensor.':'纽米图像张量。',
'Performs a channel shift.':'执行通道移位。',
'intensity: Transformation intensity.':'强度：转化强度。',
'Converts a 3D Numpy array to a PIL Image instance.':'将3d numpy数组转换为pil图像实例。',
'A PIL Image instance.':'PIL图像实例。',
'## Class DirectoryIterator':'## 类目录迭代器',
'Iterator capable of reading images from a directory on disk.':'能够从磁盘上的目录读取图像的迭代器。',
'### filepaths':'### 文件路径',
'List of absolute paths to image files':'图像文件的绝对路径列表',
'### labels':'### 标签',
'Class labels of every observation':'每个观察的类标签',
'Gets batch at position index.':'在位置索引处获取批处理。',
'A batch':'一批',
'Create a generator that iterate over the Sequence.':'创建一个遍历序列的生成器。',
'Number of batch in the Sequence.':'序列中的批数。',
'The number of batches in the Sequence.':'序列中的批数。',
'For python 2.x.':'对于Python2.x。',
' The next batch.':'下一批。',
'Method called at the end of every epoch.':'方法在每个纪元结束时调用。',
#'    interpolation':'插值',
'Sets attributes to use later for processing files into a batch.':'设置稍后用于将文件处理为批处理的属性。',
#'    to use for random transformations and normalization.':'用于随机转换和规范化。',
#'    Color mode to read images.':'读取图像的颜色模式。',
'subset: Subset of data (`"training"` or `"validation"`) if':'subset：如果',
'interpolation: Interpolation method used to resample the image if the':'插值：用于对图像重新采样的插值方法，如果',
#'    target size is different from that of the loaded image.':'目标大小与加载的图像大小不同。',
'## Class ImageDataGenerator':'## 类ImageDataGenerator',
#'            break':'打破',
'Example of transforming images and masks together.':'将图像和遮罩转换到一起的示例。',
'Applies a transformation to an image according to given parameters.':'根据给定参数对图像应用转换。',
#'    describing the transformation.':'描述转换。',
#'    from the dictionary are used:':'使用字典中的：',
' A transformed version of the input (same shape).':'输入的转换版本（相同的形状）。',
'Fits the data generator to some sample data.':'使数据生成器适合某些示例数据。',
' x: Sample data. Should have rank 4.':'X：样本数据。应该是4级。',
'augment: Boolean (default: False).':'augment:boolean（默认值：false）。',
#'    Whether to fit on randomly augmented samples.':'是否适合随机增加的样本。',
'rounds: Int (default: 1).':'轮次：int（默认值：1）。',
#'    this is how many augmentation passes over the data to use.':'这是要使用的数据上传递的增强次数。',
'seed: Int (default: None). Random seed.':'种子：int（默认值：none）。随机种子。',
' x: Input data. Numpy array of rank 4 or a tuple.':'X：输入数据。列4或元组的numpy数组。',
#'    should contain the images and the second element':'应该包含图像和第二个元素',
#'    another numpy array or a list of numpy arrays':'另一个numpy数组或numpy数组列表',
#'    that gets passed to the output':'传递到输出',
#'    Can be used to feed the model miscellaneous data':'可用于馈送模型杂项数据',
#'    along with the images.':'以及图像。',
'y: Labels.':'Y:标签。',
'shuffle: Boolean (default: True).':'shuffle:boolean（默认值：true）。',
'seed: Int (default: None).':'种子：int（默认值：none）。',
#'    This allows you to optionally specify a directory':'这允许您选择指定一个目录',
#'    to which to save the augmented pictures being generated':'保存生成的增强图片',
#'    (useful for visualizing what you are doing).':'（有助于想象你在做什么）。',
#'    Prefix to use for filenames of saved pictures':'用于保存图片的文件名的前缀',
#'    (in the case of a single image input) or a list':'（对于单个图像输入）或列表',
#'    of numpy arrays (in the case with':'numpy数组的',
#'    additional inputs) and `y` is a numpy array':'其他输入）和“y”是numpy数组',
'Takes the dataframe and the path to a directory and generates batches of augmented/normalized data.':'获取数据帧和目录路径，并生成成批增强/规范化数据。',
' dataframe: Pandas dataframe containing the filepaths relative to':'dataframe:pandas dataframe包含相对于',
#'    images in a string column. It should include other column/s':'字符串列中的图像。应包括其他列',
#'        Values in column can be string/list/tuple if a single class':'如果是单个类，则列中的值可以是string/list/tuple',
#'        or list/tuple if multiple classes.':'如果有多个类，则为list/tuple。',
#'    absolute paths if `directory` is `None`).':'绝对路径（如果“directory”为“none”）。',
#'    weights. Default: `None`.':'重量。默认值：“无”。',
#'    The dimensions to which all images found will be resized.':'找到的所有图像将调整到的尺寸。',
#'    Whether the images will be converted to have 1 or 3 color channels.':'是否将图像转换为具有1个或3个颜色通道。',
#'    The dictionary containing the mapping from class names to class':'包含从类名到类的映射的字典',
#'    Mode for yielding the targets:':'生成目标的模式：',
'seed: optional random seed for shuffling and transformations.':'种子：可选的随机种子洗牌和转换。',
#'    (default: False).':'（默认值：false）。',
#'    Default: `True`.':'默认值：“true”。',
'Takes the path to a directory & generates batches of augmented data.':'获取一个目录的路径并生成一批扩展数据。',
#'    It should contain one subdirectory per class.':'它应该为每个类包含一个子目录。',
#'    inside each of the subdirectories directory tree':'在每个子目录目录树中',
#'    will be included in the generator.':'将包含在发电机中。',
#'    Whether the images will be converted to':'是否将图像转换为',
#'    inferred from the subdirectory names/structure':'从子目录名称/结构推断',
#'    be treated as a different class':'被当作一个不同的阶级对待',
#'    Determines the type of label arrays that are returned:':'确定返回的标签数组的类型：',
#'        to input images (mainly used to work with autoencoders).':'输入图像（主要用于自动编码器）。',
#'      the data still needs to reside in a subdirectory':'数据仍然需要驻留在子目录中',
#'      of `directory` for it to work correctly.':'才能正常工作。',
'seed: Optional random seed for shuffling and transformations.':'种子：可选的随机种子洗牌和转换。',
#'    This allows you to optionally specify':'这允许您选择指定',
#'    a directory to which to save':'要保存到的目录',
#'    the augmented pictures being generated':'生成的增强图片',
'interpolation: Interpolation method used to':'插值：用于',
#'    resample the image if the':'如果',
'Generates random parameters for a transformation.':'为转换生成随机参数。',
' seed: Random seed.':'种子：随机种子。',
#'    Shape of the image that is transformed.':'被转换的图像的形状。',
' A dictionary containing randomly chosen parameters describing the':'包含随机选择的参数的字典，描述',
'transformation.':'转变。',
'Applies a random transformation to an image.':'对图像应用随机变换。',
'seed: Random seed.':'种子：随机种子。',
' A randomly transformed version of the input (same shape).':'输入的随机转换版本（相同形状）。',
'### standardize':'### 标准化',
' x: Batch of inputs to be normalized.':'X：要规范化的一批输入。',
'Converts a PIL Image instance to a Numpy array.':'将pil图像实例转换为numpy数组。',
'A 3D Numpy array.':'三维核阵列。',
'Base class for image data iterators.':'图像数据迭代器的基类。',
'seed: Random seeding for data shuffling.':'种子：随机种子数据洗牌。',
#'    seed':'种子',
'Loads an image into PIL format.':'将图像加载为PIL格式。',
' path: Path to image file.':'路径：图像文件的路径。',
#'    The desired image format.':'所需的图像格式。',
' A PIL Image instance.':'PIL图像实例。',
' ImportError: if PIL is not available.':'重要提示：如果PIL不可用。',
'ValueError: if interpolation method is not supported.':'值错误：如果不支持插值方法。',
'## Class NumpyArrayIterator':'## 类numpYarrayIterator',
'Iterator yielding data from a Numpy array.':'从numpy数组生成数据的迭代器。',
'Performs a random brightness shift.':'执行随机亮度偏移。',
'Performs a random channel shift.':'执行随机信道移位。',
'Performs a random rotation of a Numpy image tensor.':'执行Numpy图像张量的随机旋转。',
' Rotated Numpy image tensor.':'旋转的numpy图像张量。',
'Performs a random spatial shear of a Numpy image tensor.':'执行Numpy图像张量的随机空间剪切。',
'intensity: Transformation intensity in degrees.':'强度：转换强度，单位为度。',
' Sheared Numpy image tensor.':'剪核图像张量。',
'Performs a random spatial shift of a Numpy image tensor.':'执行numpy图像张量的随机空间偏移。',
' Shifted Numpy image tensor.':'移位的核图像张量。',
'Performs a random spatial zoom of a Numpy image tensor.':'执行Numpy图像张量的随机空间缩放。',
' Zoomed Numpy image tensor.':'缩放的Numpy图像张量。',
'Saves an image stored as a Numpy array to a path or file object.':'将存储为numpy数组的图像保存到path或file对象。',
'The sampling probabilities are generated according to the sampling distribution used in word2vec:':'采样概率根据word2vec中使用的采样分布生成：',
' A 1D Numpy array of length `size` where the ith entry':'长度为“size”的1d numpy数组，其中第i个条目',
'is the probability that a word of rank i should be sampled.':'是一个等级i的单词被抽样的概率。',
'Pads sequences to the same length.':'焊盘序列长度相同。',
'dtype: Type of the output sequences.':'dtype：输出序列的类型。',
#'    pad either before or after each sequence.':'在每个序列之前或之后填充。',
#'    remove values from sequences larger than':'从大于的序列中删除值',
#'    or in case of invalid shape for a `sequences` entry.':'或者“sequences”条目的形状无效。',
'Generates skipgram word pairs.':'生成skipgram词对。',
'This function transforms a sequence of word indexes (list of integers) into tuples of words of the form:':'此函数将一系列单词索引（整数列表）转换为以下形式的单词元组：',
#'    word indices are expected to match the rank':'单词索引应与排名匹配',
'shuffle: Whether to shuffle the word couples before returning them.':'shuffle：在返回单词couples之前是否对其进行shuffle。',
#'    encodes the probability to sample a word of rank i.':'编码对一个等级为I的单词进行抽样的概率。',
'## Class TimeseriesGenerator':'## 类时间序列生成器',
'Utility class for generating batches of temporal data.':'用于生成时间数据批的实用程序类。',
#'    containing consecutive data points (timesteps).':'包含连续数据点（时间步）。',
#'    to be the time dimension.':'成为时间维度。',
'targets: Targets corresponding to timesteps in `data`.':'targets：与“data”中的timestep相对应的目标。',
#'    It should have same length as `data`.':'它的长度应该与“data”相同。',
'length: Length of the output sequences (in number of timesteps).':'长度：输出序列的长度（以时间步数为单位）。',
#'    are used for create a sample sequence.':'用于创建示例序列。',
'stride: Period between successive output sequences.':'步幅：连续输出序列之间的周期。',
#'    in the output sequences. This is useful to reserve part of the':'在输出序列中。这有助于保留',
#'    data for test or validation.':'用于测试或验证的数据。',
#'    or instead draw them in chronological order.':'或者按时间顺序画出来。',
#'    in reverse chronological order.':'按时间倒序排列。',
#'    (except maybe the last one).':'（除了最后一个）。',
' from keras.preprocessing.sequence import TimeseriesGenerator':'从keras.preprocessing.sequence import timeseriesgenerator',
'Returns the TimeseriesGenerator configuration as Python dictionary.':'将TimeSeriesGenerator配置作为Python字典返回。',
' A Python dictionary with the TimeseriesGenerator configuration.':'具有TimeSeriesGenerator配置的Python字典。',
#'    to be passed to `json.dumps()`.':'传递给“json.dumps（）”。',
' A JSON string containing the tokenizer configuration.':'包含标记器配置的json字符串。',
' text: Input text (string).':'文本：输入文本（字符串）。',
'n: Dimension of the hashing space.':'n：散列空间的维数。',
#'    any function that takes in input a string and returns a int.':'任何接受输入字符串并返回int的函数。',
#'    is a stable hashing function.':'是一个稳定的哈希函数。',
'lower: boolean. Whether to set the text to lowercase.':'下：布尔值。是否将文本设置为小写。',
'split: str. Separator for word splitting.':'拆分：单词拆分的str分隔符。',
'n: int. Size of vocabulary.':'N：内景，词汇量。',
'Converts a text to a sequence of words (or tokens).':'将文本转换为一系列单词（或标记）。',
'lower: boolean. Whether to convert the input to lowercase.':'下：布尔值。是否将输入转换为小写。',
' A list of words (or tokens).':'单词（或记号）的列表。',
'## Class Tokenizer':'## 类标记器',
'Text tokenization utility class.':'文本标记化实用程序类。',
#'    be kept.':'被保留。',
'filters: a string where each element is a character that will be':'过滤器：一个字符串，其中每个元素都是',
'lower: boolean. Whether to convert the texts to lowercase.':'下：布尔值。是否将文本转换为小写。',
'Updates internal vocabulary based on a list of sequences.':'根据序列列表更新内部词汇表。',
' sequences: A list of sequence.':'序列：序列的列表。',
#'    A "sequence" is a list of integer word indices.':'“序列”是一个整数词索引列表。',
'Updates internal vocabulary based on a list of texts.':'根据文本列表更新内部词汇。',
#'    or a list of list of strings.':'或字符串列表。',
' A Python dictionary with the tokenizer configuration.':'具有标记器配置的python字典。',
'Converts a list of sequences into a Numpy matrix.':'将序列列表转换为numpy矩阵。',
' sequences: list of sequences':'序列：序列列表',
#'    (a sequence is a list of integer word indices).':'（序列是一个整数字索引的列表）。',
' A Numpy matrix.':'纽米矩阵。',
#'    or if the Tokenizer requires to be fit to sample data.':'或者标记器需要适合样本数据。',
'Transforms each sequence into a list of text.':'将每个序列转换为文本列表。',
' sequences: A list of sequences (list of integers).':'序列：序列列表（整数列表）。',
'Transforms each sequence in sequences to a list of texts(strings).':'将序列中的每个序列转换为文本列表（字符串）。',
' sequences: A list of sequences.':'序列：序列列表。',
' Yields individual texts.':'生成单个文本。',
'Convert a list of texts to a Numpy matrix.':'将文本列表转换为numpy矩阵。',
' texts: list of strings.':'文本：字符串列表。',
'Transforms each text in texts to a sequence of integers.':'将文本中的每个文本转换为一个整数序列。',
' texts: A list of texts (strings).':'文本：文本（字符串）列表。',
' A list of sequences.':'序列列表。',
' Yields individual sequences.':'产生单个序列。',
'## Class L1L2':'##L1L2级',
'Regularizer for L1 and L2 regularization.':'l1和l2正则化的正则化器。',
'## Class Regularizer':'## 类正则化子',
'Regularizer base class.':'正则化基类。',
'Converts all convolution kernels in a model from Theano to TensorFlow.':'将模型中的所有卷积核从ano转换为tensorflow。',
'Also works from TensorFlow to Theano.':'也可以从tensorflow到theano。',
'## Class CustomObjectScope':'## 类customobjectscope',
'Consider a custom object MyObject (e.g. a class):':'考虑一个自定义对象myobject（例如一个类）：',
'Consider a custom object MyObject':'考虑自定义对象myobject',
'Object of type CustomObjectScope.':'customobjectscope类型的对象。',
'## Class GeneratorEnqueuer':'## 类生成器',
'Builds a queue out of a data generator.':'从数据生成器生成队列。',
'The provided generator can be finite in which case the class will throw a StopIteration exception.':'提供的生成器可以是有限的，在这种情况下，类将抛出StopIteration异常。',
'Creates a generator to extract data from the queue.':'创建生成器以从队列中提取数据。',
'Skip the data if it is None.':'如果没有，跳过数据。',
'Starts the handler\'s workers.':'启动处理程序的工作线程。',
'Should be called by the same thread which called start().':'应该由调用start（）的同一线程调用。',
'Retrieves a live reference to the global dictionary of custom objects.':'检索对自定义对象的全局词典的实时引用。',
'Downloads a file from a URL if it not already in the cache.':'如果文件不在缓存中，则从url下载该文件。',
'Path to the downloaded file':'下载文件的路径',
'Returns the list of input tensors necessary to compute tensor.':'返回计算张量所需的输入张量列表。',
'Output will always be a list of tensors (potentially with 1 element).':'输出将始终是张量列表（可能有1个元素）。',
'List of input tensors.':'输入张量列表。',
'## Class HDF5Matrix':'##HDF5类矩阵',
'Representation of HDF5 dataset to be used instead of a Numpy array.':'要使用的HDF5数据集的表示形式，而不是numpy数组。',
'Providing start and end allows use of a slice of the dataset.':'提供start和end允许使用数据集的一个片段。',
'Gets the datatype of the dataset.':'获取数据集的数据类型。',
'A numpy dtype string.':'numpy数据类型字符串。',
'### ndim':'### 新吉布提国际机场',
'Gets the number of dimensions (rank) of the dataset.':'获取数据集的维度（列组）数。',
'An integer denoting the number of dimensions (rank) of the dataset.':'表示数据集维数（秩）的整数。',
'Gets the total dataset size (number of elements).':'获取数据集的总大小（元素数）。',
'An integer denoting the number of elements in the dataset.':'表示数据集中元素数的整数。',
'Convert a Keras model to dot format.':'将路缘石模型转换为点格式。',
'This function is only available with the TensorFlow backend for the time being.':'此函数暂时仅在TensorFlow后端可用。',
'Example 1: Training models with weights merge on CPU':'示例1：在CPU上合并权重的训练模型',
#'    from keras.applications import Xception':'从keras.applications导入异常',
#'     except:':'除外：',
'Normalizes a Numpy array.':'规范化numpy数组。',
'A normalized copy of the array.':'数组的规范化副本。',
'## Class OrderedEnqueuer':'## 类OrderedQueuer',
'Builds a Enqueuer from a Sequence.':'从序列生成排队器。',
'Converts a Keras model to dot format and save to a file.':'将路缘石模型转换为点格式并保存为文件。',
'## Class Progbar':'## 类progbar',
'Displays a progress bar.':'显示进度条。',
'Updates the progress bar.':'更新进度条。',
'## Class Sequence':'## 类序列',
'Sequence are a safer way to do multiprocessing. This structure guarantees that the network will only train once on each sample per epoch which is not the case with generators.':'序列是进行多处理的更安全的方法。这种结构保证了网络在每个历元的每个样本上只训练一次，而发电机则不是这样。',
#'     from skimage.io import imread':'从skipage.io导入imread',
#'    from skimage.transform import resize':'从skipage.transform导入调整大小',
'## Class SequenceEnqueuer':'## 类序列排队器',
'Base class to enqueue inputs.':'将输入排队的基类。',
'The task of an Enqueuer is to use parallelism to speed up preprocessing. This is done with processes or threads.':'排队器的任务是使用并行性来加速预处理。这是通过进程或线程完成的。',
'The enqueuer.get() should be an infinite stream of datas.':'enqueuer.get（）应该是无限的数据流。',
'Converts a class vector (integers) to binary class matrix.':'将类向量（整数）转换为二进制类矩阵。',
'A binary matrix representation of the input. The classes axis is placed last.':'输入的二进制矩阵表示法。类轴放在最后。',
'## Class KerasClassifier':'## 类KerasClassifier',
'Checks for user typos in params.':'检查参数中的用户输入错误。',
'Gets parameters for this estimator.':'获取此估计器的参数。',
'Dictionary of parameter names mapped to their values.':'映射到其值的参数名字典。',
'Returns the class predictions for the given test data.':'返回给定测试数据的类预测。',
'Returns class probability estimates for the given test data.':'返回给定测试数据的类概率估计。',
'Returns the mean accuracy on the given test data and labels.':'返回给定测试数据和标签的平均精度。',
'Sets the parameters of this estimator.':'设置此估计器的参数。',
'## Class KerasRegressor':'## 类kerasregressor',
'Returns predictions for the given test data.':'返回给定测试数据的预测。',
'Returns the mean loss on the given test data and labels.':'返回给定测试数据和标签的平均损失。',
'Transposes the last two dimensions of and conjugates tensor matrix.':'转置和共轭张量矩阵的后二维。',
'The adjoint (a.k.a. Hermitian transpose a.k.a. conjugate transpose) of matrix.':'矩阵的伴随（a.k.a.hermitian转置a.k.a.共轭转置）。',
'Copy a tensor setting everything outside a central band in each innermost matrix':'复制一个张量，在每个最里面的矩阵中设置中心带之外的所有内容',
'to zero.':'归零。',
'The indicator function':'指示器功能',
'#### Useful special cases:':'#### 有用的特殊情况：',
'Computes the Cholesky decomposition of one or more square matrices.':'计算一个或多个方阵的cholesky分解。',
'Note: The gradient computation on GPU is faster for large matrices but not for large batch dimensions when the submatrices are small. In this case it might be faster to use the CPU.':'注：对于大型矩阵，GPU上的梯度计算速度更快，但对于子矩阵较小的大批量尺寸，则不是如此。在这种情况下，使用CPU可能更快。',
'Compute the pairwise cross product.':'计算成对交叉积。',
'A Tensor. Has the same type as a.':'张量与A具有相同的类型。',
'Computes the determinant of one or more square matrices.':'计算一个或多个方阵的行列式。',
'Returns a batched diagonal tensor with given batched diagonal values.':'返回具有给定批处理对角值的批处理对角张量。',
'A Tensor. Has the same type as diagonal.':'张量与对角线类型相同。',
'Returns the batched diagonal part of a batched tensor.':'返回批处理张量的批处理对角线部分。',
'The input must be at least a matrix.':'输入必须至少是矩阵。',
'A Tensor containing diagonals of input. Has the same type as input.':'包含输入对角线的张量。与输入类型相同。',
'Computes the matrix exponential of one or more square matrices.':'计算一个或多个方阵的矩阵指数。',
'the matrix exponential of the input.':'输入的矩阵指数。',
'#### Scipy Compatibility':'####scipy兼容性',
'Equivalent to scipy.linalg.expm':'相当于scipy.linalg.expm',
'Computes the global norm of multiple tensors.':'计算多个张量的全局范数。',
'Computes the inverse of one or more square invertible matrices or their':'计算一个或多个平方可逆矩阵的逆',
'adjoints (conjugate transposes).':'伴随（共轭转置）。',
'The op uses LU decomposition with partial pivoting to compute the inverses.':'op使用lu分解和部分旋转来计算逆。',
'If a matrix is not invertible there is no guarantee what the op does. It may detect the condition and raise an exception or it may simply return a garbage result.':'如果一个矩阵是不可逆的，就不能保证运算是做什么的。它可能检测到该条件并引发异常，也可能只是返回一个垃圾结果。',
'## Class LinearOperator':'## 类线性化器',
'#### Performance contract':'#### 履约合同',
'#### Shape compatibility':'#### 形状兼容性',
'LinearOperator subclasses should operate on a [batch] matrix with compatible shape. Class docstrings should define what is meant by compatible shape. Some subclasses may not support batching.':'linearoperator子类应在具有兼容形状的[batch]矩阵上操作。类docstrings应该定义兼容形状的含义。某些子类可能不支持批处理。',
'x is a batch matrix with compatible shape for matmul if':'x是matmul if的具有相容形状的批处理矩阵',
'rhs is a batch matrix with compatible shape for solve if':'rhs是一个具有相容形状的批处理矩阵。',
'#### Example docstring for subclasses.':'#### 子类的示例docstring。',
'This operator acts on batch matrices with compatible shape. FILL IN WHAT IS MEANT BY COMPATIBLE SHAPE':'此运算符作用于具有相容形状的批处理矩阵。填写兼容形状的含义',
'#### Performance':'#### 性能',
'FILL THIS IN':'填这个',
'#### Matrix property hints':'#### 矩阵属性提示',
'Initialize the LinearOperator.':'初始化lineropertor。',
'### H':'### 小时',
'Returns the adjoint of the current LinearOperator.':'返回当前线性属性器的伴随点。',
'LinearOperator which represents the adjoint of this LinearOperator.':'表示此线性分析器的伴随点的线性分析器。',
'TensorShape of batch dimensions of this LinearOperator.':'该线性化器批量尺寸的张量形状。',
'Dimension (in the sense of vector spaces) of the domain of this operator.':'这个算子域的维数（在向量空间的意义上）。',
'Dimension object.':'维度对象。',
'The DType of Tensors handled by this LinearOperator.':'此线性分析器处理的张量的数据类型。',
'List of graph dependencies of this LinearOperator.':'此线性属性器的图形依赖项列表。',
'Return True/False depending on if this operator is square.':'返回真/假取决于此运算符是否为方形。',
'Dimension (in the sense of vector spaces) of the range of this operator.':'此运算符范围的维数（在向量空间的意义上）。',
'TensorShape of this LinearOperator.':'这个直线牵引器的张力形状。',
'Rank (in the sense of tensors) of matrix corresponding to this operator.':'与此算子对应的矩阵的秩（在张量意义上）。',
'Add matrix represented by this operator to x. Equivalent to A + x.':'把这个算符表示的矩阵加到x上，等于a+x。',
'A Tensor with broadcast shape and same dtype as self.':'具有广播形状和与self相同数据类型的张量。',
'### adjoint':'### 伴随',
'Returns an Op that asserts this operator is non singular.':'返回断言此运算符是非单数的操作。',
'Returns an Op that asserts this operator is positive definite.':'返回断言此运算符为正定的操作。',
'Here we check that this operator is exactly equal to its hermitian transpose.':'这里我们检查这个算符是否完全等于它的厄米转置。',
'### cholesky':'### 乔尔斯基',
'Returns a Cholesky factor as a LinearOperator.':'将cholesky因子作为线性参数返回。',
'LinearOperator which represents the lower triangular matrix in the Cholesky decomposition.':'在cholesky分解中表示下三角矩阵的线性化器。',
'### determinant':'### 行列式',
'Determinant for every batch member.':'每个批处理成员的行列式。',
'Efficiently get the [batch] diagonal part of this operator.':'有效地得到该运算符的[批处理]对角线部分。',
'Determined at runtime.':'在运行时确定。',
'### inverse':'### 逆',
'Returns the Inverse of this LinearOperator.':'返回此线性属性器的相反值。',
'LinearOperator representing inverse of this matrix.':'表示该矩阵逆的线性化器。',
'Log absolute value of determinant for every batch member.':'记录每个批处理成员的行列式的绝对值。',
'### matmul':'### 马特穆尔',
'Y.shape':'Y形',
'### matvec':'###matvec公司',
'### solve':'### 解决',
'The returned Tensor will be close to an exact solution if A is well conditioned. Otherwise closeness will vary. See class docstring for details.':'如果a条件良好，则返回的张量将接近于精确解。否则亲密程度会有所不同。有关详细信息，请参见类docstring。',
'### solvevec':'### 解算器',
'Tensor with shape [...,N] and same dtype as rhs.':'形状为[…，n]的张量，其数据类型与RHS相同。',
'Return a dense (batch) matrix representing this operator.':'返回表示此运算符的密集（批处理）矩阵。',
'### trace':'### 痕迹',
'Shape [B1,...,Bb] Tensor of same dtype as self.':'形状[b1，…，bb]张量与self具有相同的数据类型。',
'## Class LinearOperatorAdjoint':'## 类线性属性或伴随点',
'LinearOperator representing the adjoint of another operator.':'表示另一个运算符的伴随的线性运算符。',
'This operator represents the adjoint of another operator.':'此运算符表示另一个运算符的伴随。',
'The performance of LinearOperatorAdjoint depends on the underlying operators performance.':'linearropertoradjoint的性能取决于底层运算符的性能。',
'Initialize a LinearOperatorAdjoint.':'初始化linearropertoradjoint。',
'LinearOperatorAdjoint is initialized with an operator A. The solve and matmul methods effectively flip the adjoint argument. E.g.':'linearropertoradjoint是用算子a初始化的。solve和matmul方法有效地翻转了伴随参数。例如。',
'### operator':'### 操作员',
'The operator before taking the adjoint.':'在取伴随之前的算符。',
'## Class LinearOperatorBlockDiag':'## 类LinearPropertorBlockDiag',
'Combines one or more LinearOperators in to a Block Diagonal matrix.':'将一个或多个线性属性合并到块对角矩阵中。',
'operator.shape':'运算符.shape',
'The performance of LinearOperatorBlockDiag on any operation is equal to the sum of the individual operators\' operations.':'LinearPropertorBlockDiag在任何操作上的性能都等于单个运算符的操作之和。',
'Initialize a LinearOperatorBlockDiag.':'初始化LinearPropertorBlockDiag。',
'### operators':'### 操作员',
'## Class LinearOperatorCirculant':'## 类线性或循环',
'LinearOperator acting like a circulant matrix.':'线性化器的作用类似于循环矩阵。',
'#### Description in terms of circulant matrices':'#### 循环矩阵的描述',
#'    |x w z y|':'| x宽z y|',
#'    |y x w z|':'|长x宽z|',
#'    |z y x w|':'|长x宽|',
'See http://ee.stanford.edu/~gray/toeplitz.pdf':'见http://ee.stanford.edu/~gray/toeplitz.pdf',
'#### Description in terms of the frequency spectrum':'#### 频谱描述',
'#### Operator properties deduced from the spectrum.':'#### 由谱导出的算子性质。',
'A general property of Fourier transforms is the correspondence between Hermitian functions and real valued transforms.':'傅里叶变换的一个一般性质是厄米函数与实值变换之间的对应关系。',
'#### Example of defining in terms of a real convolution kernel':'#### 用实卷积核定义的例子',
'#### Example of Hermitian spectrum':'#### 厄米特谱示例',
'#### Example of forcing real dtype when spectrum is Hermitian':'#### 频谱为厄米特时强制实数据类型的示例',
'Initialize an LinearOperatorCirculant.':'初始化LinearPropertorCirculant。',
'Depth of recursively defined circulant blocks defining this Operator.':'定义此运算符的递归定义循环块的深度。',
#'    |X W Z Y|':'| x宽z y|',
#'    |Y X W Z|':'|长x宽z|',
#'    |Z Y X W|':'|长x宽|',
'Python integer.':'python整数。',
'### spectrum':'### 光谱',
'Returns an Op that asserts this operator has Hermitian spectrum.':'返回断言此运算符具有厄米特谱的操作。',
'An Op that asserts this operator has Hermitian spectrum.':'断言这个算符具有厄米特谱的运算。',
'Shape of the block dimensions of self.spectrum.':'自谱块维数的形状。',
'Convolution kernel corresponding to self.spectrum.':'对应于自谱的卷积核。',
'The D dimensional DFT of this kernel is the frequency domain spectrum of this operator.':'该核的d维dft是该算子的频域谱。',
'Tensor with dtype self.dtype.':'具有dtype self.dtype的张量。',
'## Class LinearOperatorCirculant2D':'## 类LinearPropertorCirculant2D',
'LinearOperator acting like a block circulant matrix.':'线性化器的作用类似于块循环矩阵。',
'#### Description in terms of block circulant matrices':'#### 用分块循环矩阵描述',
'Note that A itself will not in general be circulant.':'注意a本身一般不会循环。',
'Initialize an LinearOperatorCirculant2D.':'初始化LinearPropertorCirculant2D。',
'## Class LinearOperatorCirculant3D':'## 类LinearPropertorCirculant3D',
'LinearOperator acting like a nested block circulant matrix.':'线性化器的作用类似于嵌套的块循环矩阵。',
'### Examples':'### 实例',
'See LinearOperatorCirculant and LinearOperatorCirculant2D for examples.':'有关示例，请参见LinearPropertorCirculant和LinearPropertorCirculant2D。',
'## Class LinearOperatorComposition':'## 类线性属性或组合',
'Composes one or more LinearOperators.':'组成一个或多个线性参数。',
'The performance of LinearOperatorComposition on any operation is equal to the sum of the individual operators\' operations.':'在任何操作上，linearropertorcomposition的性能都等于单个运算符的操作之和。',
'Initialize a LinearOperatorComposition.':'初始化lineropertorcomposition。',
'## Class LinearOperatorDiag':'## 类线性属性标记',
'LinearOperator acting like a [batch] square diagonal matrix.':'线性化器，作用类似于[批处理]平方对角矩阵。',
'LinearOperatorDiag is initialized with a (batch) vector.':'LinearPropertyDiag是用（批处理）向量初始化的。',
'This operator acts on [batch] matrix with compatible shape. x is a batch matrix with compatible shape for matmul and solve if':'此运算符作用于具有兼容形状的[批处理]矩阵。x是matmul的具有相容形状的批处理矩阵，并求解',
'Initialize a LinearOperatorDiag.':'初始化线性属性标记。',
'### diag':'### 诊断',
'## Class LinearOperatorFullMatrix':'## 类linearropertorfullmatrix',
'LinearOperator that wraps a [batch] matrix.':'包装[批处理]矩阵的线性分析器。',
'LinearOperatorFullMatrix has exactly the same performance as would be achieved by using standard TensorFlow matrix ops. Intelligent choices are made based on the following initialization hints.':'linearropertorfullmatrix具有与使用标准tensorflow矩阵ops完全相同的性能。根据以下初始化提示进行智能选择。',
'Initialize a LinearOperatorFullMatrix.':'初始化linearropertorfullmatrix。',
'## Class LinearOperatorHouseholder':'## 班主任',
'LinearOperator acting like a [batch] of Householder transformations.':'线性化器的作用类似于户主转换的[批处理]。',
'LinearOperatorHouseholder is initialized with a (batch) vector.':'lineropertorhouseholder使用（批处理）向量初始化。',
'This operator acts on [batch] matrix with compatible shape.':'此运算符作用于具有兼容形状的[批处理]矩阵。',
' #### Matrix property hints':'#### 矩阵属性提示',
'These have the following meaning:':'其含义如下：',
#'  in these promises being violated.':'在这些承诺被违背的时候。',
#'  way.':'太好了。',
'Initialize a LinearOperatorHouseholder.':'初始化lineropertorhouseholder。',
'## Class LinearOperatorIdentity':'## 类线性属性',
'LinearOperator acting like a [batch] square identity matrix.':'线性化器的作用类似于一个[batch]方恒等式矩阵。',
'### Shape compatibility':'### 形状兼容性',
'### Performance':'### 性能',
'Initialize a LinearOperatorIdentity.':'初始化线性属性。',
'The LinearOperatorIdentity is initialized with arguments defining dtype and shape.':'lineropertoridenty由定义dtype和shape的参数初始化。',
'Add matrix represented by this operator to mat. Equiv to I + mat.':'将此运算符表示的矩阵添加到mat。相当于i+mat。',
'## Class LinearOperatorInversion':'## 类线性属性转换',
'LinearOperator representing the inverse of another operator.':'表示另一个运算符的逆的线性运算符。',
'This operator represents the inverse of another operator.':'此运算符表示另一个运算符的逆。',
'Initialize a LinearOperatorInversion.':'初始化LinearPropertorInversion。',
'LinearOperatorInversion is initialized with an operator A. The solve and matmul methods are effectively swapped. E.g.':'用算子a初始化linearropertorInversion，有效地交换了solve和matmul方法。例如。',
'The operator before inversion.':'反转前的算符。',
'## Class LinearOperatorKronecker':'## 类LinearPropertorRonecker',
'Kronecker product between two LinearOperators.':'两个线性方程之间的kronecker积。',
'The performance of LinearOperatorKronecker on any operation is equal to the sum of the individual operators\' operations.':'lineropertorkronecker在任何操作上的性能都等于单个运算符的操作之和。',
'Initialize a LinearOperatorKronecker.':'初始化lineropertorkeronecker。',
'## Class LinearOperatorLowerTriangular':'## 类线性或弱三角形',
'LinearOperator acting like a [batch] square lower triangular matrix.':'线性化器，作用类似于[批]平方下三角矩阵。',
'Initialize a LinearOperatorLowerTriangular.':'初始化LinearPropertorLowerTriangular。',
'## Class LinearOperatorLowRankUpdate':'## 类别线性属性Lowrankupdate',
'Perturb a LinearOperator with a rank K update.':'用秩k更新扰动线性化器。',
'V^H is the Hermitian transpose (adjoint) of V.':'v^h是v的厄米转置（伴随）。',
'Initialize a LinearOperatorLowRankUpdate.':'初始化linearropertorlowrankupdate。',
'### u':'###U型',
'### v':'### 五',
'## Class LinearOperatorScaledIdentity':'## 类LinearPropertorScaleDidEntity',
'Initialize a LinearOperatorScaledIdentity.':'初始化LinearPropertorScaleDidEntity。',
'This operator is able to broadcast the leading (batch) dimensions.':'此操作员能够广播前导（批）维度。',
'### multiplier':'### 乘数',
'## Class LinearOperatorToeplitz':'## 类linearropertoeplitz',
'LinearOperator acting like a [batch] of toeplitz matrices.':'线性化器的作用类似于toeplitz矩阵的[批]。',
'#### Description in terms of toeplitz matrices':'####toeplitz矩阵的描述',
'Below is a 4 x 4 example:':'下面是一个4 x 4示例：',
#'    |e a b c|':'|乙丙|',
#'    |f e a b|':'|餐饮部|',
#'    |g f e a|':'| G F E A公司|',
'#### Example of a Toeplitz operator.':'####toeplitz算子的示例。',
'Initialize a LinearOperatorToeplitz.':'初始化linearropertoeplitz。',
'### col':'###col列',
'### row':'### 行',
'## Class LinearOperatorZeros':'## 类线性属性零',
'LinearOperator acting like a [batch] zero matrix.':'线性化器的作用类似于[批处理]零矩阵。',
'Initialize a LinearOperatorZeros.':'初始化linearropertorzeros。',
'The LinearOperatorZeros is initialized with arguments defining dtype and shape.':'lineropertorzeros由定义dtype和shape的参数初始化。',
'Computes log of the determinant of a hermitian positive definite matrix.':'计算厄米正定矩阵行列式的对数。',
'underflow:':'底流：',
'The natural log of the determinant of matrix.':'矩阵行列式的自然对数。',
'Computes the matrix logarithm of one or more square matrices:':'计算一个或多个方阵的矩阵对数：',
'Computes the LU decomposition of one or more square matrices.':'计算一个或多个方阵的lu分解。',
'The input has to be invertible.':'输入必须是可逆的。',
'Transposes last two dimensions of tensor a.':'转置张量A的最后两个维度。',
'A transposed batch matrix Tensor.':'转置的批矩阵张量。',
'Matrix a can be transposed or adjointed (conjugated and transposed) on the fly by setting one of the corresponding flag to True. These are False by default.':'通过将对应的标志之一设置为true，矩阵a可以动态地进行转置或伴随（共轭和转置）。默认情况下这些是错误的。',
'Normalizes tensor along dimension axis using specified norm.':'使用指定的范数沿尺寸轴规格化张量。',
'Computes the QR decompositions of one or more matrices.':'计算一个或多个矩阵的qr分解。',
'Returns a batched matrix tensor with new batched diagonal values.':'返回具有新的批处理对角值的批处理矩阵张量。',
'Computes the sign and the log of the absolute value of the determinant of':'计算行列式绝对值的符号和对数',
'one or more square matrices.':'一个或多个方阵。',
'Solves systems of linear equations.':'解线性方程组。',
'A Tensor. Has the same type as matrix.':'张量与矩阵类型相同。',
'Computes the matrix square root of one or more square matrices:':'计算一个或多个方阵的矩阵平方根：',
'Computes the singular value decompositions of one or more matrices.':'计算一个或多个矩阵的奇异值分解。',
'as the third output argument.':'作为第三个输出参数。',
'Returns a diagonal tensor with a given diagonal values.':'返回具有给定对角值的对角张量。',
'Returns the diagonal part of the tensor.':'返回张量的对角线部分。',
'This operation returns a tensor with the diagonal part of the input. The diagonal part is computed as follows:':'此操作返回一个带有输入对角部分的张量。对角线部分计算如下：',
'Compute the trace of a tensor x.':'计算张量x的轨迹。',
'The trace of input tensor.':'输入张量的轨迹。',
'Solves systems of linear equations with upper or lower triangular matrices by backsubstitution.':'用反代换法求解上下三角矩阵线性方程组。',
#'x':'十',
'Multiplies tridiagonal matrix by matrix.':'将三对角矩阵乘以矩阵。',
'The sequence format is recommended as the one with the best performance.':'建议使用性能最好的序列格式。',
'Solves tridiagonal systems of equations.':'解三对角方程组。',
'## Class Interpreter':'## 类解释器',
'Interpreter interface for TensorFlow Lite Models.':'Tensorflow Lite模型的解释器接口。',
'Gets model input details.':'获取模型输入详细信息。',
'A list of input details.':'输入详细信息的列表。',
'Gets model output details.':'获取模型输出详细信息。',
'A list of output details.':'输出详细信息的列表。',
'Gets the value of the input tensor (get a copy).':'获取输入张量的值（获取副本）。',
'a numpy array.':'一个核阵列。',
'Gets tensor details for every tensor with valid tensor details.':'获取具有有效张量详细信息的每个张量的张量详细信息。',
'Tensors where required information about the tensor is not found are not added to the list. This includes temporary tensors without a name.':'未找到有关张量的必需信息的张量不会添加到列表中。这包括没有名字的临时张量。',
'A list of dictionaries containing tensor information.':'包含张量信息的字典列表。',
'### invoke':'### 调用',
'Invoke the interpreter.':'调用解释器。',
'Resizes an input tensor.':'调整输入张量的大小。',
'Sets the value of the input tensor. Note this copies data in value.':'设置输入张量的值。注意，这会复制有价值的数据。',
'Returns function that gives a numpy view of the current tensor buffer.':'返回函数，该函数提供当前张量缓冲区的numpy视图。',
'#### WRONG:':'#### 错误：',
'## Class OpsSet':'## 类选项',
'Enum class defining the sets of ops available to generate TFLite models.':'枚举类定义可用于生成tflite模型的操作集。',
'## Class Optimize':'## 类优化',
'Enum defining the optimizations to apply when generating tflite graphs.':'枚举定义生成tflite图时要应用的优化。',
'Some optimizations may come at the cost of accuracy.':'一些优化可能以牺牲准确性为代价。',
'## Class RepresentativeDataset':'## 类代表数据集',
'Representative dataset to evaluate optimizations.':'用于评估优化的代表性数据集。',
'Creates a representative dataset.':'创建具有代表性的数据集。',
'## Class TargetSpec':'## 类目标规范',
'Specification of target device.':'目标设备规范。',
'Details about target device. Converter optimizes the generated model for specific device.':'有关目标设备的详细信息。转换器为特定设备优化生成的模型。',
'Converts a TensorFlow model into TensorFlow Lite model.':'将TensorFlow模型转换为TensorFlow Lite模型。',
'The converted data in serialized format.':'以序列化格式转换的数据。',
#'    funcs':'函数',
'Creates a TFLiteConverter object from ConcreteFunctions.':'从ConcreteFunctions创建TfliteConverter对象。',
'TFLiteConverter object.':'TFLiteConverter对象。',
'Invalid input type.':'输入类型无效。',
#'    model':'模型',
'Creates a TFLiteConverter object from a Keras model.':'从keras模型创建tflitecoverter对象。',
'Creates a TFLiteConverter object from a SavedModel directory.':'从savedModel目录创建tflitecoverter对象。',
'Invalid signature keys.':'无效的签名密钥。',
'Returns loaded Delegate object.':'返回加载的委托对象。',
'Delegate object.':'委托对象。',
'## Class KeyValueTensorInitializer':'## 类键值初始化器',
'Table initializers given keys and values tensors.':'给定键和值张量的表初始值设定项。',
'Constructs a table initializer object based on keys and values tensors.':'基于键和值张量构造表初始值设定项对象。',
'The expected table key dtype.':'所需的表键dtype。',
'The expected table value dtype.':'所需的表值DTYPE。',
'### initialize':'### 初始化',
'Initializes the given table with keys and values tensors.':'用键和值张量初始化给定的表。',
'The operation that initializes the table.':'初始化表的操作。',
'## Class TextFileIndex':'## 类textfileindex',
'The key and value content to get from each line.':'要从每行获取的键和值内容。',
'This class defines the key and value used for tf.lookup.TextFileInitializer.':'此类定义用于tf.lookup.textfileinitializer的键和值。',
'## Class TextFileInitializer':'## 类textfileinitializer',
'Table initializers from a text file.':'文本文件中的表初始值设定项。',
'This initializer assigns one entry in the table for each line in the file.':'此初始值设定项为文件中的每一行在表中分配一个条目。',
'For example if we have a file with the following content:':'例如，如果我们有一个包含以下内容的文件：',
'The following snippet initializes a table with the first column as keys and second column as values:':'以下代码段初始化一个表，其中第一列为键，第二列为值：',
'Similarly to initialize the whole line as keys and the line number as values.':'类似地，将整行初始化为键，将行号初始化为值。',
'Constructs a table initializer object to populate from a text file.':'构造要从文本文件填充的表初始值设定项对象。',
'Initializes the table from a text file.':'从文本文件初始化表。',
'## Class DenseHashTable':'## 类densehashtable',
'A generic mutable hash table implementation using tensors as backing store.':'使用张量作为后备存储的通用可变哈希表实现。',
'Data can be inserted by calling the insert method and removed by calling the remove method. It does not support initialization via the init method.':'可以通过调用insert方法插入数据，也可以通过调用remove方法删除数据。它不支持通过init方法进行初始化。',
'Creates an empty DenseHashTable object.':'创建空的densehashtable对象。',
'A DenseHashTable object.':'DensHashTable对象。',
'### erase':'### 删除',
'Removes keys and its associated values from the table.':'从表中删除键及其关联值。',
'### insert':'### 插入',
'Associates keys with values.':'将键与值关联。',
'A tensor containing the values in the same shape as keys using the table\'s value type.':'使用表的值类型包含与键形状相同的值的张量。',
'### remove':'### 删除',
'A Tensor of same shape and type as the elements of inputs.':'与输入元素形状和类型相同的张量。',
'Converts IndexedSlices objects into dense tensors prior to adding.':'在添加之前将indexedlices对象转换为密集张量。',
'The argument returned by this function is of the form':'此函数返回的参数的格式为',
'A Tensor of type float32 or float64.':'float32或float64类型的张量。',
'Returns the index with the largest value across axes of a tensor.':'返回在张量的轴上具有最大值的索引。',
'Returns the index with the smallest value across axes of a tensor.':'返回在张量的轴上具有最小值的索引。',
'A Tensor. Has the same type as y.':'张量与y的类型相同。',
'Modified Bessel function of order 1.':'一阶修正贝塞尔函数。',
'It is preferable to use the numerically stabler function i1e(x) instead.':'最好使用数值稳定函数i1e（x）。',
'Equivalent to scipy.special.i1':'相当于scipy.special.i1',
'Compute the regularized incomplete beta integral Ix(a,b).':'计算正则不完全β积分ix（a，b）。',
'The regularized incomplete beta integral is defined as:':'正则不完全β积分定义为：',
'is the incomplete beta function and':'是不完全的β函数',
'is the complete beta function.':'是完全的beta函数。',
'InvalidArgumentError if negative values are provided as an input.':'如果提供负值作为输入，则为InvalidArgumenterRor。',
'Returns the complex conjugate of a complex number.':'返回复数的复共轭。',
'The complex conjugate returned by this operation is of the form .':'这个操作返回的复共轭是这样的。',
'A Tensor that is the conjugate of x (with the same type).':'x的共轭张量（具有相同类型）。',
'Computes number of nonzero elements across dimensions of a tensor.':'计算张量维度上非零元素的数目。',
'Compute the cumulative product of the tensor x along axis.':'计算张量x沿轴的累积积。',
'Compute the cumulative sum of the tensor x along axis.':'计算张量x沿轴的累积和。',
'The reverse and exclusive kwargs can also be combined:':'反面和独家的夸尔格也可以结合起来：',
'A Tensor. Has the same shape and type as x.':'张量具有与x相同的形状和类型。',
'Computes Python style division of x by y.':'计算python样式的x除以y。',
'The lower regularized incomplete Gamma function is defined as:':'下正则化不完全伽马函数定义为：',
'is the lower incomplete Gamma function.':'是下不完全伽马函数。',
'The upper regularized incomplete Gamma function is defined as:':'上正则化不完全伽马函数定义为：',
'is the upper incomplete Gama function.':'是上不完全gama函数。',
'Returns the imaginary part of a complex (or real) tensor.':'返回复张量（或实张量）的虚部。',
'Computes the inverse permutation of a tensor.':'计算张量的逆置换。',
'Returns which elements of x are finite.':'返回x的哪些元素是有限的。',
'Equivalent to np.isfinite':'等价于np.isfinite',
'Returns which elements of x are Inf.':'返回x的哪些元素是inf。',
'Equivalent to np.isinf':'相当于np.isinf',
'Returns which elements of x are NaN.':'返回x的哪些元素是nan。',
'Equivalent to np.isnan':'相当于np.isnan',
'Returns True if x is strictly increasing.':'如果x严格递增，则返回true。',
'Normalizes along dimension axis using an L2 norm.':'使用L2范数沿尺寸轴规格化。',
'The logarithm of':'的对数',
'reducing along the last dimension.':'沿最后一个维度缩小。',
'A Tensor with the same type as x.':'与x类型相同的张量。',
'This operation returns the same result as the C++ std::nextafter function.':'此操作返回与c++std：：nextafter函数相同的结果。',
'It can also return a subnormal number.':'它还可以返回一个次正规数。',
'A Tensor. Has the same type as x1.':'张量具有与x1相同的类型。',
'#### Cpp Compatibility':'####CPP兼容性',
'Equivalent to C++ std::nextafter function.':'相当于c++std：：nextafter函数。',
'Compute the polygamma function ψ(n)(x).':'计算polygamma函数Ψ（n）（x）。',
'The polygamma function is defined as:':'polygamma函数定义为：',
'Computes the elementwise value of a polynomial.':'计算多项式的元素值。',
'Equivalent to numpy.polyval.':'相当于numpy.polyval。',
'Returns the real part of a complex (or real) tensor.':'返回复张量（或实张量）的实部。',
'A Tensor of same shape and type as x.':'与x形状和类型相同的张量。',
'Computes the "logical or" of elements across dimensions of a tensor.':'计算张量维度上元素的“逻辑或”。',
'Computes the Euclidean norm of elements across dimensions of a tensor.':'计算元素在张量维度上的欧几里德范数。',
'Computes log(sum(exp(elements across dimensions of a tensor))).':'计算log（sum（exp（张量维度上的元素））。',
'Computes the maximum of elements across dimensions of a tensor.':'计算张量维度上元素的最大值。',
'Computes the minimum of elements across dimensions of a tensor.':'计算张量维度上元素的最小值。',
'Computes the product of elements across dimensions of a tensor.':'计算元素在张量维度上的乘积。',
'Computes the standard deviation of elements across dimensions of a tensor.':'计算元素在张量维度上的标准偏差。',
'Equivalent to np.std':'等同于NP.STD',
'Computes the sum of elements across dimensions of a tensor.':'计算张量维度上元素的总和。',
'Computes the variance of elements across dimensions of a tensor.':'计算元素在张量维度上的方差。',
'Equivalent to np.var':'相当于np.var',
'Rounds half to even. Also known as bankers rounding. If you want to round according to the current system rounding mode use tf::cint. For example:':'一半到一半。也称为银行家围捕。如果要根据当前系统舍入模式进行舍入，请使用tf：：cint。例如：',
'Computes the maximum along segments of a tensor.':'计算张量沿线段的最大值。',
'Computes the mean along segments of a tensor.':'计算张量沿线段的平均值。',
'Computes the minimum along segments of a tensor.':'沿张量的线段计算最小值。',
'Computes the product along segments of a tensor.':'沿张量的线段计算乘积。',
'Computes the sum along segments of a tensor.':'沿张量的段计算和。',
'Computes a tensor such that':'计算张量，使',
'Equivalent to scipy.special.expit':'相当于scipy.special.expit',
'Computes softplus: log(exp(features) + 1).':'计算softplus:log（exp（features）+1）。',
'A Tensor. Has the same type as features.':'张量具有与功能相同的类型。',
'Finds values and indices of the k largest entries for the last dimension.':'查找最后一个维度的k个最大项的值和索引。',
'Computes the sum along segments of a tensor divided by the sqrt(N).':'计算沿张量分段除以sqrt（n）的和。',
'Returns the fraction of zeros in value.':'返回值中零的小数。',
'Compute the Hurwitz zeta function':'计算hurwitz-zeta函数',
'The Hurwitz zeta function is defined as:':'hurwitz zeta函数定义为：',
'Asserts that two structures are nested in the same way.':'断言两个结构以相同的方式嵌套。',
'Returns a flat list from a given nested structure.':'从给定的嵌套结构返回平面列表。',
'Users must not modify any collections used in nest while this function is running.':'运行此函数时，用户不得修改嵌套中使用的任何集合。',
'Returns true if its input is a collections.abc.Sequence (except strings).':'如果输入为collections.abc.sequence（字符串除外），则返回true。',
'True if the sequence is a not a string and is a collections.abc.Sequence or a dict.':'如果序列不是字符串并且是collections.abc.sequence或dict，则为true。',
'Applies func to each entry in structure and returns a new structure.':'对结构中的每个条目应用func并返回一个新结构。',
'Returns a given flattened sequence packed into a given structure.':'返回压缩到给定结构中的给定展平序列。',
'Atrous convolution (a.k.a. convolution with holes or dilated convolution).':'萎缩卷曲（亦称有孔卷曲或扩张卷曲）。',
'#### More specifically:':'#### 更具体地说：',
'There are many different ways to implement atrous convolution (see the refs above). The implementation here reduces':'有许多不同的方法来实现阿托罗斯卷积（见上面的参考文献）。这里的实现减少了',
'to the following three operations:':'执行以下三个操作：',
'can be equivalently performed cheaper in terms of computation and memory as:':'在计算和内存方面，可以等效地以更低的成本执行：',
'A Tensor with the same type as value. Output shape with \'VALID\' padding is:':'与值类型相同的张量。“有效”填充的输出形状为：',
'Output shape with \'SAME\' padding is:':'具有“相同”填充的输出形状为：',
'Performs the avg pooling on the input.':'对输入执行平均池。',
'Note internally this op reshapes and uses the underlying 2d operation.':'注意，这个操作在内部重塑并使用底层的2d操作。',
'Adds bias to value.':'增加价值偏差。',
'Merge repeated labels into single labels.':'将重复的标签合并为单个标签。',
'Usage with distribution strategy and custom training loop:':'使用分销策略和定制培训循环：',
'Scalar loss value.':'标量损失值。',
'The transpose of conv1d.':'conv1d的转置。',
'A Tensor with the same type as input.':'与输入类型相同的张量。',
'a rank (N+2) filters Tensor of shape':'秩（n+2）滤波形状张量',
'The transpose of convolution.':'卷积的转置。',
'Performs greedy decoding on the logits given in input (best path).':'对输入（最佳路径）中给定的登录执行贪婪解码。',
'Computes CTC (Connectionist Temporal Classification) loss.':'计算CTC（连接主义时间分类）损失。',
'Computes the gradients of depthwise convolution with respect to the filter.':'计算相对于滤波器的深度卷积的梯度。',
'Computes the gradients of depthwise convolution with respect to the input.':'计算相对于输入的深度卷积的梯度。',
'Computes dropout.':'计算辍学。',
'Performs fractional average pooling on the input.':'对输入执行分数平均池。',
'Performs fractional max pooling on the input.':'对输入执行分数最大池。',
'L2 Loss.':'二级损失。',
'Computes half the L2 norm of a tensor without the sqrt:':'计算不带sqrt的张量的l2范数的一半：',
'A Tensor. Has the same type as t.':'张量与t的类型相同。',
'Compute the Leaky ReLU activation function.':'计算leaky relu激活函数。',
'The activation value.':'激活值。',
'Local Response Normalization.':'本地响应规范化。',
'Computes log softmax activations.':'计算Log SoftMax激活。',
'Calculates the mean and variance of x.':'计算x的均值和方差。',
'Calculate the mean and variance of based on the sufficient statistics.':'在充分统计的基础上计算的均值和方差。',
'## Class RNNCellDeviceWrapper':'##RNNCellDeviceWrapper类',
'## Class RNNCellDropoutWrapper':'##RNNCellDropOutRapper类',
'## Class RNNCellResidualWrapper':'##RNNCellResidualWrapper类',
'Scales the sum of the given regularization losses by number of replicas.':'按副本数缩放给定正则化损失的总和。',
'Computes softmax activations.':'计算SoftMax激活。',
'Computes softmax cross entropy between logits and labels.':'计算登录和标签之间的SoftMax交叉熵。',
'Computes softsign: features / (abs(features) + 1).':'计算SoftSign:Features/（abs（Features）+1）。',
'Computes a weighted cross entropy.':'计算加权交叉熵。',
'Dequantize the \'input\' tensor into a float Tensor.':'将“input”张量反量化为浮点张量。',
'SCALED mode Example':'缩放模式示例',
'SCALED mode matches the quantization approach used in QuantizeAndDequantize{V2|V3}.':'缩放模式匹配量化和去量化{v2 v3}中使用的量化方法。',
'Now we can dequantize the elements of our tensor:':'现在我们可以去量化张量的元素：',
'Quantization is called fake since the output is still in floating point.':'量化称为假，因为输出仍在浮点。',
'Compute gradients for a FakeQuantWithMinMaxArgs operation.':'计算fakequantwithminmaxargs操作的渐变。',
'This operation has a gradient and thus allows for training min and max values.':'此操作具有渐变，因此允许训练最小值和最大值。',
'Compute gradients for a FakeQuantWithMinMaxVars operation.':'计算fakequantwithminmaxvars操作的渐变。',
'Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.':'计算fakequantwithminmaxvarsperchannel操作的渐变。',
'Quantize the \'input\' tensor of type float to \'output\' tensor of type \'T\'.':'将float类型的“input”张量量化为“t”类型的“output”张量。',
'Now we can quantize the elements of our tensor:':'现在我们可以量化张量的元素：',
'Concatenates quantized tensors along one dimension.':'沿一维连接量化张量。',
'Quantizes then dequantizes a tensor.':'量子化然后去量子化张量。',
'A Tensor. Each element is the result of quantizing and dequantizing the corresponding element of input.':'张量每个元素都是对相应的输入元素进行量化和去量化的结果。',
'## Class FIFOQueue':'## 五年级',
'### dtypes':'### 数据类型',
'The list of dtypes for each component of a queue element.':'队列元素每个组件的数据类型列表。',
'The name of the underlying queue.':'基础队列的名称。',
'### names':'### 姓名',
'The list of names for each component of a queue element.':'队列元素的每个组件的名称列表。',
'The underlying queue reference.':'基础队列引用。',
'The list of shapes for each component of a queue element.':'队列元素每个组件的形状列表。',
'Closes this queue.':'关闭此队列。',
'The operation that closes the queue.':'关闭队列的操作。',
'### dequeue':'### 出列',
'Dequeues one element from this queue.':'将此队列中的一个元素出列。',
'The tuple of tensors that was dequeued.':'出列的二元组张量。',
'Dequeues and concatenates n elements from this queue.':'将此队列中的n个元素出列并连接。',
'The list of concatenated tensors that was dequeued.':'已出列的连接张量列表。',
'The tuple of concatenated tensors that was dequeued.':'已出列的连接张量的元组。',
'### enqueue':'### 排队',
'Enqueues one element to this queue.':'将一个元素排入此队列。',
'The operation that enqueues a new tuple of tensors to the queue.':'将一个新的张量元组排列到队列中的操作。',
'Enqueues zero or more elements to this queue.':'将零个或多个元素排入此队列。',
'The operation that enqueues a batch of tuples of tensors to the queue.':'将一批张量元组排队到队列中的操作。',
#'    queues':'排队',
'A QueueBase object.':'QueueBase对象。',
'Returns true if queue is closed.':'如果队列已关闭，则返回true。',
'This operation returns true if the queue is closed and false if the queue is open.':'如果队列已关闭，则此操作返回true；如果队列已打开，则返回false。',
'True if the queue is closed and false if the queue is open.':'如果队列已关闭，则为true；如果队列已打开，则为false。',
'Compute the number of elements in this queue.':'计算此队列中的元素数。',
'A scalar tensor containing the number of elements in this queue.':'包含此队列中元素数的标量张量。',
'## Class PaddingFIFOQueue':'## 补课',
'## Class PriorityQueue':'## 类优先级队列',
'A queue implementation that dequeues elements in prioritized order.':'一种队列实现，按优先顺序对元素进行出列。',
'## Class QueueBase':'## 类队列基',
'Base class for queue implementations.':'队列实现的基类。',
'Constructs a queue object from a queue reference.':'从队列引用构造队列对象。',
'## Class RandomShuffleQueue':'## 类随机洗牌',
'A queue implementation that dequeues elements in a random order.':'按随机顺序对元素进行出列的队列实现。',
'Create a queue that dequeues elements in a random order.':'创建一个队列，以随机顺序将元素出列。',
'Applies a boolean mask to data without flattening the mask dimensions.':'对数据应用布尔掩码，而不展平掩码维度。',
'Returns a potentially ragged tensor that is formed by retaining the elements in data where the corresponding value in mask is True.':'返回一个潜在的不规则张量，该张量是通过保留mask中相应值为true的数据中的元素而形成的。',
'A potentially ragged tensor that is formed by retaining the elements in data where the corresponding value in mask is True.':'一种潜在的参差不齐的张量，通过保留mask中相应值为真的数据中的元素而形成。',
'Constructs a constant RaggedTensor from a nested Python list.':'从嵌套的python列表构造常量raggedtensor。',
'Applies op to the values of one or more RaggedTensors.':'将op应用于一个或多个raggedtensors的值。',
'Returns a RaggedTensor containing the specified sequences of numbers.':'返回包含指定数字序列的raggedtensor。',
'Each row of the returned RaggedTensor contains a single sequence:':'返回的raggedtensor的每一行都包含一个序列：',
'Stacks dynamic partitions of a Tensor or RaggedTensor.':'堆叠张量或raggedtensor的动态分区。',
'Generate the set of all classes.':'生成所有类的集合。',
'Draws samples from a categorical distribution.':'从分类分布中提取样本。',
'Samples a set of classes using the provided (fixed) base distribution.':'使用提供的（固定的）基分布对一组类进行采样。',
'Draws shape samples from each of the given Gamma distribution(s).':'从每个给定的伽马分布中绘制形状样本。',
'The samples are differentiable w.r.t. alpha and beta. The derivatives are computed using the approach described in the paper':'样本是可微的w.r.t.α和β。导数是用文中描述的方法计算的',
'Samples a set of classes from a distribution learned during training.':'从训练期间所学的分布中抽取一组类。',
'Outputs random values from a normal distribution.':'从正态分布输出随机值。',
'A tensor of the specified shape filled with random normal values.':'由随机法值填充的指定形状的张量。',
'Randomly shuffles a tensor along its first dimension.':'随机地沿着张量的第一个维度移动张量。',
'Draws deterministic pseudorandom samples from a categorical distribution.':'从类别分布中提取确定性伪随机样本。',
'Outputs deterministic pseudorandom values from a normal distribution.':'从正态分布输出确定性伪随机值。',
'A tensor of the specified shape filled with random truncated normal values.':'指定形状的张量，填充随机截断的法值。',
'Outputs deterministic pseudorandom values from a uniform distribution.':'从均匀分布中输出确定的伪随机值。',
'A tensor of the specified shape filled with random uniform values.':'由随机均匀值填充的指定形状的张量。',
'Outputs random values from a truncated normal distribution.':'从截断正态分布输出随机值。',
'Outputs random values from a uniform distribution.':'从均匀分布中输出随机值。',
'Samples a set of classes using a uniform base distribution.':'使用统一的基分布对一组类进行采样。',
'Creates a RNG state.':'创建RNG状态。',
# '    algorithm':'算法',
'## Class Generator':'## 类生成器',
'Creates a generator.':'创建生成器。',
'### algorithm':'### 算法',
'The RNG algorithm.':'rng算法。',
'### state':'### 国家',
'The internal state of the RNG.':'RNG的内部状态。',
'### binomial':'### 二项式',
'Outputs random values from a binomial distribution.':'从二项式分布中输出随机值。',
'The generated values follow a binomial distribution with specified count and probability of success parameters.':'生成的值遵循具有指定计数和成功概率参数的二项分布。',
# '    alg':'阿尔格',
'Creates a generator from a key and a counter.':'从键和计数器创建生成器。',
'The new generator.':'新发电机。',
'Creates a generator from a seed.':'从种子创建生成器。',
'Creates a generator from a state.':'从状态创建生成器。',
'Generates seeds for stateless random ops.':'为无状态随机操作生成种子。',
'### normal':'### 正常',
'Resets the generator by a new state.':'按新状态重置生成器。',
# '    counter':'柜台',
'Resets the generator by a new seed.':'使用新种子重置生成器。',
'Returns a list of independent Generator objects.':'返回独立生成器对象的列表。',
'A list (length count) of Generator objects independent of each other. The new generators have the same RNG algorithm as the old one.':'相互独立的生成器对象的列表（长度计数）。新发电机的rng算法与旧发电机相同。',
'### uniform':'### 制服',
'Uniform distribution on an integer type\'s entire range.':'整数类型的整个范围上的均匀分布。',
'A tensor of random numbers of the required shape.':'所需形状的随机数张量。',
'Replaces the global generator with another Generator object.':'用另一个生成器对象替换全局生成器。',
'Compute set difference of elements in last dimension of a and b.':'计算a和b的最后一维元素的集差。',
'All but the last dimension of a and b must match.':'除了A和B的最后一个维度外，其他维度都必须匹配。',
# '  #':'#',
'Compute set intersection of elements in last dimension of a and b.':'计算A和B最后一个维度中元素的集合交集。',
'Compute number of unique elements along last dimension of a.':'计算A的最后一个维度上唯一元素的数量。',
'Compute set union of elements in last dimension of a and b.':'计算a和b的最后维元素的集合并。',
'Fast Fourier transform.':'快速傅里叶变换。',
'Equivalent to numpy.fft.fftshift. https://docs.scipy.org/doc/numpy/reference/generated/numpy.fft.fftshift.html':'相当于numpy.fft.fftshift。https://docs.scipy.org/doc/numpy/reference/generated/numpy.fft.fftshift.html',
'Inverse fast Fourier transform.':'逆快速傅里叶变换。',
'Inverse 2D fast Fourier transform.':'反二维快速傅里叶变换。',
'Inverse 3D fast Fourier transform.':'三维快速傅里叶逆变换。',
'The inverse of fftshift.':'与fftshift相反。',
'Equivalent to numpy.fft.ifftshift. https://docs.scipy.org/doc/numpy/reference/generated/numpy.fft.ifftshift.html':'相当于numpy.fft.ifftshift。https://docs.scipy.org/doc/numpy/reference/generated/numpy.fft.ifftshift.html',
'Reconstructs a signal from a framed representation.':'从帧表示重建信号。',
'A Tensor of type complex64.':'复数64型张量。',
'Generates sparse cross from a list of sparse and dense tensors.':'从稀疏和稠密张量列表生成稀疏交叉。',
'then the output will be:':'那么输出将是：',
'A SparseTensor of type string.':'string类型的sparsetensor。',
'Generates hashed sparse cross from a list of sparse and dense tensors.':'从稀疏和稠密张量列表生成哈希稀疏交叉。',
'A SparseTensor of type int64.':'Int64类型的Sparsetensor。',
'This op also returns an indicator vector such that':'此操作还返回一个指示符向量，以便',
'Converts a dense tensor into a sparse tensor.':'将密集张量转换为稀疏张量。',
'Only elements not equal to zero will be present in the result. The resulting SparseTensor has the same dtype and shape as the input.':'只有不等于零的元素才会出现在结果中。生成的sparsetensor具有与输入相同的数据类型和形状。',
'The SparseTensor.':'斯巴塞传感器。',
'Masks elements of IndexedSlices.':'屏蔽indexedlices的元素。',
'This is useful when you need to extract a subset of slices in an IndexedSlices object.':'当需要提取indexedlices对象中切片的子集时，这非常有用。',
'The masked IndexedSlices instance.':'掩蔽indexedlices实例。',
'Computes the max of elements across dimensions of a SparseTensor.':'计算Sparsetensor维度上元素的最大值。',
'Computes the sum of elements across dimensions of a SparseTensor.':'计算Sparsetensor维度上元素的总和。',
'Reordering does not affect the shape of the SparseTensor.':'重新排序不会影响Sparsetensor的形状。',
'Resets the shape of a SparseTensor with indices and values unchanged.':'在索引和值不变的情况下重置Sparsetensor的形状。',
'Reshapes a SparseTensor to represent values in a new dense shape.':'重塑Sparsetensor以在新的密集形状中表示值。',
'Slice a SparseTensor based on the start and `size.':'根据开始和大小对sparsetensor进行切片。',
'A SparseTensor objects resulting from splicing.':'拼接产生的sparsetensor对象。',
'## Class SparseTensor':'## 类Sparsetensor',
'Represents a sparse tensor.':'表示稀疏张量。',
'The corresponding dense tensor satisfies:':'相应的稠密张量满足：',
'Example: The sparse tensor':'示例：稀疏张量',
'represents the dense tensor':'表示密集张量',
'Creates a SparseTensor.':'创建Sparsetensor。',
'Get the TensorShape representing the shape of the dense tensor.':'得到表示稠密张量形状的张量形状。',
'A TensorShape object.':'张量形状的物体。',
'Evaluates this sparse tensor in a Session.':'在会话中计算此稀疏张量。',
'A SparseTensorValue object.':'SparSetenservalue对象。',
'Multiply SparseTensor (of rank 2) "A" by dense matrix "B".':'将Sparsetensor（秩2）“A”乘以稠密矩阵“B”。',
'#### Benchmark system:':'#### 基准系统：',
'#### Compiled with:':'#### 编制单位：',
'Converts a SparseTensor into a dense tensor.':'将Sparsetensor转换为密集张量。',
'Converts a SparseTensor of ids into a dense bool indicator tensor.':'将ids的sparsetensor转换为密集bool指示符张量。',
'Note that repeats are allowed in the input SparseTensor. This op is useful for converting SparseTensors into dense formats for compatibility with ops that expect dense tensors.':'请注意，输入sparsetensor中允许重复。此操作对于将sparsetensors转换为密集格式以与期望密集张量的操作兼容非常有用。',
'A dense bool indicator tensor representing the indices with specified value.':'表示具有指定值的索引的稠密bool指示符张量。',
'Transposes a SparseTensor':'转换Sparsetensor',
'A transposed SparseTensor.':'转置的Sparsetensor。',
'Converts each entry in the given tensor to strings.':'将给定张量中的每个项转换为字符串。',
'Supports many numeric types and boolean.':'支持多种数值类型和布尔值。',
'Split string elements of input into bytes.':'将输入的字符串元素拆分为字节。',
'A RaggedTensor of rank N+1: the bytes that make up the source strings.':'秩n+1的raggedtensor：构成源字符串的字节。',
'Formats a string template using a list of tensors.':'使用张量列表格式化字符串模板。',
'A scalar Tensor of type string.':'字符串类型的标量张量。',
'Joins the strings in the given list of string tensors into one tensor;':'将给定的字符串张量列表中的字符串连接成一个张量；',
'TODO: add doc.':'待办事项：添加文档。',
'Check if the input matches the regex pattern.':'检查输入是否与regex模式匹配。',
'The input is a string tensor of any shape. The pattern is a scalar string tensor which is applied to every element of the input tensor. The boolean values (True or False) of the output tensor indicate if the input matches the regex pattern provided.':'输入是任意形状的字符串张量。模式是应用于输入张量的每个元素的标量字符串张量。输出张量的布尔值（真或假）指示输入是否与提供的正则表达式模式匹配。',
'Replace elements of input matching regex pattern with rewrite.':'用rewrite替换与regex模式匹配的输入元素。',
'string Tensor of the same shape as input with specified replacements.':'具有指定替换项的与输入形状相同的字符串张量。',
'Split elements of input based on sep into a RaggedTensor.':'将基于sep的输入元素拆分为raggedtensor。',
'Strip leading and trailing whitespaces from the Tensor.':'从张量中去掉前导空格和尾随空格。',
'Decodes each string in input into a sequence of Unicode code points.':'将输入中的每个字符串解码为一系列Unicode代码点。',
'Decodes each string into a sequence of code points with start offsets.':'将每个字符串解码为具有起始偏移量的代码点序列。',
'Encodes each sequence of Unicode code points in input into a string.':'将输入中的每个Unicode代码点序列编码为字符串。',
'Determine the script codes of a given tensor of Unicode integer code points.':'确定Unicode整数码位的给定张量的脚本代码。',
'Splits each string in input into a sequence of Unicode code points.':'将输入中的每个字符串拆分为一系列Unicode代码点。',
'Splits each string into a sequence of code points with start offsets.':'将每个字符串拆分为一系列具有起始偏移量的代码点。',
'Transcode the input text from a source encoding to a destination encoding.':'将输入文本从源编码转换为目标编码。',
'Example usage with legacy TF 1.x graph execution:':'使用传统tf 1.x图形执行的示例：',
'Write an audio summary.':'写一个音频摘要。',
'Creates a summary file writer for the given log directory.':'为给定的日志目录创建摘要文件编写器。',
'A SummaryWriter object.':'SummaryWriter对象。',
'Returns a summary writer that does nothing.':'返回不执行任何操作的摘要编写器。',
'This is useful as a placeholder in code that expects a context manager.':'这对于需要上下文管理器的代码中的占位符很有用。',
'Forces summary writer to send any buffered data to storage.':'强制摘要编写器将任何缓冲数据发送到存储。',
'This operation blocks until that finishes.':'这项行动一直持续到结束。',
'Write a histogram summary.':'写一个直方图摘要。',
'Write an image summary.':'写一个图像摘要。',
'Sets summary recording on or off per the provided boolean value.':'根据提供的布尔值设置摘要录制打开或关闭。',
'Returns a context manager that sets this value on enter and restores the previous value on exit.':'返回上下文管理器，该管理器在输入时设置此值，在退出时还原上一个值。',
'Write a scalar summary.':'编写标量摘要。',
'## Class SummaryWriter':'## Class 总结作者',
'Interface representing a stateful summary writer object.':'表示有状态摘要编写器对象的接口。',
'Returns a context manager that enables summary writing.':'返回启用摘要写入的上下文管理器。',
'Flushes and closes the summary writer.':'刷新并关闭摘要编写器。',
'Flushes any buffered data.':'刷新任何缓冲数据。',
'### init':'### 初始',
'Initializes the summary writer.':'初始化摘要编写器。',
'Enables this summary writer for the current thread.':'为当前线程启用此摘要编写器。',
'Write a text summary.':'写一篇课文摘要。',
'Stops and exports the active trace as a Summary and/or profile file.':'停止并将活动跟踪导出为摘要和/或配置文件。',
'Stops the current trace and discards any collected information.':'停止当前跟踪并丢弃所有收集的信息。',
'Starts a trace to record computation graphs and profiling information.':'启动跟踪以记录计算图和分析信息。',
'Must be invoked in eager mode.':'必须在紧急模式下调用。',
'Writes a generic summary to the default SummaryWriter if one exists.':'将常规摘要写入默认的SummaryWriter（如果存在）。',
'Public API for tf.summary.experimental namespace.':'tf.summary.experimental命名空间的公共API。',
'Returns the default summary step for the current thread.':'返回当前线程的默认摘要步骤。',
'Sets the default summary step for the current thread.':'设置当前线程的默认摘要步骤。',
'Experimental context manager for use when defining a custom summary op.':'用于定义自定义摘要操作的实验上下文管理器。',
'This makes the summary tag more predictable and consistent for the user.':'这使得summary标记对用户来说更加可预测和一致。',
'Get the compilation flags for custom operators.':'获取自定义运算符的编译标志。',
'The compilation flags.':'编译标志。',
'Get the directory containing the TensorFlow C++ header files.':'获取包含tensorflow c++头文件的目录。',
'The directory as string.':'作为字符串的目录。',
'Get the directory containing the TensorFlow framework library.':'获取包含tensorflow框架库的目录。',
'Get the link flags for custom operators.':'获取自定义运算符的链接标志。',
'The link flags.':'链接标志。',
# '    actual':'实际的',
'## Class Benchmark':'## 类基准',
'Abstract class that provides helpers for TensorFlow benchmarks.':'为TensorFlow基准提供帮助程序的抽象类。',
'Evaluates tensors and returns numpy values.':'计算张量并返回numpy值。',
'tensors numpy values.':'张量numpy值。',
'Report a benchmark.':'报告基准。',
'Run an op or tensor in the given session. Report the results.':'在给定的会话中运行运算或张量。报告结果。',
'Returns a tf.compat.v1.ConfigProto for disabling the dependency optimizer.':'返回用于禁用依赖项优化器的tf.compat.v1.configproto。',
'A TensorFlow ConfigProto object.':'tensorflow configproto对象。',
'Computes the theoretical and numeric Jacobian of f.':'计算f的理论雅可比和数值雅可比。',
'Create and start local servers and return the associated Server objects.':'创建并启动本地服务器并返回关联的服务器对象。',
'Read more at https://www.tensorflow.org/guide/extend/architecture':'更多信息请访问https://www.tensorflow.org/guide/extend/architecture',
'Returns the name of a GPU device if available or the empty string.':'返回GPU设备的名称（如果可用）或空字符串。',
'Returns whether TensorFlow was built with CUDA (GPU) support.':'返回是否使用CUDA（GPU）支持生成TensorFlow。',
'Returns whether TensorFlow was built with GPU (i.e. CUDA or ROCm) support.':'返回TensorFlow是使用GPU（即CUDA或ROCM）支持构建的。',
'Returns whether TensorFlow was built with ROCm (GPU) support.':'返回是否使用rocm（gpu）支持生成tensorflow。',
'Returns whether TensorFlow can access a GPU.':'返回TensorFlow是否可以访问GPU。',
'True if a GPU device of the requested kind is available.':'如果请求类型的GPU设备可用，则为true。',
'Runs all unit tests.':'运行所有单元测试。',
'## Class TestCase':'## 类测试用例',
'Base class for tests that need to test TensorFlow.':'需要测试tensorflow的测试的基类。',
'Create an instance of the class that will use the named test method when executed. Raises a ValueError if the instance does not have a method with the specified name.':'创建执行时将使用命名测试方法的类的实例。如果实例没有具有指定名称的方法，则引发valueerror。',
'### addCleanup':'### 添加清理',
'Cleanup items are called even if setUp fails (unlike tearDown).':'即使安装失败，也会调用清理项（与拆卸不同）。',
'### addTypeEqualityFunc':'###addTypeEqualityFunc',
#'    function':'功能',
'Add a type specific assertEqual style function to compare a type.':'添加特定于类型的asserteQual样式函数以比较类型。',
'This method is for use by TestCase subclasses that need to register their own type equality functions to provide nicer error messages.':'此方法供需要注册自己的类型相等函数以提供更好的错误消息的testcase子类使用。',
'### assertAllClose':'### 资产结算',
'### assertAllCloseAccordingToType':'### 按类型关闭资产',
'### assertAllEqual':'### 资产质量',
'Asserts that two numpy arrays or Tensors have the same values.':'断言两个numpy数组或张量具有相同的值。',
'### assertAllGreater':'### 资产负债表',
'Assert element values are all greater than a target value.':'断言元素值都大于目标值。',
'### assertAllGreaterEqual':'### 资产负债表',
'Assert element values are all greater than or equal to a target value.':'断言元素值都大于或等于目标值。',
'### assertAllInRange':'### 阿瑟他林',
'Assert that elements in a Tensor are all in a given range.':'断言张量中的元素都在给定的范围内。',
'### assertAllInSet':'### 阿瑟茶碱',
'Assert that elements of a Tensor are all in a given closed set.':'断言张量的元素都在给定的闭集中。',
'### assertAllLess':'### 无资产',
'Assert element values are all less than a target value.':'断言元素值都小于目标值。',
'### assertAllLessEqual':'### 资产负债表',
'Assert element values are all less than or equal to a target value.':'断言元素值都小于或等于目标值。',
'### assertAlmostEqual':'### 资产质量',
'Note that decimal places (from zero) are usually not the same as significant digits (measured from the most signficant digit).':'注意，小数点（从零开始）通常与有效数字（从最重要的数字开始测量）不同。',
'If the two objects compare equal then they will automatically compare almost equal.':'如果两个对象比较相等，那么它们将自动比较几乎相等。',
'### assertAlmostEquals':'### 资产质量',
'### assertArrayNear':'###AssertArrayNear公司',
'Asserts that two float arrays are near each other.':'断言两个浮点数组彼此靠近。',
'### assertBetween':'### 资产之间',
'Asserts that value is between minv and maxv (inclusive).':'断言该值介于minv和maxv（包括）之间。',
'### assertCommandFails':'###assertcommand失败',
'Asserts a shell command fails and the error matches a regex in a list.':'断言shell命令失败，错误与列表中的正则表达式匹配。',
'### assertCommandSucceeds':'###assertcommand成功',
'### assertContainsExactSubsequence':'###AssertContainesActSubSequence组件',
'Asserts that "container" contains "subsequence" as an exact subsequence.':'断言“container”包含“subsequence”作为确切的子序列。',
'### assertContainsInOrder':'### 资产目录',
'Asserts that the strings provided are found in the target in order.':'断言提供的字符串按顺序在目标中找到。',
'This may be useful for checking HTML output.':'这对于检查html输出可能很有用。',
'### assertContainsSubsequence':'### 资产包含序列',
'Asserts that "container" contains "subsequence" as a subsequence.':'断言“container”包含作为子序列的“subsequence”。',
'### assertContainsSubset':'### 资产内容集',
'Checks whether actual iterable is a superset of expected iterable.':'检查实际iterable是否为预期iterable的超集。',
'### assertCountEqual':'### 资产计数器',
'### assertDTypeEqual':'### 资产类型相等',
'Assert ndarray data type is equal to expected.':'assert ndarray数据类型等于预期值。',
'### assertDeviceEqual':'### 资产设备同等',
'Asserts that the two given devices are the same.':'断言两个给定的设备是相同的。',
'### assertDictContainsSubset':'###assertdictcontainssubset属性',
'Checks whether dictionary is a superset of subset.':'检查字典是否为子集的超集。',
'### assertDictEqual':'### 听写器',
'Raises AssertionError if a and b are not equal dictionaries.':'如果a和b不是相等的字典，则引发断言错误。',
'### assertEmpty':'### 断言',
'Asserts that an object has zero length.':'断言对象的长度为零。',
'### assertEndsWith':'### 资产交换',
'### assertEqual':'### 资产质量',
'### assertEquals':'### 资产质量',
'### assertFalse':'### 断言错误',
'Check that the expression is false.':'检查表达式是否为false。',
'### assertGreater':'### 大资产',
'### assertGreaterEqual':'### 资产净值',
'### assertIn':'### 断言',
'### assertIs':'### 断言',
'### assertIsInstance':'### 断言',
'### assertIsNone':'### 断言',
'### assertIsNot':'### 断言',
'### assertIsNotNone':'### 断言',
'Included for symmetry with assertIsNone.':'包括对称与断言。',
'### assertItemsEqual':'### 断言性',
'### assertJsonEqual':'### 资产净值',
'Asserts that the JSON objects defined in two strings are equal.':'断言在两个字符串中定义的json对象是相等的。',
'A summary of the differences will be included in the failure message using assertSameStructure.':'使用AssertSameStructure的失败消息中将包含差异摘要。',
'### assertLen':'### 资产',
'Asserts that an object has the expected length.':'断言对象具有预期的长度。',
'### assertLess':'### 无资产',
'### assertLessEqual':'### 资产负债表',
'### assertListEqual':'### 资产负债表',
'### assertLogs':'### 资产日志',
'Example::':'例子：：',
'### assertMultiLineEqual':'### 资产多行',
'### assertNDArrayNear':'### 资产负债表',
'Asserts that two numpy arrays have near values.':'断言两个numpy数组有接近的值。',
'### assertNear':'### 资产负债表',
'Asserts that two floats are near each other.':'断言两个浮标彼此靠近。',
'### assertNoCommonElements':'### 资产委员会',
'Checks whether actual iterable and expected iterable are disjoint.':'检查实际iterable和预期iterable是否不相交。',
'### assertNotAllClose':'### 资产未结清',
'### assertNotAllEqual':'### 资产不平等',
'Asserts that two numpy arrays or Tensors do not have the same values.':'断言两个numpy数组或张量的值不相同。',
'### assertNotAlmostEqual':'### 资产负债表',
'Objects that are equal automatically fail.':'相等的对象将自动失败。',
'### assertNotAlmostEquals':'### 资产负债表',
'### assertNotEmpty':'### 资产不空',
'### assertNotEndsWith':'### 资产负债表',
'### assertNotEqual':'### 资产质量',
'### assertNotEquals':'### 资产负债表',
'### assertNotIn':'### 阿瑟诺丁',
'### assertNotIsInstance':'### 资产通知',
'Included for symmetry with assertIsInstance.':'包括对称性和断言性。',
'### assertNotRegex':'### 资产负债表',
'Fail the test if the text matches the regular expression.':'如果文本与正则表达式匹配，则测试失败。',
'### assertNotRegexpMatches':'###assertnotregexpmatches',
'### assertNotStartsWith':'### 资产未启动',
'### assertProtoEquals':'### 资产协议',
'### assertProtoEqualsVersion':'### 资产协议版本',
'### assertRaises':'### 资产提存',
'An optional keyword argument \'msg\' can be provided when assertRaises is used as a context object.':'当assertraises用作上下文对象时，可以提供可选的关键字参数“msg”。',
'The context manager keeps a reference to the exception as the \'exception\' attribute. This allows you to inspect the exception after the assertion::':'上下文管理器将对异常的引用保留为“exception”属性。这允许您在断言之后检查异常：',
'### assertRaisesOpError':'### 资产评估',
'### assertRaisesRegex':'### 资产评估',
'Asserts that the message in a raised exception matches a regex.':'断言引发的异常中的消息与正则表达式匹配。',
'### assertRaisesRegexp':'### 资产评估',
'### assertRaisesWithLiteralMatch':'###AssertRaiseWithLiteralMatch资产',
'Asserts that the message in a raised exception equals the given string.':'断言引发的异常中的消息等于给定的字符串。',
'### assertRaisesWithPredicateMatch':'###AssertRaiseWithPredicteMatch',
'Returns a context manager to enclose code expected to raise an exception.':'返回一个上下文管理器，将引发异常的代码括起来。',
'A context manager to surround code that is expected to raise an exception.':'一个上下文管理器，用于包围预期引发异常的代码。',
'### assertRegex':'### 资产调整表',
'Fail the test unless the text matches the regular expression.':'除非文本与正则表达式匹配，否则测试将失败。',
'### assertRegexMatch':'### 资产调整匹配',
'Asserts that at least one regex in regexes matches str.':'断言正则表达式中至少有一个正则表达式与str匹配。',
'### assertRegexpMatches':'###assertregexpmatches',
'### assertSameElements':'### 资产共享要素',
'Asserts that two sequences have the same elements (in any order).':'断言两个序列具有相同的元素（以任何顺序）。',
'### assertSameStructure':'### 资产结构',
'Asserts that two values contain the same structural content.':'断言两个值包含相同的结构内容。',
'### assertSequenceAlmostEqual':'### 资产序列表',
'An approximate equality assertion for ordered sequences.':'有序序列的近似相等断言。',
'Note that decimal places (from zero) are usually not the same as significant digits (measured from the most significant digit).':'注意，小数位数（从零开始）通常与有效数字（从最有效数字开始测量）不同。',
'If the two sequences compare equal then they will automatically compare almost equal.':'如果两个序列比较相等，那么它们将自动比较几乎相等。',
'### assertSequenceEqual':'### 资产序列相等',
'An equality assertion for ordered sequences (like lists and tuples).':'有序序列（如列表和元组）的相等断言。',
'### assertSequenceStartsWith':'###assertsequencestartswith',
'An equality assertion for the beginning of ordered sequences.':'顺序序列开头的相等断言。',
'### assertSetEqual':'### 资产净值',
'### assertShapeEqual':'### 资产质量',
'Asserts that a Numpy ndarray and a TensorFlow tensor have the same shape.':'断言numpy-ndarray和tensorflow张量具有相同的形状。',
'### assertStartsWith':'### 资产启动',
'### assertTotallyOrdered':'### 资产总额',
'Asserts that total ordering has been implemented correctly.':'断言已正确实现总排序。',
'### assertTrue':'### 资产真实',
'Check that the expression is true.':'检查表达式是否为真。',
'### assertTupleEqual':'### 资产净值',
'### assertUrlEqual':'### 资产质量',
'### assertWarns':'### 资产警告',
'An optional keyword argument \'msg\' can be provided when assertWarns is used as a context object.':'当assertwarns用作上下文对象时，可以提供可选的关键字参数“msg”。',
'### assertWarnsRegex':'### 资产警告',
'Asserts that the message in a triggered warning matches a regexp. Basic functioning is similar to assertWarns() with the addition that only warnings whose messages also match the regular expression are considered successful matches.':'断言触发的警告中的消息与regexp匹配。基本功能类似于assertwarns（），另外，只有消息也与正则表达式匹配的警告才被视为成功匹配。',
'Returns a TensorFlow Session for use in executing tests.':'返回用于执行测试的tensorflow会话。',
'A Session object that should be used as a context manager to surround the graph building and execution code in a test case.':'一个会话对象，应该用作上下文管理器，在测试用例中包围图形生成和执行代码。',
'### captureWritesToStream':'###CaptureWriteStorestream捕获',
'A context manager that captures the writes to a given stream.':'捕获对给定流的写入的上下文管理器。',
'A CapturedWrites object that contains all writes to the specified stream made during this context.':'CapturedWrites对象，包含在此上下文中对指定流的所有写入。',
'### checkedThread':'### 检查线程',
'Returns a Thread wrapper that asserts \'target\' completes successfully.':'返回断言“target”已成功完成的线程包装器。',
'A wrapper for threading.Thread that supports start() and join() methods.':'支持start（）和join（）方法的threading.thread的包装器。',
'### countTestCases':'### 计数测试用例',
'Create a temporary directory specific to the test.':'创建特定于测试的临时目录。',
'Create a temporary file specific to the test.':'创建特定于测试的临时文件。',
'### debug':'### 调试',
'Run the test without collecting errors in a TestResult':'在不收集测试结果错误的情况下运行测试',
'### defaultTestResult':'### 默认测试结果',
'### doCleanups':'### 文档清理',
'Execute all cleanup functions. Normally called for you after tearDown.':'执行所有清理函数。通常是在你哭过之后叫你的。',
'### fail':'### 失败',
'### failIf':'### 失败',
'### failIfAlmostEqual':'### 失败',
'### failIfEqual':'### 失败相等',
'### failUnless':'### 失败除非',
'### failUnlessAlmostEqual':'### 失语',
'### failUnlessEqual':'### 失效评定',
'### failUnlessRaises':'### 失败',
'Returns a unique temporary directory for the test to use.':'返回测试要使用的唯一临时目录。',
'### id':'### 身份证',
'Note that this will set this session and the graph as global defaults.':'请注意，这会将此会话和图形设置为全局默认值。',
'### setUp':'### 设置',
'Hook method for setting up the test fixture before exercising it.':'在使用前设置测试夹具的钩子法。',
'### setUpClass':'### 设置类',
'Hook method for setting up class fixture before running tests in the class.':'在类中运行测试之前设置类fixture的钩子方法。',
'### shortDescription':'### 简短描述',
'Formats both the test method name and the first line of its docstring.':'格式化测试方法名及其docstring的第一行。',
'### skipTest':'### 能手',
'Skip this test.':'跳过这个测试。',
'### subTest':'### 子测验',
'### tearDown':'### 撕裂',
'Hook method for deconstructing the test fixture after testing it.':'试验夹具试验后解构的钩子法。',
'### tearDownClass':'### 泪腺',
'Hook method for deconstructing the class fixture after running all tests in the class.':'hook方法，用于在运行类中的所有测试之后解构类fixture。',
'Assertion failed.':'断言失败。',
'## Class DeviceAssignment':'## 类设备签名',
'Mapping from logical cores in a computation to the physical TPU topology.':'从计算中的逻辑核心到物理tpu拓扑的映射。',
'Constructs a DeviceAssignment object.':'构造设备签名对象。',
'The logical to physical core mapping.':'逻辑到物理核心的映射。',
'The number of cores per replica.':'每个副本的核心数。',
'The number of replicas of the computation.':'计算的副本数。',
'### topology':'### 拓扑结构',
'A Topology that describes the TPU topology.':'描述TPU拓扑的拓扑。',
'### coordinates':'### 坐标系',
'Returns the physical topology coordinates of a logical core.':'返回逻辑核心的物理拓扑坐标。',
'Returns the CPU device attached to a logical core.':'返回连接到逻辑核心的CPU设备。',
'Lookup replica ids by task number and logical core.':'按任务号和逻辑核心查找副本ID。',
'Returns the name of the TPU device assigned to a logical core.':'返回分配给逻辑核心的TPU设备的名称。',
'Returns the ordinal of the TPU device assigned to a logical core.':'返回分配给逻辑核心的TPU设备的序号。',
'Initialize the TPU devices.':'初始化TPU设备。',
'The tf.tpu.Topology object for the topology of the TPU cluster.':'tpu集群拓扑的tf.tpu.topology对象。',
'## Class BytesList':'## 类字节列表',
'repeated bytes value':'重复字节值',
'## Class CheckpointManager':'## 类检查点管理器',
'Deletes old checkpoints.':'删除旧检查点。',
'Configure a CheckpointManager for use in directory.':'配置检查点管理器以在目录中使用。',
'### checkpoints':'### 检查点',
'A list of managed checkpoints.':'管理的检查点列表。',
'The prefix of the most recent checkpoint in directory.':'目录中最近检查点的前缀。',
'Creates a new checkpoint and manages it.':'创建并管理新的检查点。',
'Continuously yield new checkpoint files as they appear.':'不断生成新的检查点文件。',
'String paths to latest checkpoint files as they arrive.':'字符串最新检查点文件到达时的路径。',
'## Class ClusterDef':'## 类clusterdef',
'repeated JobDef job':'重复作业定义作业',
'## Class ClusterSpec':'## 类群集规范',
'Each job may also be specified as a sparse mapping from task indices to network addresses. This enables a server to be configured without needing to know the identity of (for example) all other worker tasks:':'每个作业也可以指定为从任务索引到网络地址的稀疏映射。这样可以配置服务器，而无需知道（例如）所有其他工作任务的标识：',
'Creates a ClusterSpec.':'创建ClusterSpec。',
'### jobs':'### 工作',
'Returns a list of job names in this cluster.':'返回此群集中作业名称的列表。',
'Returns a dictionary from job names to their tasks.':'返回从作业名称到其任务的字典。',
'A dictionary mapping job names to lists or dictionaries describing the tasks in those jobs.':'将作业名称映射到描述这些作业中的任务的列表或字典的字典。',
'Returns a mapping from task ID to address in the given job.':'返回从任务ID到给定作业中地址的映射。',
'Returns the number of tasks defined in the given job.':'返回在给定作业中定义的任务数。',
'The number of tasks defined in the given job.':'在给定作业中定义的任务数。',
'Returns the address of the given task in the given job.':'返回给定作业中给定任务的地址。',
'The address of the given task in the given job.':'给定作业中给定任务的地址。',
'Returns a list of valid task indices in the given job.':'返回给定作业中有效任务索引的列表。',
'A list of valid task indices in the given job.':'给定作业中有效任务索引的列表。',
'## Class Coordinator':'## Class 协调员',
'A coordinator for threads.':'线程的协调器。',
'This class implements a simple mechanism to coordinate the termination of a set of threads.':'这个类实现了一个简单的机制来协调一组线程的终止。',
'A typical thread running with a coordinator will do something like:':'使用协调器运行的典型线程将执行以下操作：',
'#### Exception handling:':'#### 异常处理：',
'#### Thread code:':'#### 线程代码：',
'except Exception as e:':'除E例外：',
'#### Main code:':'#### 主代码：',
'#### Grace period for stopping:':'#### 停止宽限期：',
'except RuntimeError:':'除了运行时错误：',
'except Exception:':'例外情况除外：',
'Create a new Coordinator.':'创建一个新的协调器。',
'### joined':'### 加入',
'Clears the stop flag.':'清除停止标志。',
'Wait for threads to terminate.':'等待线程终止。',
'Register a thread to join.':'注册要加入的线程。',
'Request that the threads stop.':'请求线程停止。',
'Check if stop was requested.':'检查是否请求停止。',
'True if a stop was requested.':'如果请求停止，则为true。',
'Context manager to request stop when an Exception is raised.':'在引发异常时请求停止的上下文管理器。',
'This context handler simplifies the exception handling. Use it as follows:':'这个上下文处理程序简化了异常处理。使用方法如下：',
'This is completely equivalent to the slightly longer code:':'这完全等同于稍长的代码：',
'nothing.':'没有什么。',
'Wait till the Coordinator is told to stop.':'等协调员被叫停。',
'## Class Example':'## 类示例',
'Features features':'特点',
'## Class ExponentialMovingAverage':'## 类指数移动平均值',
'Maintains moving averages of variables by employing an exponential decay.':'通过指数衰减保持变量的移动平均值。',
'Example usage when creating a training model:':'创建培训模型时的示例用法：',
'There are two ways to use the moving averages for evaluations:':'使用移动平均数进行评估有两种方法：',
'Example of restoring the shadow variable values:':'恢复阴影变量值的示例：',
'Creates a new ExponentialMovingAverage object.':'创建新的指数移动平均对象。',
'The apply() method has to be called to create shadow variables and add ops to maintain moving averages.':'必须调用apply（）方法来创建阴影变量并添加操作以保持移动平均值。',
'The name of this ExponentialMovingAverage object.':'此指数移动平均对象的名称。',
'Maintains moving averages of variables.':'保持变量的移动平均值。',
'Returns an op that updates all shadow variables from the current value of their associated variables.':'返回一个op，该op根据关联变量的当前值更新所有阴影变量。',
'An Operation that updates the moving averages.':'更新移动平均值的操作。',
'### average':'### 平均',
'Returns the Variable holding the average of var.':'返回保持var平均值的变量。',
'A Variable object or None if the moving average of var is not maintained.':'变量对象，如果变量的移动平均值没有保持，则为无。',
'Returns the name of the Variable holding the average for var.':'返回保持var平均值的变量的名称。',
'A string: The name of the variable that will be used or was used by the ExponentialMovingAverage class to hold the moving average of var.':'字符串：ExponentialMovingAverage类将使用或曾经使用的变量的名称，用于保存变量的移动平均值。',
'Returns a map of names to Variables to restore.':'返回要还原的变量的名称映射。',
'Below is an example of such mapping:':'下面是这种映射的一个示例：',
'## Class FeatureList':'## Class 特色表',
'### feature':'### 特色',
'repeated Feature feature':'重复特征',
'## Class FeatureLists':'## 课程特色列表',
'## Class FeatureListEntry':'## Class 特色',
'FeatureList value':'特性列表值',
'## Class Features':'## 类功能',
'repeated FeatureEntry feature':'重复功能条目功能',
'## Class FeatureEntry':'## Class 特色项目',
'Feature value':'特征值',
'## Class FloatList':'## 类浮动列表',
'repeated float value':'重复浮点值',
'Returns CheckpointState proto from the "checkpoint" file.':'从“checkpoint”文件返回checkpointstate proto。',
'## Class Int64List':'## Int64类列表',
'repeated int64 value':'重复Int64值',
'## Class JobDef':'## 作业定义类',
'### tasks':'### 任务',
'repeated TasksEntry tasks':'重复任务',
'## Class TasksEntry':'## Class 任务哨',
'Finds the filename of latest saved checkpoint file.':'查找最近保存的检查点文件的文件名。',
'Returns list of all variables in the checkpoint.':'返回检查点中所有变量的列表。',
'CheckpointReader object.':'检查点读取器对象。',
'Returns the tensor value of the given variable in the checkpoint.':'返回检查点中给定变量的张量值。',
'## Class SequenceExample':'## 类序列示例',
'### context':'### 上下文',
'Features context':'功能上下文',
'## Class ServerDef':'## 类服务器定义',
'ClusterDef cluster':'clusterDef群集',
'string protocol':'字符串协议',
'## Class DynamicLossScale':'## 类dynamiclossscale',
'Loss scale that dynamically adjusts itself.':'动态调整自身的损耗量表。',
'Creates the dynamic loss scale.':'创建动态损耗刻度。',
'Returns the current loss scale as a scalar float32 tensor.':'以标量float32张量返回当前损耗刻度。',
'Creates the LossScale from its config.':'从其配置创建losscale。',
'Returns the config of this loss scale.':'返回此损失等级的配置。',
'Updates loss scale based on if gradients are finite in current step.':'根据当前步骤中的梯度是否有限来更新损失比例。',
'## Class FixedLossScale':'## 固定损耗等级',
'Loss scale with a fixed value.':'定值损失量表。',
'The loss scale is not updated for the lifetime of instances of this class. A given instance of this class always returns the same number when called.':'在此类实例的生存期内，不会更新丢失比例。此类的给定实例在调用时总是返回相同的数字。',
'Creates the fixed loss scale.':'创建固定损耗刻度。',
'Updates the value of the loss scale.':'更新损失等级的值。',
'## Class LossScale':'## 类损失量',
'Loss scale base class.':'损失等级基类。',
'Initializes the loss scale class.':'初始化损失等级。',
'## Class PythonState':'##pythonstate类',
'### deserialize':'### 反序列化',
'Callback to deserialize the object.':'回调以反序列化对象。',
'Callback to serialize the object. Returns a string.':'回调以序列化对象。返回字符串。',
'Builds an operator that compiles and runs computation with XLA.':'生成用XLA编译和运行计算的运算符。',
'All `Operation`s returned from `computation` will be executed when evaluating any of the returned output tensors.':'在计算任何返回的输出张量时，将执行从“computation”返回的所有“operation”。',
'Enable or disable JIT compilation of operators within the scope.':'启用或禁用范围内运算符的JIT编译。',
'NOTE: This is an experimental feature.':'注：这是一个实验特性。',
'## Primary symbols':'## 主要符号',
'## Compat v2 symbols':'## 兼容v2符号',
'## Compat v1 symbols':'## 兼容v1符号',
}