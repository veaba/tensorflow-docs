Experimental Distribution Strategy library.

## Classes
[ `class CentralStorageStrategy` ](https://tensorflow.google.cn/api_docs/python/tf/distribute/experimental/CentralStorageStrategy): A one-machine strategy that puts all variables on a single device.

[ `class CollectiveCommunication` ](https://tensorflow.google.cn/api_docs/python/tf/distribute/experimental/CollectiveCommunication): Communication choices for CollectiveOps.

[ `class MultiWorkerMirroredStrategy` ](https://tensorflow.google.cn/api_docs/python/tf/distribute/experimental/MultiWorkerMirroredStrategy): A distribution strategy for synchronous training on multiple workers.

[ `class ParameterServerStrategy` ](https://tensorflow.google.cn/api_docs/python/tf/distribute/experimental/ParameterServerStrategy): An asynchronous multi-worker parameter server tf.distribute strategy.

[ `class TPUStrategy` ](https://tensorflow.google.cn/api_docs/python/tf/distribute/experimental/TPUStrategy): TPU distribution strategy implementation.

