Callbacks: utilities called at certain points during model training.

## Classes
[ `class BaseLogger` ](https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/BaseLogger): Callback that accumulates epoch averages of metrics.

[ `class CSVLogger` ](https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/CSVLogger): Callback that streams epoch results to a csv file.

[ `class Callback` ](https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/Callback): Abstract base class used to build new callbacks.

[ `class EarlyStopping` ](https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/EarlyStopping): Stop training when a monitored quantity has stopped improving.

[ `class History` ](https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/History): Callback that records events into a  `History`  object.

[ `class LambdaCallback` ](https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/LambdaCallback): Callback for creating simple, custom callbacks on-the-fly.

[ `class LearningRateScheduler` ](https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/LearningRateScheduler): Learning rate scheduler.

[ `class ModelCheckpoint` ](https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/ModelCheckpoint): Save the model after every epoch.

[ `class ProgbarLogger` ](https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/ProgbarLogger): Callback that prints metrics to stdout.

[ `class ReduceLROnPlateau` ](https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau): Reduce learning rate when a metric has stopped improving.

[ `class RemoteMonitor` ](https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/RemoteMonitor): Callback used to stream events to a server.

[ `class TensorBoard` ](https://tensorflow.google.cn/api_docs/python/tf/compat/v1/keras/callbacks/TensorBoard): Enable visualizations for TensorBoard.

[ `class TerminateOnNaN` ](https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/TerminateOnNaN): Callback that terminates training when a NaN loss is encountered.

