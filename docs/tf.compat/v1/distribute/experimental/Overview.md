Experimental Distribution Strategy library.
## Classes
[class CentralStorageStrategy](https://tensorflow.google.cn/api_docs/python/tf/compat/v1/distribute/experimental/CentralStorageStrategy): A one-machine strategy that puts all variables on a single device.

[class CollectiveCommunication](https://tensorflow.google.cn/api_docs/python/tf/distribute/experimental/CollectiveCommunication): Communication choices for CollectiveOps.

[class MultiWorkerMirroredStrategy](https://tensorflow.google.cn/api_docs/python/tf/compat/v1/distribute/experimental/MultiWorkerMirroredStrategy): A distribution strategy for synchronous training on multiple workers.

[class ParameterServerStrategy](https://tensorflow.google.cn/api_docs/python/tf/compat/v1/distribute/experimental/ParameterServerStrategy): An asynchronous multi-worker parameter server tf.distribute strategy.

[class TPUStrategy](https://tensorflow.google.cn/api_docs/python/tf/compat/v1/distribute/experimental/TPUStrategy): TPU distribution strategy implementation.

