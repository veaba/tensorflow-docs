Exponential linear unit.
### Aliases:
- tf.compat.v1.keras.backend.elu
- tf.compat.v2.keras.backend.elu

```
 tf.keras.backend.elu(
    x,
    alpha=1.0
)
```
#### Arguments:
- x: A tensor or variable to compute the activation function for.
- alpha: A scalar, slope of negative section.
#### Returns:
A tensor.
