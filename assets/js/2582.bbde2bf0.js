(window.webpackJsonp=window.webpackJsonp||[]).push([[2582],{2773:function(e,t,s){"use strict";s.r(t);var a=s(0),n=Object(a.a)({},(function(){var e=this,t=e.$createElement,s=e._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[s("p",[e._v("Defined in generated file: "),s("code",[e._v("python/ops/gen_array_ops.py")]),e._v("\nScatter "),s("code",[e._v("updates")]),e._v(" into a new tensor according to "),s("code",[e._v("indices")]),e._v(".")]),e._v(" "),s("h3",{attrs:{id:"aliases"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[e._v("#")]),e._v(" Aliases:")]),e._v(" "),s("ul",[s("li",[s("code",[e._v("tf.compat.v1.manip.scatter_nd")])]),e._v(" "),s("li",[s("code",[e._v("tf.compat.v1.scatter_nd")])]),e._v(" "),s("li",[s("code",[e._v("tf.compat.v2.scatter_nd")])])]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v(" tf.scatter_nd(\n    indices,\n    updates,\n    shape,\n    name=None\n)\n")])])]),s("p",[s("a",{attrs:{href:"https://tensorflow.google.cn/api_docs/python/tf/gather_nd",target:"_blank",rel:"noopener noreferrer"}},[e._v("tf.gather_nd"),s("OutboundLink")],1),e._v("Creates a new tensor by applying sparse updates to individual values or slices within a tensor (initially zero for numeric, empty for string) of the given shape according to indices. This operator is the inverse of the  operator which extracts values or slices from a given tensor.")]),e._v(" "),s("p",[s("a",{attrs:{href:"https://tensorflow.google.cn/api_docs/python/tf/scatter_nd",target:"_blank",rel:"noopener noreferrer"}},[e._v("tf.scatter_nd(indices, values, shape)"),s("OutboundLink")],1),e._v("This operation is similar to tensor_scatter_add, except that the tensor is zero-initialized. Calling  is identical to tensor_scatter_add(tf.zeros(shape, values.dtype), indices, values)")]),e._v(" "),s("p",[e._v("If "),s("code",[e._v("indices")]),e._v(" contains duplicates, then their updates are accumulated (summed).\nWARNING: The order in which updates are applied is nondeterministic, so the output will be nondeterministic if "),s("code",[e._v("indices")]),e._v(" contains duplicates -- because of some numerical approximation issues, numbers summed in different order may yield different results.\n"),s("code",[e._v("indices")]),e._v(" is an integer tensor containing "),s("code",[e._v("indices")]),e._v(" into a new tensor of "),s("code",[e._v("shape")]),e._v(" "),s("code",[e._v("shape")]),e._v(". The last dimension of "),s("code",[e._v("indices")]),e._v(" can be at most the rank of "),s("code",[e._v("shape")]),e._v(":")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v(" indices.shape[-1] <= shape.rank\n")])])]),s("p",[e._v("The last dimension of "),s("code",[e._v("indices")]),e._v(" corresponds to "),s("code",[e._v("indices")]),e._v(" into elements (if "),s("code",[e._v("indices")]),e._v("."),s("code",[e._v("shape")]),e._v("[-1] = "),s("code",[e._v("shape")]),e._v(".rank) or slices (if "),s("code",[e._v("indices")]),e._v("."),s("code",[e._v("shape")]),e._v("[-1] < "),s("code",[e._v("shape")]),e._v(".rank) along dimension "),s("code",[e._v("indices")]),e._v("."),s("code",[e._v("shape")]),e._v("[-1] of "),s("code",[e._v("shape")]),e._v(". "),s("code",[e._v("updates")]),e._v(" is a tensor with "),s("code",[e._v("shape")])]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v(" indices.shape[:-1] + shape[indices.shape[-1]:]\n")])])]),s("p",[e._v("The simplest form of scatter is to insert individual elements in a tensor by index. For example, say we want to insert 4 scattered elements in a rank-1 tensor with 8 elements.\nIn Python, this scatter operation would look like this:")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("     indices = tf.constant([[4], [3], [1], [7]])\n    updates = tf.constant([9, 10, 11, 12])\n    shape = tf.constant([8])\n    scatter = tf.scatter_nd(indices, updates, shape)\n    with tf.Session() as sess:\n      print(sess.run(scatter))\n")])])]),s("p",[e._v("The resulting tensor would look like this:")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v(" [0, 11, 0, 10, 9, 0, 0, 12]\n")])])]),s("p",[e._v("We can also, insert entire slices of a higher rank tensor all at once. For example, if we wanted to insert two slices in the first dimension of a rank-3 tensor with two matrices of new values.\nIn Python, this scatter operation would look like this:")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("     indices = tf.constant([[0], [2]])\n    updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n                            [7, 7, 7, 7], [8, 8, 8, 8]],\n                           [[5, 5, 5, 5], [6, 6, 6, 6],\n                            [7, 7, 7, 7], [8, 8, 8, 8]]])\n    shape = tf.constant([4, 4, 4])\n    scatter = tf.scatter_nd(indices, updates, shape)\n    with tf.Session() as sess:\n      print(sess.run(scatter))\n")])])]),s("p",[e._v("The resulting tensor would look like this:")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v(" [[[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],\n [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]]\n")])])]),s("p",[e._v("Note that on CPU, if an out of bound index is found, an error is returned. On GPU, if an out of bound index is found, the index is ignored.")]),e._v(" "),s("h4",{attrs:{id:"args"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),s("ul",[s("li",[s("code",[e._v("indices")]),e._v(": A "),s("code",[e._v("Tensor")]),e._v(". Must be one of the following types: "),s("code",[e._v("int32")]),e._v(", "),s("code",[e._v("int64")]),e._v(". Index tensor.")]),e._v(" "),s("li",[s("code",[e._v("updates")]),e._v(": A "),s("code",[e._v("Tensor")]),e._v(". Updates to scatter into output.")]),e._v(" "),s("li",[s("code",[e._v("shape")]),e._v(": A "),s("code",[e._v("Tensor")]),e._v(". Must have the same type as "),s("code",[e._v("indices")]),e._v(". 1-D. The "),s("code",[e._v("shape")]),e._v(" of the resulting tensor.")]),e._v(" "),s("li",[s("code",[e._v("name")]),e._v(": A "),s("code",[e._v("name")]),e._v(" for the operation (optional).")])]),e._v(" "),s("h4",{attrs:{id:"returns"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),s("p",[e._v("A "),s("code",[e._v("Tensor")]),e._v(". Has the same type as "),s("code",[e._v("updates")]),e._v(".")])])}),[],!1,null,null,null);t.default=n.exports}}]);