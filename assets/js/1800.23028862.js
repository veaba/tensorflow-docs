(window.webpackJsonp=window.webpackJsonp||[]).push([[1800],{1991:function(e,t,a){"use strict";a.r(t);var s=a(0),r=Object(s.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h2",{attrs:{id:"class-timedistributed"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#class-timedistributed","aria-hidden":"true"}},[e._v("#")]),e._v(" Class TimeDistributed")]),e._v(" "),a("p",[e._v("This wrapper allows to apply a layer to every temporal slice of an input.\n"),a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Wrapper",target:"_blank",rel:"noopener noreferrer"}},[e._v("Wrapper"),a("OutboundLink")],1),e._v("Inherits From:")]),e._v(" "),a("h3",{attrs:{id:"aliases"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[e._v("#")]),e._v(" Aliases:")]),e._v(" "),a("ul",[a("li",[e._v("Class "),a("code",[e._v("tf.compat.v1.keras.layers.TimeDistributed")])]),e._v(" "),a("li",[e._v("Class "),a("code",[e._v("tf.compat.v2.keras.layers.TimeDistributed")])])]),e._v(" "),a("p",[e._v("The input should be at least 3D, and the dimension of index one will be considered to be the temporal dimension.")]),e._v(" "),a("p",[e._v("Consider a batch of 32 samples, where each sample is a sequence of 10 vectors of 16 dimensions. The batch input shape of the layer is then (32, 10, 16), and the input_shape, not including the samples dimension, is (10, 16).")]),e._v(" "),a("p",[e._v("You can then use TimeDistributed to apply a Dense layer to each of the 10 timesteps, independently:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" # as the first layer in a model\nmodel = Sequential()\nmodel.add(TimeDistributed(Dense(8), input_shape=(10, 16)))\n# now model.output_shape == (None, 10, 8)\n")])])]),a("p",[e._v("The output will then have shape (32, 10, 8).")]),e._v(" "),a("p",[e._v("In subsequent layers, there is no need for the input_shape:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" model.add(TimeDistributed(Dense(32)))\n# now model.output_shape == (None, 10, 32)\n")])])]),a("p",[e._v("The output will then have shape (32, 10, 32).")]),e._v(" "),a("p",[e._v("TimeDistributed can be used with arbitrary layers, not just Dense, for instance with a Conv2D layer:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" model = Sequential()\nmodel.add(TimeDistributed(Conv2D(64, (3, 3)),\n                          input_shape=(10, 299, 299, 3)))\n")])])]),a("h4",{attrs:{id:"arguments"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#arguments","aria-hidden":"true"}},[e._v("#")]),e._v(" Arguments:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("layer")]),e._v(": a "),a("code",[e._v("layer")]),e._v(" instance.")])]),e._v(" "),a("h4",{attrs:{id:"call-arguments"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#call-arguments","aria-hidden":"true"}},[e._v("#")]),e._v(" Call arguments:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("inputs")]),e._v(": Input tensor.")]),e._v(" "),a("li",[a("code",[e._v("training")]),e._v(": Python boolean indicating whether the layer should behave in "),a("code",[e._v("training")]),e._v(" mode or in inference mode. This argument is passed to the wrapped layer (only if the layer supports this argument).")]),e._v(" "),a("li",[a("code",[e._v("mask")]),e._v(": Binary tensor of shape ("),a("code",[e._v("samples, timesteps")]),e._v(") indicating whether a given timestep should be "),a("code",[e._v("mask")]),e._v("ed. This argument is passed to the wrapped layer (only if the layer supports this argument).")])]),e._v(" "),a("h4",{attrs:{id:"raises"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[e._v("#")]),e._v(" Raises:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("ValueError")]),e._v(": If not initialized with a "),a("code",[e._v("Layer")]),e._v(" instance.")])]),e._v(" "),a("h2",{attrs:{id:"init"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#init","aria-hidden":"true"}},[e._v("#")]),e._v(" "),a("strong",[e._v("init")])]),e._v(" "),a("p",[a("a",{attrs:{href:"https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/wrappers.py#L147-L159",target:"_blank",rel:"noopener noreferrer"}},[e._v("View source"),a("OutboundLink")],1)]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" __init__(\n    layer,\n    **kwargs\n)\n")])])])])}),[],!1,null,null,null);t.default=r.exports}}]);