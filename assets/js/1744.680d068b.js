(window.webpackJsonp=window.webpackJsonp||[]).push([[1744],{1935:function(t,e,a){"use strict";a.r(e);var r=a(0),s=Object(r.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h2",{attrs:{id:"class-cropping1d"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#class-cropping1d","aria-hidden":"true"}},[t._v("#")]),t._v(" Class Cropping1D")]),t._v(" "),a("p",[t._v("Cropping layer for 1D input (e.g. temporal sequence).\n"),a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer",target:"_blank",rel:"noopener noreferrer"}},[t._v("Layer"),a("OutboundLink")],1),t._v("Inherits From:")]),t._v(" "),a("h3",{attrs:{id:"aliases"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[t._v("#")]),t._v(" Aliases:")]),t._v(" "),a("ul",[a("li",[t._v("Class "),a("code",[t._v("tf.compat.v1.keras.layers.Cropping1D")])]),t._v(" "),a("li",[t._v("Class "),a("code",[t._v("tf.compat.v2.keras.layers.Cropping1D")])])]),t._v(" "),a("p",[t._v("It crops along the time dimension (axis 1).")]),t._v(" "),a("h4",{attrs:{id:"arguments"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#arguments","aria-hidden":"true"}},[t._v("#")]),t._v(" Arguments:")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("cropping")]),t._v(": Int or tuple of int (length 2) How many units should be trimmed off at the beginning and end of the "),a("code",[t._v("cropping")]),t._v(" dimension (axis 1). If a single int is provided, the same value will be used for both.")])]),t._v(" "),a("h4",{attrs:{id:"input-shape"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#input-shape","aria-hidden":"true"}},[t._v("#")]),t._v(" Input shape:")]),t._v(" "),a("p",[t._v("3D tensor with shape (batch, axis_to_crop, features)")]),t._v(" "),a("h4",{attrs:{id:"output-shape"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#output-shape","aria-hidden":"true"}},[t._v("#")]),t._v(" Output shape:")]),t._v(" "),a("p",[t._v("3D tensor with shape (batch, cropped_axis, features)")]),t._v(" "),a("h2",{attrs:{id:"init"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#init","aria-hidden":"true"}},[t._v("#")]),t._v(" "),a("strong",[t._v("init")])]),t._v(" "),a("p",[a("a",{attrs:{href:"https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/convolutional.py#L2352-L2355",target:"_blank",rel:"noopener noreferrer"}},[t._v("View source"),a("OutboundLink")],1)]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v(" __init__(\n    cropping=(1, 1),\n    **kwargs\n)\n")])])])])}),[],!1,null,null,null);e.default=s.exports}}]);