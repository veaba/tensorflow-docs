(window.webpackJsonp=window.webpackJsonp||[]).push([[1753],{1944:function(e,_,v){"use strict";v.r(_);var o=v(0),d=Object(o.a)({},(function(){var e=this,_=e.$createElement,v=e._self._c||_;return v("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[v("h2",{attrs:{id:"class-embedding"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#class-embedding","aria-hidden":"true"}},[e._v("#")]),e._v(" Class Embedding")]),e._v(" "),v("p",[e._v("Turns positive integers (indexes) into dense vectors of fixed size.\n"),v("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer",target:"_blank",rel:"noopener noreferrer"}},[e._v("Layer"),v("OutboundLink")],1),e._v("Inherits From:")]),e._v(" "),v("h3",{attrs:{id:"aliases"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[e._v("#")]),e._v(" Aliases:")]),e._v(" "),v("ul",[v("li",[e._v("Class "),v("code",[e._v("tf.compat.v1.keras.layers.Embedding")])]),e._v(" "),v("li",[e._v("Class "),v("code",[e._v("tf.compat.v2.keras.layers.Embedding")])])]),e._v(" "),v("h3",{attrs:{id:"used-in-the-guide"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#used-in-the-guide","aria-hidden":"true"}},[e._v("#")]),e._v(" Used in the guide:")]),e._v(" "),v("ul",[v("li",[v("code",[e._v("M")]),e._v("a"),v("code",[e._v("s")]),e._v("k"),v("code",[e._v("i")]),e._v("n"),v("code",[e._v("g")]),e._v(" "),v("code",[e._v("a")]),e._v("n"),v("code",[e._v("d")]),e._v(" "),v("code",[e._v("p")]),e._v("a"),v("code",[e._v("d")]),e._v("d"),v("code",[e._v("i")]),e._v("n"),v("code",[e._v("g")]),e._v(" "),v("code",[e._v("w")]),e._v("i"),v("code",[e._v("t")]),e._v("h"),v("code"),e._v("K"),v("code",[e._v("e")]),e._v("r"),v("code",[e._v("a")]),e._v("s``")]),e._v(" "),v("li",[v("code",[e._v("R")]),e._v("e"),v("code",[e._v("c")]),e._v("u"),v("code",[e._v("r")]),e._v("r"),v("code",[e._v("e")]),e._v("n"),v("code",[e._v("t")]),e._v(" "),v("code",[e._v("N")]),e._v("e"),v("code",[e._v("u")]),e._v("r"),v("code",[e._v("a")]),e._v("l"),v("code"),e._v("N"),v("code",[e._v("e")]),e._v("t"),v("code",[e._v("w")]),e._v("o"),v("code",[e._v("r")]),e._v("k"),v("code",[e._v("s")]),e._v(" "),v("code",[e._v("(")]),e._v("R"),v("code",[e._v("N")]),e._v("N"),v("code",[e._v(")")]),e._v(" "),v("code",[e._v("w")]),e._v("i"),v("code",[e._v("t")]),e._v("h"),v("code"),e._v("K"),v("code",[e._v("e")]),e._v("r"),v("code",[e._v("a")]),e._v("s``")]),e._v(" "),v("li",[v("code",[e._v("T")]),e._v("h"),v("code",[e._v("e")]),e._v(" "),v("code",[e._v("K")]),e._v("e"),v("code",[e._v("r")]),e._v("a"),v("code",[e._v("s")]),e._v(" "),v("code",[e._v("f")]),e._v("u"),v("code",[e._v("n")]),e._v("c"),v("code",[e._v("t")]),e._v("i"),v("code",[e._v("o")]),e._v("n"),v("code",[e._v("a")]),e._v("l"),v("code"),e._v("A"),v("code",[e._v("P")]),e._v("I"),v("code"),e._v("i"),v("code",[e._v("n")]),e._v(" "),v("code",[e._v("T")]),e._v("e"),v("code",[e._v("n")]),e._v("s"),v("code",[e._v("o")]),e._v("r"),v("code",[e._v("F")]),e._v("l"),v("code",[e._v("o")]),e._v("w``")])]),e._v(" "),v("h3",{attrs:{id:"used-in-the-tutorials"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#used-in-the-tutorials","aria-hidden":"true"}},[e._v("#")]),e._v(" Used in the tutorials:")]),e._v(" "),v("ul",[v("li",[v("code",[e._v("I")]),e._v("m"),v("code",[e._v("a")]),e._v("g"),v("code",[e._v("e")]),e._v(" "),v("code",[e._v("c")]),e._v("a"),v("code",[e._v("p")]),e._v("t"),v("code",[e._v("i")]),e._v("o"),v("code",[e._v("n")]),e._v("i"),v("code",[e._v("n")]),e._v("g"),v("code"),e._v("w"),v("code",[e._v("i")]),e._v("t"),v("code",[e._v("h")]),e._v(" "),v("code",[e._v("v")]),e._v("i"),v("code",[e._v("s")]),e._v("u"),v("code",[e._v("a")]),e._v("l"),v("code"),e._v("a"),v("code",[e._v("t")]),e._v("t"),v("code",[e._v("e")]),e._v("n"),v("code",[e._v("t")]),e._v("i"),v("code",[e._v("o")]),e._v("n``")]),e._v(" "),v("li",[v("code",[e._v("L")]),e._v("o"),v("code",[e._v("a")]),e._v("d"),v("code"),e._v("t"),v("code",[e._v("e")]),e._v("x"),v("code",[e._v("t")])]),e._v(" "),v("li",[v("code",[e._v("N")]),e._v("e"),v("code",[e._v("u")]),e._v("r"),v("code",[e._v("a")]),e._v("l"),v("code"),e._v("m"),v("code",[e._v("a")]),e._v("c"),v("code",[e._v("h")]),e._v("i"),v("code",[e._v("n")]),e._v("e"),v("code"),e._v("t"),v("code",[e._v("r")]),e._v("a"),v("code",[e._v("n")]),e._v("s"),v("code",[e._v("l")]),e._v("a"),v("code",[e._v("t")]),e._v("i"),v("code",[e._v("o")]),e._v("n"),v("code"),e._v("w"),v("code",[e._v("i")]),e._v("t"),v("code",[e._v("h")]),e._v(" "),v("code",[e._v("a")]),e._v("t"),v("code",[e._v("t")]),e._v("e"),v("code",[e._v("n")]),e._v("t"),v("code",[e._v("i")]),e._v("o"),v("code",[e._v("n")])]),e._v(" "),v("li",[v("code",[e._v("T")]),e._v("e"),v("code",[e._v("x")]),e._v("t"),v("code"),e._v("c"),v("code",[e._v("l")]),e._v("a"),v("code",[e._v("s")]),e._v("s"),v("code",[e._v("i")]),e._v("f"),v("code",[e._v("i")]),e._v("c"),v("code",[e._v("a")]),e._v("t"),v("code",[e._v("i")]),e._v("o"),v("code",[e._v("n")]),e._v(" "),v("code",[e._v("w")]),e._v("i"),v("code",[e._v("t")]),e._v("h"),v("code"),e._v("a"),v("code",[e._v("n")]),e._v(" "),v("code",[e._v("R")]),e._v("N"),v("code",[e._v("N")])]),e._v(" "),v("li",[v("code",[e._v("T")]),e._v("e"),v("code",[e._v("x")]),e._v("t"),v("code"),e._v("c"),v("code",[e._v("l")]),e._v("a"),v("code",[e._v("s")]),e._v("s"),v("code",[e._v("i")]),e._v("f"),v("code",[e._v("i")]),e._v("c"),v("code",[e._v("a")]),e._v("t"),v("code",[e._v("i")]),e._v("o"),v("code",[e._v("n")]),e._v(" "),v("code",[e._v("w")]),e._v("i"),v("code",[e._v("t")]),e._v("h"),v("code"),e._v("p"),v("code",[e._v("r")]),e._v("e"),v("code",[e._v("p")]),e._v("r"),v("code",[e._v("o")]),e._v("c"),v("code",[e._v("e")]),e._v("s"),v("code",[e._v("s")]),e._v("e"),v("code",[e._v("d")]),e._v(" "),v("code",[e._v("t")]),e._v("e"),v("code",[e._v("x")]),e._v("t"),v("code",[e._v(":")]),e._v(" "),v("code",[e._v("M")]),e._v("o"),v("code",[e._v("v")]),e._v("i"),v("code",[e._v("e")]),e._v(" "),v("code",[e._v("r")]),e._v("e"),v("code",[e._v("v")]),e._v("i"),v("code",[e._v("e")]),e._v("w"),v("code",[e._v("s")])]),e._v(" "),v("li",[v("code",[e._v("T")]),e._v("e"),v("code",[e._v("x")]),e._v("t"),v("code"),e._v("g"),v("code",[e._v("e")]),e._v("n"),v("code",[e._v("e")]),e._v("r"),v("code",[e._v("a")]),e._v("t"),v("code",[e._v("i")]),e._v("o"),v("code",[e._v("n")]),e._v(" "),v("code",[e._v("w")]),e._v("i"),v("code",[e._v("t")]),e._v("h"),v("code"),e._v("a"),v("code",[e._v("n")]),e._v(" "),v("code",[e._v("R")]),e._v("N"),v("code",[e._v("N")])]),e._v(" "),v("li",[v("code",[e._v("T")]),e._v("r"),v("code",[e._v("a")]),e._v("n"),v("code",[e._v("s")]),e._v("f"),v("code",[e._v("o")]),e._v("r"),v("code",[e._v("m")]),e._v("e"),v("code",[e._v("r")]),e._v(" "),v("code",[e._v("m")]),e._v("o"),v("code",[e._v("d")]),e._v("e"),v("code",[e._v("l")]),e._v(" "),v("code",[e._v("f")]),e._v("o"),v("code",[e._v("r")]),e._v(" "),v("code",[e._v("l")]),e._v("a"),v("code",[e._v("n")]),e._v("g"),v("code",[e._v("u")]),e._v("a"),v("code",[e._v("g")]),e._v("e"),v("code"),e._v("u"),v("code",[e._v("n")]),e._v("d"),v("code",[e._v("e")]),e._v("r"),v("code",[e._v("s")]),e._v("t"),v("code",[e._v("a")]),e._v("n"),v("code",[e._v("d")]),e._v("i"),v("code",[e._v("n")]),e._v("g``")]),e._v(" "),v("li",[v("code",[e._v("W")]),e._v("o"),v("code",[e._v("r")]),e._v("d"),v("code"),e._v("e"),v("code",[e._v("m")]),e._v("b"),v("code",[e._v("e")]),e._v("d"),v("code",[e._v("d")]),e._v("i"),v("code",[e._v("n")]),e._v("g"),v("code",[e._v("s")])])]),e._v(" "),v("p",[e._v("e.g. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]")]),e._v(" "),v("p",[e._v("This layer can only be used as the first layer in a model.")]),e._v(" "),v("h4",{attrs:{id:"example"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#example","aria-hidden":"true"}},[e._v("#")]),e._v(" Example:")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v(" model = Sequential()\nmodel.add(Embedding(1000, 64, input_length=10))\n# the model will take as input an integer matrix of size (batch,\n# input_length).\n# the largest integer (i.e. word index) in the input should be no larger\n# than 999 (vocabulary size).\n# now model.output_shape == (None, 10, 64), where None is the batch\n# dimension.\n\ninput_array = np.random.randint(1000, size=(32, 10))\n\nmodel.compile('rmsprop', 'mse')\noutput_array = model.predict(input_array)\nassert output_array.shape == (32, 10, 64)\n")])])]),v("h4",{attrs:{id:"arguments"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#arguments","aria-hidden":"true"}},[e._v("#")]),e._v(" Arguments:")]),e._v(" "),v("ul",[v("li",[v("code",[e._v("input_dim")]),e._v(": int > 0. Size of the vocabulary, i.e. maximum integer index + 1.")]),e._v(" "),v("li",[v("code",[e._v("output_dim")]),e._v(": int >= 0. Dimension of the dense embedding.")]),e._v(" "),v("li",[v("code",[e._v("embeddings_initializer")]),e._v(": Initializer for the "),v("code",[e._v("embeddings")]),e._v(" matrix.")]),e._v(" "),v("li",[v("code",[e._v("embeddings")]),e._v("_regularizer: Regularizer function applied to the "),v("code",[e._v("embeddings")]),e._v(" matrix.")]),e._v(" "),v("li",[v("code",[e._v("embeddings")]),e._v("_constraint: Constraint function applied to the "),v("code",[e._v("embeddings")]),e._v(" matrix.")]),e._v(" "),v("li",[v("code",[e._v("mask_zero")]),e._v(': Whether or not the input value 0 is a special "padding" value that should be masked out. This is useful when using recurrent layers which may take variable length input. If this is '),v("code",[e._v("True")]),e._v(" then all subsequent layers in the model need to support masking or an exception will be raised. If "),v("code",[e._v("mask_zero")]),e._v(" is set to "),v("code",[e._v("True")]),e._v(", as a consequence, index 0 cannot be used in the vocabulary ("),v("code",[e._v("input_dim")]),e._v(" should equal size of vocabulary + 1).")]),e._v(" "),v("li",[v("code",[e._v("input_length")]),e._v(": Length of input sequences, when it is constant. This argument is required if you are going to connect "),v("code",[e._v("Flatten")]),e._v(" then "),v("code",[e._v("Dense")]),e._v(" layers upstream (without it, the shape of the dense outputs cannot be computed).")])]),e._v(" "),v("h4",{attrs:{id:"input-shape"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#input-shape","aria-hidden":"true"}},[e._v("#")]),e._v(" Input shape:")]),e._v(" "),v("p",[e._v("2D tensor with shape: (batch_size, input_length).")]),e._v(" "),v("h4",{attrs:{id:"output-shape"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#output-shape","aria-hidden":"true"}},[e._v("#")]),e._v(" Output shape:")]),e._v(" "),v("p",[e._v("3D tensor with shape: (batch_size, input_length, output_dim).")]),e._v(" "),v("h2",{attrs:{id:"init"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#init","aria-hidden":"true"}},[e._v("#")]),e._v(" "),v("strong",[e._v("init")])]),e._v(" "),v("p",[v("a",{attrs:{href:"https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/embeddings.py#L91-L122",target:"_blank",rel:"noopener noreferrer"}},[e._v("View source"),v("OutboundLink")],1)]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v(" __init__(\n    input_dim,\n    output_dim,\n    embeddings_initializer='uniform',\n    embeddings_regularizer=None,\n    activity_regularizer=None,\n    embeddings_constraint=None,\n    mask_zero=False,\n    input_length=None,\n    **kwargs\n)\n")])])])])}),[],!1,null,null,null);_.default=d.exports}}]);