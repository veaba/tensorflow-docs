(window.webpackJsonp=window.webpackJsonp||[]).push([[275],{463:function(e,a,t){"use strict";t.r(a);var s=t(0),o=Object(s.a)({},(function(){var e=this,a=e.$createElement,t=e._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("p",[e._v("Returns a dense Tensor as input layer based on given feature_columns.")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v(" tf.compat.v1.feature_column.input_layer(\n    features,\n    feature_columns,\n    weight_collections=None,\n    trainable=True,\n    cols_to_vars=None,\n    cols_to_output_tensors=None\n)\n")])])]),t("p",[e._v("Generally a single example in training data is described with FeatureColumns. At the first layer of the model, this column oriented data should be converted to a single Tensor.")]),e._v(" "),t("h4",{attrs:{id:"example"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#example","aria-hidden":"true"}},[e._v("#")]),e._v(" Example:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v(" price = numeric_column('price')\nkeywords_embedded = embedding_column(\n    categorical_column_with_hash_bucket(\"keywords\", 10K), dimensions=16)\ncolumns = [price, keywords_embedded, ...]\nfeatures = tf.io.parse_example(..., features=make_parse_example_spec(columns))\ndense_tensor = input_layer(features, columns)\nfor units in [128, 64, 32]:\n  dense_tensor = tf.compat.v1.layers.dense(dense_tensor, units, tf.nn.relu)\nprediction = tf.compat.v1.layers.dense(dense_tensor, 1)\n")])])]),t("h4",{attrs:{id:"args"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),t("ul",[t("li",[t("code",[e._v("features")]),e._v(": A mapping from key to tensors. "),t("code",[e._v("_FeatureColumn")]),e._v("s look up via these keys. For example numeric_column('price') will look at 'price' key in this dict. Values can be a "),t("code",[e._v("SparseTensor")]),e._v(" or a "),t("code",[e._v("Tensor")]),e._v(" depends on corresponding "),t("code",[e._v("_FeatureColumn")]),e._v(".")]),e._v(" "),t("li",[t("code",[e._v("feature_columns")]),e._v(": An iterable containing the FeatureColumns to use as inputs to your model. All items should be instances of classes derived from "),t("code",[e._v("_DenseColumn")]),e._v(" such as "),t("code",[e._v("numeric_column")]),e._v(", "),t("code",[e._v("embedding_column")]),e._v(", "),t("code",[e._v("bucketized_column")]),e._v(", "),t("code",[e._v("indicator_column")]),e._v(". If you have categorical "),t("code",[e._v("features")]),e._v(", you can wrap them with an "),t("code",[e._v("embedding_column")]),e._v(" or "),t("code",[e._v("indicator_column")]),e._v(".")]),e._v(" "),t("li",[t("code",[e._v("weight_collections")]),e._v(": A list of collection names to which the Variable will be added. Note that variables will also be added to collections "),t("code",[e._v("tf.GraphKeys.GLOBAL_VARIABLES")]),e._v(" and "),t("code",[e._v("ops.GraphKeys.MODEL_VARIABLES")]),e._v(".")]),e._v(" "),t("li",[t("code",[e._v("trainable")]),e._v(": If "),t("code",[e._v("True")]),e._v(" also add the variable to the graph collection "),t("code",[e._v("GraphKeys.TRAINABLE_VARIABLES")]),e._v(" (see "),t("code",[e._v("tf.Variable")]),e._v(").")]),e._v(" "),t("li",[t("code",[e._v("cols_to_vars")]),e._v(": If not "),t("code",[e._v("None")]),e._v(", must be a dictionary that will be filled with a mapping from "),t("code",[e._v("_FeatureColumn")]),e._v(" to list of "),t("code",[e._v("Variable")]),e._v("s. For example, after the call, we might have "),t("code",[e._v("cols_to_vars")]),e._v(" = {_EmbeddingColumn( categorical_column=_HashedCategoricalColumn( key='sparse_feature', hash_bucket_size=5, dtype=tf.string), dimension=10): [<"),t("code",[e._v("tf.Variable")]),e._v(" 'some_variable:0' shape=(5, 10), <"),t("code",[e._v("tf.Variable")]),e._v(" 'some_variable:1' shape=(5, 10)]} If a column creates no variables, its value will be an empty list.")]),e._v(" "),t("li",[t("code",[e._v("cols_to_output_tensors")]),e._v(": If not "),t("code",[e._v("None")]),e._v(", must be a dictionary that will be filled with a mapping from '"),t("code",[e._v("_FeatureColumn")]),e._v("' to the associated output "),t("code",[e._v("Tensor")]),e._v("s.")])]),e._v(" "),t("h4",{attrs:{id:"returns"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),t("p",[e._v("A Tensor which represents input layer of a model. Its shape is (batch_size, first_layer_dimension) and its dtype is float32. first_layer_dimension is determined based on given feature_columns.")]),e._v(" "),t("h4",{attrs:{id:"raises"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[e._v("#")]),e._v(" Raises:")]),e._v(" "),t("ul",[t("li",[t("code",[e._v("ValueError")]),e._v(": if an item in "),t("code",[e._v("feature_columns")]),e._v(" is not a "),t("code",[e._v("_DenseColumn")]),e._v(".")])])])}),[],!1,null,null,null);a.default=o.exports}}]);