(window.webpackJsonp=window.webpackJsonp||[]).push([[506],{694:function(e,t,i){"use strict";i.r(t);var n=i(0),a=Object(n.a)({},(function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[i("p",[e._v("Functional interface for transposed 3D convolution layer. (deprecated)")]),e._v(" "),i("div",{staticClass:"language- extra-class"},[i("pre",{pre:!0,attrs:{class:"language-text"}},[i("code",[e._v(" tf.compat.v1.layers.conv3d_transpose(\n    inputs,\n    filters,\n    kernel_size,\n    strides=(1, 1, 1),\n    padding='valid',\n    data_format='channels_last',\n    activation=None,\n    use_bias=True,\n    kernel_initializer=None,\n    bias_initializer=tf.zeros_initializer(),\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    trainable=True,\n    name=None,\n    reuse=None\n)\n")])])]),i("h4",{attrs:{id:"arguments"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#arguments","aria-hidden":"true"}},[e._v("#")]),e._v(" Arguments:")]),e._v(" "),i("ul",[i("li",[i("code",[e._v("inputs")]),e._v(": Input tensor.")]),e._v(" "),i("li",[i("code",[e._v("filters")]),e._v(": Integer, the dimensionality of the output space (i.e. the number of "),i("code",[e._v("filters")]),e._v(" in the convolution).")]),e._v(" "),i("li",[i("code",[e._v("kernel_size")]),e._v(": A tuple or list of 3 positive integers specifying the spatial dimensions of the "),i("code",[e._v("filters")]),e._v(". Can be a single integer to specify the same value for all spatial dimensions.")]),e._v(" "),i("li",[i("code",[e._v("strides")]),e._v(": A tuple or list of 3 positive integers specifying the "),i("code",[e._v("strides")]),e._v(" of the convolution. Can be a single integer to specify the same value for all spatial dimensions.")]),e._v(" "),i("li",[i("code",[e._v("padding")]),e._v(": one of "),i("code",[e._v('"valid"')]),e._v(" or "),i("code",[e._v('"same"')]),e._v(" (case-insensitive).")]),e._v(" "),i("li",[i("code",[e._v("data_format")]),e._v(": A string, one of "),i("code",[e._v("channels_last")]),e._v(" (default) or "),i("code",[e._v("channels_first")]),e._v(". The ordering of the dimensions in the "),i("code",[e._v("inputs")]),e._v(". "),i("code",[e._v("channels_last")]),e._v(" corresponds to "),i("code",[e._v("inputs")]),e._v(" with shape ("),i("code",[e._v("batch, depth, height, width, channels")]),e._v(") while "),i("code",[e._v("channels_first")]),e._v(" corresponds to "),i("code",[e._v("inputs")]),e._v(" with shape ("),i("code",[e._v("batch, channels, depth, height, width")]),e._v(").")]),e._v(" "),i("li",[i("code",[e._v("activation")]),e._v(": Activation function. Set it to None to maintain a linear "),i("code",[e._v("activation")]),e._v(".")]),e._v(" "),i("li",[i("code",[e._v("use_bias")]),e._v(": Boolean, whether the layer uses a bias.")]),e._v(" "),i("li",[i("code",[e._v("kernel_initializer")]),e._v(": An initializer for the convolution kernel.")]),e._v(" "),i("li",[i("code",[e._v("bias_initializer")]),e._v(": An initializer for the bias vector. If None, the default initializer will be used.")]),e._v(" "),i("li",[i("code",[e._v("kernel_regularizer")]),e._v(": Optional regularizer for the convolution kernel.")]),e._v(" "),i("li",[i("code",[e._v("bias_regularizer")]),e._v(": Optional regularizer for the bias vector.")]),e._v(" "),i("li",[i("code",[e._v("activity_regularizer")]),e._v(": Optional regularizer function for the output.")]),e._v(" "),i("li",[i("code",[e._v("kernel_constraint")]),e._v(": Optional projection function to be applied to the kernel after being updated by an "),i("code",[e._v("Optimizer")]),e._v(" (e.g. used to implement norm constraints or value constraints for layer weights). The function must take as input the unprojected variable and must return the projected variable (which must have the same shape). Constraints are not safe to use when doing asynchronous distributed training.")]),e._v(" "),i("li",[i("code",[e._v("bias_constraint")]),e._v(": Optional projection function to be applied to the bias after being updated by an "),i("code",[e._v("Optimizer")]),e._v(".")]),e._v(" "),i("li",[i("code",[e._v("trainable")]),e._v(": Boolean, if "),i("code",[e._v("True")]),e._v(" also add variables to the graph collection "),i("code",[e._v("GraphKeys.TRAINABLE_VARIABLES")]),e._v(" (see "),i("code",[e._v("tf.Variable")]),e._v(").")]),e._v(" "),i("li",[i("code",[e._v("name")]),e._v(": A string, the "),i("code",[e._v("name")]),e._v(" of the layer.")]),e._v(" "),i("li",[i("code",[e._v("reuse")]),e._v(": Boolean, whether to "),i("code",[e._v("reuse")]),e._v(" the weights of a previous layer by the same "),i("code",[e._v("name")]),e._v(".")])]),e._v(" "),i("h4",{attrs:{id:"returns"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),i("p",[e._v("Output tensor.")]),e._v(" "),i("h4",{attrs:{id:"raises"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[e._v("#")]),e._v(" Raises:")]),e._v(" "),i("ul",[i("li",[i("code",[e._v("ValueError")]),e._v(": if eager execution is enabled.")])])])}),[],!1,null,null,null);t.default=a.exports}}]);