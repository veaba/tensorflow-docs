(window.webpackJsonp=window.webpackJsonp||[]).push([[2203],{2391:function(t,e,a){"use strict";a.r(e);var i=a(0),s=Object(i.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("p",[t._v("Computes sums of N-D convolutions (actually cross-correlation).")]),t._v(" "),a("h3",{attrs:{id:"aliases"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[t._v("#")]),t._v(" Aliases:")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("tf.compat.v2.nn.convolution")])])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v(" tf.nn.convolution(\n    input,\n    filters,\n    strides=None,\n    padding='VALID',\n    data_format=None,\n    dilations=None,\n    name=None\n)\n")])])]),a("p",[t._v('This also supports either output striding via the optional strides parameter or atrous convolution (also known as convolution with holes or dilated convolution, based on the French word "trous" meaning holes in English) via the optional dilations parameter. Currently, however, output striding is not supported for atrous convolutions.')]),t._v(" "),a("p",[t._v('Specifically, in the case that data_format does not start with "NC", given a rank (N+2) input Tensor of shape')]),t._v(" "),a("p",[t._v("[num_batches, input_spatial_shape[0], ..., input_spatial_shape[N-1], num_input_channels],")]),t._v(" "),a("p",[t._v("a rank (N+2) filters Tensor of shape")]),t._v(" "),a("p",[t._v("[spatial_filter_shape[0], ..., spatial_filter_shape[N-1], num_input_channels, num_output_channels],\n"),a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/nn/defaulting%20to%20%5B1%5D*N",target:"_blank",rel:"noopener noreferrer"}},[t._v("N"),a("OutboundLink")],1),t._v("an optional dilations tensor of shape  specifying the filter upsampling/input downsampling rate, and an optional list of  strides (defaulting [1]*), this computes for each -D spatial output position (x[0], ..., x[-1]):")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("   output[b, x[0], ..., x[N-1], k] =\n      sum_{z[0], ..., z[N-1], q}\n          filter[z[0], ..., z[N-1], q, k] *\n          padded_input[b,\n                       x[0]*strides[0] + dilation_rate[0]*z[0],\n                       ...,\n                       x[N-1]*strides[N-1] + dilation_rate[N-1]*z[N-1],\n                       q]\n")])])]),a("p",[a("a",{attrs:{href:"https://tensorflow.org/api_guides/python/nn#Convolution",target:"_blank",rel:"noopener noreferrer"}},[t._v("comment here"),a("OutboundLink")],1),t._v("where b is the index into the batch, k is the output channel number, q is the input channel number, and z is the N-D spatial offset within the filter. Here, padded_input is obtained by zero padding the input using an effective spatial filter shape of (spatial_filter_shape-1) * dilation_rate + 1 and output striding strides as described in the .")]),t._v(" "),a("p",[t._v('In the case that data_format does start with "NC", the input and output (but not the filters) are simply transposed as follows:')]),t._v(" "),a("p",[t._v("convolution(input, data_format, **kwargs) = tf.transpose(convolution(tf.transpose(input, [0] + range(2,N+2) + [1]), **kwargs), [0, N+1] + range(1, N+1))")]),t._v(" "),a("p",[t._v("It is required that 1 <= N <= 3.")]),t._v(" "),a("h4",{attrs:{id:"args"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[t._v("#")]),t._v(" Args:")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("input")]),t._v(": An (N+2)-D "),a("code",[t._v("Tensor")]),t._v(" of type "),a("code",[t._v("T")]),t._v(", of shape [batch_size] + "),a("code",[t._v("input")]),t._v('_spatial_shape + [in_channels] if data_format does not start with "NC" (default), or [batch_size, in_channels] + '),a("code",[t._v("input")]),t._v('_spatial_shape if data_format starts with "NC".')]),t._v(" "),a("li",[a("code",[t._v("filters")]),t._v(": An (N+2)-D "),a("code",[t._v("Tensor")]),t._v(" with the same type as "),a("code",[t._v("input")]),t._v(" and shape spatial_filter_shape + [in_channels, out_channels].")]),t._v(" "),a("li",[a("code",[t._v("padding")]),t._v(": A string, either "),a("code",[t._v('"VALID"')]),t._v(" or "),a("code",[t._v('"SAME"')]),t._v(". "),a("code",[t._v("T")]),t._v("he "),a("code",[t._v("padding")]),t._v(" algorithm.")]),t._v(" "),a("li",[a("code",[t._v("strides")]),t._v(": Optional. Sequence of N ints >= 1. Specifies the output stride. Defaults to [1]*N. If any value of "),a("code",[t._v("strides")]),t._v(" is > 1, then all values of dilation_rate must be 1.")]),t._v(" "),a("li",[a("code",[t._v("dilations")]),t._v(": Optional. Sequence of N ints >= 1. Specifies the filter upsampling/"),a("code",[t._v("input")]),t._v(" downsampling rate. In the literature, the same parameter is sometimes called "),a("code",[t._v("input")]),t._v(" stride or "),a("code",[t._v("dilation")]),t._v(". "),a("code",[t._v("T")]),t._v("he effective filter size used for the convolution will be spatial_filter_shape + (spatial_filter_shape - 1) * (rate - 1), obtained by inserting ("),a("code",[t._v("dilation")]),t._v("_rate[i]-1) zeros between consecutive elements of the original filter in each spatial dimension i. If any value of "),a("code",[t._v("dilation")]),t._v("_rate is > 1, then all values of "),a("code",[t._v("strides")]),t._v(" must be 1.")]),t._v(" "),a("li",[a("code",[t._v("name")]),t._v(": Optional "),a("code",[t._v("name")]),t._v(" for the returned tensor.")]),t._v(" "),a("li",[a("code",[t._v("data_format")]),t._v(": A string or None. Specifies whether the channel dimension of the "),a("code",[t._v("input")]),t._v(" and output is the last dimension (default, or if "),a("code",[t._v("data_format")]),t._v(' does not start with "NC"), or the second dimension (if '),a("code",[t._v("data_format")]),t._v(' starts with "NC"). For N=1, the valid values are "NWC" (default) and "NCW". For N=2, the valid values are "NHWC" (default) and "NCHW". For N=3, the valid values are "NDHWC" (default) and "NCDHW".')]),t._v(" "),a("li",[a("code",[t._v("filters")]),t._v(": Alias of filter.")]),t._v(" "),a("li",[a("code",[t._v("dilations")]),t._v(": Alias of "),a("code",[t._v("dilation")]),t._v("_rate.")])]),t._v(" "),a("h4",{attrs:{id:"returns"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[t._v("#")]),t._v(" Returns:")]),t._v(" "),a("p",[t._v("A Tensor with the same type as input of shape")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v(" `[batch_size] + output_spatial_shape + [out_channels]`\n")])])]),a("p",[t._v('if data_format is None or does not start with "NC", or')]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v(" `[batch_size, out_channels] + output_spatial_shape`\n")])])]),a("p",[t._v('if data_format starts with "NC", where output_spatial_shape depends on the value of padding.')]),t._v(" "),a("p",[t._v('If padding == "SAME": output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i])')]),t._v(" "),a("p",[t._v('If padding == "VALID": output_spatial_shape[i] = ceil((input_spatial_shape[i] - (spatial_filter_shape[i]-1) * dilation_rate[i]) / strides[i]).')]),t._v(" "),a("h4",{attrs:{id:"raises"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[t._v("#")]),t._v(" Raises:")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("ValueError")]),t._v(": If input/output depth does not match "),a("code",[t._v("filters")]),t._v(" shape, if padding is other than "),a("code",[t._v('"VALID"')]),t._v(" or "),a("code",[t._v('"SAME"')]),t._v(", or if data_format is invalid.")])])])}),[],!1,null,null,null);e.default=s.exports}}]);