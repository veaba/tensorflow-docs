(window.webpackJsonp=window.webpackJsonp||[]).push([[1194],{1383:function(t,e,r){"use strict";r.r(e);var a=r(0),n=Object(a.a)({},(function(){var t=this,e=t.$createElement,r=t._self._c||e;return r("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[r("p",[t._v("Experimental Distribution Strategy library.")]),t._v(" "),r("h2",{attrs:{id:"classes"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#classes","aria-hidden":"true"}},[t._v("#")]),t._v(" Classes")]),t._v(" "),r("p",[r("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/CentralStorageStrategy",target:"_blank",rel:"noopener noreferrer"}},[t._v("class CentralStorageStrategy"),r("OutboundLink")],1),t._v(": A one-machine strategy that puts all variables on a single device.")]),t._v(" "),r("p",[r("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/CollectiveCommunication",target:"_blank",rel:"noopener noreferrer"}},[t._v("class CollectiveCommunication"),r("OutboundLink")],1),t._v(": Communication choices for CollectiveOps.")]),t._v(" "),r("p",[r("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/MultiWorkerMirroredStrategy",target:"_blank",rel:"noopener noreferrer"}},[t._v("class MultiWorkerMirroredStrategy"),r("OutboundLink")],1),t._v(": A distribution strategy for synchronous training on multiple workers.")]),t._v(" "),r("p",[r("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/ParameterServerStrategy",target:"_blank",rel:"noopener noreferrer"}},[t._v("class ParameterServerStrategy"),r("OutboundLink")],1),t._v(": An asynchronous multi-worker parameter server tf.distribute strategy.")]),t._v(" "),r("p",[r("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/TPUStrategy",target:"_blank",rel:"noopener noreferrer"}},[t._v("class TPUStrategy"),r("OutboundLink")],1),t._v(": TPU distribution strategy implementation.")])])}),[],!1,null,null,null);e.default=n.exports}}]);