(window.webpackJsonp=window.webpackJsonp||[]).push([[1686],{1877:function(e,t,a){"use strict";a.r(t);var r=a(0),s=Object(r.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("p",[e._v("Loads the IMDB dataset.")]),e._v(" "),a("h3",{attrs:{id:"aliases"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[e._v("#")]),e._v(" Aliases:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("tf.compat.v1.keras.datasets.imdb.load_data")])]),e._v(" "),a("li",[a("code",[e._v("tf.compat.v2.keras.datasets.imdb.load_data")])])]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" tf.keras.datasets.imdb.load_data(\n    path='imdb.npz',\n    num_words=None,\n    skip_top=0,\n    maxlen=None,\n    seed=113,\n    start_char=1,\n    oov_char=2,\n    index_from=3,\n    **kwargs\n)\n")])])]),a("h3",{attrs:{id:"used-in-the-tutorials"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#used-in-the-tutorials","aria-hidden":"true"}},[e._v("#")]),e._v(" Used in the tutorials:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("E")]),e._v("x"),a("code",[e._v("p")]),e._v("l"),a("code",[e._v("o")]),e._v("r"),a("code",[e._v("e")]),e._v(" "),a("code",[e._v("o")]),e._v("v"),a("code",[e._v("e")]),e._v("r"),a("code",[e._v("f")]),e._v("i"),a("code",[e._v("t")]),e._v(" "),a("code",[e._v("a")]),e._v("n"),a("code",[e._v("d")]),e._v(" "),a("code",[e._v("u")]),e._v("n"),a("code",[e._v("d")]),e._v("e"),a("code",[e._v("r")]),e._v("f"),a("code",[e._v("i")]),e._v("t``")])]),e._v(" "),a("h4",{attrs:{id:"arguments"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#arguments","aria-hidden":"true"}},[e._v("#")]),e._v(" Arguments:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("path")]),e._v(": where to cache the data (relative to "),a("code",[e._v("~/.keras/dataset")]),e._v(").")]),e._v(" "),a("li",[a("code",[e._v("num_words")]),e._v(": max number of words to include. Words are ranked by how often they occur (in the training set) and only the most frequent words are kept")]),e._v(" "),a("li",[a("code",[e._v("skip_top")]),e._v(": skip the top N most frequently occurring words (which may not be informative).")]),e._v(" "),a("li",[a("code",[e._v("maxlen")]),e._v(": sequences longer than this will be filtered out.")]),e._v(" "),a("li",[a("code",[e._v("seed")]),e._v(": random "),a("code",[e._v("seed")]),e._v(" for sample shuffling.")]),e._v(" "),a("li",[a("code",[e._v("start_char")]),e._v(": The start of a sequence will be marked with this character. Set to 1 because 0 is usually the padding character.")]),e._v(" "),a("li",[a("code",[e._v("oov_char")]),e._v(": words that were cut out because of the "),a("code",[e._v("num_words")]),e._v(" or "),a("code",[e._v("skip_top")]),e._v(" limit will be replaced with this character.")]),e._v(" "),a("li",[a("code",[e._v("index_from")]),e._v(": index actual words with this index and higher.")])]),e._v(" "),a("h4",{attrs:{id:"returns"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),a("p",[e._v("Tuple of Numpy arrays: (x_train, y_train), (x_test, y_test).")]),e._v(" "),a("h4",{attrs:{id:"raises"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[e._v("#")]),e._v(" Raises:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("ValueError")]),e._v(": in case "),a("code",[e._v("maxlen")]),e._v(" is so low that no input sequence could be kept.")])]),e._v(" "),a("p",[e._v("Note that the 'out of vocabulary' character is only used for words that were present in the training set but are not included because they're not making the num_words cut here. Words that were not seen in the training set but are in the test set have simply been skipped.")])])}),[],!1,null,null,null);t.default=s.exports}}]);