(window.webpackJsonp=window.webpackJsonp||[]).push([[1692],{1883:function(e,t,a){"use strict";a.r(t);var s=a(0),r=Object(s.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("p",[e._v("Loads the Reuters newswire classification dataset.")]),e._v(" "),a("h3",{attrs:{id:"aliases"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[e._v("#")]),e._v(" Aliases:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("tf.compat.v1.keras.datasets.reuters.load_data")])]),e._v(" "),a("li",[a("code",[e._v("tf.compat.v2.keras.datasets.reuters.load_data")])])]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" tf.keras.datasets.reuters.load_data(\n    path='reuters.npz',\n    num_words=None,\n    skip_top=0,\n    maxlen=None,\n    test_split=0.2,\n    seed=113,\n    start_char=1,\n    oov_char=2,\n    index_from=3,\n    **kwargs\n)\n")])])]),a("h4",{attrs:{id:"arguments"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#arguments","aria-hidden":"true"}},[e._v("#")]),e._v(" Arguments:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("path")]),e._v(": where to cache the data (relative to "),a("code",[e._v("~/.keras/dataset")]),e._v(").")]),e._v(" "),a("li",[a("code",[e._v("num_words")]),e._v(": max number of words to include. Words are ranked by how often they occur (in the training set) and only the most frequent words are kept")]),e._v(" "),a("li",[a("code",[e._v("skip_top")]),e._v(": skip the top N most frequently occurring words (which may not be informative).")]),e._v(" "),a("li",[a("code",[e._v("maxlen")]),e._v(": truncate sequences after this length.")]),e._v(" "),a("li",[a("code",[e._v("test_split")]),e._v(": Fraction of the dataset to be used as test data.")]),e._v(" "),a("li",[a("code",[e._v("seed")]),e._v(": random "),a("code",[e._v("seed")]),e._v(" for sample shuffling.")]),e._v(" "),a("li",[a("code",[e._v("start_char")]),e._v(": The start of a sequence will be marked with this character. Set to 1 because 0 is usually the padding character.")]),e._v(" "),a("li",[a("code",[e._v("oov_char")]),e._v(": words that were cut out because of the "),a("code",[e._v("num_words")]),e._v(" or "),a("code",[e._v("skip_top")]),e._v(" limit will be replaced with this character.")]),e._v(" "),a("li",[a("code",[e._v("index_from")]),e._v(": index actual words with this index and higher.")])]),e._v(" "),a("h4",{attrs:{id:"returns"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),a("p",[e._v("Tuple of Numpy arrays: (x_train, y_train), (x_test, y_test).")]),e._v(" "),a("p",[e._v("Note that the 'out of vocabulary' character is only used for words that were present in the training set but are not included because they're not making the num_words cut here. Words that were not seen in the training set but are in the test set have simply been skipped.")])])}),[],!1,null,null,null);t.default=r.exports}}]);