(window.webpackJsonp=window.webpackJsonp||[]).push([[2209],{2397:function(e,t,a){"use strict";a.r(t);var s=a(0),o=Object(s.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("p",[e._v("DepthToSpace for tensors of type T.")]),e._v(" "),a("h3",{attrs:{id:"aliases"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[e._v("#")]),e._v(" Aliases:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("tf.compat.v2.nn.depth_to_space")])])]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" tf.nn.depth_to_space(\n    input,\n    block_size,\n    data_format='NHWC',\n    name=None\n)\n")])])]),a("p",[e._v("Rearranges data from depth into blocks of spatial data. This is the reverse transformation of SpaceToDepth. More specifically, this op outputs a copy of the input tensor where values from the depth dimension are moved in spatial blocks to the height and width dimensions. The attr block_size indicates the input block size and how the data is moved.")]),e._v(" "),a("ul",[a("li",[e._v("Chunks of data of size block_size * block_size from depth are rearranged into non-overlapping blocks of size "),a("code",[e._v("block_size x block_size")])]),e._v(" "),a("li",[e._v("The width the output tensor is input_depth * block_size, whereas the height is input_height * block_size.")]),e._v(" "),a("li",[e._v("The Y, X coordinates within each block of the output image are determined by the high order component of the input channel index.")]),e._v(" "),a("li",[e._v("The depth of the input tensor must be divisible by block_size * block_size.")])]),e._v(" "),a("p",[e._v('The data_format attr specifies the layout of the input and output tensors with the following options: "NHWC": [ batch, height, width, channels ] "NCHW": [ batch, channels, height, width ] "NCHW_VECT_C": qint8 [ batch, channels / 4, height, width, 4 ]')]),e._v(" "),a("p",[e._v("It is useful to consider the operation as transforming a 6-D Tensor. e.g. for data_format = NHWC, Each element in the input tensor can be specified via 6 coordinates, ordered by decreasing memory layout significance as: n,iY,iX,bY,bX,oC (where n=batch index, iX, iY means X or Y coordinates within the input image, bX, bY means coordinates within the output block, oC means output channels). The output would be the input transposed to the following layout: n,iY,bY,iX,bX,oC")]),e._v(" "),a("p",[e._v("This operation is useful for resizing the activations between convolutions (but keeping all data), e.g. instead of pooling. It is also useful for training purely convolutional models.")]),e._v(" "),a("p",[e._v('For example, given an input of shape [1, 1, 1, 4], data_format = "NHWC" and block_size = 2:')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" x = [[[[1, 2, 3, 4]]]]\n")])])]),a("p",[e._v("This operation will output a tensor of shape [1, 2, 2, 1]:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("    [[[[1], [2]],\n     [[3], [4]]]]\n")])])]),a("p",[e._v("Here, the input has a batch of 1 and each batch element has shape [1, 1, 4], the corresponding output will have 2x2 elements and will have a depth of 1 channel (1 = 4 / (block_size * block_size)). The output element shape is [2, 2, 1].")]),e._v(" "),a("p",[e._v("For an input tensor with larger depth, here of shape [1, 1, 1, 12], e.g.")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" x = [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]\n")])])]),a("p",[e._v("This operation, for block size of 2, will return the following tensor of shape [1, 2, 2, 3]")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("    [[[[1, 2, 3], [4, 5, 6]],\n     [[7, 8, 9], [10, 11, 12]]]]\n")])])]),a("p",[e._v("Similarly, for the following input of shape [1 2 2 4], and a block size of 2:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" x =  [[[[1, 2, 3, 4],\n       [5, 6, 7, 8]],\n      [[9, 10, 11, 12],\n       [13, 14, 15, 16]]]]\n")])])]),a("p",[e._v("the operator will return the following tensor of shape [1 4 4 1]:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" x = [[[ [1],   [2],  [5],  [6]],\n      [ [3],   [4],  [7],  [8]],\n      [ [9],  [10], [13],  [14]],\n      [ [11], [12], [15],  [16]]]]\n")])])]),a("h4",{attrs:{id:"args"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("input")]),e._v(": A "),a("code",[e._v("Tensor")]),e._v(".")]),e._v(" "),a("li",[a("code",[e._v("block_size")]),e._v(": An "),a("code",[e._v("int")]),e._v(" that is "),a("code",[e._v(">= 2")]),e._v(". The size of the spatial block, same as in Space2Depth.")]),e._v(" "),a("li",[a("code",[e._v("data_format")]),e._v(": An optional "),a("code",[e._v("string")]),e._v(" from: "),a("code",[e._v('"NHWC", "NCHW", "NCHW_VECT_C"')]),e._v(". Defaults to "),a("code",[e._v('"NHWC"')]),e._v(".")]),e._v(" "),a("li",[a("code",[e._v("name")]),e._v(": A "),a("code",[e._v("name")]),e._v(" for the operation (optional).")])]),e._v(" "),a("h4",{attrs:{id:"returns"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),a("p",[e._v("A Tensor. Has the same type as input.")])])}),[],!1,null,null,null);t.default=o.exports}}]);