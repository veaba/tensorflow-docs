(window.webpackJsonp=window.webpackJsonp||[]).push([[1129],{1318:function(e,a,t){"use strict";t.r(a);var n=t(0),s=Object(n.a)({},(function(){var e=this,a=e.$createElement,t=e._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("p",[e._v("Fused implementation of map and batch. (deprecated)")]),e._v(" "),t("h3",{attrs:{id:"aliases"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[e._v("#")]),e._v(" Aliases:")]),e._v(" "),t("ul",[t("li",[t("code",[e._v("tf.compat.v1.data.experimental.map_and_batch")])]),e._v(" "),t("li",[t("code",[e._v("tf.compat.v2.data.experimental.map_and_batch")])])]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v(" tf.data.experimental.map_and_batch(\n    map_func,\n    batch_size,\n    num_parallel_batches=None,\n    drop_remainder=False,\n    num_parallel_calls=None\n)\n")])])]),t("p",[e._v("Maps map_func across batch_size consecutive elements of this dataset and then combines them into a batch. Functionally, it is equivalent to map followed by batch. However, by fusing the two transformations together, the implementation can be more efficient. Surfacing this transformation in the API is temporary. Once automatic input pipeline optimization is implemented, the fusing of map and batch will happen automatically and this API will be deprecated.")]),e._v(" "),t("h4",{attrs:{id:"args"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),t("ul",[t("li",[t("code",[e._v("map_func")]),e._v(": A function mapping a nested structure of tensors to another nested structure of tensors.")]),e._v(" "),t("li",[t("code",[e._v("batch_size")]),e._v(": A "),t("code",[e._v("tf.int64")]),e._v(" scalar "),t("code",[e._v("tf.Tensor")]),e._v(", representing the number of consecutive elements of this dataset to combine in a single batch.")]),e._v(" "),t("li",[t("code",[e._v("num_parallel_batches")]),e._v(": (Optional.) A "),t("code",[e._v("tf.int64")]),e._v(" scalar "),t("code",[e._v("tf.Tensor")]),e._v(", representing the number of batches to create in parallel. On one hand, higher values can help mitigate the effect of stragglers. On the other hand, higher values can increase contention if CPU is scarce.")]),e._v(" "),t("li",[t("code",[e._v("drop_remainder")]),e._v(": (Optional.) A "),t("code",[e._v("tf.bool")]),e._v(" scalar "),t("code",[e._v("tf.Tensor")]),e._v(", representing whether the last batch should be dropped in case its size is smaller than desired; the default behavior is not to drop the smaller batch.")]),e._v(" "),t("li",[t("code",[e._v("num_parallel_calls")]),e._v(": (Optional.) A "),t("code",[e._v("tf.int32")]),e._v(" scalar "),t("code",[e._v("tf.Tensor")]),e._v(", representing the number of elements to process in parallel. If not specified, "),t("code",[e._v("batch_size")]),e._v(" * "),t("code",[e._v("num_parallel_batches")]),e._v(" elements will be processed in parallel. If the value "),t("code",[e._v("tf.data.experimental.AUTOTUNE")]),e._v(" is used, then the number of parallel calls is set dynamically based on available CPU.")])]),e._v(" "),t("h4",{attrs:{id:"returns"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),t("p",[t("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/data/Dataset#apply",target:"_blank",rel:"noopener noreferrer"}},[e._v("tf.data.Dataset.apply"),t("OutboundLink")],1),e._v("A Dataset transformation function, which can be passed to .")]),e._v(" "),t("h4",{attrs:{id:"raises"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[e._v("#")]),e._v(" Raises:")]),e._v(" "),t("ul",[t("li",[t("code",[e._v("ValueError")]),e._v(": If both "),t("code",[e._v("num_parallel_batches")]),e._v(" and "),t("code",[e._v("num_parallel_calls")]),e._v(" are specified.")])])])}),[],!1,null,null,null);a.default=s.exports}}]);