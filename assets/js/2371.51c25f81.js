(window.webpackJsonp=window.webpackJsonp||[]).push([[2371],{2559:function(e,t,a){"use strict";a.r(t);var s=a(0),n=Object(s.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("p",[e._v("Create a tensor of n-grams based on data.")]),e._v(" "),a("h3",{attrs:{id:"aliases"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[e._v("#")]),e._v(" Aliases:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("tf.compat.v1.strings.ngrams")])]),e._v(" "),a("li",[a("code",[e._v("tf.compat.v2.strings.ngrams")])])]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" tf.strings.ngrams(\n    data,\n    ngram_width,\n    separator=' ',\n    pad_values=None,\n    padding_width=None,\n    preserve_short_sequences=False,\n    name=None\n)\n")])])]),a("p",[e._v("Creates a tensor of n-grams based on data. The n-grams are created by joining windows of width adjacent strings from the inner axis of data using separator.")]),e._v(" "),a("p",[e._v("The input data can be padded on both the start and end of the sequence, if desired, using the pad_values argument. If set, pad_values should contain either a tuple of strings or a single string; the 0th element of the tuple will be used to pad the left side of the sequence and the 1st element of the tuple will be used to pad the right side of the sequence. The padding_width arg controls how many padding values are added to each side; it defaults to ngram_width-1.")]),e._v(" "),a("p",[e._v("If this op is configured to not have padding, or if it is configured to add padding with padding_width set to less than ngram_width-1, it is possible that a sequence, or a sequence plus padding, is smaller than the ngram width. In that case, no ngrams will be generated for that sequence. This can be prevented by setting preserve_short_sequences, which will cause the op to always generate at least one ngram per non-empty sequence.")]),e._v(" "),a("h4",{attrs:{id:"args"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("data")]),e._v(": A Tensor or RaggedTensor containing the source "),a("code",[e._v("data")]),e._v(" for the ngrams.")]),e._v(" "),a("li",[a("code",[e._v("ngram_width")]),e._v(": The width(s) of the ngrams to create. If this is a list or tuple, the op will return ngrams of all specified arities in list order. Values must be non-Tensor integers greater than 0.")]),e._v(" "),a("li",[a("code",[e._v("separator")]),e._v(": The "),a("code",[e._v("separator")]),e._v(" string used between ngram elements. Must be a string constant, not a Tensor.")]),e._v(" "),a("li",[a("code",[e._v("pad_values")]),e._v(": A tuple of (left_pad_value, right_pad_value), a single string, or None. If None, no padding will be added; if a single string, then that string will be used for both left and right padding. Values must be Python strings.")]),e._v(" "),a("li",[a("code",[e._v("padding_width")]),e._v(": If set, "),a("code",[e._v("padding_width")]),e._v(" pad values will be added to both sides of each sequence. Defaults to "),a("code",[e._v("ngram_width")]),e._v("-1. Must be greater than\n(Note that 1-grams are never padded, regardless of this value.)")]),e._v(" "),a("li",[e._v("(Note that 1-grams are never padded, regardless of this value.)")]),e._v(" "),a("li",[a("code",[e._v("preserve_short_sequences")]),e._v(": If true, then ensure that at least one ngram is generated for each input sequence. In particular, if an input sequence is shorter than min("),a("code",[e._v("ngram_width")]),e._v(") + 2*pad_width, then generate a single ngram containing the entire sequence. If false, then no ngrams are generated for these short input sequences.")]),e._v(" "),a("li",[a("code",[e._v("name")]),e._v(": The op "),a("code",[e._v("name")]),e._v(".")])]),e._v(" "),a("h4",{attrs:{id:"returns"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),a("p",[e._v("A RaggedTensor of ngrams. If data.shape=[D1...DN, S], then output.shape=[D1...DN, NUM_NGRAMS], where NUM_NGRAMS=S-ngram_width+1+2*padding_width.")]),e._v(" "),a("h4",{attrs:{id:"raises"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[e._v("#")]),e._v(" Raises:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("TypeError")]),e._v(": if "),a("code",[e._v("pad_values")]),e._v(" is set to an invalid type.")]),e._v(" "),a("li",[a("code",[e._v("ValueError")]),e._v(": if "),a("code",[e._v("pad_values")]),e._v(", "),a("code",[e._v("padding_width")]),e._v(", or "),a("code",[e._v("ngram_width")]),e._v(" is set to an invalid value.")])])])}),[],!1,null,null,null);t.default=n.exports}}]);