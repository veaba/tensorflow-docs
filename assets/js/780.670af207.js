(window.webpackJsonp=window.webpackJsonp||[]).push([[780],{968:function(e,t,a){"use strict";a.r(t);var o=a(0),s=Object(o.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("p",[e._v("SpaceToDepth for tensors of type T.")]),e._v(" "),a("h3",{attrs:{id:"aliases"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[e._v("#")]),e._v(" Aliases:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("tf.compat.v1.nn.space_to_depth")])])]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" tf.compat.v1.space_to_depth(\n    input,\n    block_size,\n    name=None,\n    data_format='NHWC'\n)\n")])])]),a("p",[e._v("Rearranges blocks of spatial data, into depth. More specifically, this op outputs a copy of the input tensor where values from the height and width dimensions are moved to the depth dimension. The attr block_size indicates the input block size.")]),e._v(" "),a("ul",[a("li",[e._v("Non-overlapping blocks of size "),a("code",[e._v("block_size x block size")]),e._v(" are rearranged into depth at each location.")]),e._v(" "),a("li",[e._v("The depth of the output tensor is block_size * block_size * input_depth.")]),e._v(" "),a("li",[e._v("The Y, X coordinates within each block of the input become the high order component of the output channel index.")]),e._v(" "),a("li",[e._v("The input tensor's height and width must be divisible by block_size.")])]),e._v(" "),a("p",[e._v('The data_format attr specifies the layout of the input and output tensors with the following options: "NHWC": [ batch, height, width, channels ] "NCHW": [ batch, channels, height, width ] "NCHW_VECT_C": qint8 [ batch, channels / 4, height, width, 4 ]')]),e._v(" "),a("p",[e._v("It is useful to consider the operation as transforming a 6-D Tensor. e.g. for data_format = NHWC, Each element in the input tensor can be specified via 6 coordinates, ordered by decreasing memory layout significance as: n,oY,bY,oX,bX,iC (where n=batch index, oX, oY means X or Y coordinates within the output image, bX, bY means coordinates within the input block, iC means input channels). The output would be a transpose to the following layout: n,oY,oX,bY,bX,iC")]),e._v(" "),a("p",[e._v("This operation is useful for resizing the activations between convolutions (but keeping all data), e.g. instead of pooling. It is also useful for training purely convolutional models.")]),e._v(" "),a("p",[e._v('For example, given an input of shape [1, 2, 2, 1], data_format = "NHWC" and block_size = 2:')]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" x = [[[[1], [2]],\n      [[3], [4]]]]\n")])])]),a("p",[e._v("This operation will output a tensor of shape [1, 1, 1, 4]:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" [[[[1, 2, 3, 4]]]]\n")])])]),a("p",[e._v("Here, the input has a batch of 1 and each batch element has shape [2, 2, 1], the corresponding output will have a single element (i.e. width and height are both 1) and will have a depth of 4 channels (1 * block_size * block_size). The output element shape is [1, 1, 4].")]),e._v(" "),a("p",[e._v("For an input tensor with larger depth, here of shape [1, 2, 2, 3], e.g.")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" x = [[[[1, 2, 3], [4, 5, 6]],\n      [[7, 8, 9], [10, 11, 12]]]]\n")])])]),a("p",[e._v("This operation, for block_size of 2, will return the following tensor of shape [1, 1, 1, 12]")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]\n")])])]),a("p",[e._v("Similarly, for the following input of shape [1 4 4 1], and a block size of 2:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" x = [[[[1],   [2],  [5],  [6]],\n      [[3],   [4],  [7],  [8]],\n      [[9],  [10], [13],  [14]],\n      [[11], [12], [15],  [16]]]]\n")])])]),a("p",[e._v("the operator will return the following tensor of shape [1 2 2 4]:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" x = [[[[1, 2, 3, 4],\n       [5, 6, 7, 8]],\n      [[9, 10, 11, 12],\n       [13, 14, 15, 16]]]]\n")])])]),a("h4",{attrs:{id:"args"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("input")]),e._v(": A "),a("code",[e._v("Tensor")]),e._v(".")]),e._v(" "),a("li",[a("code",[e._v("block_size")]),e._v(": An "),a("code",[e._v("int")]),e._v(" that is "),a("code",[e._v(">= 2")]),e._v(". The size of the spatial block.")]),e._v(" "),a("li",[a("code",[e._v("data_format")]),e._v(": An optional "),a("code",[e._v("string")]),e._v(" from: "),a("code",[e._v('"NHWC", "NCHW", "NCHW_VECT_C"')]),e._v(". Defaults to "),a("code",[e._v('"NHWC"')]),e._v(".")]),e._v(" "),a("li",[a("code",[e._v("name")]),e._v(": A "),a("code",[e._v("name")]),e._v(" for the operation (optional).")])]),e._v(" "),a("h4",{attrs:{id:"returns"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),a("p",[e._v("A Tensor. Has the same type as input.")])])}),[],!1,null,null,null);t.default=s.exports}}]);