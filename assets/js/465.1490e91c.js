(window.webpackJsonp=window.webpackJsonp||[]).push([[465],{654:function(e,t,r){"use strict";r.r(t);var a=r(0),i=Object(a.a)({},(function(){var e=this,t=e.$createElement,r=e._self._c||t;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[r("h2",{attrs:{id:"class-lstm"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#class-lstm","aria-hidden":"true"}},[e._v("#")]),e._v(" Class LSTM")]),e._v(" "),r("p",[e._v("Long Short-Term Memory layer - Hochreiter 1997.\n"),r("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN",target:"_blank",rel:"noopener noreferrer"}},[e._v("RNN"),r("OutboundLink")],1),e._v("Inherits From:")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/compat/v1/keras/layers/CuDNNLSTM",target:"_blank",rel:"noopener noreferrer"}},[e._v("tf.compat.v1.keras.layers.CuDNNLSTM"),r("OutboundLink")],1),e._v("Note that this cell is not optimized for performance on GPU. Please use  for better performance on GPU.")]),e._v(" "),r("h4",{attrs:{id:"arguments"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#arguments","aria-hidden":"true"}},[e._v("#")]),e._v(" Arguments:")]),e._v(" "),r("ul",[r("li",[r("code",[e._v("units")]),e._v(": Positive integer, dimensionality of the output space.")]),e._v(" "),r("li",[r("code",[e._v("activation")]),e._v(": Activation function to use. Default: hyperbolic tangent ("),r("code",[e._v("tanh")]),e._v("). If you pass "),r("code",[e._v("None")]),e._v(", no "),r("code",[e._v("activation")]),e._v(' is applied (ie. "linear" '),r("code",[e._v("activation")]),e._v(": a(x) = x).")]),e._v(" "),r("li",[r("code",[e._v("recurrent_activation")]),e._v(": Activation function to use for the recurrent step. Default: hard sigmoid ("),r("code",[e._v("hard_sigmoid")]),e._v("). If you pass "),r("code",[e._v("None")]),e._v(", no "),r("code",[e._v("activation")]),e._v(' is applied (ie. "linear" '),r("code",[e._v("activation")]),e._v(": a(x) = x).")]),e._v(" "),r("li",[r("code",[e._v("use_bias")]),e._v(": Boolean, whether the layer uses a bias vector.")]),e._v(" "),r("li",[r("code",[e._v("kernel_initializer")]),e._v(": Initializer for the "),r("code",[e._v("kernel")]),e._v(" weights matrix, used for the linear transformation of the inputs..")]),e._v(" "),r("li",[r("code",[e._v("recurrent_initializer")]),e._v(": Initializer for the "),r("code",[e._v("recurrent_kernel")]),e._v(" weights matrix, used for the linear transformation of the recurrent state.")]),e._v(" "),r("li",[r("code",[e._v("bias_initializer")]),e._v(": Initializer for the bias vector.")]),e._v(" "),r("li",[r("code",[e._v("unit_forget_bias")]),e._v(": Boolean. If True, add 1 to the bias of the forget gate at initialization. Setting it to true will also force "),r("code",[e._v("bias_initializer")]),e._v('="zeros". This is recommended in Jozefowicz et al..')]),e._v(" "),r("li",[r("code",[e._v("kernel")]),e._v("_regularizer: Regularizer function applied to the "),r("code",[e._v("kernel")]),e._v(" weights matrix.")]),e._v(" "),r("li",[r("code",[e._v("recurrent_regularizer")]),e._v(": Regularizer function applied to the "),r("code",[e._v("recurrent_kernel")]),e._v(" weights matrix.")]),e._v(" "),r("li",[r("code",[e._v("bias_regularizer")]),e._v(": Regularizer function applied to the bias vector.")]),e._v(" "),r("li",[r("code",[e._v("activity_regularizer")]),e._v(': Regularizer function applied to the output of the layer (its "'),r("code",[e._v("activation")]),e._v('")..')]),e._v(" "),r("li",[r("code",[e._v("kernel")]),e._v("_constraint: Constraint function applied to the "),r("code",[e._v("kernel")]),e._v(" weights matrix.")]),e._v(" "),r("li",[r("code",[e._v("recurrent_constraint")]),e._v(": Constraint function applied to the "),r("code",[e._v("recurrent_kernel")]),e._v(" weights matrix.")]),e._v(" "),r("li",[r("code",[e._v("bias_constraint")]),e._v(": Constraint function applied to the bias vector.")]),e._v(" "),r("li",[r("code",[e._v("dropout")]),e._v(": Float between 0 and 1. Fraction of the "),r("code",[e._v("units")]),e._v(" to drop for the linear transformation of the inputs.")]),e._v(" "),r("li",[r("code",[e._v("recurrent_dropout")]),e._v(": Float between 0 and 1. Fraction of the "),r("code",[e._v("units")]),e._v(" to drop for the linear transformation of the recurrent state.")]),e._v(" "),r("li",[r("code",[e._v("implementation")]),e._v(": Implementation mode, either 1 or 2. Mode 1 will structure its operations as a larger number of smaller dot products and additions, whereas mode 2 will batch them into fewer, larger operations. These modes will have different performance profiles on different hardware and for different applications.")]),e._v(" "),r("li",[r("code",[e._v("return_sequences")]),e._v(": Boolean. Whether to return the last output. in the output sequence, or the full sequence.")]),e._v(" "),r("li",[r("code",[e._v("return_state")]),e._v(": Boolean. Whether to return the last state in addition to the output.")]),e._v(" "),r("li",[r("code",[e._v("go_backwards")]),e._v(": Boolean (default False). If True, process the input sequence backwards and return the reversed sequence.")]),e._v(" "),r("li",[r("code",[e._v("stateful")]),e._v(": Boolean (default False). If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.")]),e._v(" "),r("li",[r("code",[e._v("unroll")]),e._v(": Boolean (default False). If True, the network will be "),r("code",[e._v("unroll")]),e._v("ed, else a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences.")]),e._v(" "),r("li",[r("code",[e._v("time_major")]),e._v(": The shape format of the "),r("code",[e._v("inputs")]),e._v(" and "),r("code",[e._v("outputs")]),e._v(" tensors. If True, the "),r("code",[e._v("inputs")]),e._v(" and "),r("code",[e._v("outputs")]),e._v(" will be in shape ("),r("code",[e._v("timesteps, batch, ...")]),e._v("), whereas in the False case, it will be ("),r("code",[e._v("batch, timesteps, ...")]),e._v("). Using "),r("code",[e._v("time_major")]),e._v(" = True is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form.")])]),e._v(" "),r("h4",{attrs:{id:"call-arguments"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#call-arguments","aria-hidden":"true"}},[e._v("#")]),e._v(" Call arguments:")]),e._v(" "),r("ul",[r("li",[r("code",[e._v("inputs")]),e._v(": A 3D tensor.")]),e._v(" "),r("li",[r("code",[e._v("mask")]),e._v(": Binary tensor of shape ("),r("code",[e._v("samples, timesteps")]),e._v(") indicating whether a given timestep should be "),r("code",[e._v("mask")]),e._v("ed.")]),e._v(" "),r("li",[r("code",[e._v("training")]),e._v(": Python boolean indicating whether the layer should behave in "),r("code",[e._v("training")]),e._v(" mode or in inference mode. This argument is passed to the cell when calling it. This is only relevant if "),r("code",[e._v("dropout")]),e._v(" or "),r("code",[e._v("recurrent_dropout")]),e._v(" is used.")]),e._v(" "),r("li",[r("code",[e._v("initial_state")]),e._v(": List of initial state tensors to be passed to the first call of the cell.")])]),e._v(" "),r("h2",{attrs:{id:"init"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#init","aria-hidden":"true"}},[e._v("#")]),e._v(" "),r("strong",[e._v("init")])]),e._v(" "),r("p",[r("a",{attrs:{href:"https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/recurrent.py#L2486-L2543",target:"_blank",rel:"noopener noreferrer"}},[e._v("View source"),r("OutboundLink")],1)]),e._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[e._v(" __init__(\n    units,\n    activation='tanh',\n    recurrent_activation='hard_sigmoid',\n    use_bias=True,\n    kernel_initializer='glorot_uniform',\n    recurrent_initializer='orthogonal',\n    bias_initializer='zeros',\n    unit_forget_bias=True,\n    kernel_regularizer=None,\n    recurrent_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    recurrent_constraint=None,\n    bias_constraint=None,\n    dropout=0.0,\n    recurrent_dropout=0.0,\n    implementation=1,\n    return_sequences=False,\n    return_state=False,\n    go_backwards=False,\n    stateful=False,\n    unroll=False,\n    **kwargs\n)\n")])])]),r("h2",{attrs:{id:"properties"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#properties","aria-hidden":"true"}},[e._v("#")]),e._v(" Properties")]),e._v(" "),r("h3",{attrs:{id:"activation"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#activation","aria-hidden":"true"}},[e._v("#")]),e._v(" activation")]),e._v(" "),r("h3",{attrs:{id:"bias-constraint"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#bias-constraint","aria-hidden":"true"}},[e._v("#")]),e._v(" bias_constraint")]),e._v(" "),r("h3",{attrs:{id:"bias-initializer"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#bias-initializer","aria-hidden":"true"}},[e._v("#")]),e._v(" bias_initializer")]),e._v(" "),r("h3",{attrs:{id:"bias-regularizer"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#bias-regularizer","aria-hidden":"true"}},[e._v("#")]),e._v(" bias_regularizer")]),e._v(" "),r("h3",{attrs:{id:"dropout"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#dropout","aria-hidden":"true"}},[e._v("#")]),e._v(" dropout")]),e._v(" "),r("h3",{attrs:{id:"implementation"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#implementation","aria-hidden":"true"}},[e._v("#")]),e._v(" implementation")]),e._v(" "),r("h3",{attrs:{id:"kernel-constraint"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#kernel-constraint","aria-hidden":"true"}},[e._v("#")]),e._v(" kernel_constraint")]),e._v(" "),r("h3",{attrs:{id:"kernel-initializer"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#kernel-initializer","aria-hidden":"true"}},[e._v("#")]),e._v(" kernel_initializer")]),e._v(" "),r("h3",{attrs:{id:"kernel-regularizer"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#kernel-regularizer","aria-hidden":"true"}},[e._v("#")]),e._v(" kernel_regularizer")]),e._v(" "),r("h3",{attrs:{id:"recurrent-activation"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#recurrent-activation","aria-hidden":"true"}},[e._v("#")]),e._v(" recurrent_activation")]),e._v(" "),r("h3",{attrs:{id:"recurrent-constraint"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#recurrent-constraint","aria-hidden":"true"}},[e._v("#")]),e._v(" recurrent_constraint")]),e._v(" "),r("h3",{attrs:{id:"recurrent-dropout"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#recurrent-dropout","aria-hidden":"true"}},[e._v("#")]),e._v(" recurrent_dropout")]),e._v(" "),r("h3",{attrs:{id:"recurrent-initializer"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#recurrent-initializer","aria-hidden":"true"}},[e._v("#")]),e._v(" recurrent_initializer")]),e._v(" "),r("h3",{attrs:{id:"recurrent-regularizer"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#recurrent-regularizer","aria-hidden":"true"}},[e._v("#")]),e._v(" recurrent_regularizer")]),e._v(" "),r("h3",{attrs:{id:"states"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#states","aria-hidden":"true"}},[e._v("#")]),e._v(" states")]),e._v(" "),r("h3",{attrs:{id:"unit-forget-bias"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#unit-forget-bias","aria-hidden":"true"}},[e._v("#")]),e._v(" unit_forget_bias")]),e._v(" "),r("h3",{attrs:{id:"units"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#units","aria-hidden":"true"}},[e._v("#")]),e._v(" units")]),e._v(" "),r("h3",{attrs:{id:"use-bias"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#use-bias","aria-hidden":"true"}},[e._v("#")]),e._v(" use_bias")]),e._v(" "),r("h2",{attrs:{id:"methods"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#methods","aria-hidden":"true"}},[e._v("#")]),e._v(" Methods")]),e._v(" "),r("h3",{attrs:{id:"get-initial-state"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#get-initial-state","aria-hidden":"true"}},[e._v("#")]),e._v(" get_initial_state")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/recurrent.py#L593-L614",target:"_blank",rel:"noopener noreferrer"}},[e._v("View source"),r("OutboundLink")],1)]),e._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[e._v(" get_initial_state(inputs)\n")])])]),r("h3",{attrs:{id:"reset-states"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#reset-states","aria-hidden":"true"}},[e._v("#")]),e._v(" reset_states")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/recurrent.py#L806-L858",target:"_blank",rel:"noopener noreferrer"}},[e._v("View source"),r("OutboundLink")],1)]),e._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[e._v(" reset_states(states=None)\n")])])])])}),[],!1,null,null,null);t.default=i.exports}}]);