(window.webpackJsonp=window.webpackJsonp||[]).push([[684],{872:function(e,a,t){"use strict";t.r(a);var n=t(0),s=Object(n.a)({},(function(){var e=this,a=e.$createElement,t=e._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("p",[e._v("Pads a tensor.")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v(" tf.compat.v1.pad(\n    tensor,\n    paddings,\n    mode='CONSTANT',\n    name=None,\n    constant_values=0\n)\n")])])]),t("p",[e._v('This operation pads a tensor according to the paddings you specify. paddings is an integer tensor with shape [n, 2], where n is the rank of tensor. For each dimension D of input, paddings[D, 0] indicates how many values to add before the contents of tensor in that dimension, and paddings[D, 1] indicates how many values to add after the contents of tensor in that dimension. If mode is "REFLECT" then both paddings[D, 0] and paddings[D, 1] must be no greater than tensor.dim_size(D) - 1. If mode is "SYMMETRIC" then both paddings[D, 0] and paddings[D, 1] must be no greater than tensor.dim_size(D).')]),e._v(" "),t("p",[e._v("The padded size of each dimension D of the output is:")]),e._v(" "),t("p",[e._v("paddings[D, 0] + tensor.dim_size(D) + paddings[D, 1]")]),e._v(" "),t("h4",{attrs:{id:"for-example"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#for-example","aria-hidden":"true"}},[e._v("#")]),e._v(" For example:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v(' t = tf.constant([[1, 2, 3], [4, 5, 6]])\npaddings = tf.constant([[1, 1,], [2, 2]])\n# \'constant_values\' is 0.\n# rank of \'t\' is 2.\ntf.pad(t, paddings, "CONSTANT")  # [[0, 0, 0, 0, 0, 0, 0],\n                                 #  [0, 0, 1, 2, 3, 0, 0],\n                                 #  [0, 0, 4, 5, 6, 0, 0],\n                                 #  [0, 0, 0, 0, 0, 0, 0]]\n\ntf.pad(t, paddings, "REFLECT")  # [[6, 5, 4, 5, 6, 5, 4],\n                                #  [3, 2, 1, 2, 3, 2, 1],\n                                #  [6, 5, 4, 5, 6, 5, 4],\n                                #  [3, 2, 1, 2, 3, 2, 1]]\n\ntf.pad(t, paddings, "SYMMETRIC")  # [[2, 1, 1, 2, 3, 3, 2],\n                                  #  [2, 1, 1, 2, 3, 3, 2],\n                                  #  [5, 4, 4, 5, 6, 6, 5],\n                                  #  [5, 4, 4, 5, 6, 6, 5]]\n')])])]),t("h4",{attrs:{id:"args"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),t("ul",[t("li",[t("code",[e._v("tensor")]),e._v(": A "),t("code",[e._v("Tensor")]),e._v(".")]),e._v(" "),t("li",[t("code",[e._v("paddings")]),e._v(": A "),t("code",[e._v("Tensor")]),e._v(" of type "),t("code",[e._v("int32")]),e._v(".")]),e._v(" "),t("li",[t("code",[e._v("mode")]),e._v(': One of "CONSTANT", "REFLECT", or "SYMMETRIC" (case-insensitive)')]),e._v(" "),t("li",[t("code",[e._v("name")]),e._v(": A "),t("code",[e._v("name")]),e._v(" for the operation (optional).")]),e._v(" "),t("li",[t("code",[e._v("constant_values")]),e._v(': In "CONSTANT" '),t("code",[e._v("mode")]),e._v(", the scalar pad value to use. Must be same type as "),t("code",[e._v("tensor")]),e._v(".")])]),e._v(" "),t("h4",{attrs:{id:"returns"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),t("p",[e._v("A Tensor. Has the same type as tensor.")]),e._v(" "),t("h4",{attrs:{id:"raises"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[e._v("#")]),e._v(" Raises:")]),e._v(" "),t("ul",[t("li",[t("code",[e._v("ValueError")]),e._v(': When mode is not one of "CONSTANT", "REFLECT", or "SYMMETRIC".')])])])}),[],!1,null,null,null);a.default=s.exports}}]);