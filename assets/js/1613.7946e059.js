(window.webpackJsonp=window.webpackJsonp||[]).push([[1613],{1804:function(e,t,s){"use strict";s.r(t);var a=s(0),o=Object(a.a)({},(function(){var e=this,t=e.$createElement,s=e._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[s("p",[e._v("Iterates over the time dimension of a tensor.")]),e._v(" "),s("h3",{attrs:{id:"aliases"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[e._v("#")]),e._v(" Aliases:")]),e._v(" "),s("ul",[s("li",[s("code",[e._v("tf.compat.v1.keras.backend.rnn")])]),e._v(" "),s("li",[s("code",[e._v("tf.compat.v2.keras.backend.rnn")])])]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v(" tf.keras.backend.rnn(\n    step_function,\n    inputs,\n    initial_states,\n    go_backwards=False,\n    mask=None,\n    constants=None,\n    unroll=False,\n    input_length=None,\n    time_major=False,\n    zero_output_for_mask=False\n)\n")])])]),s("h4",{attrs:{id:"arguments"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#arguments","aria-hidden":"true"}},[e._v("#")]),e._v(" Arguments:")]),e._v(" "),s("ul",[s("li",[s("code",[e._v("step_function")]),e._v(": RNN step function. Args; input; Tensor with shape ("),s("code",[e._v("samples, ...")]),e._v(") (no time dimension), representing input for the batch of samples at a certain time step. states; List of tensors. Returns; output; Tensor with shape ("),s("code",[e._v("samples, out")]),e._v("put_dim) (no time dimension). new_states; List of tensors, same length and shapes as 'states'. The first state in the list must be the output tensor at the previous timestep.")]),e._v(" "),s("li",[s("code",[e._v("inputs")]),e._v(": Tensor of temporal data of shape ("),s("code",[e._v("samples, tim")]),e._v("e, ...) (at least 3D), or nested tensors, and each of which has shape ("),s("code",[e._v("samples, tim")]),e._v("e, ...).")]),e._v(" "),s("li",[s("code",[e._v("initial_states")]),e._v(": Tensor with shape ("),s("code",[e._v("samples, sta")]),e._v("te_size) (no time dimension), containing the initial values for the states used in the step function. In the case that state_size is in a nested shape, the shape of "),s("code",[e._v("initial_states")]),e._v(" will also follow the nested structure.")]),e._v(" "),s("li",[s("code",[e._v("go_backwards")]),e._v(": Boolean. If True, do the iteration over the time dimension in reverse order and return the reversed sequence.")]),e._v(" "),s("li",[s("code",[e._v("mask")]),e._v(": Binary tensor with shape ("),s("code",[e._v("samples, tim")]),e._v("e, 1), with a zero for every element that is "),s("code",[e._v("mask")]),e._v("ed.")]),e._v(" "),s("li",[s("code",[e._v("constants")]),e._v(": List of constant values passed at each step.")]),e._v(" "),s("li",[s("code",[e._v("unroll")]),e._v(": Whether to "),s("code",[e._v("unroll")]),e._v(" the RNN or to use a symbolic "),s("code",[e._v("while_loop")]),e._v(".")]),e._v(" "),s("li",[s("code",[e._v("input_length")]),e._v(": If specified, assume time dimension is of this length.")]),e._v(" "),s("li",[s("code",[e._v("time_major")]),e._v(": Boolean. If true, the "),s("code",[e._v("inputs")]),e._v(" and outputs will be in shape ("),s("code",[e._v("timesteps, batch, ...")]),e._v("), whereas in the False case, it will be ("),s("code",[e._v("batch, timesteps, ...")]),e._v("). Using "),s("code",[e._v("time_major")]),e._v(" = True is a bit more efficient because it avoids transposes at the beginning and end of the RNN calculation. However, most TensorFlow data is batch-major, so by default this function accepts input and emits output in batch-major form.")]),e._v(" "),s("li",[s("code",[e._v("zero_output_for_mask")]),e._v(": Boolean. If True, the output for "),s("code",[e._v("mask")]),e._v("ed timestep will be zeros, whereas in the False case, output from previous timestep is returned.")])]),e._v(" "),s("h4",{attrs:{id:"returns"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),s("p",[e._v("A tuple, (last_output, outputs, new_states). last_output: the latest output of the rnn, of shape (samples, ...) outputs: tensor with shape (samples, time, ...) where each entry outputs[s, t] is the output of the step function at time t for sample s. new_states: list of tensors, latest states returned by the step function, of shape (samples, ...).")]),e._v(" "),s("h4",{attrs:{id:"raises"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[e._v("#")]),e._v(" Raises:")]),e._v(" "),s("ul",[s("li",[s("code",[e._v("ValueError")]),e._v(": if input dimension is less than 3.")]),e._v(" "),s("li",[s("code",[e._v("ValueError")]),e._v(": if "),s("code",[e._v("unroll")]),e._v(" is "),s("code",[e._v("True")]),e._v(" but input timestep is not a fixed number.")]),e._v(" "),s("li",[s("code",[e._v("ValueError")]),e._v(": if "),s("code",[e._v("mask")]),e._v(" is provided (not "),s("code",[e._v("None")]),e._v(") but states is not provided (len(states) == 0).")])])])}),[],!1,null,null,null);t.default=o.exports}}]);