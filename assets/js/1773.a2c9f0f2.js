(window.webpackJsonp=window.webpackJsonp||[]).push([[1773],{1964:function(e,t,a){"use strict";a.r(t);var i=a(0),n=Object(i.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h2",{attrs:{id:"class-locallyconnected1d"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#class-locallyconnected1d","aria-hidden":"true"}},[e._v("#")]),e._v(" Class LocallyConnected1D")]),e._v(" "),a("p",[e._v("Locally-connected layer for 1D inputs.\n"),a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer",target:"_blank",rel:"noopener noreferrer"}},[e._v("Layer"),a("OutboundLink")],1),e._v("Inherits From:")]),e._v(" "),a("h3",{attrs:{id:"aliases"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[e._v("#")]),e._v(" Aliases:")]),e._v(" "),a("ul",[a("li",[e._v("Class "),a("code",[e._v("tf.compat.v1.keras.layers.LocallyConnected1D")])]),e._v(" "),a("li",[e._v("Class "),a("code",[e._v("tf.compat.v2.keras.layers.LocallyConnected1D")])])]),e._v(" "),a("p",[e._v("The LocallyConnected1D layer works similarly to the Conv1D layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.")]),e._v(" "),a("h4",{attrs:{id:"example"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#example","aria-hidden":"true"}},[e._v("#")]),e._v(" Example:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("     # apply a unshared weight convolution 1d of length 3 to a sequence with\n    # 10 timesteps, with 64 output filters\n    model = Sequential()\n    model.add(LocallyConnected1D(64, 3, input_shape=(10, 32)))\n    # now model.output_shape == (None, 8, 64)\n    # add a new conv1d on top\n    model.add(LocallyConnected1D(32, 3))\n    # now model.output_shape == (None, 6, 32)\n")])])]),a("h4",{attrs:{id:"arguments"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#arguments","aria-hidden":"true"}},[e._v("#")]),e._v(" Arguments:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("filters")]),e._v(": Integer, the dimensionality of the output space (i.e. the number of output "),a("code",[e._v("filters")]),e._v(" in the convolution).")]),e._v(" "),a("li",[a("code",[e._v("kernel_size")]),e._v(": An integer or tuple/list of a single integer, specifying the length of the 1D convolution window.")]),e._v(" "),a("li",[a("code",[e._v("strides")]),e._v(": An integer or tuple/list of a single integer, specifying the stride length of the convolution. Specifying any stride value != 1 is incompatible with specifying any "),a("code",[e._v("dilation_rate")]),e._v(" value != 1.")]),e._v(" "),a("li",[a("code",[e._v("padding")]),e._v(": Currently only supports "),a("code",[e._v('"valid"')]),e._v(" (case-insensitive). "),a("code",[e._v('"same"')]),e._v(" may be supported in the future.")]),e._v(" "),a("li",[a("code",[e._v("data_format")]),e._v(": A string, one of "),a("code",[e._v("channels_last")]),e._v(" (default) or "),a("code",[e._v("channels_first")]),e._v(". The ordering of the dimensions in the inputs. "),a("code",[e._v("channels_last")]),e._v(" corresponds to inputs with shape ("),a("code",[e._v("batch, length, channels")]),e._v(") while "),a("code",[e._v("channels_first")]),e._v(" corresponds to inputs with shape ("),a("code",[e._v("batch, channels, length")]),e._v("). It defaults to the "),a("code",[e._v("image_data_format")]),e._v(" value found in your Keras config file at "),a("code",[e._v("~/.keras/keras.json")]),e._v('. If you never set it, then it will be "'),a("code",[e._v("channels_last")]),e._v('".')]),e._v(" "),a("li",[a("code",[e._v("activation")]),e._v(": Activation function to use. If you don't specify anything, no "),a("code",[e._v("activation")]),e._v(' is applied (ie. "linear" '),a("code",[e._v("activation")]),e._v(": a(x) = x).")]),e._v(" "),a("li",[a("code",[e._v("use_bias")]),e._v(": Boolean, whether the layer uses a bias vector.")]),e._v(" "),a("li",[a("code",[e._v("kernel_initializer")]),e._v(": Initializer for the "),a("code",[e._v("kernel")]),e._v(" weights matrix.")]),e._v(" "),a("li",[a("code",[e._v("bias_initializer")]),e._v(": Initializer for the bias vector.")]),e._v(" "),a("li",[a("code",[e._v("kernel")]),e._v("_regularizer: Regularizer function applied to the "),a("code",[e._v("kernel")]),e._v(" weights matrix.")]),e._v(" "),a("li",[a("code",[e._v("bias_regularizer")]),e._v(": Regularizer function applied to the bias vector.")]),e._v(" "),a("li",[a("code",[e._v("activity_regularizer")]),e._v(': Regularizer function applied to the output of the layer (its "'),a("code",[e._v("activation")]),e._v('")..')]),e._v(" "),a("li",[a("code",[e._v("kernel")]),e._v("_constraint: Constraint function applied to the "),a("code",[e._v("kernel")]),e._v(" matrix.")]),e._v(" "),a("li",[a("code",[e._v("bias_constraint")]),e._v(": Constraint function applied to the bias vector.")]),e._v(" "),a("li",[a("code",[e._v("implementation")]),e._v(": "),a("code",[e._v("implementation")]),e._v(" mode, either "),a("code",[e._v("1")]),e._v(", "),a("code",[e._v("2")]),e._v(", or "),a("code",[e._v("3")]),e._v(". "),a("code",[e._v("1")]),e._v(" loops over input spatial locations to perform the forward pass. It is memory-efficient but performs a lot of (small) ops.\n"),a("code",[e._v("2")]),e._v(" stores layer weights in a dense but sparsely-populated "),a("code",[e._v("2")]),e._v("D matrix and implements the forward pass as a single matrix-multiply. It uses a lot of RAM but performs few (large) ops.\n"),a("code",[e._v("3")]),e._v(" stores layer weights in a sparse tensor and implements the forward pass as a single sparse matrix-multiply.\nHow to choose:\n"),a("code",[e._v("1")]),e._v(": large, dense models, "),a("code",[e._v("2")]),e._v(": small models, "),a("code",[e._v("3")]),e._v(': large, sparse models,\nwhere "large" stands for large input/output '),a("code",[e._v("activation")]),e._v("s (i.e. many "),a("code",[e._v("filters")]),e._v(", "),a("code",[e._v("input_filters")]),e._v(", large "),a("code",[e._v("input_size")]),e._v(", "),a("code",[e._v("output_size")]),e._v('), and "sparse" stands for few connections between inputs and outputs, i.e. small ratio '),a("code",[e._v("filters")]),e._v(" * "),a("code",[e._v("input_filters")]),e._v(" * "),a("code",[e._v("kernel_size")]),e._v(" / ("),a("code",[e._v("input_size")]),e._v(" * "),a("code",[e._v("strides")]),e._v("), where inputs to and outputs of the layer are assumed to have shapes ("),a("code",[e._v("input_size")]),e._v(", "),a("code",[e._v("input_filters")]),e._v("), ("),a("code",[e._v("output_size")]),e._v(", "),a("code",[e._v("filters")]),e._v(") respectively.\nIt is recommended to benchmark each in the setting of interest to pick the most efficient one (in terms of speed and memory usage). Correct choice of "),a("code",[e._v("implementation")]),e._v(" can lead to dramatic speed improvements (e.g. 50X), potentially at the expense of RAM.\nAlso, only "),a("code",[e._v("padding")]),e._v("="),a("code",[e._v('"valid"')]),e._v(" is supported by "),a("code",[e._v("implementation")]),e._v("="),a("code",[e._v("1")]),e._v(".")])]),e._v(" "),a("h4",{attrs:{id:"input-shape"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#input-shape","aria-hidden":"true"}},[e._v("#")]),e._v(" Input shape:")]),e._v(" "),a("p",[e._v("3D tensor with shape: (batch_size, steps, input_dim)")]),e._v(" "),a("h4",{attrs:{id:"output-shape"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#output-shape","aria-hidden":"true"}},[e._v("#")]),e._v(" Output shape:")]),e._v(" "),a("p",[e._v("3D tensor with shape: (batch_size, new_steps, filters) steps value might have changed due to padding or strides.")]),e._v(" "),a("h2",{attrs:{id:"init"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#init","aria-hidden":"true"}},[e._v("#")]),e._v(" "),a("strong",[e._v("init")])]),e._v(" "),a("p",[a("a",{attrs:{href:"https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/local.py#L131-L168",target:"_blank",rel:"noopener noreferrer"}},[e._v("View source"),a("OutboundLink")],1)]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" __init__(\n    filters,\n    kernel_size,\n    strides=1,\n    padding='valid',\n    data_format=None,\n    activation=None,\n    use_bias=True,\n    kernel_initializer='glorot_uniform',\n    bias_initializer='zeros',\n    kernel_regularizer=None,\n    bias_regularizer=None,\n    activity_regularizer=None,\n    kernel_constraint=None,\n    bias_constraint=None,\n    implementation=1,\n    **kwargs\n)\n")])])])])}),[],!1,null,null,null);t.default=n.exports}}]);