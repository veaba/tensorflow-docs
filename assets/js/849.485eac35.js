(window.webpackJsonp=window.webpackJsonp||[]).push([[849],{1037:function(e,n,t){"use strict";t.r(n);var o=t(0),a=Object(o.a)({},(function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("p",[t("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/compat/v1/feature_column/shared_embedding_columns",target:"_blank",rel:"noopener noreferrer"}},[e._v("tf.compat.v1.feature_column.shared_embedding_columns"),t("OutboundLink")],1),e._v("TPU version of .")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v(" tf.compat.v1.tpu.experimental.shared_embedding_columns(\n    categorical_columns,\n    dimension,\n    combiner='mean',\n    initializer=None,\n    shared_embedding_collection_name=None,\n    max_sequence_lengths=None\n)\n")])])]),t("p",[t("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/compat/v1/feature_column/shared_embedding_columns",target:"_blank",rel:"noopener noreferrer"}},[e._v("tf.compat.v1.feature_column.shared_embedding_columns"),t("OutboundLink")],1),e._v("Note that the interface for tf.tpu.experimental.shared_embedding_columns is different from that of : The following arguments are NOT supported: ckpt_to_load_from, tensor_name_in_ckpt, max_norm and trainable.")]),e._v(" "),t("p",[e._v("Use this function in place of tf.compat.v1.feature_column.shared_embedding_columns` when you want to use the TPU to accelerate your embedding lookups via TPU embeddings.")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v(" column_a = tf.feature_column.categorical_column_with_identity(...)\ncolumn_b = tf.feature_column.categorical_column_with_identity(...)\ntpu_columns = tf.tpu.experimental.shared_embedding_columns(\n    [column_a, column_b], 10)\n...\ndef model_fn(features):\n  dense_feature = tf.keras.layers.DenseFeature(tpu_columns)\n  embedded_feature = dense_feature(features)\n  ...\n\nestimator = tf.estimator.tpu.TPUEstimator(\n    model_fn=model_fn,\n    ...\n    embedding_config_spec=tf.estimator.tpu.experimental.EmbeddingConfigSpec(\n        column=tpu_columns,\n        ...))\n")])])]),t("h4",{attrs:{id:"args"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),t("ul",[t("li",[t("code",[e._v("categorical_columns")]),e._v(": A list of categorical columns returned from "),t("code",[e._v("categorical_column_with_identity")]),e._v(", "),t("code",[e._v("weighted_categorical_column")]),e._v(", "),t("code",[e._v("categorical_column_with_vocabulary_file")]),e._v(", "),t("code",[e._v("categorical_column_with_vocabulary_list")]),e._v(", "),t("code",[e._v("sequence_categorical_column_with_identity")]),e._v(", "),t("code",[e._v("sequence_categorical_column_with_vocabulary_file")]),e._v(", "),t("code",[e._v("sequence_categorical_column_with_vocabulary_list")])]),e._v(" "),t("li",[t("code",[e._v("dimension")]),e._v(": An integer specifying "),t("code",[e._v("dimension")]),e._v(" of the embedding, must be > 0.")]),e._v(" "),t("li",[t("code",[e._v("combiner")]),e._v(": A string specifying how to reduce if there are multiple entries in a single row for a non-sequence column. For more information, see "),t("code",[e._v("tf.feature_column.embedding_column")]),e._v(".")]),e._v(" "),t("li",[t("code",[e._v("initializer")]),e._v(": A variable "),t("code",[e._v("initializer")]),e._v(" function to be used in embedding variable initialization. If not specified, defaults to "),t("code",[e._v("tf.truncated_normal_initializer")]),e._v(" with mean "),t("code",[e._v("0.0")]),e._v(" and standard deviation 1/sqrt("),t("code",[e._v("dimension")]),e._v(").")]),e._v(" "),t("li",[t("code",[e._v("shared_embedding_collection_name")]),e._v(": Optional name of the collection where shared embedding weights are added. If not given, a reasonable name will be chosen based on the names of "),t("code",[e._v("categorical_columns")]),e._v(". This is also used in "),t("code",[e._v("variable_scope")]),e._v(" when creating shared embedding weights.")]),e._v(" "),t("li",[t("code",[e._v("max_sequence_lengths")]),e._v(": An list of non-negative integers, either None or empty or the same length as the argument "),t("code",[e._v("categorical_columns")]),e._v(". Entries corresponding to non-sequence columns must be 0 and entries corresponding to sequence columns specify the max sequence length for the column. Any sequence shorter then this will be padded with 0 embeddings and any sequence longer will be truncated.")])]),e._v(" "),t("h4",{attrs:{id:"returns"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),t("p",[e._v("A list of _TPUSharedEmbeddingColumnV2.")]),e._v(" "),t("h4",{attrs:{id:"raises"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[e._v("#")]),e._v(" Raises:")]),e._v(" "),t("ul",[t("li",[t("code",[e._v("ValueError")]),e._v(": if "),t("code",[e._v("dimension")]),e._v(" not > 0.")]),e._v(" "),t("li",[t("code",[e._v("ValueError")]),e._v(": if "),t("code",[e._v("initializer")]),e._v(" is specified but not callable.")]),e._v(" "),t("li",[t("code",[e._v("ValueError")]),e._v(": if "),t("code",[e._v("max_sequence_lengths")]),e._v(" is specified and not the same length as "),t("code",[e._v("categorical_columns")]),e._v(".")]),e._v(" "),t("li",[t("code",[e._v("ValueError")]),e._v(": if "),t("code",[e._v("max_sequence_lengths")]),e._v(" is positive for a non sequence column or 0 for a sequence column.")])])])}),[],!1,null,null,null);n.default=a.exports}}]);