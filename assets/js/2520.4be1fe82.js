(window.webpackJsonp=window.webpackJsonp||[]).push([[2520],{2711:function(e,t,s){"use strict";s.r(t);var a=s(0),n=Object(a.a)({},(function(){var e=this,t=e.$createElement,s=e._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[s("p",[e._v("Computes the Levenshtein distance between sequences.")]),e._v(" "),s("h3",{attrs:{id:"aliases"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[e._v("#")]),e._v(" Aliases:")]),e._v(" "),s("ul",[s("li",[s("code",[e._v("tf.compat.v1.edit_distance")])]),e._v(" "),s("li",[s("code",[e._v("tf.compat.v2.edit_distance")])])]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v(" tf.edit_distance(\n    hypothesis,\n    truth,\n    normalize=True,\n    name='edit_distance'\n)\n")])])]),s("p",[e._v("This operation takes variable-length sequences ("),s("code",[e._v("hypothesis")]),e._v(" and "),s("code",[e._v("truth")]),e._v("), each provided as a "),s("code",[e._v("SparseTensor")]),e._v(", and computes the Levenshtein distance. You can "),s("code",[e._v("normalize")]),e._v(" the edit distance by length of "),s("code",[e._v("truth")]),e._v(" by setting "),s("code",[e._v("normalize")]),e._v(" to true.\nFor example, given the following input:")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v(' # \'hypothesis\' is a tensor of shape `[2, 1]` with variable-length values:\n#   (0,0) = ["a"]\n#   (1,0) = ["b"]\nhypothesis = tf.SparseTensor(\n    [[0, 0, 0],\n     [1, 0, 0]],\n    ["a", "b"],\n    (2, 1, 1))\n\n# \'truth\' is a tensor of shape `[2, 2]` with variable-length values:\n#   (0,0) = []\n#   (0,1) = ["a"]\n#   (1,0) = ["b", "c"]\n#   (1,1) = ["a"]\ntruth = tf.SparseTensor(\n    [[0, 1, 0],\n     [1, 0, 0],\n     [1, 0, 1],\n     [1, 1, 0]],\n    ["a", "b", "c", "a"],\n    (2, 2, 2))\n\nnormalize = True\n')])])]),s("p",[e._v("This operation would return the following:")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v(" # 'output' is a tensor of shape `[2, 2]` with edit distances normalized\n# by 'truth' lengths.\noutput ==> [[inf, 1.0],  # (0,0): no truth, (0,1): no hypothesis\n           [0.5, 1.0]]  # (1,0): addition, (1,1): no hypothesis\n")])])]),s("h4",{attrs:{id:"args"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),s("ul",[s("li",[s("code",[e._v("hypothesis")]),e._v(": A "),s("code",[e._v("SparseTensor")]),e._v(" containing "),s("code",[e._v("hypothesis")]),e._v(" sequences.")]),e._v(" "),s("li",[s("code",[e._v("truth")]),e._v(": A "),s("code",[e._v("SparseTensor")]),e._v(" containing "),s("code",[e._v("truth")]),e._v(" sequences.")]),e._v(" "),s("li",[s("code",[e._v("normalize")]),e._v(": A "),s("code",[e._v("bool")]),e._v(". If "),s("code",[e._v("True")]),e._v(", "),s("code",[e._v("normalize")]),e._v("s the Levenshtein distance by length of "),s("code",[e._v("truth")]),e._v(".")]),e._v(" "),s("li",[s("code",[e._v("name")]),e._v(": A "),s("code",[e._v("name")]),e._v(" for the operation (optional).")])]),e._v(" "),s("h4",{attrs:{id:"returns"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),s("p",[e._v("A dense "),s("code",[e._v("Tensor")]),e._v(" with rank "),s("code",[e._v("R - 1")]),e._v(", where R is the rank of the "),s("code",[e._v("SparseTensor")]),e._v(" inputs "),s("code",[e._v("hypothesis")]),e._v(" and "),s("code",[e._v("truth")]),e._v(".")]),e._v(" "),s("h4",{attrs:{id:"raises"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[e._v("#")]),e._v(" Raises:")]),e._v(" "),s("ul",[s("li",[s("code",[e._v("TypeError")]),e._v(": If either "),s("code",[e._v("hypothesis")]),e._v(" or "),s("code",[e._v("truth")]),e._v(" are not a "),s("code",[e._v("SparseTensor")]),e._v(".")])])])}),[],!1,null,null,null);t.default=n.exports}}]);