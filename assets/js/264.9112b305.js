(window.webpackJsonp=window.webpackJsonp||[]).push([[264],{449:function(e,t,i){"use strict";i.r(t);var r=i(0),a=Object(r.a)({},(function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[i("h2",{attrs:{id:"class-tpuconfig"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#class-tpuconfig","aria-hidden":"true"}},[e._v("#")]),e._v(" Class TPUConfig")]),e._v(" "),i("p",[e._v("TPU related configuration required by TPUEstimator.")]),e._v(" "),i("h4",{attrs:{id:"args"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),i("ul",[i("li",[i("code",[e._v("iterations_per_loop")]),e._v(": This is the number of train "),i("code",[e._v("steps")]),e._v(" running in TPU system before returning to CPU host for each "),i("code",[e._v("Session.run")]),e._v(". This means global step is increased "),i("code",[e._v("iterations_per_loop")]),e._v(" times in one "),i("code",[e._v("Session.run")]),e._v(". It is recommended to be set as number of global "),i("code",[e._v("steps")]),e._v(" for next checkpoint. Note that in evaluation don't use this value, instead we run total eval "),i("code",[e._v("steps")]),e._v(" on TPU for a single "),i("code",[e._v("Session.run")]),e._v(". [Experimental]: "),i("code",[e._v("iterations_per_loop")]),e._v(" can be specified as a time interval. To specify N seconds in one "),i("code",[e._v("Session.run")]),e._v(", one can specify it as "),i("code",[e._v("Ns")]),e._v(" and substitute the N with the N with the number of desired seconds. Alternatively, the unit of time can also be specified in minutes or hours, e.g. "),i("code",[e._v("3600s")]),e._v(" or "),i("code",[e._v("60m")]),e._v(" or "),i("code",[e._v("1h")]),e._v(".")]),e._v(" "),i("li",[i("code",[e._v("num_shards")]),e._v(": (Deprecated, ignored by TPUEstimator). The number of model replicas in the system. For non-model-parallelism case, this number equals the total number of TPU cores. For model-parallelism, the total number of TPU cores equals num_cores_per_replica * "),i("code",[e._v("num_shards")]),e._v(".")]),e._v(" "),i("li",[i("code",[e._v("num_cores_per_replica")]),e._v(": Defaults to "),i("code",[e._v("None")]),e._v(", which disables model parallelism. An integer which describes the number of TPU cores per model replica. This is required by model-parallelism which enables partitioning the model to multiple cores. Currently "),i("code",[e._v("num_cores_per_replica")]),e._v(" must be 1, 2, 4, or 8.")]),e._v(" "),i("li",[i("code",[e._v("per_host_input_for_training")]),e._v(": If "),i("code",[e._v("True")]),e._v(", for "),i("code",[e._v("PER_HOST_V1")]),e._v(", the "),i("code",[e._v("input_fn")]),e._v(" is invoked once on each host, and the number of hosts must be smaller or equal to the number of replicas. For "),i("code",[e._v("PER_HOST_V2")]),e._v(", the "),i("code",[e._v("input_fn")]),e._v(" is invoked once for each host (if the number of hosts is less than the number of replicas) or replica (if the number of replicas is less than the number of hosts. With the per-core input pipeline configuration, it is invoked once for each core. With a global batch size "),i("code",[e._v("train_batch_size")]),e._v(" in "),i("code",[e._v("TPUEstimator")]),e._v(" constructor, the batch size for each shard is "),i("code",[e._v("train_batch_size")]),e._v(" // #hosts in the "),i("code",[e._v("True")]),e._v(" or "),i("code",[e._v("PER_HOST_V1")]),e._v(" mode. In "),i("code",[e._v("PER_HOST_V2")]),e._v(" mode, it is "),i("code",[e._v("train_batch_size")]),e._v(" // #cores. In "),i("code",[e._v("BROADCAST")]),e._v(" mode, "),i("code",[e._v("input_fn")]),e._v(" is only invoked once on host 0 and the tensors are broadcasted to all other replicas. The batch size equals to "),i("code",[e._v("train_batch_size")]),e._v(". With the per-core input pipeline configuration, the shard batch size is also "),i("code",[e._v("train_batch_size")]),e._v(" // #cores. Note: "),i("code",[e._v("per_host_input_for_training")]),e._v("==PER_SHARD_V1 only supports mode.TRAIN.")]),e._v(" "),i("li",[i("code",[e._v("tpu_job_name")]),e._v(": The name of the TPU job. Typically, this name is auto-inferred within "),i("code",[e._v("TPUEstimator")]),e._v(", however when using ClusterSpec propagation in more esoteric cluster configurations, you may need to specify the job name as a string.")]),e._v(" "),i("li",[i("code",[e._v("initial_infeed_sleep_secs")]),e._v(": The number of seconds the infeed thread should wait before enqueueing the first batch. This helps avoid timeouts for models that require a long compilation time.")]),e._v(" "),i("li",[i("code",[e._v("input_partition_dims")]),e._v(": A nested list to describe the partition dims for all the tensors from "),i("code",[e._v("input_fn")]),e._v("(). The structure of "),i("code",[e._v("input_partition_dims")]),e._v(" must match the structure of "),i("code",[e._v("features")]),e._v(" and "),i("code",[e._v("labels")]),e._v(" from "),i("code",[e._v("input_fn")]),e._v("(). The total number of partitions must match "),i("code",[e._v("num_cores_per_replica")]),e._v(". For example, if "),i("code",[e._v("input_fn")]),e._v("() returns two tensors: images with shape [N, H, W, C] and "),i("code",[e._v("labels")]),e._v(" [N]. "),i("code",[e._v("input_partition_dims")]),e._v(" = [[1, 2, 2, 1], "),i("code",[e._v("None")]),e._v("] will split the images to 4 pieces and feed into 4 TPU cores. "),i("code",[e._v("labels")]),e._v(" tensor are directly broadcasted to all the TPU cores since the partition dims is "),i("code",[e._v("None")]),e._v(". Current limitations: This feature is only supported with the "),i("code",[e._v("PER_HOST_V2")]),e._v(" input mode.")]),e._v(" "),i("li",[i("code",[e._v("eval_training_input_configuration")]),e._v(": If "),i("code",[e._v("SLICED")]),e._v(", "),i("code",[e._v("input_fn")]),e._v(" is only invoked once on host 0 and the tensors are broadcasted to all other replicas. Unlike "),i("code",[e._v("per_host_input_for_training")]),e._v("="),i("code",[e._v("BROADCAST")]),e._v(", each replica will only get a slice of the data instead of a whole copy. If "),i("code",[e._v("PER_HOST_V1")]),e._v(", the behaviour is determined by "),i("code",[e._v("per_host_input_for_training")]),e._v(".")]),e._v(" "),i("li",[i("code",[e._v("experimental_host_call_every_n_steps")]),e._v(": Within a training loop, this argument sets how often host calls are performed during training. Host calls will be evaluated every n "),i("code",[e._v("steps")]),e._v(" within a training loop where n is the value of this argument.")])]),e._v(" "),i("h4",{attrs:{id:"raises"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[e._v("#")]),e._v(" Raises:")]),e._v(" "),i("ul",[i("li",[i("code",[e._v("ValueError")]),e._v(": If "),i("code",[e._v("num_cores_per_replica")]),e._v(" is not 1, 2, 4, 8, ..., 128.")])]),e._v(" "),i("h2",{attrs:{id:"new"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#new","aria-hidden":"true"}},[e._v("#")]),e._v(" "),i("strong",[e._v("new")])]),e._v(" "),i("p",[i("a",{attrs:{href:"https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/tpu/tpu_config.py",target:"_blank",rel:"noopener noreferrer"}},[e._v("View source"),i("OutboundLink")],1)]),e._v(" "),i("div",{staticClass:"language- extra-class"},[i("pre",{pre:!0,attrs:{class:"language-text"}},[i("code",[e._v(" @staticmethod\n__new__(\n    cls,\n    iterations_per_loop=2,\n    num_shards=None,\n    num_cores_per_replica=None,\n    per_host_input_for_training=True,\n    tpu_job_name=None,\n    initial_infeed_sleep_secs=None,\n    input_partition_dims=None,\n    eval_training_input_configuration=InputPipelineConfig.PER_HOST_V1,\n    experimental_host_call_every_n_steps=1\n)\n")])])]),i("p",[e._v("Create new instance of TPUConfig(iterations_per_loop, num_shards, num_cores_per_replica, per_host_input_for_training, tpu_job_name, initial_infeed_sleep_secs, input_partition_dims, eval_training_input_configuration, experimental_host_call_every_n_steps)")]),e._v(" "),i("h2",{attrs:{id:"properties"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#properties","aria-hidden":"true"}},[e._v("#")]),e._v(" Properties")]),e._v(" "),i("h3",{attrs:{id:"iterations-per-loop"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#iterations-per-loop","aria-hidden":"true"}},[e._v("#")]),e._v(" iterations_per_loop")]),e._v(" "),i("h3",{attrs:{id:"num-shards"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#num-shards","aria-hidden":"true"}},[e._v("#")]),e._v(" num_shards")]),e._v(" "),i("h3",{attrs:{id:"num-cores-per-replica"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#num-cores-per-replica","aria-hidden":"true"}},[e._v("#")]),e._v(" num_cores_per_replica")]),e._v(" "),i("h3",{attrs:{id:"per-host-input-for-training"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#per-host-input-for-training","aria-hidden":"true"}},[e._v("#")]),e._v(" per_host_input_for_training")]),e._v(" "),i("h3",{attrs:{id:"tpu-job-name"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#tpu-job-name","aria-hidden":"true"}},[e._v("#")]),e._v(" tpu_job_name")]),e._v(" "),i("h3",{attrs:{id:"initial-infeed-sleep-secs"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#initial-infeed-sleep-secs","aria-hidden":"true"}},[e._v("#")]),e._v(" initial_infeed_sleep_secs")]),e._v(" "),i("h3",{attrs:{id:"input-partition-dims"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#input-partition-dims","aria-hidden":"true"}},[e._v("#")]),e._v(" input_partition_dims")]),e._v(" "),i("h3",{attrs:{id:"eval-training-input-configuration"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#eval-training-input-configuration","aria-hidden":"true"}},[e._v("#")]),e._v(" eval_training_input_configuration")]),e._v(" "),i("h3",{attrs:{id:"experimental-host-call-every-n-steps"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#experimental-host-call-every-n-steps","aria-hidden":"true"}},[e._v("#")]),e._v(" experimental_host_call_every_n_steps")])])}),[],!1,null,null,null);t.default=a.exports}}]);