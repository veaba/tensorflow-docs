(window.webpackJsonp=window.webpackJsonp||[]).push([[2358],{2546:function(e,t,a){"use strict";a.r(t);var s=a(0),n=Object(s.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("p",[e._v("Applies softmax to a batched N-D SparseTensor.")]),e._v(" "),a("h3",{attrs:{id:"aliases"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[e._v("#")]),e._v(" Aliases:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("tf.compat.v1.sparse.softmax")])]),e._v(" "),a("li",[a("code",[e._v("tf.compat.v1.sparse_softmax")])]),e._v(" "),a("li",[a("code",[e._v("tf.compat.v2.sparse.softmax")])])]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" tf.sparse.softmax(\n    sp_input,\n    name=None\n)\n")])])]),a("p",[e._v("The inputs represent an N-D SparseTensor with logical shape [..., B, C] (where N >= 2), and with indices sorted in the canonical lexicographic order.\n"),a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/nn/softmax",target:"_blank",rel:"noopener noreferrer"}},[e._v("tf.nn.softmax()"),a("OutboundLink")],1),e._v("This op is equivalent to applying the normal  to each innermost logical submatrix with shape [B, C], but with the catch that the implicitly zero elements do not participate. Specifically, the algorithm is equivalent to:")]),e._v(" "),a("p",[a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/nn/softmax",target:"_blank",rel:"noopener noreferrer"}},[e._v("tf.nn.softmax()"),a("OutboundLink")],1),e._v("(1) Applies  to a densified view of each innermost submatrix with shape [B, C], along the size-C dimension; (2) Masks out the original implicitly-zero locations; (3) Renormalizes the remaining elements.")]),e._v(" "),a("p",[e._v("Hence, the SparseTensor result has exactly the same non-zero indices and shape.")]),e._v(" "),a("h4",{attrs:{id:"example"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#example","aria-hidden":"true"}},[e._v("#")]),e._v(" Example:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" # First batch:\n# [?   e.]\n# [1.  ? ]\n# Second batch:\n# [e   ? ]\n# [e   e ]\nshape = [2, 2, 2]  # 3-D SparseTensor\nvalues = np.asarray([[[0., np.e], [1., 0.]], [[np.e, 0.], [np.e, np.e]]])\nindices = np.vstack(np.where(values)).astype(np.int64).T\n\nresult = tf.sparse.softmax(tf.SparseTensor(indices, values, shape))\n# ...returning a 3-D SparseTensor, equivalent to:\n# [?   1.]     [1    ?]\n# [1.  ? ] and [.5  .5]\n# where ? means implicitly zero.\n")])])]),a("h4",{attrs:{id:"args"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("sp_input")]),e._v(": N-D "),a("code",[e._v("SparseTensor")]),e._v(", where "),a("code",[e._v("N >= 2")]),e._v(".")]),e._v(" "),a("li",[a("code",[e._v("name")]),e._v(": optional "),a("code",[e._v("name")]),e._v(" of the operation.")])]),e._v(" "),a("h4",{attrs:{id:"returns"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("output")]),e._v(": N-D "),a("code",[e._v("SparseTensor")]),e._v(" representing the results.")])])])}),[],!1,null,null,null);t.default=n.exports}}]);