(window.webpackJsonp=window.webpackJsonp||[]).push([[1334],{1525:function(a,t,e){"use strict";e.r(t);var s=e(0),r=Object(s.a)({},(function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[e("p",[a._v("Adjust saturation of RGB images.")]),a._v(" "),e("h3",{attrs:{id:"aliases"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[a._v("#")]),a._v(" Aliases:")]),a._v(" "),e("ul",[e("li",[e("code",[a._v("tf.compat.v1.image.adjust_saturation")])]),a._v(" "),e("li",[e("code",[a._v("tf.compat.v2.image.adjust_saturation")])])]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v(" tf.image.adjust_saturation(\n    image,\n    saturation_factor,\n    name=None\n)\n")])])]),e("p",[a._v("This is a convenience method that converts RGB images to float representation, converts them to HSV, add an offset to the saturation channel, converts back to RGB and then back to the original data type. If several adjustments are chained it is advisable to minimize the number of redundant conversions.")]),a._v(" "),e("p",[a._v("image is an RGB image or images. The image saturation is adjusted by converting the images to HSV and multiplying the saturation (S) channel by saturation_factor and clipping. The images are then converted back to RGB.")]),a._v(" "),e("h4",{attrs:{id:"args"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[a._v("#")]),a._v(" Args:")]),a._v(" "),e("ul",[e("li",[e("code",[a._v("image")]),a._v(": RGB "),e("code",[a._v("image")]),a._v(" or "),e("code",[a._v("image")]),a._v("s. Size of the last dimension must be 3.")]),a._v(" "),e("li",[e("code",[a._v("saturation_factor")]),a._v(": float. Factor to multiply the saturation by.")]),a._v(" "),e("li",[e("code",[a._v("name")]),a._v(": A "),e("code",[a._v("name")]),a._v(" for this operation (optional).")])]),a._v(" "),e("h4",{attrs:{id:"returns"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[a._v("#")]),a._v(" Returns:")]),a._v(" "),e("p",[a._v("Adjusted image(s), same shape and DType as image.")]),a._v(" "),e("h4",{attrs:{id:"usage-example"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#usage-example","aria-hidden":"true"}},[a._v("#")]),a._v(" Usage Example:")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v(" >> import tensorflow as tf\n>> x = tf.random.normal(shape=(256, 256, 3))\n>> tf.image.adjust_saturation(x, 0.5)\n")])])]),e("h4",{attrs:{id:"raises"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[a._v("#")]),a._v(" Raises:")]),a._v(" "),e("ul",[e("li",[e("code",[a._v("InvalidArgumentError")]),a._v(": input must have 3 channels")])])])}),[],!1,null,null,null);t.default=r.exports}}]);