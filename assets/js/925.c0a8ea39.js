(window.webpackJsonp=window.webpackJsonp||[]).push([[925],{1113:function(e,t,a){"use strict";a.r(t);var s=a(0),o=Object(s.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("p",[e._v("Defined in generated file: python/ops/gen_sdca_ops.py")]),e._v(" "),a("p",[e._v("Distributed version of Stochastic Dual Coordinate Ascent (SDCA) optimizer for")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" tf.compat.v1.train.sdca_optimizer(\n    sparse_example_indices,\n    sparse_feature_indices,\n    sparse_feature_values,\n    dense_features,\n    example_weights,\n    example_labels,\n    sparse_indices,\n    sparse_weights,\n    dense_weights,\n    example_state_data,\n    loss_type,\n    l1,\n    l2,\n    num_loss_partitions,\n    num_inner_iterations,\n    adaptative=True,\n    name=None\n)\n")])])]),a("p",[e._v("linear models with L1 + L2 regularization. As global optimization objective is strongly-convex, the optimizer optimizes the dual objective at each step. The optimizer applies each update one example at a time. Examples are sampled uniformly, and the optimizer is learning rate free and enjoys linear convergence rate.\n"),a("a",{attrs:{href:"http://arxiv.org/pdf/1211.2717v1.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Proximal Stochastic Dual Coordinate Ascent"),a("OutboundLink")],1),e._v(".\nShai Shalev-Shwartz, Tong Zhang. 2012")]),e._v(" "),a("p",[a("a",{attrs:{href:"http://arxiv.org/abs/1502.03508",target:"_blank",rel:"noopener noreferrer"}},[e._v("Adding vs. Averaging in Distributed Primal-Dual Optimization"),a("OutboundLink")],1),e._v(".\nChenxin Ma, Virginia Smith, Martin Jaggi, Michael I. Jordan, Peter Richtarik, Martin Takac. 2015")]),e._v(" "),a("p",[a("a",{attrs:{href:"https://arxiv.org/abs/1502.08053",target:"_blank",rel:"noopener noreferrer"}},[e._v("Stochastic Dual Coordinate Ascent with Adaptive Probabilities"),a("OutboundLink")],1),e._v(".\nDominik Csiba, Zheng Qu, Peter Richtarik. 2015")]),e._v(" "),a("h4",{attrs:{id:"args"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("sparse_example_indices")]),e._v(": A list of "),a("code",[e._v("Tensor")]),e._v(" objects with type "),a("code",[e._v("int64")]),e._v(". a list of vectors which contain example indices.")]),e._v(" "),a("li",[a("code",[e._v("sparse_feature_indices")]),e._v(": A list with the same length as "),a("code",[e._v("sparse_example_indices")]),e._v(" of "),a("code",[e._v("Tensor")]),e._v(" objects with type "),a("code",[e._v("int64")]),e._v(". a list of vectors which contain feature indices.")]),e._v(" "),a("li",[a("code",[e._v("sparse_feature_values")]),e._v(": A list of "),a("code",[e._v("Tensor")]),e._v(" objects with type "),a("code",[e._v("float32")]),e._v(". a list of vectors which contains feature value associated with each feature group.")]),e._v(" "),a("li",[a("code",[e._v("dense_features")]),e._v(": A list of "),a("code",[e._v("Tensor")]),e._v(" objects with type "),a("code",[e._v("float32")]),e._v(". a list of matrices which contains the dense feature values.")]),e._v(" "),a("li",[a("code",[e._v("example_weights")]),e._v(": A "),a("code",[e._v("Tensor")]),e._v(" of type "),a("code",[e._v("float32")]),e._v(". a vector which contains the weight associated with each example.")]),e._v(" "),a("li",[a("code",[e._v("example_labels")]),e._v(": A "),a("code",[e._v("Tensor")]),e._v(" of type "),a("code",[e._v("float32")]),e._v(". a vector which contains the label/target associated with each example.")]),e._v(" "),a("li",[a("code",[e._v("sparse_indices")]),e._v(": A list with the same length as "),a("code",[e._v("sparse_example_indices")]),e._v(" of "),a("code",[e._v("Tensor")]),e._v(" objects with type "),a("code",[e._v("int64")]),e._v(". a list of vectors where each value is the indices which has corresponding weights in sparse_weights. This field maybe omitted for the dense approach.")]),e._v(" "),a("li",[a("code",[e._v("sparse_weights")]),e._v(": A list with the same length as "),a("code",[e._v("sparse_example_indices")]),e._v(" of "),a("code",[e._v("Tensor")]),e._v(" objects with type "),a("code",[e._v("float32")]),e._v(". a list of vectors where each value is the weight associated with a sparse feature group.")]),e._v(" "),a("li",[a("code",[e._v("dense_weights")]),e._v(": A list with the same length as "),a("code",[e._v("dense_features")]),e._v(" of "),a("code",[e._v("Tensor")]),e._v(" objects with type "),a("code",[e._v("float32")]),e._v(". a list of vectors where the values are the weights associated with a dense feature group.")]),e._v(" "),a("li",[a("code",[e._v("example_state_data")]),e._v(": A "),a("code",[e._v("Tensor")]),e._v(" of type "),a("code",[e._v("float32")]),e._v(". a list of vectors containing the example state data.")]),e._v(" "),a("li",[a("code",[e._v("loss_type")]),e._v(": A "),a("code",[e._v("string")]),e._v(" from: "),a("code",[e._v('"logistic_loss", "squared_loss", "hinge_loss", "smooth_hinge_loss", "poisson_loss"')]),e._v(". Type of the primal loss. Currently SdcaSolver supports logistic, squared and hinge losses.")]),e._v(" "),a("li",[a("code",[e._v("l1")]),e._v(": A "),a("code",[e._v("float")]),e._v(". Symmetric "),a("code",[e._v("l1")]),e._v(" regularization strength.")]),e._v(" "),a("li",[a("code",[e._v("l2")]),e._v(": A "),a("code",[e._v("float")]),e._v(". Symmetric "),a("code",[e._v("l2")]),e._v(" regularization strength.")]),e._v(" "),a("li",[a("code",[e._v("num_loss_partitions")]),e._v(": An "),a("code",[e._v("int")]),e._v(" that is "),a("code",[e._v(">= 1")]),e._v(". Number of partitions of the global loss function.")]),e._v(" "),a("li",[a("code",[e._v("num_inner_iterations")]),e._v(": An "),a("code",[e._v("int")]),e._v(" that is "),a("code",[e._v(">= 1")]),e._v(". Number of iterations per mini-batch.")]),e._v(" "),a("li",[a("code",[e._v("adaptative")]),e._v(": An optional "),a("code",[e._v("bool")]),e._v(". Defaults to "),a("code",[e._v("True")]),e._v(". Whether to use Adaptive SDCA for the inner loop.")]),e._v(" "),a("li",[a("code",[e._v("name")]),e._v(": A "),a("code",[e._v("name")]),e._v(" for the operation (optional).")])]),e._v(" "),a("h4",{attrs:{id:"returns"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),a("p",[e._v("A tuple of Tensor objects (out_example_state_data, out_delta_sparse_weights, out_delta_dense_weights).")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("out_example_state_data")]),e._v(": A "),a("code",[e._v("Tensor")]),e._v(" of type "),a("code",[e._v("float32")]),e._v(".")]),e._v(" "),a("li",[a("code",[e._v("out_delta_sparse_weights")]),e._v(": A list with the same length as "),a("code",[e._v("sparse_example_indices")]),e._v(" of "),a("code",[e._v("Tensor")]),e._v(" objects with type "),a("code",[e._v("float32")]),e._v(".")]),e._v(" "),a("li",[a("code",[e._v("out_delta_dense_weights")]),e._v(": A list with the same length as "),a("code",[e._v("dense_features")]),e._v(" of "),a("code",[e._v("Tensor")]),e._v(" objects with type "),a("code",[e._v("float32")]),e._v(".")])])])}),[],!1,null,null,null);t.default=o.exports}}]);