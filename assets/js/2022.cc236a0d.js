(window.webpackJsonp=window.webpackJsonp||[]).push([[2022],{2213:function(e,o,r){"use strict";r.r(o);var t=r(0),a=Object(t.a)({},(function(){var e=this,o=e.$createElement,r=e._self._c||o;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[r("p",[e._v("Normalizes tensor along dimension axis using specified norm.")]),e._v(" "),r("h3",{attrs:{id:"aliases"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[e._v("#")]),e._v(" Aliases:")]),e._v(" "),r("ul",[r("li",[r("code",[e._v("tf.compat.v1.linalg.normalize")])]),e._v(" "),r("li",[r("code",[e._v("tf.compat.v2.linalg.normalize")])])]),e._v(" "),r("div",{staticClass:"language- extra-class"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[e._v(" tf.linalg.normalize(\n    tensor,\n    ord='euclidean',\n    axis=None,\n    name=None\n)\n")])])]),r("p",[r("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/norm",target:"_blank",rel:"noopener noreferrer"}},[e._v("tf.linalg.norm"),r("OutboundLink")],1),e._v("This uses  to compute the norm along axis.")]),e._v(" "),r("p",[e._v("This function can compute several different vector norms (the 1-norm, the Euclidean or 2-norm, the inf-norm, and in general the p-norm for p > 0) and matrix norms (Frobenius, 1-norm, 2-norm and inf-norm).")]),e._v(" "),r("h4",{attrs:{id:"args"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),r("ul",[r("li",[r("code",[e._v("tensor")]),e._v(": "),r("code",[e._v("Tensor")]),e._v(" of types "),r("code",[e._v("float32")]),e._v(", "),r("code",[e._v("float64")]),e._v(", "),r("code",[e._v("complex64")]),e._v(", "),r("code",[e._v("complex128")])]),e._v(" "),r("li",[r("code",[e._v("ord")]),e._v(": Order of the norm. Supported values are "),r("code",[e._v("'fro'")]),e._v(", "),r("code",[e._v("'euclidean'")]),e._v(", "),r("code",[e._v("1")]),e._v(", "),r("code",[e._v("2")]),e._v(", "),r("code",[e._v("np.inf")]),e._v(" and any positive real number yielding the corresponding p-norm. Default is "),r("code",[e._v("'euclidean'")]),e._v(" which is equivalent to Frobenius norm if "),r("code",[e._v("tensor")]),e._v(" is a matrix and equivalent to "),r("code",[e._v("2")]),e._v("-norm for vectors. Some restrictions apply: a) The Frobenius norm "),r("code",[e._v("'fro'")]),e._v(" is not defined for vectors, b) If "),r("code",[e._v("axis")]),e._v(" is a "),r("code",[e._v("2")]),e._v("-tuple (matrix norm), only "),r("code",[e._v("'euclidean'")]),e._v(", "),r("code",[e._v("'fro'")]),e._v(", "),r("code",[e._v("1")]),e._v(", "),r("code",[e._v("2")]),e._v(", "),r("code",[e._v("np.inf")]),e._v(" are supported. See the description of "),r("code",[e._v("axis")]),e._v(" on how to compute norms for a batch of vectors or matrices stored in a "),r("code",[e._v("tensor")]),e._v(".")]),e._v(" "),r("li",[r("code",[e._v("axis")]),e._v(": If "),r("code",[e._v("axis")]),e._v(" is "),r("code",[e._v("None")]),e._v(" (the default), the input is considered a vector and a single vector norm is computed over the entire set of values in the "),r("code",[e._v("tensor")]),e._v(", i.e. norm("),r("code",[e._v("tensor")]),e._v(", "),r("code",[e._v("ord")]),e._v("="),r("code",[e._v("ord")]),e._v(") is equivalent to norm(reshape("),r("code",[e._v("tensor")]),e._v(", [-"),r("code",[e._v("1")]),e._v("]), "),r("code",[e._v("ord")]),e._v("="),r("code",[e._v("ord")]),e._v("). If "),r("code",[e._v("axis")]),e._v(" is a Python integer, the input is considered a batch of vectors, and "),r("code",[e._v("axis")]),e._v(" determines the "),r("code",[e._v("axis")]),e._v(" in "),r("code",[e._v("tensor")]),e._v(" over which to compute vector norms. If "),r("code",[e._v("axis")]),e._v(" is a "),r("code",[e._v("2")]),e._v("-tuple of Python integers it is considered a batch of matrices and "),r("code",[e._v("axis")]),e._v(" determines the axes in "),r("code",[e._v("tensor")]),e._v(" over which to compute a matrix norm. Negative indices are supported. Example: If you are passing a "),r("code",[e._v("tensor")]),e._v(" that can be either a matrix or a batch of matrices at runtime, pass "),r("code",[e._v("axis")]),e._v("=[-"),r("code",[e._v("2")]),e._v(",-"),r("code",[e._v("1")]),e._v("] instead of "),r("code",[e._v("axis")]),e._v("="),r("code",[e._v("None")]),e._v(" to make sure that matrix norms are computed.")]),e._v(" "),r("li",[r("code",[e._v("name")]),e._v(": The "),r("code",[e._v("name")]),e._v(" of the op.")])]),e._v(" "),r("h4",{attrs:{id:"returns"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),r("ul",[r("li",[r("code",[e._v("normalized")]),e._v(": A "),r("code",[e._v("normalized")]),e._v(" "),r("code",[e._v("Tensor")]),e._v(" with the same shape as "),r("code",[e._v("tensor")]),e._v(".")]),e._v(" "),r("li",[r("code",[e._v("norm")]),e._v(": The computed "),r("code",[e._v("norm")]),e._v("s with the same shape and dtype "),r("code",[e._v("tensor")]),e._v(" but the final axis is 1 instead. Same as running tf.cast(tf.linalg."),r("code",[e._v("norm")]),e._v("("),r("code",[e._v("tensor")]),e._v(", ord, axis keepdims=True), "),r("code",[e._v("tensor")]),e._v(".dtype).")])]),e._v(" "),r("h4",{attrs:{id:"raises"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[e._v("#")]),e._v(" Raises:")]),e._v(" "),r("ul",[r("li",[r("code",[e._v("ValueError")]),e._v(": If "),r("code",[e._v("ord")]),e._v(" or "),r("code",[e._v("axis")]),e._v(" is invalid.")])])])}),[],!1,null,null,null);o.default=a.exports}}]);