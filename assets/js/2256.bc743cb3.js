(window.webpackJsonp=window.webpackJsonp||[]).push([[2256],{2444:function(a,t,e){"use strict";e.r(t);var n=e(0),i=Object(n.a)({},(function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[e("p",[a._v("Defined in generated file: python/ops/gen_array_ops.py")]),a._v(" "),e("p",[a._v("Fake-quantize the 'inputs' tensor, type float to 'outputs' tensor of same type.")]),a._v(" "),e("h3",{attrs:{id:"aliases"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[a._v("#")]),a._v(" Aliases:")]),a._v(" "),e("ul",[e("li",[e("code",[a._v("tf.compat.v1.fake_quant_with_min_max_args")])]),a._v(" "),e("li",[e("code",[a._v("tf.compat.v1.quantization.fake_quant_with_min_max_args")])]),a._v(" "),e("li",[e("code",[a._v("tf.compat.v2.quantization.fake_quant_with_min_max_args")])])]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v(" tf.quantization.fake_quant_with_min_max_args(\n    inputs,\n    min=-6,\n    max=6,\n    num_bits=8,\n    narrow_range=False,\n    name=None\n)\n")])])]),e("p",[a._v("Attributes [min; max] define the clamping range for the inputs data. inputs values are quantized into the quantization range ([0; 2^num_bits - 1] when narrow_range is false and [1; 2^num_bits - 1] when it is true) and then de-quantized and output as floats in [min; max] interval. num_bits is the bitwidth of the quantization; between 2 and 16, inclusive.")]),a._v(" "),e("p",[a._v("Before quantization, min and max values are adjusted with the following logic. It is suggested to have min <= 0 <= max. If 0 is not in the range of values, the behavior can be unexpected: If 0 < min < max: min_adj = 0 and max_adj = max - min. If min < max < 0: min_adj = min - max and max_adj = 0. If min <= 0 <= max: scale = (max - min) / (2^num_bits - 1), min_adj = scale * round(min / scale) and max_adj = max + min_adj - min.")]),a._v(" "),e("p",[a._v("Quantization is called fake since the output is still in floating point.")]),a._v(" "),e("h4",{attrs:{id:"args"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[a._v("#")]),a._v(" Args:")]),a._v(" "),e("ul",[e("li",[e("code",[a._v("inputs")]),a._v(": A "),e("code",[a._v("Tensor")]),a._v(" of type "),e("code",[a._v("float32")]),a._v(".")]),a._v(" "),e("li",[e("code",[a._v("min")]),a._v(": An optional "),e("code",[a._v("float")]),a._v(". Defaults to "),e("code",[a._v("-6")]),a._v(".")]),a._v(" "),e("li",[e("code",[a._v("max")]),a._v(": An optional "),e("code",[a._v("float")]),a._v(". Defaults to "),e("code",[a._v("6")]),a._v(".")]),a._v(" "),e("li",[e("code",[a._v("num_bits")]),a._v(": An optional "),e("code",[a._v("int")]),a._v(". Defaults to "),e("code",[a._v("8")]),a._v(".")]),a._v(" "),e("li",[e("code",[a._v("narrow_range")]),a._v(": An optional "),e("code",[a._v("bool")]),a._v(". Defaults to "),e("code",[a._v("False")]),a._v(".")]),a._v(" "),e("li",[e("code",[a._v("name")]),a._v(": A "),e("code",[a._v("name")]),a._v(" for the operation (optional).")])]),a._v(" "),e("h4",{attrs:{id:"returns"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[a._v("#")]),a._v(" Returns:")]),a._v(" "),e("p",[a._v("A Tensor of type float32.")])])}),[],!1,null,null,null);t.default=i.exports}}]);