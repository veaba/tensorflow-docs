(window.webpackJsonp=window.webpackJsonp||[]).push([[913],{1101:function(e,t,a){"use strict";a.r(t);var s=a(0),n=Object(s.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("p",[e._v("Runs a list of tensors to conditionally fill a queue to create batches. (deprecated)")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" tf.compat.v1.train.maybe_batch_join(\n    tensors_list,\n    keep_input,\n    batch_size,\n    capacity=32,\n    enqueue_many=False,\n    shapes=None,\n    dynamic_pad=False,\n    allow_smaller_final_batch=False,\n    shared_name=None,\n    name=None\n)\n")])])]),a("p",[e._v("See docstring in batch_join for more details.")]),e._v(" "),a("h4",{attrs:{id:"args"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("tensors_list")]),e._v(": A list of tuples or dictionaries of tensors to enqueue.")]),e._v(" "),a("li",[a("code",[e._v("keep_input")]),e._v(": A "),a("code",[e._v("bool")]),e._v(" Tensor. This tensor controls whether the input is added to the queue or not. If it is a scalar and evaluates "),a("code",[e._v("True")]),e._v(", then "),a("code",[e._v("tensors")]),e._v(" are all added to the queue. If it is a vector and "),a("code",[e._v("enqueue_many")]),e._v(" is "),a("code",[e._v("True")]),e._v(", then each example is added to the queue only if the corresponding value in "),a("code",[e._v("keep_input")]),e._v(" is "),a("code",[e._v("True")]),e._v(". This tensor essentially acts as a filtering mechanism.")]),e._v(" "),a("li",[a("code",[e._v("batch_size")]),e._v(": An integer. The new batch size pulled from the queue.")]),e._v(" "),a("li",[a("code",[e._v("capacity")]),e._v(": An integer. The maximum number of elements in the queue.")]),e._v(" "),a("li",[a("code",[e._v("enqueue_many")]),e._v(": Whether each tensor in "),a("code",[e._v("tensor_list_list")]),e._v(" is a single example.")]),e._v(" "),a("li",[a("code",[e._v("shapes")]),e._v(": (Optional) The "),a("code",[e._v("shapes")]),e._v(" for each example. Defaults to the inferred "),a("code",[e._v("shapes")]),e._v(" for "),a("code",[e._v("tensor_list_list")]),e._v("[i].")]),e._v(" "),a("li",[a("code",[e._v("dynamic_pad")]),e._v(": Boolean. Allow variable dimensions in input "),a("code",[e._v("shapes")]),e._v(". The given dimensions are padded upon dequeue so that "),a("code",[e._v("tensors")]),e._v(" within a batch have the same "),a("code",[e._v("shapes")]),e._v(".")]),e._v(" "),a("li",[a("code",[e._v("allow_smaller_final_batch")]),e._v(": (Optional) Boolean. If "),a("code",[e._v("True")]),e._v(", allow the final batch to be smaller if there are insufficient items left in the queue.")]),e._v(" "),a("li",[a("code",[e._v("shared_name")]),e._v(": (Optional) If set, this queue will be shared under the given name across multiple sessions.")]),e._v(" "),a("li",[a("code",[e._v("name")]),e._v(": (Optional) A "),a("code",[e._v("name")]),e._v(" for the operations.")])]),e._v(" "),a("h4",{attrs:{id:"returns"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),a("p",[e._v("A list or dictionary of tensors with the same number and types as tensors_list[i].")]),e._v(" "),a("h4",{attrs:{id:"raises"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[e._v("#")]),e._v(" Raises:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("ValueError")]),e._v(": If the "),a("code",[e._v("shapes")]),e._v(" are not specified, and cannot be inferred from the elements of "),a("code",[e._v("tensor_list_list")]),e._v(".")])])])}),[],!1,null,null,null);t.default=n.exports}}]);