(window.webpackJsonp=window.webpackJsonp||[]).push([[2191],{2379:function(e,v,_){"use strict";_.r(v);var o=_(0),d=Object(o.a)({},(function(){var e=this,v=e.$createElement,_=e._self._c||v;return _("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[_("p",[e._v("Batch normalization.")]),e._v(" "),_("h3",{attrs:{id:"aliases"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[e._v("#")]),e._v(" Aliases:")]),e._v(" "),_("ul",[_("li",[_("code",[e._v("tf.compat.v1.nn.batch_normalization")])]),e._v(" "),_("li",[_("code",[e._v("tf.compat.v2.nn.batch_normalization")])])]),e._v(" "),_("div",{staticClass:"language- extra-class"},[_("pre",{pre:!0,attrs:{class:"language-text"}},[_("code",[e._v(" tf.nn.batch_normalization(\n    x,\n    mean,\n    variance,\n    offset,\n    scale,\n    variance_epsilon,\n    name=None\n)\n")])])]),_("p",[e._v("Normalizes a tensor by mean and variance, and applies (optionally) a scale γ to it, as well as an offset β:")]),e._v(" "),_("p",[e._v("mean, variance, offset and scale are all expected to be of one of two shapes:")]),e._v(" "),_("ul",[_("li",[e._v("In all generality, they can have the same number of dimensions as the input "),_("code",[e._v("x")]),e._v(", with identical sizes as "),_("code",[e._v("x")]),e._v(" for the dimensions that are not normalized over (the 'depth' dimension(s)), and dimension 1 for the others which are being normalized over. "),_("code",[e._v("mean")]),e._v(" and "),_("code",[e._v("variance")]),e._v(" in this case would typically be the outputs of tf.nn.moments(..., keep_dims=True) during training, or running averages thereof during inference.")]),e._v(" "),_("li",[e._v("In"),_("code",[e._v("``t``h``e`` ``c")]),e._v("ommon"),_("code",[e._v("``c``a")]),e._v("s"),_("code",[e._v("e`` ``w``h``e")]),e._v("r"),_("code",[e._v("e`` ``t``h``e``")]),e._v("'"),_("code",[e._v("d``e``p``t``h")]),e._v("'"),_("code",[e._v("``d``i")]),e._v("m"),_("code",[e._v("e")]),e._v("ns"),_("code",[e._v("i")]),e._v("on"),_("code",[e._v("``i")]),e._v("s"),_("code",[e._v("``t``h``e``")]),e._v("l"),_("code",[e._v("a")]),e._v("s"),_("code",[e._v("t`` ``d``i")]),e._v("m"),_("code",[e._v("e")]),e._v("ns"),_("code",[e._v("i")]),e._v("on"),_("code",[e._v("``i")]),e._v("n"),_("code",[e._v("``t``h``e`` ``i")]),e._v("n"),_("code",[e._v("p")]),e._v("u"),_("code",[e._v("t`` ``t``e")]),e._v("nsor"),_("code",[e._v("``x``,`` ``t``h``e")]),e._v("y"),_("code"),e._v("m"),_("code",[e._v("a")]),e._v("y"),_("code",[e._v("``b``e``")]),e._v("on"),_("code",[e._v("e`` ``d``i")]),e._v("m"),_("code",[e._v("e")]),e._v("ns"),_("code",[e._v("i")]),e._v("on"),_("code",[e._v("a")]),e._v("l"),_("code",[e._v("``t``e")]),e._v("nsors"),_("code"),e._v("of"),_("code",[e._v("``t``h``e``")]),e._v("s"),_("code",[e._v("a")]),e._v("m"),_("code",[e._v("e``")]),e._v("s"),_("code",[e._v("i")]),e._v("z"),_("code",[e._v("e`` ``a")]),e._v("s"),_("code",[e._v("``t``h``e``")]),e._v("'"),_("code",[e._v("d``e``p``t``h")]),e._v("'"),_("code",[e._v("``d``i")]),e._v("m"),_("code",[e._v("e")]),e._v("ns"),_("code",[e._v("i")]),e._v("on."),_("code"),e._v("T"),_("code",[e._v("h``i")]),e._v("s"),_("code",[e._v("``i")]),e._v("s"),_("code",[e._v("``t``h``e`` ``c``a")]),e._v("s"),_("code",[e._v("e``")]),e._v("for"),_("code",[e._v("``e``x``a")]),e._v("m"),_("code",[e._v("p")]),e._v("l"),_("code",[e._v("e``")]),e._v("for"),_("code",[e._v("``t``h``e`` ``c")]),e._v("ommon"),_("code"),e._v("["),_("code",[e._v("b``a``t``c``h``,`` ``d``e``p``t``h")]),e._v("]"),_("code"),e._v("l"),_("code",[e._v("a")]),e._v("you"),_("code",[e._v("t``")]),e._v("of"),_("code"),e._v("fully-"),_("code",[e._v("c")]),e._v("onn"),_("code",[e._v("e``c``t``e``d``")]),e._v("l"),_("code",[e._v("a")]),e._v("y"),_("code",[e._v("e")]),e._v("rs"),_("code",[e._v(",`` ``a")]),e._v("n"),_("code",[e._v("d``")]),e._v("["),_("code",[e._v("b``a``t``c``h``,`` ``h``e``i``g``h``t``,`` ``w``i``d``t``h``,`` ``d``e``p``t``h")]),e._v("]"),_("code"),e._v("for"),_("code",[e._v("``c")]),e._v("onvolu"),_("code",[e._v("t``i")]),e._v("ons."),_("code",[e._v("``mean`` ``a")]),e._v("n"),_("code",[e._v("d`` ``variance`` ``i")]),e._v("n"),_("code",[e._v("``t``h``i")]),e._v("s"),_("code",[e._v("``c``a")]),e._v("s"),_("code",[e._v("e`` ``w")]),e._v("oul"),_("code",[e._v("d`` ``t")]),e._v("y"),_("code",[e._v("p``i``c``a")]),e._v("lly"),_("code",[e._v("``b``e`` ``t``h``e``")]),e._v("ou"),_("code",[e._v("t``p")]),e._v("u"),_("code",[e._v("t")]),e._v("s"),_("code"),e._v("of"),_("code",[e._v("``t")]),e._v("f.nn.mom"),_("code",[e._v("e")]),e._v("n"),_("code",[e._v("t")]),e._v("s(..."),_("code",[e._v(",``")]),e._v("k"),_("code",[e._v("e``e``p")]),e._v("_"),_("code",[e._v("d``i")]),e._v("ms=F"),_("code",[e._v("a")]),e._v("ls"),_("code",[e._v("e")]),e._v(")"),_("code",[e._v("``d")]),e._v("ur"),_("code",[e._v("i")]),e._v("n"),_("code",[e._v("g`` ``t")]),e._v("r"),_("code",[e._v("a``i")]),e._v("n"),_("code",[e._v("i")]),e._v("n"),_("code",[e._v("g``,``")]),e._v("or"),_("code"),e._v("runn"),_("code",[e._v("i")]),e._v("n"),_("code",[e._v("g`` ``a")]),e._v("v"),_("code",[e._v("e")]),e._v("r"),_("code",[e._v("a``g``e")]),e._v("s"),_("code",[e._v("``t``h``e")]),e._v("r"),_("code",[e._v("e")]),e._v("of"),_("code",[e._v("``d")]),e._v("ur"),_("code",[e._v("i")]),e._v("n"),_("code",[e._v("g`` ``i")]),e._v("nf"),_("code",[e._v("e")]),e._v("r"),_("code",[e._v("e")]),e._v("n"),_("code",[e._v("c``e")]),e._v(".\n"),_("a",{attrs:{href:"http://arxiv.org/abs/1502.03167",target:"_blank",rel:"noopener noreferrer"}},[e._v("Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift; S. Ioffe, C. Szegedy"),_("OutboundLink")],1),e._v("See Source: .")])]),e._v(" "),_("h4",{attrs:{id:"args"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),_("ul",[_("li",[_("code",[e._v("x")]),e._v(": Input "),_("code",[e._v("Tensor")]),e._v(" of arbitrary dimensionality.")]),e._v(" "),_("li",[_("code",[e._v("mean")]),e._v(": A "),_("code",[e._v("mean")]),e._v(" "),_("code",[e._v("Tensor")]),e._v(".")]),e._v(" "),_("li",[_("code",[e._v("variance")]),e._v(": A "),_("code",[e._v("variance")]),e._v(" "),_("code",[e._v("Tensor")]),e._v(".")]),e._v(" "),_("li",[_("code",[e._v("offset")]),e._v(": An "),_("code",[e._v("offset")]),e._v(" "),_("code",[e._v("Tensor")]),e._v(", often denoted\nin equations, or None. If present, will be added to the normalized tensor.")]),e._v(" "),_("li",[_("code",[e._v("scale")]),e._v(": A "),_("code",[e._v("scale")]),e._v(" "),_("code",[e._v("Tensor")]),e._v(", often denoted\nin equations, or "),_("code",[e._v("None")]),e._v(". If present, the "),_("code",[e._v("scale")]),e._v(" is applied to the normalized tensor.")]),e._v(" "),_("li",[_("code",[e._v("variance")]),e._v("_epsilon: A small float number to avoid dividing by 0.")]),e._v(" "),_("li",[_("code",[e._v("name")]),e._v(": A "),_("code",[e._v("name")]),e._v(" for this operation (optional).")])]),e._v(" "),_("h4",{attrs:{id:"returns"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),_("p",[e._v("the normalized, scaled, offset tensor.")])])}),[],!1,null,null,null);v.default=d.exports}}]);