(window.webpackJsonp=window.webpackJsonp||[]).push([[459],{648:function(e,v,_){"use strict";_.r(v);var o=_(0),a=Object(o.a)({},(function(){var e=this,v=e.$createElement,_=e._self._c||v;return _("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[_("h2",{attrs:{id:"class-batchnormalization"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#class-batchnormalization","aria-hidden":"true"}},[e._v("#")]),e._v(" Class BatchNormalization")]),e._v(" "),_("p",[e._v("Base class of Batch normalization layer (Ioffe and Szegedy, 2014).")]),e._v(" "),_("p",[e._v("Normalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.")]),e._v(" "),_("h4",{attrs:{id:"arguments"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#arguments","aria-hidden":"true"}},[e._v("#")]),e._v(" Arguments:")]),e._v(" "),_("ul",[_("li",[_("code",[e._v("axis")]),e._v(": Integer, the "),_("code",[e._v("axis")]),e._v(" that should be normalized (typically the features "),_("code",[e._v("axis")]),e._v("). For instance, after a "),_("code",[e._v("Conv2D")]),e._v(" layer with "),_("code",[e._v('data_format="channels_first"')]),e._v(", set "),_("code",[e._v("axis")]),e._v("=1 in "),_("code",[e._v("BatchNormalization")]),e._v(".")]),e._v(" "),_("li",[_("code",[e._v("momentum")]),e._v(": Momentum for the moving average.")]),e._v(" "),_("li",[_("code",[e._v("epsilon")]),e._v(": Small float added to variance to avoid dividing by zero.")]),e._v(" "),_("li",[_("code",[e._v("center")]),e._v(": If True, add offset of "),_("code",[e._v("beta")]),e._v(" to normalized tensor. If False, "),_("code",[e._v("beta")]),e._v(" is ignored.")]),e._v(" "),_("li",[_("code",[e._v("scale")]),e._v(": If True, multiply by "),_("code",[e._v("gamma")]),e._v(". If False, "),_("code",[e._v("gamma")]),e._v(" is not used. When the next layer is linear (also e.g. "),_("code",[e._v("nn.relu")]),e._v("), this can be disabled since the scaling will be done by the next layer.")]),e._v(" "),_("li",[_("code",[e._v("beta")]),e._v("_initializer: Initializer for the "),_("code",[e._v("beta")]),e._v(" weight.")]),e._v(" "),_("li",[_("code",[e._v("gamma")]),e._v("_initializer: Initializer for the "),_("code",[e._v("gamma")]),e._v(" weight.")]),e._v(" "),_("li",[_("code",[e._v("moving_mean_initializer")]),e._v(": Initializer for the moving mean.")]),e._v(" "),_("li",[_("code",[e._v("moving_variance_initializer")]),e._v(": Initializer for the moving variance.")]),e._v(" "),_("li",[_("code",[e._v("beta")]),e._v("_regularizer: Optional regularizer for the "),_("code",[e._v("beta")]),e._v(" weight.")]),e._v(" "),_("li",[_("code",[e._v("gamma")]),e._v("_regularizer: Optional regularizer for the "),_("code",[e._v("gamma")]),e._v(" weight.")]),e._v(" "),_("li",[_("code",[e._v("beta")]),e._v("_constraint: Optional constraint for the "),_("code",[e._v("beta")]),e._v(" weight.")]),e._v(" "),_("li",[_("code",[e._v("gamma")]),e._v("_constraint: Optional constraint for the "),_("code",[e._v("gamma")]),e._v(" weight.")]),e._v(" "),_("li",[_("code",[e._v("renorm")]),e._v(": Whether to use Batch Renormalization (https://arxiv.org/abs/1702.03275). This adds extra variables during training. The inference is the same for either value of this parameter.")]),e._v(" "),_("li",[_("code",[e._v("renorm")]),e._v("_clipping: A "),_("code",[e._v("d")]),e._v("ictiona"),_("code",[e._v("r")]),e._v("y that may map keys '"),_("code",[e._v("r")]),e._v("max', '"),_("code",[e._v("r")]),e._v("min', '"),_("code",[e._v("d")]),e._v("max' to scala"),_("code",[e._v("r")]),e._v(" "),_("code",[e._v("Tensors")]),e._v(" use"),_("code",[e._v("d")]),e._v(" to clip the "),_("code",[e._v("renorm")]),e._v(" co"),_("code",[e._v("r``r")]),e._v("ection. The co"),_("code",[e._v("r``r")]),e._v("ection ("),_("code",[e._v("r, d")]),e._v(") is use"),_("code",[e._v("d")]),e._v(" as co"),_("code",[e._v("r``r")]),e._v("ecte"),_("code",[e._v("d")]),e._v("_value = no"),_("code",[e._v("r")]),e._v("malize"),_("code",[e._v("d")]),e._v("_value * "),_("code",[e._v("r")]),e._v(" + "),_("code",[e._v("d")]),e._v(", with "),_("code",[e._v("r")]),e._v(" clippe"),_("code",[e._v("d")]),e._v(" to ["),_("code",[e._v("r")]),e._v("min, "),_("code",[e._v("r")]),e._v("max], an"),_("code",[e._v("d")]),e._v(" "),_("code",[e._v("d")]),e._v(" to [-"),_("code",[e._v("d")]),e._v("max, "),_("code",[e._v("d")]),e._v("max]. Missing "),_("code",[e._v("r")]),e._v("max, "),_("code",[e._v("r")]),e._v("min, "),_("code",[e._v("d")]),e._v("max a"),_("code",[e._v("r")]),e._v("e set to inf, 0, inf, "),_("code",[e._v("r")]),e._v("espectively.")]),e._v(" "),_("li",[_("code",[e._v("renorm")]),e._v("_"),_("code",[e._v("momentum")]),e._v(": Momentum use"),_("code",[e._v("d")]),e._v(" to up"),_("code",[e._v("d")]),e._v("ate the moving means an"),_("code",[e._v("d")]),e._v(" stan"),_("code",[e._v("d")]),e._v("a"),_("code",[e._v("r``d")]),e._v(" "),_("code",[e._v("d")]),e._v("eviations with "),_("code",[e._v("renorm")]),e._v(". Unlike "),_("code",[e._v("momentum")]),e._v(", this affects t"),_("code",[e._v("r")]),e._v("aining an"),_("code",[e._v("d")]),e._v(" shoul"),_("code",[e._v("d")]),e._v(" be neithe"),_("code",[e._v("r")]),e._v(" too small (which woul"),_("code",[e._v("d")]),e._v(" a"),_("code",[e._v("d``d")]),e._v(" noise) no"),_("code",[e._v("r")]),e._v(" too la"),_("code",[e._v("r")]),e._v("ge (which woul"),_("code",[e._v("d")]),e._v(" give stale estimates). Note that "),_("code",[e._v("momentum")]),e._v(" is still applie"),_("code",[e._v("d")]),e._v(" to get the means an"),_("code",[e._v("d")]),e._v(" va"),_("code",[e._v("r")]),e._v("iances fo"),_("code",[e._v("r")]),e._v(" infe"),_("code",[e._v("r")]),e._v("ence.")]),e._v(" "),_("li",[_("code",[e._v("fused")]),e._v(": if "),_("code",[e._v("True")]),e._v(", use a faste"),_("code",[e._v("r")]),e._v(", "),_("code",[e._v("fused")]),e._v(" implementation, o"),_("code",[e._v("r")]),e._v(" "),_("code",[e._v("r")]),e._v("aise a ValueE"),_("code",[e._v("r``r")]),e._v("o"),_("code",[e._v("r")]),e._v(" if the "),_("code",[e._v("fused")]),e._v(" implementation cannot be use"),_("code",[e._v("d")]),e._v(". If "),_("code",[e._v("None")]),e._v(", use the faste"),_("code",[e._v("r")]),e._v(" implementation if possible. If False, "),_("code",[e._v("d")]),e._v("o not use"),_("code",[e._v("d")]),e._v(" the "),_("code",[e._v("fused")]),e._v(" implementation.")]),e._v(" "),_("li",[_("code",[e._v("trainable")]),e._v(": Boolean, if "),_("code",[e._v("True")]),e._v(" the va"),_("code",[e._v("r")]),e._v("iables will be ma"),_("code",[e._v("r")]),e._v("ke"),_("code",[e._v("d")]),e._v(" as "),_("code",[e._v("trainable")]),e._v(".")]),e._v(" "),_("li",[_("code",[e._v("virtual_batch_size")]),e._v(": An "),_("code",[e._v("int")]),e._v(". By "),_("code",[e._v("d")]),e._v("efault, "),_("code",[e._v("virtual_batch_size")]),e._v(" is "),_("code",[e._v("None")]),e._v(", which means batch no"),_("code",[e._v("r")]),e._v("malization is pe"),_("code",[e._v("r")]),e._v("fo"),_("code",[e._v("r")]),e._v("me"),_("code",[e._v("d")]),e._v(" ac"),_("code",[e._v("r")]),e._v("oss the whole batch. When "),_("code",[e._v("virtual_batch_size")]),e._v(" is not "),_("code",[e._v("None")]),e._v(", instea"),_("code",[e._v("d")]),e._v(" pe"),_("code",[e._v("r")]),e._v("fo"),_("code",[e._v("r")]),e._v('m "Ghost Batch No'),_("code",[e._v("r")]),e._v('malization", which c'),_("code",[e._v("r")]),e._v("eates vi"),_("code",[e._v("r")]),e._v("tual sub-batches which a"),_("code",[e._v("r")]),e._v("e each no"),_("code",[e._v("r")]),e._v("malize"),_("code",[e._v("d")]),e._v(" sepa"),_("code",[e._v("r")]),e._v("ately (with sha"),_("code",[e._v("r")]),e._v("e"),_("code",[e._v("d")]),e._v(" "),_("code",[e._v("gamma")]),e._v(", "),_("code",[e._v("beta")]),e._v(", an"),_("code",[e._v("d")]),e._v(" moving statistics). Must "),_("code",[e._v("d")]),e._v("ivi"),_("code",[e._v("d")]),e._v("e the actual batch size "),_("code",[e._v("d")]),e._v("u"),_("code",[e._v("r")]),e._v("ing execution.")]),e._v(" "),_("li",[_("code",[e._v("adjustment")]),e._v(": A function taking the "),_("code",[e._v("Tensor")]),e._v(" containing the ("),_("code",[e._v("d")]),e._v("ynamic) shape of the input tenso"),_("code",[e._v("r")]),e._v(" an"),_("code",[e._v("d")]),e._v(" "),_("code",[e._v("r")]),e._v("etu"),_("code",[e._v("r")]),e._v("ning a pai"),_("code",[e._v("r")]),e._v(" ("),_("code",[e._v("scale")]),e._v(", bias) to apply to the no"),_("code",[e._v("r")]),e._v("malize"),_("code",[e._v("d")]),e._v(" values (befo"),_("code",[e._v("r")]),e._v("e "),_("code",[e._v("gamma")]),e._v(" an"),_("code",[e._v("d")]),e._v(" "),_("code",[e._v("beta")]),e._v("), only "),_("code",[e._v("d")]),e._v("u"),_("code",[e._v("r")]),e._v("ing t"),_("code",[e._v("r")]),e._v("aining. Fo"),_("code",[e._v("r")]),e._v(" example, if "),_("code",[e._v("axis")]),e._v("==-1, "),_("code",[e._v("adjustment")]),e._v(" = lamb"),_("code",[e._v("d")]),e._v("a shape: ( tf."),_("code",[e._v("r")]),e._v("an"),_("code",[e._v("d")]),e._v("om.unifo"),_("code",[e._v("r")]),e._v("m(shape[-1:], 0.93, 1.07), tf."),_("code",[e._v("r")]),e._v("an"),_("code",[e._v("d")]),e._v("om.unifo"),_("code",[e._v("r")]),e._v("m(shape[-1:], -0.1, 0.1)) will "),_("code",[e._v("scale")]),e._v(" the no"),_("code",[e._v("r")]),e._v("malize"),_("code",[e._v("d")]),e._v(" value by up to 7% up o"),_("code",[e._v("r")]),e._v(" "),_("code",[e._v("d")]),e._v("own, then shift the "),_("code",[e._v("r")]),e._v("esult by up to 0.1 (with in"),_("code",[e._v("d")]),e._v("epen"),_("code",[e._v("d")]),e._v("ent scaling an"),_("code",[e._v("d")]),e._v(" bias fo"),_("code",[e._v("r")]),e._v(" each featu"),_("code",[e._v("r")]),e._v("e but sha"),_("code",[e._v("r")]),e._v("e"),_("code",[e._v("d")]),e._v(" ac"),_("code",[e._v("r")]),e._v("oss all examples), an"),_("code",[e._v("d")]),e._v(" finally apply "),_("code",[e._v("gamma")]),e._v(" an"),_("code",[e._v("d")]),e._v("/o"),_("code",[e._v("r")]),e._v(" "),_("code",[e._v("beta")]),e._v(". If "),_("code",[e._v("None")]),e._v(", no "),_("code",[e._v("adjustment")]),e._v(" is applie"),_("code",[e._v("d")]),e._v(". Cannot be specifie"),_("code",[e._v("d")]),e._v(" if "),_("code",[e._v("virtual_batch_size")]),e._v(" is specifie"),_("code",[e._v("d")]),e._v(".")])]),e._v(" "),_("h4",{attrs:{id:"call-arguments"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#call-arguments","aria-hidden":"true"}},[e._v("#")]),e._v(" Call arguments:")]),e._v(" "),_("ul",[_("li",[_("code",[e._v("inputs")]),e._v(": Input tensor (of any rank).")]),e._v(" "),_("li",[_("code",[e._v("training")]),e._v(": Python boolean indicating whether the layer should behave in "),_("code",[e._v("training")]),e._v(" mode or in inference mode.\n"),_("code",[e._v("training")]),e._v("=True: The layer will normalize its "),_("code",[e._v("inputs")]),e._v(" using the mean and variance of the current batch of "),_("code",[e._v("inputs")]),e._v(".\n"),_("code",[e._v("training")]),e._v("=False: The layer will normalize its "),_("code",[e._v("inputs")]),e._v(" using the mean and variance of its moving statistics, learned during "),_("code",[e._v("training")]),e._v(".")]),e._v(" "),_("li",[_("code",[e._v("training")]),e._v("=True: The layer will normalize its "),_("code",[e._v("inputs")]),e._v(" using the mean and variance of the current batch of "),_("code",[e._v("inputs")]),e._v(".")]),e._v(" "),_("li",[_("code",[e._v("training")]),e._v("=False: The layer will normalize its "),_("code",[e._v("inputs")]),e._v(" using the mean and variance of its moving statistics, learned during "),_("code",[e._v("training")]),e._v(".")])]),e._v(" "),_("h4",{attrs:{id:"input-shape"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#input-shape","aria-hidden":"true"}},[e._v("#")]),e._v(" Input shape:")]),e._v(" "),_("p",[e._v("Arbitrary. Use the keyword argument input_shape (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.")]),e._v(" "),_("h4",{attrs:{id:"output-shape"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#output-shape","aria-hidden":"true"}},[e._v("#")]),e._v(" Output shape:")]),e._v(" "),_("p",[e._v("Same shape as input.")]),e._v(" "),_("h4",{attrs:{id:"references"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#references","aria-hidden":"true"}},[e._v("#")]),e._v(" References:")]),e._v(" "),_("ul",[_("li",[_("code",[e._v("B")]),e._v("a"),_("code",[e._v("t")]),e._v("c"),_("code",[e._v("h")]),e._v(" "),_("code",[e._v("N")]),e._v("o"),_("code",[e._v("r")]),e._v("m"),_("code",[e._v("a")]),e._v("l"),_("code",[e._v("i")]),e._v("z"),_("code",[e._v("a")]),e._v("t"),_("code",[e._v("i")]),e._v("o"),_("code",[e._v("n")]),e._v(":"),_("code"),e._v("A"),_("code",[e._v("c")]),e._v("c"),_("code",[e._v("e")]),e._v("l"),_("code",[e._v("e")]),e._v("r"),_("code",[e._v("a")]),e._v("t"),_("code",[e._v("i")]),e._v("n"),_("code",[e._v("g")]),e._v(" "),_("code",[e._v("D")]),e._v("e"),_("code",[e._v("e")]),e._v("p"),_("code"),e._v("N"),_("code",[e._v("e")]),e._v("t"),_("code",[e._v("w")]),e._v("o"),_("code",[e._v("r")]),e._v("k"),_("code"),e._v("T"),_("code",[e._v("r")]),e._v("a"),_("code",[e._v("i")]),e._v("n"),_("code",[e._v("i")]),e._v("n"),_("code",[e._v("g")]),e._v(" "),_("code",[e._v("b")]),e._v("y"),_("code"),e._v("R"),_("code",[e._v("e")]),e._v("d"),_("code",[e._v("u")]),e._v("c"),_("code",[e._v("i")]),e._v("n"),_("code",[e._v("g")]),e._v(" "),_("code",[e._v("I")]),e._v("n"),_("code",[e._v("t")]),e._v("e"),_("code",[e._v("r")]),e._v("n"),_("code",[e._v("a")]),e._v("l"),_("code"),e._v("C"),_("code",[e._v("o")]),e._v("v"),_("code",[e._v("a")]),e._v("r"),_("code",[e._v("i")]),e._v("a"),_("code",[e._v("t")]),e._v("e"),_("code"),e._v("S"),_("code",[e._v("h")]),e._v("i"),_("code",[e._v("f")]),e._v("t``")])]),e._v(" "),_("p",[e._v("{ {TRAINABLE_ATTRIBUTE_NOTE}}")]),e._v(" "),_("h2",{attrs:{id:"init"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#init","aria-hidden":"true"}},[e._v("#")]),e._v(" "),_("strong",[e._v("init")])]),e._v(" "),_("p",[_("a",{attrs:{href:"https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/normalization.py#L138-L209",target:"_blank",rel:"noopener noreferrer"}},[e._v("View source"),_("OutboundLink")],1)]),e._v(" "),_("div",{staticClass:"language- extra-class"},[_("pre",{pre:!0,attrs:{class:"language-text"}},[_("code",[e._v(" __init__(\n    axis=-1,\n    momentum=0.99,\n    epsilon=0.001,\n    center=True,\n    scale=True,\n    beta_initializer='zeros',\n    gamma_initializer='ones',\n    moving_mean_initializer='zeros',\n    moving_variance_initializer='ones',\n    beta_regularizer=None,\n    gamma_regularizer=None,\n    beta_constraint=None,\n    gamma_constraint=None,\n    renorm=False,\n    renorm_clipping=None,\n    renorm_momentum=0.99,\n    fused=None,\n    trainable=True,\n    virtual_batch_size=None,\n    adjustment=None,\n    name=None,\n    **kwargs\n)\n")])])])])}),[],!1,null,null,null);v.default=a.exports}}]);