(window.webpackJsonp=window.webpackJsonp||[]).push([[1277],{1466:function(a,t,e){"use strict";e.r(t);var s=e(0),o=Object(s.a)({},(function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[e("h2",{attrs:{id:"class-vocabinfo"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#class-vocabinfo","aria-hidden":"true"}},[a._v("#")]),a._v(" Class VocabInfo")]),a._v(" "),e("p",[a._v("Vocabulary information for warm-starting.")]),a._v(" "),e("h3",{attrs:{id:"aliases"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[a._v("#")]),a._v(" Aliases:")]),a._v(" "),e("ul",[e("li",[a._v("Class "),e("code",[a._v("tf.compat.v1.estimator.VocabInfo")])]),a._v(" "),e("li",[a._v("Class "),e("code",[a._v("tf.compat.v1.train.VocabInfo")])]),a._v(" "),e("li",[a._v("Class "),e("code",[a._v("tf.compat.v2.estimator.VocabInfo")]),a._v(" "),e("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/estimator/WarmStartSettings",target:"_blank",rel:"noopener noreferrer"}},[a._v("tf.estimator.WarmStartSettings"),e("OutboundLink")],1),a._v("See  for examples of using VocabInfo to warm-start.")])]),a._v(" "),e("p",[a._v("Args: new_vocab: [Required] A path to the new vocabulary file (used with the model to be trained). new_vocab_size: [Required] An integer indicating how many entries of the new vocabulary will used in training. num_oov_buckets: [Required] An integer indicating how many OOV buckets are associated with the vocabulary. old_vocab: [Required] A path to the old vocabulary file (used with the checkpoint to be warm-started from). old_vocab_size: [Optional] An integer indicating how many entries of the old vocabulary were used in the creation of the checkpoint. If not provided, the entire old vocabulary will be used. backup_initializer: [Optional] A variable initializer used for variables corresponding to new vocabulary entries and OOV. If not provided, these entries will be zero-initialized. axis: [Optional] Denotes what axis the vocabulary corresponds to. The default, 0, corresponds to the most common use case (embeddings or linear weights for binary classification / regression). An axis of 1 could be used for warm-starting output layers with class vocabularies.")]),a._v(" "),e("p",[a._v("Returns: A VocabInfo which represents the vocabulary information for warm-starting.")]),a._v(" "),e("p",[a._v("Raises: ValueError: axis is neither 0 or 1.")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("   Example Usage:\n")])])]),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v("       embeddings_vocab_info = tf.VocabInfo(\n          new_vocab='embeddings_vocab',\n          new_vocab_size=100,\n          num_oov_buckets=1,\n          old_vocab='pretrained_embeddings_vocab',\n          old_vocab_size=10000,\n          backup_initializer=tf.compat.v1.truncated_normal_initializer(\n              mean=0.0, stddev=(1 / math.sqrt(embedding_dim))),\n          axis=0)\n\n      softmax_output_layer_kernel_vocab_info = tf.VocabInfo(\n          new_vocab='class_vocab',\n          new_vocab_size=5,\n          num_oov_buckets=0,  # No OOV for classes.\n          old_vocab='old_class_vocab',\n          old_vocab_size=8,\n          backup_initializer=tf.compat.v1.glorot_uniform_initializer(),\n          axis=1)\n\n      softmax_output_layer_bias_vocab_info = tf.VocabInfo(\n          new_vocab='class_vocab',\n          new_vocab_size=5,\n          num_oov_buckets=0,  # No OOV for classes.\n          old_vocab='old_class_vocab',\n          old_vocab_size=8,\n          backup_initializer=tf.compat.v1.zeros_initializer(),\n          axis=0)\n\n      #Currently, only axis=0 and axis=1 are supported.\n")])])]),e("h2",{attrs:{id:"__new__"}},[e("code",[a._v("__new__")])]),a._v(" "),e("p",[e("a",{attrs:{target:"_blank",href:"https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/training/warm_starting_util.py#L113-L134"}},[a._v("View source")])]),a._v(" "),e("div",{staticClass:"language-python extra-class"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[a._v("@staticmethod")]),a._v("\n__new__"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("\n    cls"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n    new_vocab"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n    new_vocab_size"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n    num_oov_buckets"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n    old_vocab"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n    old_vocab_size"),e("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),e("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n    backup_initializer"),e("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),e("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("None")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n    axis"),e("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),e("p",[a._v("Create new instance of VocabInfo(new_vocab, new_vocab_size, num_oov_buckets, old_vocab, old_vocab_size, backup_initializer, axis)")]),a._v(" "),e("h2",{attrs:{id:"properties"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#properties","aria-hidden":"true"}},[a._v("#")]),a._v(" Properties")]),a._v(" "),e("h3",{attrs:{id:"new-vocab"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#new-vocab","aria-hidden":"true"}},[a._v("#")]),a._v(" new_vocab")]),a._v(" "),e("h3",{attrs:{id:"new-vocab-size"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#new-vocab-size","aria-hidden":"true"}},[a._v("#")]),a._v(" new_vocab_size")]),a._v(" "),e("h3",{attrs:{id:"num-oov-buckets"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#num-oov-buckets","aria-hidden":"true"}},[a._v("#")]),a._v(" num_oov_buckets")]),a._v(" "),e("h3",{attrs:{id:"old-vocab"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#old-vocab","aria-hidden":"true"}},[a._v("#")]),a._v(" old_vocab")]),a._v(" "),e("h3",{attrs:{id:"old-vocab-size"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#old-vocab-size","aria-hidden":"true"}},[a._v("#")]),a._v(" old_vocab_size")]),a._v(" "),e("h3",{attrs:{id:"backup-initializer"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#backup-initializer","aria-hidden":"true"}},[a._v("#")]),a._v(" backup_initializer")]),a._v(" "),e("h3",{attrs:{id:"axis"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#axis","aria-hidden":"true"}},[a._v("#")]),a._v(" axis")])])}),[],!1,null,null,null);t.default=o.exports}}]);