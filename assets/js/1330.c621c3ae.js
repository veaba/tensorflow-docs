(window.webpackJsonp=window.webpackJsonp||[]).push([[1330],{1519:function(a,t,e){"use strict";e.r(t);var s=e(0),n=Object(s.a)({},(function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[e("p",[a._v("Adjust contrast of RGB or grayscale images.")]),a._v(" "),e("h3",{attrs:{id:"aliases"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[a._v("#")]),a._v(" Aliases:")]),a._v(" "),e("ul",[e("li",[e("code",[a._v("tf.compat.v1.image.adjust_contrast")])]),a._v(" "),e("li",[e("code",[a._v("tf.compat.v2.image.adjust_contrast")])])]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v(" tf.image.adjust_contrast(\n    images,\n    contrast_factor\n)\n")])])]),e("p",[a._v("This is a convenience method that converts RGB images to float representation, adjusts their contrast, and then converts them back to the original data type. If several adjustments are chained, it is advisable to minimize the number of redundant conversions.")]),a._v(" "),e("p",[a._v("images is a tensor of at least 3 dimensions. The last 3 dimensions are interpreted as [height, width, channels]. The other dimensions only represent a collection of images, such as [batch, height, width, channels].")]),a._v(" "),e("p",[a._v("Contrast is adjusted independently for each channel of each image.")]),a._v(" "),e("p",[a._v("For each channel, this Op computes the mean of the image pixels in the channel and then adjusts each component x of each pixel to (x - mean) * contrast_factor + mean.")]),a._v(" "),e("h4",{attrs:{id:"args"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[a._v("#")]),a._v(" Args:")]),a._v(" "),e("ul",[e("li",[e("code",[a._v("images")]),a._v(": Images to adjust. At least 3-D.")]),a._v(" "),e("li",[e("code",[a._v("contrast_factor")]),a._v(": A float multiplier for adjusting contrast.")])]),a._v(" "),e("h4",{attrs:{id:"returns"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[a._v("#")]),a._v(" Returns:")]),a._v(" "),e("p",[a._v("The contrast-adjusted image or images.")]),a._v(" "),e("h4",{attrs:{id:"usage-example"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#usage-example","aria-hidden":"true"}},[a._v("#")]),a._v(" Usage Example:")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[a._v(" import tensorflow as tf\nx = tf.random.normal(shape=(256, 256, 3))\ntf.image.adjust_contrast(x,2)\n")])])])])}),[],!1,null,null,null);t.default=n.exports}}]);