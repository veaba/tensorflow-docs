(window.webpackJsonp=window.webpackJsonp||[]).push([[2224],{2412:function(t,e,o){"use strict";o.r(e);var s=o(0),a=Object(s.a)({},(function(){var t=this,e=t.$createElement,o=t._self._c||e;return o("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[o("p",[t._v("Computes log Poisson loss given log_input.")]),t._v(" "),o("h3",{attrs:{id:"aliases"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[t._v("#")]),t._v(" Aliases:")]),t._v(" "),o("ul",[o("li",[o("code",[t._v("tf.compat.v1.nn.log_poisson_loss")])]),t._v(" "),o("li",[o("code",[t._v("tf.compat.v2.nn.log_poisson_loss")])])]),t._v(" "),o("div",{staticClass:"language- extra-class"},[o("pre",{pre:!0,attrs:{class:"language-text"}},[o("code",[t._v(" tf.nn.log_poisson_loss(\n    targets,\n    log_input,\n    compute_full_loss=False,\n    name=None\n)\n")])])]),o("p",[t._v("Gives the log-likelihood loss between the prediction and the target under the assumption that the target has a Poisson distribution. Caveat: By default, this is not the exact loss, but the loss minus a constant term [log(z!)]. That has no effect for optimization, but does not play well with relative loss comparisons. To compute an approximation of the log factorial term, specify compute_full_loss=True to enable Stirling's Approximation.")]),t._v(" "),o("p",[t._v("For brevity, let c = log(x) = log_input, z = targets. The log Poisson loss is")]),t._v(" "),o("div",{staticClass:"language- extra-class"},[o("pre",{pre:!0,attrs:{class:"language-text"}},[o("code",[t._v("   -log(exp(-x) * (x^z) / z!)\n= -log(exp(-x) * (x^z)) + log(z!)\n~ -log(exp(-x)) - log(x^z) [+ z * log(z) - z + 0.5 * log(2 * pi * z)]\n    [ Note the second term is the Stirling's Approximation for log(z!).\n      It is invariant to x and does not affect optimization, though\n      important for correct relative loss comparisons. It is only\n      computed when compute_full_loss == True. ]\n= x - z * log(x) [+ z * log(z) - z + 0.5 * log(2 * pi * z)]\n= exp(c) - z * c [+ z * log(z) - z + 0.5 * log(2 * pi * z)]\n")])])]),o("h4",{attrs:{id:"args"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[t._v("#")]),t._v(" Args:")]),t._v(" "),o("ul",[o("li",[o("code",[t._v("targets")]),t._v(": A "),o("code",[t._v("Tensor")]),t._v(" of the same type and shape as "),o("code",[t._v("log_input")]),t._v(".")]),t._v(" "),o("li",[o("code",[t._v("log_input")]),t._v(": A "),o("code",[t._v("Tensor")]),t._v(" of type "),o("code",[t._v("float32")]),t._v(" or "),o("code",[t._v("float64")]),t._v(".")]),t._v(" "),o("li",[o("code",[t._v("compute_full_loss")]),t._v(": whether to compute the full loss. If false, a constant term is dropped in favor of more efficient optimization.")]),t._v(" "),o("li",[o("code",[t._v("name")]),t._v(": A "),o("code",[t._v("name")]),t._v(" for the operation (optional).")])]),t._v(" "),o("h4",{attrs:{id:"returns"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[t._v("#")]),t._v(" Returns:")]),t._v(" "),o("p",[t._v("A Tensor of the same shape as log_input with the componentwise logistic losses.")]),t._v(" "),o("h4",{attrs:{id:"raises"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[t._v("#")]),t._v(" Raises:")]),t._v(" "),o("ul",[o("li",[o("code",[t._v("ValueError")]),t._v(": If "),o("code",[t._v("log_input")]),t._v(" and "),o("code",[t._v("targets")]),t._v(" do not have the same shape.")])])])}),[],!1,null,null,null);e.default=a.exports}}]);