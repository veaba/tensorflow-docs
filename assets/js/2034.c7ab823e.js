(window.webpackJsonp=window.webpackJsonp||[]).push([[2034],{2662:function(e,a,t){"use strict";t.r(a);var s=t(0),i=Object(s.a)({},(function(){var e=this,a=e.$createElement,t=e._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("p",[e._v("Solves tridiagonal systems of equations.")]),e._v(" "),t("h3",{attrs:{id:"aliases"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[e._v("#")]),e._v(" Aliases:")]),e._v(" "),t("ul",[t("li",[t("code",[e._v("tf.compat.v1.linalg.tridiagonal_solve")])]),e._v(" "),t("li",[t("code",[e._v("tf.compat.v2.linalg.tridiagonal_solve")])])]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v(" tf.linalg.tridiagonal_solve(\n    diagonals,\n    rhs,\n    diagonals_format='compact',\n    transpose_rhs=False,\n    conjugate_rhs=False,\n    name=None,\n    partial_pivoting=True\n)\n")])])]),t("p",[e._v("The input can be supplied in various formats: matrix, sequence and compact, specified by the diagonals_format arg.")]),e._v(" "),t("p",[e._v("In matrix format, diagonals must be a tensor of shape [..., M, M], with two inner-most dimensions representing the square tridiagonal matrices. Elements outside of the three diagonals will be ignored.")]),e._v(" "),t("p",[e._v("In sequence format, diagonals are supplied as a tuple or list of three tensors of shapes [..., N], [..., M], [..., N] representing superdiagonals, diagonals, and subdiagonals, respectively. N can be either M-1 or M; in the latter case, the last element of superdiagonal and the first element of subdiagonal will be ignored.")]),e._v(" "),t("p",[e._v("In compact format the three diagonals are brought together into one tensor of shape [..., 3, M], with last two dimensions containing superdiagonals, diagonals, and subdiagonals, in order. Similarly to sequence format, elements diagonals[..., 0, M-1] and diagonals[..., 2, 0] are ignored.\n"),t("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/gather_nd",target:"_blank",rel:"noopener noreferrer"}},[e._v("tf.gather_nd"),t("OutboundLink")],1),e._v("The compact format is recommended as the one with best performance. In case you need to cast a tensor into a compact format manually, use . An example for a tensor of shape [m, m]:")]),e._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v(" rhs = tf.constant([...])\nmatrix = tf.constant([[...]])\nm = matrix.shape[0]\ndummy_idx = [0, 0]  # An arbitrary element to use as a dummy\nindices = [[[i, i + 1] for i in range(m - 1)] + [dummy_idx],  # Superdiagonal\n         [[i, i] for i in range(m)],                          # Diagonal\n         [dummy_idx] + [[i + 1, i] for i in range(m - 1)]]    # Subdiagonal\ndiagonals=tf.gather_nd(matrix, indices)\nx = tf.linalg.tridiagonal_solve(diagonals, rhs)\n")])])]),t("p",[e._v("Regardless of the diagonals_format, rhs is a tensor of shape [..., M] or [..., M, K]. The latter allows to simultaneously solve K systems with the same left-hand sides and K different right-hand sides. If transpose_rhs is set to True the expected shape is [..., M] or [..., K, M].")]),e._v(" "),t("p",[e._v("The batch dimensions, denoted as ..., must be the same in diagonals and rhs.")]),e._v(" "),t("p",[e._v("The output is a tensor of the same shape as rhs: either [..., M] or [..., M, K].\n"),t("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/debugging/check_numerics",target:"_blank",rel:"noopener noreferrer"}},[e._v("tf.debugging.check_numerics"),t("OutboundLink")],1),e._v("The op isn't guaranteed to raise an error if the input matrix is not invertible.  can be applied to the output to detect invertibility problems.")]),e._v(" "),t("p",[e._v("Note: with large batch sizes, the computation on the GPU may be slow, if either partial_pivoting=True or there are multiple right-hand sides (K > 1). If this issue arises, consider if it's possible to disable pivoting and have K = 1, or, alternatively, consider using CPU.")]),e._v(" "),t("p",[e._v("On CPU, solution is computed via Gaussian elimination with or without partial pivoting, depending on partial_pivoting parameter. On GPU, Nvidia's cuSPARSE library is used: https://docs.nvidia.com/cuda/cusparse/index.html#gtsv")]),e._v(" "),t("h4",{attrs:{id:"args"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),t("ul",[t("li",[t("code",[e._v("diagonals")]),e._v(": A "),t("code",[e._v("Tensor")]),e._v(" or tuple of "),t("code",[e._v("Tensor")]),e._v("s describing left-hand sides. The shape depends of "),t("code",[e._v("diagonals")]),e._v("_format, see description above. Must be "),t("code",[e._v("float32")]),e._v(", "),t("code",[e._v("float64")]),e._v(", "),t("code",[e._v("complex64")]),e._v(", or "),t("code",[e._v("complex128")]),e._v(".")]),e._v(" "),t("li",[t("code",[e._v("rhs")]),e._v(": A "),t("code",[e._v("Tensor")]),e._v(" of shape [..., M] or [..., M, K] and with the same dtype as "),t("code",[e._v("diagonals")]),e._v(".")]),e._v(" "),t("li",[t("code",[e._v("diagonals")]),e._v("_format: one of "),t("code",[e._v("matrix")]),e._v(", "),t("code",[e._v("sequence")]),e._v(", or "),t("code",[e._v("compact")]),e._v(". Default is "),t("code",[e._v("compact")]),e._v(".")]),e._v(" "),t("li",[t("code",[e._v("transpose_rhs")]),e._v(": If "),t("code",[e._v("True")]),e._v(", "),t("code",[e._v("rhs")]),e._v(" is transposed before solving (has no effect if the shape of "),t("code",[e._v("rhs")]),e._v(" is [..., M]).")]),e._v(" "),t("li",[t("code",[e._v("conjugate_rhs")]),e._v(": If "),t("code",[e._v("True")]),e._v(", "),t("code",[e._v("rhs")]),e._v(" is conjugated before solving.")]),e._v(" "),t("li",[t("code",[e._v("name")]),e._v(": A "),t("code",[e._v("name")]),e._v(" to give this "),t("code",[e._v("Op")]),e._v(" (optional).")]),e._v(" "),t("li",[t("code",[e._v("partial_pivoting")]),e._v(": whether to perform partial pivoting. "),t("code",[e._v("True")]),e._v(" by default. Partial pivoting makes the procedure more stable, but slower. Partial pivoting is unnecessary in some cases, including diagonally dominant and symmetric positive definite matrices (see e.g. theorem 9.12 in [1]).")])]),e._v(" "),t("h4",{attrs:{id:"returns"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),t("p",[e._v("A Tensor of shape [..., M] or [..., M, K] containing the solutions.")]),e._v(" "),t("h4",{attrs:{id:"raises"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[e._v("#")]),e._v(" Raises:")]),e._v(" "),t("ul",[t("li",[t("code",[e._v("ValueError")]),e._v(": An unsupported type is provided as input, or when the input tensors have incorrect shapes.")])]),e._v(" "),t("p",[e._v("[1] Nicholas J. Higham (2002). Accuracy and Stability of Numerical Algorithms: Second Edition. SIAM. p. 175. ISBN 978-0-89871-802-7.")])])}),[],!1,null,null,null);a.default=i.exports}}]);