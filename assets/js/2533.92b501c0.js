(window.webpackJsonp=window.webpackJsonp||[]).push([[2533],{2724:function(a,e,s){"use strict";s.r(e);var n=s(0),t=Object(n.a)({},(function(){var a=this,e=a.$createElement,s=a._self._c||e;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("p",[a._v("Gather slices from "),s("code",[a._v("params")]),a._v(" into a Tensor with shape specified by "),s("code",[a._v("indices")]),a._v(".")]),a._v(" "),s("h3",{attrs:{id:"aliases"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[a._v("#")]),a._v(" Aliases:")]),a._v(" "),s("ul",[s("li",[s("code",[a._v("tf.compat.v2.gather_nd")])])]),a._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[a._v(" tf.gather_nd(\n    params,\n    indices,\n    batch_dims=0,\n    name=None\n)\n")])])]),s("p",[s("code",[a._v("indices")]),a._v(" is an K-dimensional integer tensor, best thought of as a (K-1)-dimensional tensor of "),s("code",[a._v("indices")]),a._v(" into "),s("code",[a._v("params")]),a._v(", where each element defines a slice of "),s("code",[a._v("params")]),a._v(":")]),a._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[a._v(" output[\\\\(i_0, ..., i_{K-2}\\\\)] = params[indices[\\\\(i_0, ..., i_{K-2}\\\\)]]\n")])])]),s("p",[s("a",{attrs:{href:"https://tensorflow.google.cn/api_docs/python/tf/gather",target:"_blank",rel:"noopener noreferrer"}},[a._v("tf.gather"),s("OutboundLink")],1),a._v("Whereas in  indices defines slices into the first dimension of params, in _nd, indices defines slices into the first N dimensions of params, where N = indices.shape[-1].")]),a._v(" "),s("p",[a._v("The last dimension of "),s("code",[a._v("indices")]),a._v(" can be at most the rank of "),s("code",[a._v("params")]),a._v(":")]),a._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[a._v(" indices.shape[-1] <= params.rank\n")])])]),s("p",[a._v("The last dimension of "),s("code",[a._v("indices")]),a._v(" corresponds to elements (if "),s("code",[a._v("indices")]),a._v(".shape[-1] == "),s("code",[a._v("params")]),a._v(".rank) or slices (if "),s("code",[a._v("indices")]),a._v(".shape[-1] < "),s("code",[a._v("params")]),a._v(".rank) along dimension "),s("code",[a._v("indices")]),a._v(".shape[-1] of "),s("code",[a._v("params")]),a._v(". The output tensor has shape")]),a._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[a._v(" indices.shape[:-1] + params.shape[indices.shape[-1]:]\n")])])]),s("p",[a._v("Additionally both 'params' and 'indices' can have M leading batch dimensions that exactly match. In this case 'batch_dims' must be M.\nNote that on CPU, if an out of bound index is found, an error is returned. On GPU, if an out of bound index is found, a 0 is stored in the corresponding output value.\nSome examples below.\nSimple indexing into a matrix:")]),a._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[a._v("     indices = [[0, 0], [1, 1]]\n    params = [['a', 'b'], ['c', 'd']]\n    output = ['a', 'd']\n")])])]),s("p",[a._v("Slice indexing into a matrix:")]),a._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[a._v("     indices = [[1], [0]]\n    params = [['a', 'b'], ['c', 'd']]\n    output = [['c', 'd'], ['a', 'b']]\n")])])]),s("p",[a._v("Indexing into a 3-tensor:")]),a._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[a._v("     indices = [[1]]\n    params = [[['a0', 'b0'], ['c0', 'd0']],\n              [['a1', 'b1'], ['c1', 'd1']]]\n    output = [[['a1', 'b1'], ['c1', 'd1']]]\n\n\n    indices = [[0, 1], [1, 0]]\n    params = [[['a0', 'b0'], ['c0', 'd0']],\n              [['a1', 'b1'], ['c1', 'd1']]]\n    output = [['c0', 'd0'], ['a1', 'b1']]\n\n\n    indices = [[0, 0, 1], [1, 0, 1]]\n    params = [[['a0', 'b0'], ['c0', 'd0']],\n              [['a1', 'b1'], ['c1', 'd1']]]\n    output = ['b0', 'b1']\n")])])]),s("p",[a._v("The examples below are for the case when only indices have leading extra dimensions. If both 'params' and 'indices' have leading batch dimensions, use the 'batch_dims' parameter to run gather_nd in batch mode.\nBatched indexing into a matrix:")]),a._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[a._v("     indices = [[[0, 0]], [[0, 1]]]\n    params = [['a', 'b'], ['c', 'd']]\n    output = [['a'], ['b']]\n")])])]),s("p",[a._v("Batched slice indexing into a matrix:")]),a._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[a._v("     indices = [[[1]], [[0]]]\n    params = [['a', 'b'], ['c', 'd']]\n    output = [[['c', 'd']], [['a', 'b']]]\n")])])]),s("p",[a._v("Batched indexing into a 3-tensor:")]),a._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[a._v("     indices = [[[1]], [[0]]]\n    params = [[['a0', 'b0'], ['c0', 'd0']],\n              [['a1', 'b1'], ['c1', 'd1']]]\n    output = [[[['a1', 'b1'], ['c1', 'd1']]],\n              [[['a0', 'b0'], ['c0', 'd0']]]]\n\n    indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]]\n    params = [[['a0', 'b0'], ['c0', 'd0']],\n              [['a1', 'b1'], ['c1', 'd1']]]\n    output = [[['c0', 'd0'], ['a1', 'b1']],\n              [['a0', 'b0'], ['c1', 'd1']]]\n\n\n    indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]]\n    params = [[['a0', 'b0'], ['c0', 'd0']],\n              [['a1', 'b1'], ['c1', 'd1']]]\n    output = [['b0', 'b1'], ['d0', 'c1']]\n")])])]),s("p",[a._v("Examples with batched 'params' and 'indices':")]),a._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[a._v("     batch_dims = 1\n    indices = [[1], [0]]\n    params = [[['a0', 'b0'], ['c0', 'd0']],\n              [['a1', 'b1'], ['c1', 'd1']]]\n    output = [['c0', 'd0'], ['a1', 'b1']]\n\n    batch_dims = 1\n    indices = [[[1]], [[0]]]\n    params = [[['a0', 'b0'], ['c0', 'd0']],\n              [['a1', 'b1'], ['c1', 'd1']]]\n    output = [[['c0', 'd0']], [['a1', 'b1']]]\n\n    batch_dims = 1\n    indices = [[[1, 0]], [[0, 1]]]\n    params = [[['a0', 'b0'], ['c0', 'd0']],\n              [['a1', 'b1'], ['c1', 'd1']]]\n    output = [['c0'], ['b1']]\n")])])]),s("p",[s("a",{attrs:{href:"https://tensorflow.google.cn/api_docs/python/tf/gather",target:"_blank",rel:"noopener noreferrer"}},[a._v("tf.gather"),s("OutboundLink")],1),a._v("See also .")]),a._v(" "),s("h4",{attrs:{id:"args"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[a._v("#")]),a._v(" Args:")]),a._v(" "),s("ul",[s("li",[s("code",[a._v("params")]),a._v(": A "),s("code",[a._v("Tensor")]),a._v(". The tensor from which to gather values.")]),a._v(" "),s("li",[s("code",[a._v("indices")]),a._v(": A "),s("code",[a._v("Tensor")]),a._v(". Must be one of the following types: "),s("code",[a._v("int32")]),a._v(", "),s("code",[a._v("int64")]),a._v(". Index tensor.")]),a._v(" "),s("li",[s("code",[a._v("name")]),a._v(": A "),s("code",[a._v("name")]),a._v(" for the operation (optional).")]),a._v(" "),s("li",[s("code",[a._v("batch_dims")]),a._v(": An integer or a scalar '"),s("code",[a._v("Tensor")]),a._v("'. The number of batch dimensions.")])]),a._v(" "),s("h4",{attrs:{id:"returns"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[a._v("#")]),a._v(" Returns:")]),a._v(" "),s("p",[a._v("A "),s("code",[a._v("Tensor")]),a._v(". Has the same type as "),s("code",[a._v("params")]),a._v(".")])])}),[],!1,null,null,null);e.default=t.exports}}]);