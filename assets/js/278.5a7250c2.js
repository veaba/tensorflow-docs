(window.webpackJsonp=window.webpackJsonp||[]).push([[278],{466:function(e,a,o){"use strict";o.r(a);var i=o(0),n=Object(i.a)({},(function(){var e=this,a=e.$createElement,o=e._self._c||a;return o("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[o("p",[e._v("List of dense columns that convert from sparse, categorical input.")]),e._v(" "),o("div",{staticClass:"language- extra-class"},[o("pre",{pre:!0,attrs:{class:"language-text"}},[o("code",[e._v(" tf.compat.v1.feature_column.shared_embedding_columns(\n    categorical_columns,\n    dimension,\n    combiner='mean',\n    initializer=None,\n    shared_embedding_collection_name=None,\n    ckpt_to_load_from=None,\n    tensor_name_in_ckpt=None,\n    max_norm=None,\n    trainable=True\n)\n")])])]),o("p",[e._v("This is similar to embedding_column, except that it produces a list of embedding columns that share the same embedding weights.")]),e._v(" "),o("p",[e._v("Use this when your inputs are sparse and of the same type (e.g. watched and impression video IDs that share the same vocabulary), and you want to convert them to a dense representation (e.g., to feed to a DNN).")]),e._v(" "),o("p",[e._v("Inputs must be a list of categorical columns created by any of the categorical_column_* function. They must all be of the same type and have the same arguments except key. E.g. they can be categorical_column_with_vocabulary_file with the same vocabulary_file. Some or all columns could also be weighted_categorical_column.")]),e._v(" "),o("p",[e._v("Here is an example embedding of two features for a DNNClassifier model:")]),e._v(" "),o("div",{staticClass:"language- extra-class"},[o("pre",{pre:!0,attrs:{class:"language-text"}},[o("code",[e._v(" watched_video_id = categorical_column_with_vocabulary_file(\n    'watched_video_id', video_vocabulary_file, video_vocabulary_size)\nimpression_video_id = categorical_column_with_vocabulary_file(\n    'impression_video_id', video_vocabulary_file, video_vocabulary_size)\ncolumns = shared_embedding_columns(\n    [watched_video_id, impression_video_id], dimension=10)\n\nestimator = tf.estimator.DNNClassifier(feature_columns=columns, ...)\n\nlabel_column = ...\ndef input_fn():\n  features = tf.io.parse_example(\n      ..., features=make_parse_example_spec(columns + [label_column]))\n  labels = features.pop(label_column.name)\n  return features, labels\n\nestimator.train(input_fn=input_fn, steps=100)\n")])])]),o("p",[e._v("Here is an example using shared_embedding_columns with model_fn:")]),e._v(" "),o("div",{staticClass:"language- extra-class"},[o("pre",{pre:!0,attrs:{class:"language-text"}},[o("code",[e._v(" def model_fn(features, ...):\n  watched_video_id = categorical_column_with_vocabulary_file(\n      'watched_video_id', video_vocabulary_file, video_vocabulary_size)\n  impression_video_id = categorical_column_with_vocabulary_file(\n      'impression_video_id', video_vocabulary_file, video_vocabulary_size)\n  columns = shared_embedding_columns(\n      [watched_video_id, impression_video_id], dimension=10)\n  dense_tensor = input_layer(features, columns)\n  # Form DNN layers, calculate loss, and return EstimatorSpec.\n  ...\n")])])]),o("h4",{attrs:{id:"args"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),o("ul",[o("li",[o("code",[e._v("categorical_columns")]),e._v(": List of categorical columns created by a "),o("code",[e._v("categorical_column_with_")]),e._v("* function. These columns produce the sparse IDs that are inputs to the embedding lookup. All columns must be of the same type and have the same arguments except "),o("code",[e._v("key")]),e._v(". E.g. they can be "),o("code",[e._v("categorical_column_with_")]),e._v("vocabulary_file with the same vocabulary_file. Some or all columns could also be weighted_categorical_column.")]),e._v(" "),o("li",[o("code",[e._v("dimension")]),e._v(": An integer specifying "),o("code",[e._v("dimension")]),e._v(" of the embedding, must be > 0.")]),e._v(" "),o("li",[o("code",[e._v("combiner")]),e._v(": A string specifying how to reduce if there are multiple entries in a single row. Currently 'mean', 'sqrtn' and 'sum' are supported, with 'mean' the default. 'sqrtn' often achieves good accuracy, in particular with bag-of-words columns. Each of this can be thought as example level normalizations on the column. For more information, see "),o("code",[e._v("tf.embedding_lookup_sparse")]),e._v(".")]),e._v(" "),o("li",[o("code",[e._v("initializer")]),e._v(": A variable "),o("code",[e._v("initializer")]),e._v(" function to be used in embedding variable initialization. If not specified, defaults to "),o("code",[e._v("truncated_normal_initializer")]),e._v(" with mean "),o("code",[e._v("0.0")]),e._v(" and standard deviation 1/sqrt("),o("code",[e._v("dimension")]),e._v(").")]),e._v(" "),o("li",[o("code",[e._v("shared_embedding_collection_name")]),e._v(": Optional name of the collection where shared embedding weights are added. If not given, a reasonable name will be chosen based on the names of "),o("code",[e._v("categorical_columns")]),e._v(". This is also used in "),o("code",[e._v("variable_scope")]),e._v(" when creating shared embedding weights.")]),e._v(" "),o("li",[o("code",[e._v("ckpt_to_load_from")]),e._v(": String representing checkpoint name/pattern from which to restore column weights. Required if "),o("code",[e._v("tensor_name_in_ckpt")]),e._v(" is not "),o("code",[e._v("None")]),e._v(".")]),e._v(" "),o("li",[o("code",[e._v("tensor_name_in_ckpt")]),e._v(": Name of the "),o("code",[e._v("Tensor")]),e._v(" in "),o("code",[e._v("ckpt_to_load_from")]),e._v(" from which to restore the column weights. Required if "),o("code",[e._v("ckpt_to_load_from")]),e._v(" is not "),o("code",[e._v("None")]),e._v(".")]),e._v(" "),o("li",[o("code",[e._v("max_norm")]),e._v(": If not "),o("code",[e._v("None")]),e._v(", each embedding is clipped if its l2-norm is larger than this value, before combining.")]),e._v(" "),o("li",[o("code",[e._v("trainable")]),e._v(": Whether or not the embedding is "),o("code",[e._v("trainable")]),e._v(". Default is True.")])]),e._v(" "),o("h4",{attrs:{id:"returns"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),o("p",[e._v("A list of dense columns that converts from sparse input. The order of results follows the ordering of categorical_columns.")]),e._v(" "),o("h4",{attrs:{id:"raises"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[e._v("#")]),e._v(" Raises:")]),e._v(" "),o("ul",[o("li",[o("code",[e._v("ValueError")]),e._v(": if "),o("code",[e._v("dimension")]),e._v(" not > 0.")]),e._v(" "),o("li",[o("code",[e._v("ValueError")]),e._v(": if any of the given "),o("code",[e._v("categorical_columns")]),e._v(" is of different type or has different arguments than the others.")]),e._v(" "),o("li",[o("code",[e._v("ValueError")]),e._v(": if exactly one of "),o("code",[e._v("ckpt_to_load_from")]),e._v(" and "),o("code",[e._v("tensor_name_in_ckpt")]),e._v(" is specified.")]),e._v(" "),o("li",[o("code",[e._v("ValueError")]),e._v(": if "),o("code",[e._v("initializer")]),e._v(" is specified and is not callable.")]),e._v(" "),o("li",[o("code",[e._v("RuntimeError")]),e._v(": if eager execution is enabled.")])])])}),[],!1,null,null,null);a.default=n.exports}}]);