(window.webpackJsonp=window.webpackJsonp||[]).push([[564],{752:function(e,t,s){"use strict";s.r(t);var o=s(0),a=Object(o.a)({},(function(){var e=this,t=e.$createElement,s=e._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[s("p",[e._v("Adds a hinge loss to the training procedure.")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v(" tf.compat.v1.losses.hinge_loss(\n    labels,\n    logits,\n    weights=1.0,\n    scope=None,\n    loss_collection=tf.GraphKeys.LOSSES,\n    reduction=Reduction.SUM_BY_NONZERO_WEIGHTS\n)\n")])])]),s("h4",{attrs:{id:"args"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),s("ul",[s("li",[s("code",[e._v("labels")]),e._v(": The ground truth output tensor. Its shape should match the shape of logits. The values of the tensor are expected to be 0.0 or 1.0. Internally the {0,1} "),s("code",[e._v("labels")]),e._v(" are converted to {-1,1} when calculating the hinge loss.")]),e._v(" "),s("li",[s("code",[e._v("logits")]),e._v(": The "),s("code",[e._v("logits")]),e._v(", a float tensor. Note that "),s("code",[e._v("logits")]),e._v(" are assumed to be unbounded and 0-centered. A value > 0 (resp. < 0) is considered a positive (resp. negative) binary prediction.")]),e._v(" "),s("li",[s("code",[e._v("weights")]),e._v(": Optional "),s("code",[e._v("Tensor")]),e._v(" whose rank is either 0, or the same rank as "),s("code",[e._v("labels")]),e._v(", and must be broadcastable to "),s("code",[e._v("labels")]),e._v(" (i.e., all dimensions must be either "),s("code",[e._v("1")]),e._v(", or the same as the corresponding "),s("code",[e._v("losses")]),e._v(" dimension).")]),e._v(" "),s("li",[s("code",[e._v("scope")]),e._v(": The "),s("code",[e._v("scope")]),e._v(" for the operations performed in computing the loss.")]),e._v(" "),s("li",[s("code",[e._v("loss_collection")]),e._v(": collection to which the loss will be added.")]),e._v(" "),s("li",[s("code",[e._v("reduction")]),e._v(": Type of "),s("code",[e._v("reduction")]),e._v(" to apply to loss.")])]),e._v(" "),s("h4",{attrs:{id:"returns"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),s("p",[e._v("Weighted loss float Tensor. If reduction is NONE, this has the same shape as labels; otherwise, it is scalar.")]),e._v(" "),s("h4",{attrs:{id:"raises"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[e._v("#")]),e._v(" Raises:")]),e._v(" "),s("ul",[s("li",[s("code",[e._v("ValueError")]),e._v(": If the shapes of "),s("code",[e._v("logits")]),e._v(" and "),s("code",[e._v("labels")]),e._v(" don't match or if "),s("code",[e._v("labels")]),e._v(" or "),s("code",[e._v("logits")]),e._v(" is None.")])]),e._v(" "),s("h4",{attrs:{id:"eager-compatibility"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#eager-compatibility","aria-hidden":"true"}},[e._v("#")]),e._v(" Eager Compatibility")]),e._v(" "),s("p",[s("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/keras/Model",target:"_blank",rel:"noopener noreferrer"}},[e._v("tf.keras.Model"),s("OutboundLink")],1),e._v("The loss_collection argument is ignored when executing eagerly. Consider holding on to the return value or collecting losses via a .")])])}),[],!1,null,null,null);t.default=a.exports}}]);