(window.webpackJsonp=window.webpackJsonp||[]).push([[1123],{1312:function(e,t,a){"use strict";a.r(t);var n=a(0),s=Object(n.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("p",[e._v("A transformation that groups windows of elements by key and reduces them.")]),e._v(" "),a("h3",{attrs:{id:"aliases"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[e._v("#")]),e._v(" Aliases:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("tf.compat.v1.data.experimental.group_by_window")])]),e._v(" "),a("li",[a("code",[e._v("tf.compat.v2.data.experimental.group_by_window")])])]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" tf.data.experimental.group_by_window(\n    key_func,\n    reduce_func,\n    window_size=None,\n    window_size_func=None\n)\n")])])]),a("p",[e._v("This transformation maps each consecutive element in a dataset to a key using key_func and groups the elements by key. It then applies reduce_func to at most window_size_func(key) elements matching the same key. All except the final window for each key will contain window_size_func(key) elements; the final window may be smaller.")]),e._v(" "),a("p",[e._v("You may provide either a constant window_size or a window size determined by the key through window_size_func.")]),e._v(" "),a("h4",{attrs:{id:"args"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("key_func")]),e._v(": A function mapping a nested structure of tensors (having shapes and types defined by "),a("code",[e._v("self.output_shapes")]),e._v(" and "),a("code",[e._v("self.output_types")]),e._v(") to a scalar "),a("code",[e._v("tf.int64")]),e._v(" tensor.")]),e._v(" "),a("li",[a("code",[e._v("reduce_func")]),e._v(": A function mapping a key and a dataset of up to "),a("code",[e._v("window_size")]),e._v(" consecutive elements matching that key to another dataset.")]),e._v(" "),a("li",[a("code",[e._v("window_size")]),e._v(": A "),a("code",[e._v("tf.int64")]),e._v(" scalar "),a("code",[e._v("tf.Tensor")]),e._v(", representing the number of consecutive elements matching the same key to combine in a single batch, which will be passed to "),a("code",[e._v("reduce_func")]),e._v(". Mutually exclusive with "),a("code",[e._v("window_size")]),e._v("_func.")]),e._v(" "),a("li",[a("code",[e._v("window_size")]),e._v("_func: A function mapping a key to a "),a("code",[e._v("tf.int64")]),e._v(" scalar "),a("code",[e._v("tf.Tensor")]),e._v(", representing the number of consecutive elements matching the same key to combine in a single batch, which will be passed to "),a("code",[e._v("reduce_func")]),e._v(". Mutually exclusive with "),a("code",[e._v("window_size")]),e._v(".")])]),e._v(" "),a("h4",{attrs:{id:"returns"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),a("p",[a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/data/Dataset#apply",target:"_blank",rel:"noopener noreferrer"}},[e._v("tf.data.Dataset.apply"),a("OutboundLink")],1),e._v("A Dataset transformation function, which can be passed to .")]),e._v(" "),a("h4",{attrs:{id:"raises"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[e._v("#")]),e._v(" Raises:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("ValueError")]),e._v(": if neither or both of {"),a("code",[e._v("window_size")]),e._v(", "),a("code",[e._v("window_size")]),e._v("_func} are passed.")])])])}),[],!1,null,null,null);t.default=s.exports}}]);