(window.webpackJsonp=window.webpackJsonp||[]).push([[2507],{2698:function(e,t,o){"use strict";o.r(t);var r=o(0),a=Object(r.a)({},(function(){var e=this,t=e.$createElement,o=e._self._c||t;return o("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[o("p",[e._v("Clips values of multiple tensors by the ratio of the sum of their norms.")]),e._v(" "),o("h3",{attrs:{id:"aliases"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[e._v("#")]),e._v(" Aliases:")]),e._v(" "),o("ul",[o("li",[o("code",[e._v("tf.compat.v1.clip_by_global_norm")])]),e._v(" "),o("li",[o("code",[e._v("tf.compat.v2.clip_by_global_norm")])])]),e._v(" "),o("div",{staticClass:"language- extra-class"},[o("pre",{pre:!0,attrs:{class:"language-text"}},[o("code",[e._v(" tf.clip_by_global_norm(\n    t_list,\n    clip_norm,\n    use_norm=None,\n    name=None\n)\n")])])]),o("p",[e._v("Given a tuple or list of tensors "),o("code",[e._v("t_list")]),e._v(", and a clipping ratio "),o("code",[e._v("clip_norm")]),e._v(", this operation returns a list of clipped tensors "),o("code",[e._v("list_clipped")]),e._v(" and the global norm ("),o("code",[e._v("global_norm")]),e._v(") of all tensors in "),o("code",[e._v("t_list")]),e._v(". Optionally, if you've already computed the global norm for "),o("code",[e._v("t_list")]),e._v(", you can specify the global norm with "),o("code",[e._v("use_norm")]),e._v(".\nTo perform the clipping, the values "),o("code",[e._v("t_list[i]")]),e._v(" are set to:")]),e._v(" "),o("div",{staticClass:"language- extra-class"},[o("pre",{pre:!0,attrs:{class:"language-text"}},[o("code",[e._v(" t_list[i] * clip_norm / max(global_norm, clip_norm)\n")])])]),o("p",[e._v("where:")]),e._v(" "),o("div",{staticClass:"language- extra-class"},[o("pre",{pre:!0,attrs:{class:"language-text"}},[o("code",[e._v(" global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))\n")])])]),o("p",[e._v("If "),o("code",[e._v("clip_norm > global_norm")]),e._v(" then the entries in "),o("code",[e._v("t_list")]),e._v(" remain as they are, otherwise they're all shrunk by the global ratio.\nIf "),o("code",[e._v("global_norm == infinity")]),e._v(" then the entries in "),o("code",[e._v("t_list")]),e._v(" are all set to "),o("code",[e._v("NaN")]),e._v(" to signal that an error occurred.\nAny of the entries of "),o("code",[e._v("t_list")]),e._v(" that are of type "),o("code",[e._v("None")]),e._v(" are ignored.\n"),o("a",{attrs:{href:"http://arxiv.org/abs/1211.5063",target:"_blank",rel:"noopener noreferrer"}},[e._v("Pascanu et al., 2012"),o("OutboundLink")],1),e._v("This is the correct way to perform gradient clipping (for example, see  (pdf)).")]),e._v(" "),o("p",[e._v("However, it is slower than "),o("code",[e._v("clip_by_norm")]),e._v("() because all the parameters must be ready before the clipping operation can be performed.")]),e._v(" "),o("h4",{attrs:{id:"args"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),o("ul",[o("li",[o("code",[e._v("t_list")]),e._v(": A tuple or list of mixed "),o("code",[e._v("Tensors")]),e._v(", "),o("code",[e._v("IndexedSlices")]),e._v(", or None.")]),e._v(" "),o("li",[o("code",[e._v("clip_norm")]),e._v(": A 0-D (scalar) "),o("code",[e._v("Tensor")]),e._v(" > 0. The clipping ratio.")]),e._v(" "),o("li",[o("code",[e._v("use_norm")]),e._v(": A 0-D (scalar) "),o("code",[e._v("Tensor")]),e._v(" of type "),o("code",[e._v("float")]),e._v(" (optional). The global norm to use. If not provided, "),o("code",[e._v("global_norm")]),e._v("() is used to compute the norm.")]),e._v(" "),o("li",[o("code",[e._v(": A")]),e._v(" for the operation (optional).")])]),e._v(" "),o("h4",{attrs:{id:"returns"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),o("ul",[o("li",[o("code",[e._v("list_clipped")]),e._v(": A list of "),o("code",[e._v("Tensors")]),e._v(" of the same type as "),o("code",[e._v("list_t")]),e._v(".")]),e._v(" "),o("li",[o("code",[e._v("global_norm")]),e._v(": A 0-D (scalar) "),o("code",[e._v("Tensor")]),e._v(" representing the global norm.")])]),e._v(" "),o("h4",{attrs:{id:"raises"}},[o("a",{staticClass:"header-anchor",attrs:{href:"#raises","aria-hidden":"true"}},[e._v("#")]),e._v(" Raises:")]),e._v(" "),o("ul",[o("li",[o("code",[e._v("TypeError")]),e._v(": If "),o("code",[e._v("t_list")]),e._v(" is not a sequence.")])])])}),[],!1,null,null,null);t.default=a.exports}}]);