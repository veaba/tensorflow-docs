(window.webpackJsonp=window.webpackJsonp||[]).push([[2461],{2649:function(e,t,s){"use strict";s.r(t);var i=s(0),n=Object(i.a)({},(function(){var e=this,t=e.$createElement,s=e._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[s("p",[e._v("Disables the mixed precision graph rewrite.")]),e._v(" "),s("h3",{attrs:{id:"aliases"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[e._v("#")]),e._v(" Aliases:")]),e._v(" "),s("ul",[s("li",[s("code",[e._v("tf.compat.v2.train.experimental.disable_mixed_precision_graph_rewrite")])])]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v(" tf.train.experimental.disable_mixed_precision_graph_rewrite()\n")])])]),s("p",[e._v("After this is called, the mixed precision graph rewrite will no longer run for tf.functions, and so float32 operations will no longer be converted to float16.")]),e._v(" "),s("p",[e._v("This does not undo the effects of loss scaling. Any optimizers wrapped with a LossScaleOptimizer will continue to do loss scaling, although this loss scaling will no longer be useful, as the graph rewrite no longer converts tf.functions to use float16.")]),e._v(" "),s("p",[e._v("This function is useful for unit testing. A unit test can test using the mixed precision graph rewrite, then disable it so future unit tests continue using float32.")])])}),[],!1,null,null,null);t.default=n.exports}}]);