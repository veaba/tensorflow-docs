(window.webpackJsonp=window.webpackJsonp||[]).push([[1260],{1449:function(e,t,a){"use strict";a.r(t);var s=a(0),o=Object(s.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h2",{attrs:{id:"class-multilabelhead"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#class-multilabelhead","aria-hidden":"true"}},[e._v("#")]),e._v(" Class MultiLabelHead")]),e._v(" "),a("p",[e._v("Creates a Head for multi-label classification.\n"),a("a",{attrs:{href:"https://www.tensorflow.org/api_docs/python/tf/estimator/Head",target:"_blank",rel:"noopener noreferrer"}},[e._v("Head"),a("OutboundLink")],1),e._v("Inherits From:")]),e._v(" "),a("h3",{attrs:{id:"aliases"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#aliases","aria-hidden":"true"}},[e._v("#")]),e._v(" Aliases:")]),e._v(" "),a("ul",[a("li",[e._v("Class "),a("code",[e._v("tf.compat.v1.estimator.MultiLabelHead")])]),e._v(" "),a("li",[e._v("Class "),a("code",[e._v("tf.compat.v2.estimator.MultiLabelHead")])])]),e._v(" "),a("p",[e._v("Multi-label classification handles the case where each example may have zero or more associated labels, from a discrete set. This is distinct from MultiClassHead which has exactly one label per example.")]),e._v(" "),a("p",[e._v("Uses sigmoid_cross_entropy loss average over classes and weighted sum over the batch. Namely, if the input logits have shape [batch_size, n_classes], the loss is the average over n_classes and the weighted sum over batch_size.")]),e._v(" "),a("p",[e._v("The head expects logits with shape [D0, D1, ... DN, n_classes]. In many applications, the shape is [batch_size, n_classes].")]),e._v(" "),a("h4",{attrs:{id:"labels-can-be"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#labels-can-be","aria-hidden":"true"}},[e._v("#")]),e._v(" Labels can be:")]),e._v(" "),a("ul",[a("li",[e._v("A"),a("code"),e._v("mu"),a("code",[e._v("l")]),e._v("ti-hot"),a("code"),e._v("t"),a("code",[e._v("e``n``s")]),e._v("or"),a("code"),e._v("of"),a("code",[e._v("``s")]),e._v("h"),a("code",[e._v("a")]),e._v("p"),a("code",[e._v("e``")]),e._v("["),a("code",[e._v("D``0``,`` ``D``1``,`` ``.``.``.`` ``D``N``,`` ``n``_``c``l``a``s``s``e``s")]),e._v("]")])]),e._v(" "),a("p",[e._v("If weight_column is specified, weights must be of shape [D0, D1, ... DN], or [D0, D1, ... DN, 1].")]),e._v(" "),a("p",[e._v("Also supports custom loss_fn. loss_fn takes (labels, logits) or (labels, logits, features) as arguments and returns unreduced loss with shape [D0, D1, ... DN, 1]. loss_fn must support indicator labels with shape [D0, D1, ... DN, n_classes]. Namely, the head applies label_vocabulary to the input labels before passing them to loss_fn.")]),e._v(" "),a("p",[e._v("The head can be used with a canned estimator. Example:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" my_head = tf.estimator.MultiLabelHead(n_classes=3)\nmy_estimator = tf.estimator.DNNEstimator(\n    head=my_head,\n    hidden_units=...,\n    feature_columns=...)\n")])])]),a("p",[e._v("It can also be used with a custom model_fn. Example:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" def _my_model_fn(features, labels, mode):\n  my_head = tf.estimator.MultiLabelHead(n_classes=3)\n  logits = tf.keras.Model(...)(features)\n\n  return my_head.create_estimator_spec(\n      features=features,\n      mode=mode,\n      labels=labels,\n      optimizer=tf.keras.optimizers.Adagrad(lr=0.1),\n      logits=logits)\n\nmy_estimator = tf.estimator.Estimator(model_fn=_my_model_fn)\n")])])]),a("h4",{attrs:{id:"args"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#args","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("n_classes")]),e._v(": Number of classes, must be greater than 1 (for 1 class, use "),a("code",[e._v("BinaryClassHead")]),e._v(").")]),e._v(" "),a("li",[a("code",[e._v("weight_column")]),e._v(": A string or a "),a("code",[e._v("NumericColumn")]),e._v(" created by "),a("code",[e._v("tf.feature_column.numeric_column")]),e._v(" defining feature column representing weights. It is used to down weight or boost examples during training. It will be multiplied by the loss of the example. Per-class weighting is not supported.")]),e._v(" "),a("li",[a("code",[e._v("thresholds")]),e._v(": Iterable of floats in the range ("),a("code",[e._v("0, 1")]),e._v("). Accuracy, precision and recall metrics are evaluated for each threshold value. The threshold is applied to the predicted probabilities, i.e. above the threshold is "),a("code",[e._v("true")]),e._v(", below is "),a("code",[e._v("false")]),e._v(".")]),e._v(" "),a("li",[a("code",[e._v("label_vocabulary")]),e._v(": A list of "),a("code",[e._v("string")]),e._v("s represents possible label values. If it is not given, that means labels are already encoded as integer within [0, "),a("code",[e._v("n_classes")]),e._v(") or multi-hot Tensor. If given, labels must be SparseTensor "),a("code",[e._v("string")]),e._v(" type and have any value in "),a("code",[e._v("label_vocabulary")]),e._v(". Also there will be errors if vocabulary is not provided and labels are "),a("code",[e._v("string")]),e._v(".")]),e._v(" "),a("li",[a("code",[e._v("loss_reduction")]),e._v(": One of "),a("code",[e._v("tf.losses.Reduction")]),e._v(" except "),a("code",[e._v("NONE")]),e._v(". Decides how to reduce training loss over batch. Defaults to "),a("code",[e._v("SUM_OVER_BATCH_SIZE")]),e._v(", namely weighted sum of losses divided by batch size.")]),e._v(" "),a("li",[a("code",[e._v("loss_fn")]),e._v(": Optional loss function.")]),e._v(" "),a("li",[a("code",[e._v("classes_for_class_based_metrics")]),e._v(":"),a("code"),e._v("Li"),a("code",[e._v("s")]),e._v("t"),a("code"),e._v("of"),a("code"),e._v("i"),a("code",[e._v("n")]),e._v("t"),a("code",[e._v("e")]),e._v("g"),a("code",[e._v("e")]),e._v("r"),a("code",[e._v("``c``l``a``s``s``")]),e._v("ID"),a("code",[e._v("s``")]),e._v("or"),a("code",[e._v("``string`` ``c``l``a``s``s`` ``n``a")]),e._v("m"),a("code",[e._v("e``s``")]),e._v("for"),a("code"),e._v("whi"),a("code",[e._v("c")]),e._v("h"),a("code"),e._v("p"),a("code",[e._v("e")]),e._v("r-"),a("code",[e._v("c``l``a``s``s``")]),e._v("m"),a("code",[e._v("e")]),e._v("tri"),a("code",[e._v("c``s`` ``a")]),e._v("r"),a("code",[e._v("e`` ``e")]),e._v("v"),a("code",[e._v("a``l")]),e._v("u"),a("code",[e._v("a")]),e._v("t"),a("code",[e._v("e")]),e._v("d."),a("code"),e._v("If"),a("code"),e._v("i"),a("code",[e._v("n")]),e._v("t"),a("code",[e._v("e")]),e._v("g"),a("code",[e._v("e")]),e._v("r"),a("code",[e._v("s``,`` ``a``l``l``")]),e._v("mu"),a("code",[e._v("s")]),e._v("t"),a("code"),e._v("b"),a("code",[e._v("e``")]),e._v("i"),a("code",[e._v("n``")]),e._v("th"),a("code",[e._v("e``")]),e._v("r"),a("code",[e._v("a``n")]),e._v("g"),a("code",[e._v("e``")]),e._v("["),a("code",[e._v("0``,`` ``n_classes``")]),e._v("-"),a("code",[e._v("``1")]),e._v("]."),a("code"),e._v("If"),a("code",[e._v("``string``s``,`` ``a``l``l``")]),e._v("mu"),a("code",[e._v("s")]),e._v("t"),a("code"),e._v("b"),a("code",[e._v("e``")]),e._v("i"),a("code",[e._v("n`` ``label_vocabulary")]),e._v(".")]),e._v(" "),a("li",[a("code",[e._v("n``a")]),e._v("m"),a("code",[e._v("e")]),e._v(":"),a("code"),e._v("N"),a("code",[e._v("a")]),e._v("m"),a("code",[e._v("e``")]),e._v("of"),a("code"),e._v("th"),a("code",[e._v("e``")]),e._v("h"),a("code",[e._v("e``a")]),e._v("d."),a("code"),e._v("If"),a("code"),e._v("provid"),a("code",[e._v("e")]),e._v("d"),a("code",[e._v(",`` ``s")]),e._v("umm"),a("code",[e._v("a")]),e._v("ry"),a("code",[e._v("``a``n")]),e._v("d"),a("code"),e._v("m"),a("code",[e._v("e")]),e._v("tri"),a("code",[e._v("c``s``")]),e._v("k"),a("code",[e._v("e")]),e._v("y"),a("code",[e._v("s``")]),e._v("wi"),a("code",[e._v("l``l``")]),e._v("b"),a("code",[e._v("e`` ``s")]),e._v("uffix"),a("code",[e._v("e")]),e._v("d"),a("code"),e._v("by"),a("code"),e._v('"/"'),a("code"),e._v("+"),a("code",[e._v("``n``a")]),e._v("m"),a("code",[e._v("e")]),e._v("."),a("code"),e._v("A"),a("code",[e._v("l``s")]),e._v("o"),a("code"),e._v("u"),a("code",[e._v("s``e")]),e._v("d"),a("code",[e._v("``a``s`` ``n``a")]),e._v("m"),a("code",[e._v("e``_``s``c")]),e._v("op"),a("code",[e._v("e``")]),e._v("wh"),a("code",[e._v("e``n`` ``c")]),e._v("r"),a("code",[e._v("e``a")]),e._v("ti"),a("code",[e._v("n")]),e._v("g"),a("code"),e._v("op"),a("code",[e._v("s")]),e._v(".")])]),e._v(" "),a("h2",{attrs:{id:"init"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#init","aria-hidden":"true"}},[e._v("#")]),e._v(" "),a("strong",[e._v("init")])]),e._v(" "),a("p",[a("a",{attrs:{href:"https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/multi_label_head.py",target:"_blank",rel:"noopener noreferrer"}},[e._v("View source"),a("OutboundLink")],1)]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" __init__(\n    n_classes,\n    weight_column=None,\n    thresholds=None,\n    label_vocabulary=None,\n    loss_reduction=losses_utils.ReductionV2.SUM_OVER_BATCH_SIZE,\n    loss_fn=None,\n    classes_for_class_based_metrics=None,\n    name=None\n)\n")])])]),a("p",[e._v("Initialize self. See help(type(self)) for accurate signature.")]),e._v(" "),a("h2",{attrs:{id:"properties"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#properties","aria-hidden":"true"}},[e._v("#")]),e._v(" Properties")]),e._v(" "),a("h3",{attrs:{id:"logits-dimension"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#logits-dimension","aria-hidden":"true"}},[e._v("#")]),e._v(" logits_dimension")]),e._v(" "),a("p",[e._v("See base_head.Head for details.")]),e._v(" "),a("h3",{attrs:{id:"loss-reduction"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#loss-reduction","aria-hidden":"true"}},[e._v("#")]),e._v(" loss_reduction")]),e._v(" "),a("p",[e._v("See base_head.Head for details.")]),e._v(" "),a("h3",{attrs:{id:"name"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#name","aria-hidden":"true"}},[e._v("#")]),e._v(" name")]),e._v(" "),a("p",[e._v("See base_head.Head for details.")]),e._v(" "),a("h2",{attrs:{id:"methods"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#methods","aria-hidden":"true"}},[e._v("#")]),e._v(" Methods")]),e._v(" "),a("h3",{attrs:{id:"create-estimator-spec"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#create-estimator-spec","aria-hidden":"true"}},[e._v("#")]),e._v(" create_estimator_spec")]),e._v(" "),a("p",[a("a",{attrs:{href:"https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/base_head.py",target:"_blank",rel:"noopener noreferrer"}},[e._v("View source"),a("OutboundLink")],1)]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" create_estimator_spec(\n    features,\n    mode,\n    logits,\n    labels=None,\n    optimizer=None,\n    trainable_variables=None,\n    train_op_fn=None,\n    update_ops=None,\n    regularization_losses=None\n)\n")])])]),a("p",[e._v("Returns EstimatorSpec that a model_fn can return.")]),e._v(" "),a("p",[e._v("It is recommended to pass all args via name.")]),e._v(" "),a("h4",{attrs:{id:"args-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#args-2","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("features")]),e._v(": Input "),a("code",[e._v("dict")]),e._v(" mapping string feature names to "),a("code",[e._v("Tensor")]),e._v(" or "),a("code",[e._v("SparseTensor")]),e._v(" objects containing the values for that feature in a minibatch. Often to be used to fetch example-weight tensor.")]),e._v(" "),a("li",[a("code",[e._v("mode")]),e._v(": Estimator's "),a("code",[e._v("ModeKeys")]),e._v(".")]),e._v(" "),a("li",[a("code",[e._v("logits")]),e._v(": Logits "),a("code",[e._v("Tensor")]),e._v(" to be used by the head.")]),e._v(" "),a("li",[a("code",[e._v("labels")]),e._v(": Labels "),a("code",[e._v("Tensor")]),e._v(", or "),a("code",[e._v("dict")]),e._v(" mapping string label names to "),a("code",[e._v("Tensor")]),e._v(" objects of the label values.")]),e._v(" "),a("li",[a("code",[e._v("optimizer")]),e._v(": An "),a("code",[e._v("tf.keras.optimizers.Optimizer")]),e._v(" instance to optimize the "),a("code",[e._v("loss")]),e._v(" in TRAIN "),a("code",[e._v("mode")]),e._v(". Namely, sets train_op = "),a("code",[e._v("optimizer")]),e._v(".get_updates("),a("code",[e._v("loss")]),e._v(", trainable_variables), which updates variables to minimize "),a("code",[e._v("loss")]),e._v(".")]),e._v(" "),a("li",[a("code",[e._v("trainable_variables")]),e._v(": A list or tuple of "),a("code",[e._v("Variable")]),e._v(" objects to update to minimize "),a("code",[e._v("loss")]),e._v(". In "),a("code",[e._v("Tensor")]),e._v("flow 1.x, by default these are the list of variables collected in the graph under the key "),a("code",[e._v("GraphKeys.TRAINABLE_VARIABLES")]),e._v(". As "),a("code",[e._v("Tensor")]),e._v("flow 2.x doesn't have collections and GraphKeys, "),a("code",[e._v("trainable_variables")]),e._v(" need to be passed explicitly here.")]),e._v(" "),a("li",[a("code",[e._v("train_op_fn")]),e._v(": Function that takes a scalar "),a("code",[e._v("loss")]),e._v(" "),a("code",[e._v("Tensor")]),e._v(" and returns an op to optimize the "),a("code",[e._v("mode")]),e._v("l with the "),a("code",[e._v("loss")]),e._v(" in TRAIN "),a("code",[e._v("mode")]),e._v(". Used if "),a("code",[e._v("optimizer")]),e._v(" is "),a("code",[e._v("None")]),e._v(". Exactly one of "),a("code",[e._v("train_op_fn")]),e._v(" and "),a("code",[e._v("optimizer")]),e._v(" must be set in TRAIN "),a("code",[e._v("mode")]),e._v(". By default, it is "),a("code",[e._v("None")]),e._v(" in other "),a("code",[e._v("mode")]),e._v("s. If you want to optimize "),a("code",[e._v("loss")]),e._v(" yourself, you can pass "),a("code",[e._v("lambda _: tf.no_op")]),e._v("() and then use "),a("code",[e._v("EstimatorSpec.loss")]),e._v(" to compute and apply gradients.")]),e._v(" "),a("li",[a("code",[e._v("update_ops")]),e._v(": A list or tuple of update ops to be run at training time. For example, layers such as BatchNormalization create mean and variance update ops that need to be run at training time. In "),a("code",[e._v("Tensor")]),e._v("flow 1.x, these are thrown into an UPDATE_OPS collection. As "),a("code",[e._v("Tensor")]),e._v("flow 2.x doesn't have collections, "),a("code",[e._v("update_ops")]),e._v(" need to be passed explicitly here.")]),e._v(" "),a("li",[a("code",[e._v("regularization_losses")]),e._v(": A list of additional scalar "),a("code",[e._v("loss")]),e._v("es to be added to the training "),a("code",[e._v("loss")]),e._v(", such as regularization "),a("code",[e._v("loss")]),e._v("es.")])]),e._v(" "),a("h4",{attrs:{id:"returns"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),a("p",[e._v("EstimatorSpec.")]),e._v(" "),a("h3",{attrs:{id:"loss"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#loss","aria-hidden":"true"}},[e._v("#")]),e._v(" loss")]),e._v(" "),a("p",[a("a",{attrs:{href:"https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/multi_label_head.py",target:"_blank",rel:"noopener noreferrer"}},[e._v("View source"),a("OutboundLink")],1)]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" loss(\n    labels,\n    logits,\n    features=None,\n    mode=None,\n    regularization_losses=None\n)\n")])])]),a("p",[e._v("Returns regularized training loss. See base_head.Head for details.")]),e._v(" "),a("h3",{attrs:{id:"metrics"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#metrics","aria-hidden":"true"}},[e._v("#")]),e._v(" metrics")]),e._v(" "),a("p",[a("a",{attrs:{href:"https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/multi_label_head.py",target:"_blank",rel:"noopener noreferrer"}},[e._v("View source"),a("OutboundLink")],1)]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" metrics(regularization_losses=None)\n")])])]),a("p",[e._v("Creates metrics. See base_head.Head for details.")]),e._v(" "),a("h3",{attrs:{id:"predictions"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#predictions","aria-hidden":"true"}},[e._v("#")]),e._v(" predictions")]),e._v(" "),a("p",[a("a",{attrs:{href:"https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/multi_label_head.py",target:"_blank",rel:"noopener noreferrer"}},[e._v("View source"),a("OutboundLink")],1)]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" predictions(\n    logits,\n    keys=None\n)\n")])])]),a("p",[e._v("Return predictions based on keys. See base_head.Head for details.")]),e._v(" "),a("h4",{attrs:{id:"args-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#args-3","aria-hidden":"true"}},[e._v("#")]),e._v(" Args:")]),e._v(" "),a("ul",[a("li",[a("code",[e._v("logits")]),e._v(":"),a("code",[e._v("``logits`` ``Tensor``")]),e._v("w"),a("code",[e._v("i``t``h`` ``s``h``a")]),e._v("p"),a("code",[e._v("e``")]),e._v("["),a("code",[e._v("D``0``,`` ``D``1``,`` ``.``.``.`` ``D``N``,`` ``logits``_``d``i``m``e``n``s``i``o``n")]),e._v("]"),a("code",[e._v(".``")]),e._v("F"),a("code",[e._v("o")]),e._v("r"),a("code",[e._v("``m``a``n")]),e._v("y"),a("code",[e._v("``a")]),e._v("pp"),a("code",[e._v("l``i``c``a``t``i``o``n``s``,`` ``t``h``e`` ``s``h``a")]),e._v("p"),a("code",[e._v("e`` ``i``s``")]),e._v("["),a("code",[e._v("b``a``t``c``h``_``s``i``z``e``,`` ``logits``_``d``i``m``e``n``s``i``o``n")]),e._v("]"),a("code",[e._v(".")])]),e._v(" "),a("li",[a("code",[e._v("keys")]),e._v(":"),a("code",[e._v("``a`` ``l``i``s``t`` ``o")]),e._v("f"),a("code"),e._v("pr"),a("code",[e._v("e``d``i``c``t``i``o``n`` ``keys``.``")]),e._v("K"),a("code",[e._v("e")]),e._v("y"),a("code",[e._v("``c``a``n`` ``b``e`` ``e``i``t``h``e")]),e._v("r"),a("code",[e._v("``t``h``e`` ``c``l``a``s``s``")]),e._v("v"),a("code",[e._v("a")]),e._v("r"),a("code",[e._v("i``a``b``l``e`` ``o")]),e._v("f"),a("code"),e._v("pr"),a("code",[e._v("e``d``i``c``t``i``o``n``_``keys``.")]),e._v("Pr"),a("code",[e._v("e``d``i``c``t``i``o``n")]),e._v("K"),a("code",[e._v("e")]),e._v("y"),a("code",[e._v("s`` ``o")]),e._v("r"),a("code",[e._v("``i``t``s`` ``s``t")]),e._v("r"),a("code",[e._v("i``n``g``")]),e._v("v"),a("code",[e._v("a``l")]),e._v("u"),a("code",[e._v("e``,`` ``s")]),e._v("u"),a("code",[e._v("c``h`` ``a``s")]),e._v(":"),a("code"),e._v("pr"),a("code",[e._v("e``d``i``c``t``i``o``n``_``keys``.")]),e._v("Pr"),a("code",[e._v("e``d``i``c``t``i``o``n")]),e._v("K"),a("code",[e._v("e")]),e._v("y"),a("code",[e._v("s``.")]),e._v("LOGITS"),a("code",[e._v("``o")]),e._v("r"),a("code"),e._v("'"),a("code",[e._v("logits")]),e._v("'"),a("code",[e._v(".")])])]),e._v(" "),a("h4",{attrs:{id:"returns-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#returns-2","aria-hidden":"true"}},[e._v("#")]),e._v(" Returns:")]),e._v(" "),a("p",[e._v("A dict of predictions.")]),e._v(" "),a("h3",{attrs:{id:"update-metrics"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#update-metrics","aria-hidden":"true"}},[e._v("#")]),e._v(" update_metrics")]),e._v(" "),a("p",[a("a",{attrs:{href:"https://github.com/tensorflow/estimator/tree/master/tensorflow_estimator/python/estimator/head/multi_label_head.py",target:"_blank",rel:"noopener noreferrer"}},[e._v("View source"),a("OutboundLink")],1)]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v(" update_metrics(\n    eval_metrics,\n    features,\n    logits,\n    labels,\n    regularization_losses=None\n)\n")])])]),a("p",[e._v("Updates eval metrics. See base_head.Head for details.")])])}),[],!1,null,null,null);t.default=o.exports}}]);